{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural + 512 tokens  [kfold][P3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 3**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 512 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "215ae213-e111-4211-dc44-fe5bbb8ba362"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=3  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lFCPPlujqL5L",
        "outputId": "99021c08-d2d2-4515-9bb2-850497f66c22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_3.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZxPMZOfICS",
        "outputId": "ac9104fe-8e09-44ca-aae6-d2850d0af6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RDBcpVf0TS",
        "outputId": "989df70c-e99c-4e9d-b66d-6def040363d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "b2b7ca39-854f-4712-e0bb-41ae84721c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 01:50:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "c57238d0-74cc-4878-c8c4-ee5d99b74154"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "20b54ec0-488e-46cd-a751-7bf581721f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "271fffbc8f2b45498555fb03e57ee882",
            "2adc7affad654e68afb2ff53dad357a7",
            "1f3e5d0c3fb240ec9379737a8f6e700b",
            "4e98944be8684b5a8f46c7ef88800f4d",
            "b20fbcb6830c4ce29d0d4bfa5a60f4d1",
            "4d871411877b41faacb2993402533e57",
            "6ab36ffcb2b44382bce98f12d285edcf",
            "f94e85c70687406086a2923dfda87c7a",
            "76fa041a936a48678c494702150a1f7b",
            "a928f02aee8046fba6880486a33a572e",
            "b0bda2c7ebdf4fa5a27f2432a10e41dd",
            "df91e721234447c39a0107b506cb8889",
            "af3abd6cb075428a9bfbac0481b3af55",
            "dbd755094c904596b16266c52c28d173",
            "0dee008b6525437988eff7909486d591",
            "33c8e7778d544f74a1c80e999f3c7c77",
            "67e66d706e8c46f7aff1d9b535d64f53",
            "dbc8fa08fd534422bf3dffd41f18787a",
            "55189d35df9a4ac08135991368b50b3a",
            "512fbe0dc5d84f55a43effe0e776d17f",
            "1e29d7d7ea8c43b1b0cf8e05b9dd409a",
            "5af5c95eb02b4e9a9ef4db00a2eb44c1",
            "83cc7422552c4e78a2191b6a958e4ca8",
            "91a6b2f1b4744bed84bbe5a7edca05b9",
            "d50af78d8fa94d4f9325e60c1355ef96",
            "9be3fb3484d54f0f900e783012a73b34",
            "393cae283993463193f137a6adc45993",
            "c602e010cc7643659848f2a11a37e180",
            "31d27f4012704dfa9434e8ae35821b6f",
            "2595c40f945048d4829e4a76b29e4c1b",
            "8b3b8145760f4543b0c5a9bdd49d7875",
            "a6ce3e2122804dfa9d5008f4d8fe1ee0",
            "32adad5ea23a422d8bb8cc7a5a548bcb",
            "a57c14e080cc4d778e6e9dc41971bb8c",
            "2c47d673f1bc40eea6ef49b95b2439eb",
            "9e7cd56683ac4cbb817c8f00142366ed",
            "e41cece092174b93a0ee3c3e7a244ba2",
            "c57e541e6f484d0abc4c94696094eceb",
            "4a169b8569584e2fbf7b6f20b26c7948",
            "ef0a1ee2c036476bb03c9f493fad47d2",
            "ace72c9323104ab085b2920fbbd5a300",
            "efd5acdf3f8a497ca1a6d56771b348d5",
            "eec2da1c06cb42b99fede92af5aec7d6",
            "aca14578d7b74fe1be60817104ca58ce"
          ]
        },
        "id": "WPj7c-IBgWRx",
        "outputId": "d4e67fb1-3a7e-468f-9a9c-6d4bc9f14564"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "271fffbc8f2b45498555fb03e57ee882"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df91e721234447c39a0107b506cb8889"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83cc7422552c4e78a2191b6a958e4ca8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a57c14e080cc4d778e6e9dc41971bb8c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7ab6227963af40f0876f4529943ff38d",
            "1d85171a92734302ae63d3aca90e830d",
            "4d87b54440d54a58bc1f767bd8a2f0da",
            "a7f4524092484f5fa75f8b79ccd8a646",
            "542b2b4eab784b7595940bd308855243",
            "624317f365d74addb2e7285794bc1bff",
            "854948de0ac54cbb8d6b119f23b43f16",
            "109ad707a3a54cd3a2d8875e682204d5",
            "f0c02649c359406eb98875160a90b1d0",
            "bf24062a0fb14ae583c4b12964d477d8",
            "248bc66d1fb54a81b5fbdcbc0d407bce"
          ]
        },
        "id": "qSErznNMh4P5",
        "outputId": "e5674b8d-5c60-4017-9117-f3e9b7676493"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ab6227963af40f0876f4529943ff38d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "a01aa091-3d66-4c95-9d7c-ce5b741c4cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "159cbe82-2efb-4f62-eee8-b22aae97269a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "79c3e2b9-c5c5-4705-8c1e-8c89c97cdf24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25f4b2d8-7a31-4d39-b03d-76f9a9afeccc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25f4b2d8-7a31-4d39-b03d-76f9a9afeccc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25f4b2d8-7a31-4d39-b03d-76f9a9afeccc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25f4b2d8-7a31-4d39-b03d-76f9a9afeccc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31fcda00-1337-476c-8f86-eeff05070070\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31fcda00-1337-476c-8f86-eeff05070070')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31fcda00-1337-476c-8f86-eeff05070070 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "6b118f34-7de4-4218-cb3c-740b4bae6948"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "126ec5c3-e3ad-49e6-f95c-2ebda81dc2e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107, 2), (27, 2), (34, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "8bb00541-a1bc-4402-ef4e-9b510c06a5ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "a30007eb-ac57-425f-824a-96c940121e8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "dfb5d01d-b63f-4de3-a68b-6a09fcc6b0c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "97ba22d9-103b-4dce-bd7c-914220e7e38e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "fad5e074-555a-4d26-db73-653c5121cbd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "9b52204d-4798-41b1-b4e2-62b5b2deda3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "a1c6dad8-d2a8-45e4-a8fb-edc3c10afb1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0235309856278556 accuracy 0.49532710280373826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.911046490073204 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0156746080943517 accuracy 0.5046728971962616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9119942635297775 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9300186101879392 accuracy 0.6074766355140186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6733159869909286 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8885491767099926 accuracy 0.6355140186915887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6997599825263023 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8168516946690423 accuracy 0.6261682242990654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7011145129799843 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8899054527282715 accuracy 0.6822429906542056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9180501997470856 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8978979481118066 accuracy 0.6074766355140186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6233985088765621 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6594276204705238 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6542226560413837 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.709453287933554 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.982534745708108 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7283655894654137 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5347405895590782 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6362844237259456 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5649982765316963 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6373773376856532 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5500954166054726 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6543618600283351 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.53761987388134 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6136741925563131 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5394515916705132 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6087816474693162 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5365015342831612 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6290892628686768 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5367296487092972 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6161763838359288 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5409454256296158 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6173656891499247 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5386369004845619 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6129413161958966 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5377374403178692 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5985311259116445 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5315164066851139 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.60181311411517 accuracy 0.7570093457943925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5329945720732212 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.713369471686227 accuracy 0.7009345794392523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7336232550442219 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6286742932030133 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5443080700933933 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5911067053675652 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5525493733584881 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5812972028340612 accuracy 0.7663551401869159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5621779188513756 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5100287278848035 accuracy 0.7850467289719626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6443064454942942 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.45725516815270695 accuracy 0.8317757009345794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5577374044805765 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4031740033200809 accuracy 0.8785046728971962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6473778793588281 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3550055665629251 accuracy 0.8971962616822429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5491483760997653 accuracy 0.7777777777777777\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.35892912772084984 accuracy 0.8785046728971962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.738941787276417 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3446111456890191 accuracy 0.9065420560747662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8341307356022298 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3514654862561396 accuracy 0.8971962616822429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7473993138410151 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3159783018220748 accuracy 0.9158878504672896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7653582394123077 accuracy 0.7777777777777777\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3386595994234085 accuracy 0.9065420560747662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8063803757540882 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3079717284334557 accuracy 0.9065420560747662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7235774828586727 accuracy 0.7777777777777777\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2493203722738794 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1203791499137878 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.24907841400376388 accuracy 0.925233644859813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7054292550310493 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2762851722405425 accuracy 0.925233644859813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6943223520647734 accuracy 0.7777777777777777\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.22549432077045953 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8093200142029673 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.23798836302012205 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7203205686528236 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.240206163775708 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7188224804122001 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.23515353850754245 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7660367249045521 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.23236877431294747 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.739424018887803 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.20716640652556503 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7556983374524862 accuracy 0.7777777777777777\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2196713648736477 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8899920396506786 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.22120549908972212 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8400861390400678 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.21842996629753283 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7877376147080213 accuracy 0.7777777777777777\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.22106982568012817 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8001264093909413 accuracy 0.7777777777777777\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.22576934039326652 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8005265695974231 accuracy 0.7777777777777777\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.25266695248761345 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8035504417493939 accuracy 0.7407407407407407\n",
            "\n",
            "CPU times: user 8min 19s, sys: 28.5 s, total: 8min 48s\n",
            "Wall time: 9min 33s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "728d3fca-80e5-453c-f4a3-d762b7b1e1fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "c8f9f725-a75a-4a4c-f7a8-c556c18c7c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7941176470588235"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "4a8ed59e-1bb7-4b0f-e3cb-f2323ce9688d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "0b887095-545e-40a6-a2b7-c051873e8a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.80      0.84      0.82        19\n",
            "     Faixa 2       0.62      0.62      0.62         8\n",
            "     Faixa 3       1.00      0.86      0.92         7\n",
            "\n",
            "    accuracy                           0.79        34\n",
            "   macro avg       0.81      0.77      0.79        34\n",
            "weighted avg       0.80      0.79      0.80        34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "HQ54xluu8RL3",
        "outputId": "b83af381-4ed4-4a4f-935e-b1ae594ee5a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 730
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "271fffbc8f2b45498555fb03e57ee882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2adc7affad654e68afb2ff53dad357a7",
              "IPY_MODEL_1f3e5d0c3fb240ec9379737a8f6e700b",
              "IPY_MODEL_4e98944be8684b5a8f46c7ef88800f4d"
            ],
            "layout": "IPY_MODEL_b20fbcb6830c4ce29d0d4bfa5a60f4d1"
          }
        },
        "2adc7affad654e68afb2ff53dad357a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d871411877b41faacb2993402533e57",
            "placeholder": "​",
            "style": "IPY_MODEL_6ab36ffcb2b44382bce98f12d285edcf",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "1f3e5d0c3fb240ec9379737a8f6e700b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f94e85c70687406086a2923dfda87c7a",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76fa041a936a48678c494702150a1f7b",
            "value": 29
          }
        },
        "4e98944be8684b5a8f46c7ef88800f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a928f02aee8046fba6880486a33a572e",
            "placeholder": "​",
            "style": "IPY_MODEL_b0bda2c7ebdf4fa5a27f2432a10e41dd",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.86kB/s]"
          }
        },
        "b20fbcb6830c4ce29d0d4bfa5a60f4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d871411877b41faacb2993402533e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ab36ffcb2b44382bce98f12d285edcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f94e85c70687406086a2923dfda87c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76fa041a936a48678c494702150a1f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a928f02aee8046fba6880486a33a572e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0bda2c7ebdf4fa5a27f2432a10e41dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df91e721234447c39a0107b506cb8889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af3abd6cb075428a9bfbac0481b3af55",
              "IPY_MODEL_dbd755094c904596b16266c52c28d173",
              "IPY_MODEL_0dee008b6525437988eff7909486d591"
            ],
            "layout": "IPY_MODEL_33c8e7778d544f74a1c80e999f3c7c77"
          }
        },
        "af3abd6cb075428a9bfbac0481b3af55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e66d706e8c46f7aff1d9b535d64f53",
            "placeholder": "​",
            "style": "IPY_MODEL_dbc8fa08fd534422bf3dffd41f18787a",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "dbd755094c904596b16266c52c28d173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55189d35df9a4ac08135991368b50b3a",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_512fbe0dc5d84f55a43effe0e776d17f",
            "value": 995526
          }
        },
        "0dee008b6525437988eff7909486d591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e29d7d7ea8c43b1b0cf8e05b9dd409a",
            "placeholder": "​",
            "style": "IPY_MODEL_5af5c95eb02b4e9a9ef4db00a2eb44c1",
            "value": " 996k/996k [00:00&lt;00:00, 3.94MB/s]"
          }
        },
        "33c8e7778d544f74a1c80e999f3c7c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e66d706e8c46f7aff1d9b535d64f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc8fa08fd534422bf3dffd41f18787a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55189d35df9a4ac08135991368b50b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "512fbe0dc5d84f55a43effe0e776d17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e29d7d7ea8c43b1b0cf8e05b9dd409a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af5c95eb02b4e9a9ef4db00a2eb44c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83cc7422552c4e78a2191b6a958e4ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91a6b2f1b4744bed84bbe5a7edca05b9",
              "IPY_MODEL_d50af78d8fa94d4f9325e60c1355ef96",
              "IPY_MODEL_9be3fb3484d54f0f900e783012a73b34"
            ],
            "layout": "IPY_MODEL_393cae283993463193f137a6adc45993"
          }
        },
        "91a6b2f1b4744bed84bbe5a7edca05b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c602e010cc7643659848f2a11a37e180",
            "placeholder": "​",
            "style": "IPY_MODEL_31d27f4012704dfa9434e8ae35821b6f",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "d50af78d8fa94d4f9325e60c1355ef96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2595c40f945048d4829e4a76b29e4c1b",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b3b8145760f4543b0c5a9bdd49d7875",
            "value": 1961828
          }
        },
        "9be3fb3484d54f0f900e783012a73b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ce3e2122804dfa9d5008f4d8fe1ee0",
            "placeholder": "​",
            "style": "IPY_MODEL_32adad5ea23a422d8bb8cc7a5a548bcb",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 2.88MB/s]"
          }
        },
        "393cae283993463193f137a6adc45993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c602e010cc7643659848f2a11a37e180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d27f4012704dfa9434e8ae35821b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2595c40f945048d4829e4a76b29e4c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3b8145760f4543b0c5a9bdd49d7875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6ce3e2122804dfa9d5008f4d8fe1ee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32adad5ea23a422d8bb8cc7a5a548bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a57c14e080cc4d778e6e9dc41971bb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c47d673f1bc40eea6ef49b95b2439eb",
              "IPY_MODEL_9e7cd56683ac4cbb817c8f00142366ed",
              "IPY_MODEL_e41cece092174b93a0ee3c3e7a244ba2"
            ],
            "layout": "IPY_MODEL_c57e541e6f484d0abc4c94696094eceb"
          }
        },
        "2c47d673f1bc40eea6ef49b95b2439eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a169b8569584e2fbf7b6f20b26c7948",
            "placeholder": "​",
            "style": "IPY_MODEL_ef0a1ee2c036476bb03c9f493fad47d2",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "9e7cd56683ac4cbb817c8f00142366ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ace72c9323104ab085b2920fbbd5a300",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd5acdf3f8a497ca1a6d56771b348d5",
            "value": 625
          }
        },
        "e41cece092174b93a0ee3c3e7a244ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eec2da1c06cb42b99fede92af5aec7d6",
            "placeholder": "​",
            "style": "IPY_MODEL_aca14578d7b74fe1be60817104ca58ce",
            "value": " 625/625 [00:00&lt;00:00, 41.3kB/s]"
          }
        },
        "c57e541e6f484d0abc4c94696094eceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a169b8569584e2fbf7b6f20b26c7948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef0a1ee2c036476bb03c9f493fad47d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ace72c9323104ab085b2920fbbd5a300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd5acdf3f8a497ca1a6d56771b348d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eec2da1c06cb42b99fede92af5aec7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aca14578d7b74fe1be60817104ca58ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ab6227963af40f0876f4529943ff38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d85171a92734302ae63d3aca90e830d",
              "IPY_MODEL_4d87b54440d54a58bc1f767bd8a2f0da",
              "IPY_MODEL_a7f4524092484f5fa75f8b79ccd8a646"
            ],
            "layout": "IPY_MODEL_542b2b4eab784b7595940bd308855243"
          }
        },
        "1d85171a92734302ae63d3aca90e830d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624317f365d74addb2e7285794bc1bff",
            "placeholder": "​",
            "style": "IPY_MODEL_854948de0ac54cbb8d6b119f23b43f16",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "4d87b54440d54a58bc1f767bd8a2f0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109ad707a3a54cd3a2d8875e682204d5",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0c02649c359406eb98875160a90b1d0",
            "value": 714290682
          }
        },
        "a7f4524092484f5fa75f8b79ccd8a646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf24062a0fb14ae583c4b12964d477d8",
            "placeholder": "​",
            "style": "IPY_MODEL_248bc66d1fb54a81b5fbdcbc0d407bce",
            "value": " 714M/714M [00:02&lt;00:00, 248MB/s]"
          }
        },
        "542b2b4eab784b7595940bd308855243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624317f365d74addb2e7285794bc1bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854948de0ac54cbb8d6b119f23b43f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "109ad707a3a54cd3a2d8875e682204d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c02649c359406eb98875160a90b1d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf24062a0fb14ae583c4b12964d477d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248bc66d1fb54a81b5fbdcbc0d407bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}