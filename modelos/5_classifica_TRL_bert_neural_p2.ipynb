{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural [kfold][P2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 2**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 242 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "b7609a16-0064-465e-9ba7-1964235dd8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=2  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "a845584b-500a-448b-d28a-6cc8bd29ccca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_2.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 242"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZxPMZOfICS",
        "outputId": "9ed690a4-f2d5-4500-d981-8be110cece27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RDBcpVf0TS",
        "outputId": "2fe779ea-dbbd-423e-f835-7e7ba2897fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m1.4/1.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "2796407f-3b54-4c30-dbc1-00dc70b116d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 24 01:30:44 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "69c79050-e3c2-4052-afef-41f0278d4216"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "ff58d41b-8aa3-41ce-a125-9f2287bcfd19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "00c6691f3b0744459490a42004eb1677",
            "f4874b207316441b91ecc8deaa6d971e",
            "7d4631113843432380c19cb5fbca6544",
            "889d4fedeb7c47d4adf03d9090ceece5",
            "a0f931708f23484b91370258860090bc",
            "699fd982dafd49d98374deecf42e8039",
            "17e5824e8f174b78bfa88cd9e5218366",
            "945126b10f0b4508a651ebf40a3c8402",
            "770ddeaf6c5a4b4180d59c741622ad89",
            "f6842b8a2f3b4879adaccf169185de41",
            "293cf07781dd4d4d818d1dd5386e9390",
            "fa8a94bc2dab4cfcbad1c943a45a287b",
            "fab84415da0940b1843132c1f31c906f",
            "feabc353f6f3468392dcc1f734eeaba3",
            "04291619bf494856823daf8fd3dd7920",
            "7a44b20d8b124ee499df27dc2f8f9316",
            "211a9dfbe9f14806a860f40016b5adf0",
            "a7ea9a82bc30460f8b64f2c7c9656974",
            "7f87c27759454435af36b1c51223570f",
            "05e10e3d6cca439a88bdaf5413bd5a18",
            "89e64f74d0194ebc89ec43b80eace78e",
            "c5d0a646726e477c82d856c1e4a8c4cb",
            "30b6373294d442fb8f2e80714edc0a92",
            "31fc1819f1d64a1184d0dc0a7bd23c1a",
            "66e7d6c528284e87a2e6db13a0f7f589",
            "4746018d0c1442afb2e75450f3e0bc25",
            "200222fe9ce848b5918660c1bda08464",
            "cd39416efcbc424d855e7b2d98e33bc3",
            "19470436fc6a4d1eb76475d74dc3332f",
            "bf71765f359e40d7aefa0c3c100e4737",
            "d6aad7be17084776ba0196571c5c6fd4",
            "db1f5007828c480dbd0ee7b6dcd8a734",
            "21eebb279f3f4da4bcd564a2be2d3e04",
            "4ef5e42be3494e7889ef6bb8a724427b",
            "b31766f95bbf4fe1a0d1d22428f95f2f",
            "a577d34f9ceb44388768f90fc9637663",
            "8f7176ba65fb48f4930c2aa95a1f889e",
            "6fe85e9494aa42ce9fa671f2eef9266e",
            "492ce6608c954af4b96f847993176f0d",
            "3d8fcdb52ab94b87800ad34a304a3030",
            "f88eeab2e1734cfb8adda975bc69e7f0",
            "5c270ec70c064628a47b12955f6f023f",
            "28f636aa987740eeb08f226a50b370f4",
            "08b6d86e832d412db6d32d8e740ae482"
          ]
        },
        "id": "WPj7c-IBgWRx",
        "outputId": "627c2e3e-2f52-49b2-a063-e4e721e34d93"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00c6691f3b0744459490a42004eb1677"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa8a94bc2dab4cfcbad1c943a45a287b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30b6373294d442fb8f2e80714edc0a92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ef5e42be3494e7889ef6bb8a724427b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d3143d6475f748eab894265eb027e84f",
            "f484b7a0e9054a8e915126ad5bb55486",
            "d08d1b8cbfdf43649d439c474d581f71",
            "de504924248d470fb1d6cc90a94be340",
            "f38296765a114b908a3e2fc43cbcf76a",
            "779201bdcc574d65bcbd8283b5a53207",
            "43a5027f24694986bb934985a70ce704",
            "fc22690178cf443280e5a7a6f65807d4",
            "620ac0914e1f48a89d927c3e99f604e1",
            "5236ca44894a469984bc97d9c64d67f0",
            "6519d0f384d4479d86614f4ab4126ee8"
          ]
        },
        "id": "qSErznNMh4P5",
        "outputId": "49021b03-49f7-4052-a47d-f0164509a777"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3143d6475f748eab894265eb027e84f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "00dec640-90dc-4f14-e820-0eaa5412a70f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "788712bb-a0e5-498a-bce4-f478c5021b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "3458f2ba-a413-4d7f-afb2-1119160ec2aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2015ff2-dbc0-4374-92bf-a627aa6620b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2015ff2-dbc0-4374-92bf-a627aa6620b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2015ff2-dbc0-4374-92bf-a627aa6620b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2015ff2-dbc0-4374-92bf-a627aa6620b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e5756fc-0a49-44c6-86f0-838fa115aaf1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e5756fc-0a49-44c6-86f0-838fa115aaf1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e5756fc-0a49-44c6-86f0-838fa115aaf1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "46d4f07e-5978-4a92-acfb-5d887016ff81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "d9685a5c-9e56-4080-a480-8c5c34ad6ee6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107, 2), (27, 2), (34, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "10676f60-ae6d-43fd-8ecc-159b156b608d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "5c9df3c4-f5ee-4e17-a63d-0d0e55611728"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "1185e48d-44af-44bc-bb46-70d2b978779b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "5d86ab12-4faa-4dd2-e47d-8fccf23bbc74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "cba3c7d5-779d-4175-ccc2-d065473d3603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "8a0c6010-8361-4664-9e3e-1ef02009cef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "c410718b-ab25-4968-b744-1d87aaf2b48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0014748190130507 accuracy 0.5327102803738317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8177607357501984 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.04665379013334 accuracy 0.5046728971962616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9185591787099838 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0443704639162337 accuracy 0.5607476635514018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9442793130874634 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0128667780331202 accuracy 0.5607476635514018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9281236231327057 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9923454608236041 accuracy 0.5607476635514018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9461077004671097 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9878364886556353 accuracy 0.5607476635514018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9263388365507126 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0001372396945953 accuracy 0.5607476635514018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9270645529031754 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9958207436970302 accuracy 0.5607476635514018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.92649707198143 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9843508005142212 accuracy 0.5607476635514018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9242929220199585 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9916521183082035 accuracy 0.5607476635514018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9169802665710449 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0115014272076743 accuracy 0.5514018691588785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8911340832710266 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.895247323172433 accuracy 0.6074766355140186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6908697485923767 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7637761554547718 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6585895866155624 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7527661578995841 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6595544517040253 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.706468790769577 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6638269424438477 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6974574050733021 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6678744927048683 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7180392358984266 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7907416895031929 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6714935175010136 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.909826286137104 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7827556282281876 accuracy 0.6542056074766355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.843853048980236 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7857347684247153 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8042693361639977 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8153022676706314 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.177897572517395 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7695717279400144 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6703223511576653 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7273714116641453 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6549739167094231 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7011976518801281 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6548399701714516 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7330981684582574 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6541925892233849 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7353051879576274 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7201403677463531 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7032092192343303 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7550381273031235 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7223573582512992 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7518113628029823 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7163406844649997 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.751699410378933 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.701710507273674 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7526684924960136 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7192875083003726 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7529103234410286 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6991850584745407 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7529648393392563 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7291487391505923 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7526028007268906 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7293035345418113 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.751881055533886 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6927676009280341 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7494179084897041 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7296074692692075 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7521012052893639 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6995775486741748 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7527183964848518 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6960981488227844 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7525582313537598 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6954598192657743 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7521160021424294 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.680895209312439 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7506404519081116 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6929759681224823 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6446778625249863 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6837592678410667 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7500540986657143 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6821458765438625 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7432456091046333 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6878419294953346 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7426785752177238 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6598243681447846 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6407029405236244 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6443407248173442 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6415623724460602 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6562178262642452 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6397669240832329 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6218124266181674 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6448274478316307 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6592218301125935 accuracy 0.7663551401869159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6403722018003464 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6172484744872365 accuracy 0.7570093457943925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6396616548299789 accuracy 0.6666666666666666\n",
            "\n",
            "CPU times: user 2min 56s, sys: 1min 26s, total: 4min 22s\n",
            "Wall time: 5min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "f7a6dfc5-ce63-4f32-d018-837aad29d852"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "f9d81cae-1689-461b-d768-46adccfc1cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6470588235294118"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "574d67e4-d4a1-458e-b7d0-770673615c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "45280a9c-c044-427c-ea58-a946815cc122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.63      1.00      0.78        19\n",
            "     Faixa 2       0.00      0.00      0.00         8\n",
            "     Faixa 3       1.00      0.43      0.60         7\n",
            "\n",
            "    accuracy                           0.65        34\n",
            "   macro avg       0.54      0.48      0.46        34\n",
            "weighted avg       0.56      0.65      0.56        34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HQ54xluu8RL3",
        "outputId": "269dc151-f13a-4a84-ee67-0af3e3b0caec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 998,
              "height": 723
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00c6691f3b0744459490a42004eb1677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4874b207316441b91ecc8deaa6d971e",
              "IPY_MODEL_7d4631113843432380c19cb5fbca6544",
              "IPY_MODEL_889d4fedeb7c47d4adf03d9090ceece5"
            ],
            "layout": "IPY_MODEL_a0f931708f23484b91370258860090bc"
          }
        },
        "f4874b207316441b91ecc8deaa6d971e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699fd982dafd49d98374deecf42e8039",
            "placeholder": "​",
            "style": "IPY_MODEL_17e5824e8f174b78bfa88cd9e5218366",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "7d4631113843432380c19cb5fbca6544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_945126b10f0b4508a651ebf40a3c8402",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_770ddeaf6c5a4b4180d59c741622ad89",
            "value": 29
          }
        },
        "889d4fedeb7c47d4adf03d9090ceece5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6842b8a2f3b4879adaccf169185de41",
            "placeholder": "​",
            "style": "IPY_MODEL_293cf07781dd4d4d818d1dd5386e9390",
            "value": " 29.0/29.0 [00:00&lt;00:00, 397B/s]"
          }
        },
        "a0f931708f23484b91370258860090bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "699fd982dafd49d98374deecf42e8039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e5824e8f174b78bfa88cd9e5218366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "945126b10f0b4508a651ebf40a3c8402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "770ddeaf6c5a4b4180d59c741622ad89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6842b8a2f3b4879adaccf169185de41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293cf07781dd4d4d818d1dd5386e9390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa8a94bc2dab4cfcbad1c943a45a287b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fab84415da0940b1843132c1f31c906f",
              "IPY_MODEL_feabc353f6f3468392dcc1f734eeaba3",
              "IPY_MODEL_04291619bf494856823daf8fd3dd7920"
            ],
            "layout": "IPY_MODEL_7a44b20d8b124ee499df27dc2f8f9316"
          }
        },
        "fab84415da0940b1843132c1f31c906f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_211a9dfbe9f14806a860f40016b5adf0",
            "placeholder": "​",
            "style": "IPY_MODEL_a7ea9a82bc30460f8b64f2c7c9656974",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "feabc353f6f3468392dcc1f734eeaba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f87c27759454435af36b1c51223570f",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05e10e3d6cca439a88bdaf5413bd5a18",
            "value": 995526
          }
        },
        "04291619bf494856823daf8fd3dd7920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89e64f74d0194ebc89ec43b80eace78e",
            "placeholder": "​",
            "style": "IPY_MODEL_c5d0a646726e477c82d856c1e4a8c4cb",
            "value": " 996k/996k [00:00&lt;00:00, 11.2MB/s]"
          }
        },
        "7a44b20d8b124ee499df27dc2f8f9316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211a9dfbe9f14806a860f40016b5adf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7ea9a82bc30460f8b64f2c7c9656974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f87c27759454435af36b1c51223570f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e10e3d6cca439a88bdaf5413bd5a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89e64f74d0194ebc89ec43b80eace78e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5d0a646726e477c82d856c1e4a8c4cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30b6373294d442fb8f2e80714edc0a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31fc1819f1d64a1184d0dc0a7bd23c1a",
              "IPY_MODEL_66e7d6c528284e87a2e6db13a0f7f589",
              "IPY_MODEL_4746018d0c1442afb2e75450f3e0bc25"
            ],
            "layout": "IPY_MODEL_200222fe9ce848b5918660c1bda08464"
          }
        },
        "31fc1819f1d64a1184d0dc0a7bd23c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd39416efcbc424d855e7b2d98e33bc3",
            "placeholder": "​",
            "style": "IPY_MODEL_19470436fc6a4d1eb76475d74dc3332f",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "66e7d6c528284e87a2e6db13a0f7f589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf71765f359e40d7aefa0c3c100e4737",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6aad7be17084776ba0196571c5c6fd4",
            "value": 1961828
          }
        },
        "4746018d0c1442afb2e75450f3e0bc25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db1f5007828c480dbd0ee7b6dcd8a734",
            "placeholder": "​",
            "style": "IPY_MODEL_21eebb279f3f4da4bcd564a2be2d3e04",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 8.35MB/s]"
          }
        },
        "200222fe9ce848b5918660c1bda08464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd39416efcbc424d855e7b2d98e33bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19470436fc6a4d1eb76475d74dc3332f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf71765f359e40d7aefa0c3c100e4737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6aad7be17084776ba0196571c5c6fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db1f5007828c480dbd0ee7b6dcd8a734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21eebb279f3f4da4bcd564a2be2d3e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ef5e42be3494e7889ef6bb8a724427b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b31766f95bbf4fe1a0d1d22428f95f2f",
              "IPY_MODEL_a577d34f9ceb44388768f90fc9637663",
              "IPY_MODEL_8f7176ba65fb48f4930c2aa95a1f889e"
            ],
            "layout": "IPY_MODEL_6fe85e9494aa42ce9fa671f2eef9266e"
          }
        },
        "b31766f95bbf4fe1a0d1d22428f95f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_492ce6608c954af4b96f847993176f0d",
            "placeholder": "​",
            "style": "IPY_MODEL_3d8fcdb52ab94b87800ad34a304a3030",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "a577d34f9ceb44388768f90fc9637663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f88eeab2e1734cfb8adda975bc69e7f0",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c270ec70c064628a47b12955f6f023f",
            "value": 625
          }
        },
        "8f7176ba65fb48f4930c2aa95a1f889e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f636aa987740eeb08f226a50b370f4",
            "placeholder": "​",
            "style": "IPY_MODEL_08b6d86e832d412db6d32d8e740ae482",
            "value": " 625/625 [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "6fe85e9494aa42ce9fa671f2eef9266e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "492ce6608c954af4b96f847993176f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d8fcdb52ab94b87800ad34a304a3030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f88eeab2e1734cfb8adda975bc69e7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c270ec70c064628a47b12955f6f023f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28f636aa987740eeb08f226a50b370f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b6d86e832d412db6d32d8e740ae482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3143d6475f748eab894265eb027e84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f484b7a0e9054a8e915126ad5bb55486",
              "IPY_MODEL_d08d1b8cbfdf43649d439c474d581f71",
              "IPY_MODEL_de504924248d470fb1d6cc90a94be340"
            ],
            "layout": "IPY_MODEL_f38296765a114b908a3e2fc43cbcf76a"
          }
        },
        "f484b7a0e9054a8e915126ad5bb55486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779201bdcc574d65bcbd8283b5a53207",
            "placeholder": "​",
            "style": "IPY_MODEL_43a5027f24694986bb934985a70ce704",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "d08d1b8cbfdf43649d439c474d581f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc22690178cf443280e5a7a6f65807d4",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_620ac0914e1f48a89d927c3e99f604e1",
            "value": 714290682
          }
        },
        "de504924248d470fb1d6cc90a94be340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5236ca44894a469984bc97d9c64d67f0",
            "placeholder": "​",
            "style": "IPY_MODEL_6519d0f384d4479d86614f4ab4126ee8",
            "value": " 714M/714M [00:02&lt;00:00, 220MB/s]"
          }
        },
        "f38296765a114b908a3e2fc43cbcf76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "779201bdcc574d65bcbd8283b5a53207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a5027f24694986bb934985a70ce704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc22690178cf443280e5a7a6f65807d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "620ac0914e1f48a89d927c3e99f604e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5236ca44894a469984bc97d9c64d67f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6519d0f384d4479d86614f4ab4126ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}