{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - Bertimbau + Rede Neural + 512 tokens [kfold][P4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- BERTimbau Base (aka \"bert-base-portuguese-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 21 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 4**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 512 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "vXMRttjhRQ2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYJkf84RR64K",
        "outputId": "cb1a6a8e-6a48-45f6-8432-3d21d04d2c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=4 # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bertimbau_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "dea8050f-90b5-4160-800a-e3d210becbbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bertimbau_base_neural_4.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "_6clpQcISMQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8\n",
        "- Quantidade de tokens máxima = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZxPMZOfICS",
        "outputId": "e7fd80ed-c96f-4a32-ea90-de518d36823c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RDBcpVf0TS",
        "outputId": "42fb2050-3565-4146-bd3b-1ea932847466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "dde27b41-1176-433c-9c82-74dfe09786ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 00:28:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "0bce8759-8903-4dcb-b016-d31a42d21199"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "f45f6b2e-845c-4390-bf89-a88806474303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### Bertimbau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/neuralmind/bert-base-portuguese-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@inproceedings{souza2020bertimbau,\n",
        "  author    = {F{\\'a}bio Souza and\n",
        "               Rodrigo Nogueira and\n",
        "               Roberto Lotufo},\n",
        "  title     = {{BERT}imbau: pretrained {BERT} models for {B}razilian {P}ortuguese},\n",
        "  booktitle = {9th Brazilian Conference on Intelligent Systems, {BRACIS}, Rio Grande do Sul, Brazil, October 20-23 (to appear)},\n",
        "  year      = {2020}\n",
        "}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "84150ec1f4d346618f80612062f6c9c6",
            "fff8ae8ec4ec47569005be92b8e90be0",
            "6e3db336d4724221bb688369f4b92704",
            "ffa7f6842fa64a54ad0cdc62cb22ad45",
            "ee61d190d5604a9bb3f7ff94bddfc73e",
            "b569e238c1994a7386e9c025108ee854",
            "1b851f086a954e10bc034217a570c991",
            "f5b9b30d4a8b409295ca5ebd46a8f72c",
            "12f7f2c3ff014ee48a8984995d307dfd",
            "bc9adc4c035c4c6b8f49eb9c7e653ba3",
            "15d4b1a05eb0480096d16b6642a9b352",
            "d5010c849af44cb7b2ecb19e3b5d92b3",
            "7150c5836c4d4c1fb404e0304b3b5043",
            "8153dd59733d436589072ea21996c506",
            "ede7d1f7b1aa4358a5ab573456d40f53",
            "9ee9d6fb088f40c484299781abc9504c",
            "c311506b1f0040f1b7855b38ccf16856",
            "203e2a806b874a648f4e109bd73390f4",
            "d20d7eb70bbf448a96854d1e8e516c08",
            "0eeaf0e711e24f528dc8134184cfd791",
            "0fb2096660fe4aaa8a1a5391b392ee21",
            "9dc64f22075243338dd88f3bf68aa6fd",
            "90914b1f2a4e4a248fef16c645dee92e",
            "29057d08ec0843b7a716e71228c78acc",
            "337919c39d6444928e12ff5d770e1d76",
            "989bc4da599642f39f8dd9b4e7404278",
            "726fdb639f12491c8e48848774905115",
            "f29ec177d85d469681c17e2beb9e5d55",
            "79fb4e93dcdd4a0e8faa0107f0ef7094",
            "795d9a24ffd2463e99e93b7782768f49",
            "b381595bf2be4f3e8a9aa848de5b3dec",
            "cf0884e3d96d4e958ce60e4852720d3e",
            "95e2435226c94258857c601e89c85c26",
            "9e210438e70e4be8b412b40c7a9ec30f",
            "5550de95610c4a91b6ac28c4fe65f3f1",
            "8f438b4010fa48c4a60d0214ff352c8d",
            "345c9efa00634454b38a12826bf4378e",
            "bdaf871e88b8447d978b86455a026c3a",
            "d59e8feebe9e43d5a1f476fa2e502e90",
            "1721e43c432748178820cdefb308a892",
            "57a185134974400382de083255d7f8a7",
            "6de2650314b44197955b4dc11c7e0c6a",
            "127449d9bead425a819808dfee700699",
            "ccc7e2f9750b4ef9863d783229395741",
            "d2bc050ade91417aa70b618a939d583e",
            "5f5e85a1c3bc477b8ad57d60dd8c0cff",
            "e1a7630b892c485b9d00bcfdb2d58834",
            "2fad15ad83fb4447a9f041a6317dc046",
            "9dc770e9c4e340bba9d2d9fc0a17cda4",
            "13c92360ad0c4370af8e505007db6480",
            "e7f8c43f1cb248cebaae7e06ac07f27d",
            "760b11b10af24e098998027c6828206c",
            "1fd31599ffcb466a924eec24a7b46ba2",
            "836ee9ee78e64fcab3e9ad941a7cd57c",
            "8cb6c89569f14c188c7464144383b194"
          ]
        },
        "id": "WPj7c-IBgWRx",
        "outputId": "1be7db13-fb03-494a-a31f-3a5185e4ae48"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84150ec1f4d346618f80612062f6c9c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5010c849af44cb7b2ecb19e3b5d92b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90914b1f2a4e4a248fef16c645dee92e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e210438e70e4be8b412b40c7a9ec30f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2bc050ade91417aa70b618a939d583e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d9c4e4fec650453997f9c07fb395bd01",
            "890fa1bb933449da841de02ca481d3ed",
            "482fd7d413c2449f84ddf1cacd437acf",
            "80050d004eab48b885a70888aacbd0b8",
            "d9effd1dc15f407394ec4b2f1031555c",
            "3a6d84d4b36643ddaa7805159dacc8a7",
            "bc6e931f8b5141f2ae596797f7cc9e30",
            "948dd68f1d4644c392409dbb931d7841",
            "b297a7885b4446579fedd36b5219b70f",
            "7c522bea776e48c69877402a5f928652",
            "baab56bda5654b2eaa79b6a0ba2cc4f2"
          ]
        },
        "id": "qSErznNMh4P5",
        "outputId": "831528bd-9c13-4b63-ceba-242219239d82"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9c4e4fec650453997f9c07fb395bd01"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "cec7b4d6-88d7-49fe-d1e5-0612f7f8e075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "c2e71db2-33b2-4cea-d4f0-aa808584dc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "cca1d8f7-dd26-40ee-9725-8e2b6c08f6ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c3fb234-a24b-4033-809e-d2065f2f561d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c3fb234-a24b-4033-809e-d2065f2f561d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c3fb234-a24b-4033-809e-d2065f2f561d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c3fb234-a24b-4033-809e-d2065f2f561d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecc79072-f03c-433c-a082-8796d1ce16ee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecc79072-f03c-433c-a082-8796d1ce16ee')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecc79072-f03c-433c-a082-8796d1ce16ee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "287759a2-b4e4-4b6a-b994-0ed452fff7ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "820c5632-ac8c-4f67-ea9b-5a4a33d90bd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((108, 2), (27, 2), (33, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "81984459-6397-4b1f-8d38-1d960417bcae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "9f50833c-9a52-4ace-fb92-1317ef7ccf06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "7eefa13e-1194-4270-ef7b-e42248cf97b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "069986ca-e8e8-45e6-a014-13bde62276d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "5536e40f-be56-456e-8be5-eea39d94dcee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "fe0ddaf5-94f8-4dba-fc6b-8eca23c51d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "59b10624-a467-4404-b885-cb254074e4a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7920977600983211 accuracy 0.6666666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6278346627950668 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6257139912673405 accuracy 0.7407407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.711616575717926 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6161354397024427 accuracy 0.7685185185185185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7916672825813293 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.48698876798152924 accuracy 0.787037037037037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7449411377310753 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2547313775867224 accuracy 0.9166666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9996066838502884 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04047201171384326 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5814751505386084 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0291490966753502 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7594727873802185 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013556553840836776 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.927026480436325 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.002463647904473224 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9020662754774094 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0015866112080402672 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.048282206058502 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0013501274765336088 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0989760160446167 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0012124060927557626 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1605038344860077 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0010406288160343788 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2146607041358948 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0009761599233440522 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2534745931625366 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0008213458266774458 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.283969521522522 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0008386971562036446 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3131087124347687 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0007204638802379902 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.336529850959778 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0007002596477312702 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3593329191207886 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0007108844334392675 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.382130414247513 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006315869478774923 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.4012547731399536 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0005786390476194876 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.416699141263962 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0005752174890533622 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.4337888062000275 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0005443432185399745 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.4485226571559906 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0005272244431710403 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.4618651270866394 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.000522191245441458 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.4760385751724243 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0005145938193891197 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.488741010427475 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0004642445419449359 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.499869793653488 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00046522232670603055 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5121688544750214 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0004779774296496596 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5228776931762695 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00042741268615437936 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.533281087875366 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00041514499753247947 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.540947824716568 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0004070077037405489 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.548210233449936 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0003909625915444589 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.555819660425186 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00041918402920211 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5623646080493927 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0003900946799798736 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5676032304763794 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00040461976979193944 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.572823226451874 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00037855775320037665 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5780303478240967 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00037778801509245696 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.582780033349991 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.000362747282321964 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5872282087802887 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00035453816443415623 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.591123402118683 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00036484594914197387 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.594377189874649 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00037112469103054276 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.597670793533325 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00039860372739245316 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6010005176067352 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0003579887208096417 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.603665828704834 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.000339818253581013 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6057799458503723 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0003430800549852263 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.607849597930908 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0003772965958757725 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6094400584697723 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00035605059071843116 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.610701411962509 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00033991971369167525 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6113947331905365 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0003465244610976827 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6116075217723846 accuracy 0.5925925925925926\n",
            "\n",
            "CPU times: user 8min 30s, sys: 21.3 s, total: 8min 51s\n",
            "Wall time: 9min 42s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "89b607e3-4e57-4a0c-f5f7-2faa7706b3ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "8ed00d00-0f8a-4b13-8456-d980a860d605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7272727272727273"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "cb9a3bfb-c48f-4475-d5e4-ed0352014196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "0aea86ad-1068-4536-8550-23503e798aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.82      0.95      0.88        19\n",
            "     Faixa 2       0.50      0.38      0.43         8\n",
            "     Faixa 3       0.60      0.50      0.55         6\n",
            "\n",
            "    accuracy                           0.73        33\n",
            "   macro avg       0.64      0.61      0.62        33\n",
            "weighted avg       0.70      0.73      0.71        33\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "HQ54xluu8RL3",
        "outputId": "2407d626-db97-4958-c395-e676753c9cd2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 730
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84150ec1f4d346618f80612062f6c9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fff8ae8ec4ec47569005be92b8e90be0",
              "IPY_MODEL_6e3db336d4724221bb688369f4b92704",
              "IPY_MODEL_ffa7f6842fa64a54ad0cdc62cb22ad45"
            ],
            "layout": "IPY_MODEL_ee61d190d5604a9bb3f7ff94bddfc73e"
          }
        },
        "fff8ae8ec4ec47569005be92b8e90be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b569e238c1994a7386e9c025108ee854",
            "placeholder": "​",
            "style": "IPY_MODEL_1b851f086a954e10bc034217a570c991",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "6e3db336d4724221bb688369f4b92704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5b9b30d4a8b409295ca5ebd46a8f72c",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12f7f2c3ff014ee48a8984995d307dfd",
            "value": 43
          }
        },
        "ffa7f6842fa64a54ad0cdc62cb22ad45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9adc4c035c4c6b8f49eb9c7e653ba3",
            "placeholder": "​",
            "style": "IPY_MODEL_15d4b1a05eb0480096d16b6642a9b352",
            "value": " 43.0/43.0 [00:00&lt;00:00, 838B/s]"
          }
        },
        "ee61d190d5604a9bb3f7ff94bddfc73e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b569e238c1994a7386e9c025108ee854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b851f086a954e10bc034217a570c991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5b9b30d4a8b409295ca5ebd46a8f72c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f7f2c3ff014ee48a8984995d307dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc9adc4c035c4c6b8f49eb9c7e653ba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d4b1a05eb0480096d16b6642a9b352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5010c849af44cb7b2ecb19e3b5d92b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7150c5836c4d4c1fb404e0304b3b5043",
              "IPY_MODEL_8153dd59733d436589072ea21996c506",
              "IPY_MODEL_ede7d1f7b1aa4358a5ab573456d40f53"
            ],
            "layout": "IPY_MODEL_9ee9d6fb088f40c484299781abc9504c"
          }
        },
        "7150c5836c4d4c1fb404e0304b3b5043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c311506b1f0040f1b7855b38ccf16856",
            "placeholder": "​",
            "style": "IPY_MODEL_203e2a806b874a648f4e109bd73390f4",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "8153dd59733d436589072ea21996c506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20d7eb70bbf448a96854d1e8e516c08",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0eeaf0e711e24f528dc8134184cfd791",
            "value": 209528
          }
        },
        "ede7d1f7b1aa4358a5ab573456d40f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fb2096660fe4aaa8a1a5391b392ee21",
            "placeholder": "​",
            "style": "IPY_MODEL_9dc64f22075243338dd88f3bf68aa6fd",
            "value": " 210k/210k [00:00&lt;00:00, 2.68MB/s]"
          }
        },
        "9ee9d6fb088f40c484299781abc9504c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c311506b1f0040f1b7855b38ccf16856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "203e2a806b874a648f4e109bd73390f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d20d7eb70bbf448a96854d1e8e516c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eeaf0e711e24f528dc8134184cfd791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fb2096660fe4aaa8a1a5391b392ee21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dc64f22075243338dd88f3bf68aa6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90914b1f2a4e4a248fef16c645dee92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29057d08ec0843b7a716e71228c78acc",
              "IPY_MODEL_337919c39d6444928e12ff5d770e1d76",
              "IPY_MODEL_989bc4da599642f39f8dd9b4e7404278"
            ],
            "layout": "IPY_MODEL_726fdb639f12491c8e48848774905115"
          }
        },
        "29057d08ec0843b7a716e71228c78acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f29ec177d85d469681c17e2beb9e5d55",
            "placeholder": "​",
            "style": "IPY_MODEL_79fb4e93dcdd4a0e8faa0107f0ef7094",
            "value": "Downloading (…)in/added_tokens.json: 100%"
          }
        },
        "337919c39d6444928e12ff5d770e1d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_795d9a24ffd2463e99e93b7782768f49",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b381595bf2be4f3e8a9aa848de5b3dec",
            "value": 2
          }
        },
        "989bc4da599642f39f8dd9b4e7404278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf0884e3d96d4e958ce60e4852720d3e",
            "placeholder": "​",
            "style": "IPY_MODEL_95e2435226c94258857c601e89c85c26",
            "value": " 2.00/2.00 [00:00&lt;00:00, 41.2B/s]"
          }
        },
        "726fdb639f12491c8e48848774905115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f29ec177d85d469681c17e2beb9e5d55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79fb4e93dcdd4a0e8faa0107f0ef7094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "795d9a24ffd2463e99e93b7782768f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b381595bf2be4f3e8a9aa848de5b3dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf0884e3d96d4e958ce60e4852720d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e2435226c94258857c601e89c85c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e210438e70e4be8b412b40c7a9ec30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5550de95610c4a91b6ac28c4fe65f3f1",
              "IPY_MODEL_8f438b4010fa48c4a60d0214ff352c8d",
              "IPY_MODEL_345c9efa00634454b38a12826bf4378e"
            ],
            "layout": "IPY_MODEL_bdaf871e88b8447d978b86455a026c3a"
          }
        },
        "5550de95610c4a91b6ac28c4fe65f3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d59e8feebe9e43d5a1f476fa2e502e90",
            "placeholder": "​",
            "style": "IPY_MODEL_1721e43c432748178820cdefb308a892",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "8f438b4010fa48c4a60d0214ff352c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57a185134974400382de083255d7f8a7",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6de2650314b44197955b4dc11c7e0c6a",
            "value": 112
          }
        },
        "345c9efa00634454b38a12826bf4378e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_127449d9bead425a819808dfee700699",
            "placeholder": "​",
            "style": "IPY_MODEL_ccc7e2f9750b4ef9863d783229395741",
            "value": " 112/112 [00:00&lt;00:00, 5.52kB/s]"
          }
        },
        "bdaf871e88b8447d978b86455a026c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59e8feebe9e43d5a1f476fa2e502e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1721e43c432748178820cdefb308a892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57a185134974400382de083255d7f8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de2650314b44197955b4dc11c7e0c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "127449d9bead425a819808dfee700699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc7e2f9750b4ef9863d783229395741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2bc050ade91417aa70b618a939d583e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f5e85a1c3bc477b8ad57d60dd8c0cff",
              "IPY_MODEL_e1a7630b892c485b9d00bcfdb2d58834",
              "IPY_MODEL_2fad15ad83fb4447a9f041a6317dc046"
            ],
            "layout": "IPY_MODEL_9dc770e9c4e340bba9d2d9fc0a17cda4"
          }
        },
        "5f5e85a1c3bc477b8ad57d60dd8c0cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13c92360ad0c4370af8e505007db6480",
            "placeholder": "​",
            "style": "IPY_MODEL_e7f8c43f1cb248cebaae7e06ac07f27d",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "e1a7630b892c485b9d00bcfdb2d58834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_760b11b10af24e098998027c6828206c",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fd31599ffcb466a924eec24a7b46ba2",
            "value": 647
          }
        },
        "2fad15ad83fb4447a9f041a6317dc046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_836ee9ee78e64fcab3e9ad941a7cd57c",
            "placeholder": "​",
            "style": "IPY_MODEL_8cb6c89569f14c188c7464144383b194",
            "value": " 647/647 [00:00&lt;00:00, 48.3kB/s]"
          }
        },
        "9dc770e9c4e340bba9d2d9fc0a17cda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c92360ad0c4370af8e505007db6480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f8c43f1cb248cebaae7e06ac07f27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "760b11b10af24e098998027c6828206c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd31599ffcb466a924eec24a7b46ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "836ee9ee78e64fcab3e9ad941a7cd57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cb6c89569f14c188c7464144383b194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9c4e4fec650453997f9c07fb395bd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_890fa1bb933449da841de02ca481d3ed",
              "IPY_MODEL_482fd7d413c2449f84ddf1cacd437acf",
              "IPY_MODEL_80050d004eab48b885a70888aacbd0b8"
            ],
            "layout": "IPY_MODEL_d9effd1dc15f407394ec4b2f1031555c"
          }
        },
        "890fa1bb933449da841de02ca481d3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a6d84d4b36643ddaa7805159dacc8a7",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6e931f8b5141f2ae596797f7cc9e30",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "482fd7d413c2449f84ddf1cacd437acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_948dd68f1d4644c392409dbb931d7841",
            "max": 438235074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b297a7885b4446579fedd36b5219b70f",
            "value": 438235074
          }
        },
        "80050d004eab48b885a70888aacbd0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c522bea776e48c69877402a5f928652",
            "placeholder": "​",
            "style": "IPY_MODEL_baab56bda5654b2eaa79b6a0ba2cc4f2",
            "value": " 438M/438M [00:02&lt;00:00, 287MB/s]"
          }
        },
        "d9effd1dc15f407394ec4b2f1031555c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6d84d4b36643ddaa7805159dacc8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6e931f8b5141f2ae596797f7cc9e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "948dd68f1d4644c392409dbb931d7841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b297a7885b4446579fedd36b5219b70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c522bea776e48c69877402a5f928652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baab56bda5654b2eaa79b6a0ba2cc4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}