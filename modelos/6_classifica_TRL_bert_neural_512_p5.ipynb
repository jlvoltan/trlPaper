{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural + 512 tokens [kfold][P5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 5**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 512 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "967d2802-51ab-4930-d4e7-8d7166e6ee95"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=5  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lFCPPlujqL5L",
        "outputId": "3ba58a57-a507-4eab-9864-b9c227cccad3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_5.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9cZxPMZOfICS"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "h5RDBcpVf0TS"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "ce6aea2e-b1d8-482a-cdd1-815867d3b5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 02:35:14 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    33W /  70W |   8511MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "14c0071b-2b2e-4129-e32d-a7a432ab7222"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "b906e3ff-e3a6-4baf-f0fd-359de19dd7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "WPj7c-IBgWRx"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "qSErznNMh4P5"
      },
      "outputs": [],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "99dd2de3-30a0-4510-bc29-82c2c2c4977a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "ad2d0454-ebd0-4419-f5db-c10a1a9f4763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "8e0a3329-5e46-4918-f183-f630cbbe5646"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b32e2507-8436-4621-97d1-f3319e0143c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b32e2507-8436-4621-97d1-f3319e0143c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b32e2507-8436-4621-97d1-f3319e0143c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b32e2507-8436-4621-97d1-f3319e0143c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6722c99d-c09d-417a-8363-2a84950fd052\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6722c99d-c09d-417a-8363-2a84950fd052')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6722c99d-c09d-417a-8363-2a84950fd052 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "3a7464e1-88ed-4e91-9eab-5290b325ca1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "af0c047e-b115-4709-ca8c-fdd322fb8353"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((108, 2), (27, 2), (33, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "4ae82a2b-8584-4cfd-dcb2-a320a3105847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "e402797f-c306-4294-9167-938593851cc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "816d6f3a-7368-4a36-e7ac-6a11be5df93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "5211b2f5-17fa-41ca-c349-29e699bdab37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "95ee5e73-880c-49d9-bcf9-dc2a1c3a79bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "7587e361-6aad-4ba4-d9b1-602dcf21f3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "e4024017-7246-481b-f8ff-96137a25bc7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.034130492380687 accuracy 0.5092592592592592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9016961380839348 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8977570406028202 accuracy 0.611111111111111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7446585148572922 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8214043485266822 accuracy 0.6944444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8113581389188766 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8187150423015866 accuracy 0.6851851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7488716021180153 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8019379058054515 accuracy 0.7037037037037037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9784804359078407 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7701736518314907 accuracy 0.7037037037037037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0004218146204948 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7248751882995877 accuracy 0.7407407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1306216046214104 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6038074152810233 accuracy 0.7407407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1406178548932076 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5475808743919645 accuracy 0.7685185185185185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2190859615802765 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4583511533481734 accuracy 0.861111111111111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4036630615592003 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6625512375363282 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1902139857411385 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.544219679066113 accuracy 0.7962962962962963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2268554009497166 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4805501199194363 accuracy 0.8425925925925926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.3595719002187252 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.40320263483694624 accuracy 0.861111111111111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.3984431810677052 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4777928665280342 accuracy 0.8425925925925926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5192921366542578 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.41538296693137716 accuracy 0.8796296296296295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6079266835004091 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3890124013913529 accuracy 0.8703703703703703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7424277504906058 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.31089941531951937 accuracy 0.9166666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.959403270855546 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.32475755736231804 accuracy 0.9166666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0394386085681617 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3665718634479812 accuracy 0.9166666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.140341167105362 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3415986743888685 accuracy 0.9166666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.103234005626291 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2671812352990465 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.075314400251955 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2882625282342945 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1058628209866583 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.27676343478794607 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.146295754937455 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2859629138505885 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.159855057252571 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2754919811684106 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1580530372448266 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.28295101238680737 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1652228247839957 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2768382661576782 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1900387464556843 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2817720388993621 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1708559500984848 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.26711827010980677 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1615493404679 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2428623329448913 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2030235277488828 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.23867994300755008 accuracy 0.9444444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.259415403706953 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.22605517001024314 accuracy 0.9444444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2771452281158417 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.14520407268511398 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3041314228903502 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.16727465045239245 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3321493538096547 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.17361914286656038 accuracy 0.9537037037037036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3850082765566185 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.16506496384473784 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.416262091137469 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1680709089019469 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.4209845709847286 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.14787292214376585 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.428071794216521 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.17083133727179042 accuracy 0.9537037037037036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.448431878699921 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.13756282507841075 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.480160632287152 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.09751289544094886 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.506530226790346 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08867621215592537 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5324654184514657 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1021494950566973 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5529718503239565 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.07861278801491219 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.570529343560338 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.09251254337972828 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5836411719210446 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10892586536439401 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.592099084693473 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10098920346769903 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5976137465331703 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0795284247890647 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6017577503807843 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08759255767134684 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.603342602669727 accuracy 0.5555555555555556\n",
            "\n",
            "CPU times: user 9min 4s, sys: 32.8 s, total: 9min 37s\n",
            "Wall time: 10min 25s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "e8cdfa32-8bcd-408d-8fc3-1440f7c59352"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "3f019f1a-83ad-445d-9ebd-2fa0a8f0aef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5454545454545454"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "5d09b9df-f1da-4621-fd22-ed2826fb50f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "3e435b8b-04b9-4078-c005-9bb1b247ff27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.55      1.00      0.71        18\n",
            "     Faixa 2       0.00      0.00      0.00         9\n",
            "     Faixa 3       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.55        33\n",
            "   macro avg       0.18      0.33      0.24        33\n",
            "weighted avg       0.30      0.55      0.39        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "HQ54xluu8RL3",
        "outputId": "ac30d430-1217-4b22-ff48-955b7b368f3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 730
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}