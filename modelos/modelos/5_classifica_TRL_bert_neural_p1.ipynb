{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural [kfold][P1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 1**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 242 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "cbc994be-e904-4124-dcb6-cb8c05f39006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=1  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "98a4c134-3a38-4c73-d067-6e906a4f9553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_1.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 242"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZxPMZOfICS",
        "outputId": "c4dd3de6-8677-4587-dde5-5e25f32b6c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RDBcpVf0TS",
        "outputId": "f1bcebaa-ca8f-4dad-edd8-69302bd4d811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "9e71203d-006b-49f9-f0ac-b4dab983cb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 24 01:11:28 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "c28ae360-488d-45ad-f17c-0b3239d3ccf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "7d180788-a6af-4925-cdfd-5ae2ac672d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "edb75653007d47649bbf8e85c1df47a5",
            "4d0648a836034ed5b4a44de09fcca508",
            "98ebe907c8b749e68cd869dc01abadcf",
            "7cc242c87f2e453f989b3c7a22d4a2b2",
            "f5c949f616704693aba29657593b7ed0",
            "20d6d6d983ba4cc98e048cc72f87b3b6",
            "754a5df55fca4852ae13f9f97ff6ee29",
            "839f3301e3b242daa9839ff187af227d",
            "35083988361e45b08fe66324e61ccf73",
            "4ceef528280f4598be3da740e2d28d13",
            "f2f374ff9a3744e6bafb2136c8192b28",
            "bbeb4ec6168b4f949efd35a68576a084",
            "332c4ea1fe474e2590ab33e94b1c7ae8",
            "056652c7f3f44ec5aef7e824f2cb630e",
            "2f907107dd734887a8c299cd33144cd2",
            "cf827a2b131740538823afc40b870d63",
            "e2aee3da1ff04af6abd58cdf8825a574",
            "e81b0eed46de468fa20f330ca1e3d0dc",
            "03fe6bcc3cd6441d907a864412d95708",
            "f148eab0a25d476b8e356e6c39d9226f",
            "f414b085d7f3493f8c64875f77df8332",
            "f0d4382a6eb54ed7ad9ce92b99d823e1",
            "ae368b7b47fb4b5ab2f65092ecc83ac9",
            "567b8df7224043649e778fc82721e60a",
            "9637b7056b90490f850ca77c44d7e8f3",
            "44c0d165afd8453fad4a1f4675494c7e",
            "ce617837dd794c759b2d19c4754e5897",
            "4914f896b86e48d3b470544aa0fb0e13",
            "af4bed8f7e0f478593b1bf6fdbd7ac60",
            "a805c2ad5f114459bbfaed69eab26987",
            "6e979cb3db6c449fbc09eab42b77c93c",
            "a75bf893a4f041a9adecfab47257d42c",
            "0af0e897518b4d15aa8f872de0fc7c46",
            "67a1e53200f54a60ac132b6bc60ce444",
            "994fd8925bf740e78b40accca272f8ad",
            "ffeee6937d2a4870b02b878fa939a529",
            "a98f631c3013453fb3298ea6cac10c38",
            "c1e388cd522b43cd8c397cecd4f572bb",
            "3b0dbd6feb6e42f88f8ff83cc17c1e70",
            "64b3e38d750f4ea1a502c4dd454a6033",
            "a40963caeba748c7917ea0fb0c0897f1",
            "303d3b2b602b464798ba338aa58b8f34",
            "bc9f387200e549d1b4ab2e5e7a325702",
            "49403e4d2a884b7583076e3fb61fa1d3"
          ]
        },
        "id": "WPj7c-IBgWRx",
        "outputId": "f66ff740-899d-488a-c4b8-829f8c2c4ea7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edb75653007d47649bbf8e85c1df47a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbeb4ec6168b4f949efd35a68576a084"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae368b7b47fb4b5ab2f65092ecc83ac9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67a1e53200f54a60ac132b6bc60ce444"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0dde8afd86954a6c86ac9db92f28a0c8",
            "872b36807671473a8752e8554a06bdff",
            "5bdc257dfd504040915da4a305f4f9f0",
            "a48f3b68fffc4feaa0aff91f03f39549",
            "df72b8f49f004399b658161fc5ccf564",
            "c297d9905a6e490c985849d3004bbbdb",
            "7e3e3cdff53847f2a3e00927f409e98c",
            "16b19f5eff3a4969bb62397cc0e2deb3",
            "9a26492a2b434a97be819eaace6b9f78",
            "ffd58b9081464627b9f3488fa1c19ea3",
            "c63b12d59015488ba1849056a8225809"
          ]
        },
        "id": "qSErznNMh4P5",
        "outputId": "ad2c3014-939c-439d-e171-280bfd4b4e1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dde8afd86954a6c86ac9db92f28a0c8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "e8443aec-c699-467f-8e35-5168bc0e2dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "ceba49b1-f8d5-41e8-f8d7-ae8a56ecde8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "985d071b-aa96-4240-ff84-fe3cb6b2539b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eaf44400-6f28-4170-9c24-4563b7c5bc59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eaf44400-6f28-4170-9c24-4563b7c5bc59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eaf44400-6f28-4170-9c24-4563b7c5bc59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eaf44400-6f28-4170-9c24-4563b7c5bc59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7a93f7ac-b50b-4026-a7f2-3edcc8e18f66\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a93f7ac-b50b-4026-a7f2-3edcc8e18f66')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7a93f7ac-b50b-4026-a7f2-3edcc8e18f66 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "20eb2beb-101f-4882-af5f-da1e661ef3cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "8f4ba5b7-b808-4d05-fd4f-97c6953c0af3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107, 2), (27, 2), (34, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "ec8ab809-b836-499c-cceb-dbf46b3884ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "de26248b-9510-4a6d-abc7-f3384c7e6f64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "3d772b38-6b34-49a5-a2e8-f18bb53f007d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "5db99a11-0019-4eb9-bd3d-27e24b8898f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "414fd25f-72b3-4cee-e673-a98ce6407385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "b21a5fc7-49b5-4e64-8017-959bb172d16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "e00c3ba1-612f-4de6-c8ba-058975986178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9884524047374725 accuracy 0.5233644859813084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9539644867181778 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0980528380189623 accuracy 0.514018691588785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.927826926112175 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9388426116534642 accuracy 0.5794392523364486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8622570633888245 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8379093898194176 accuracy 0.5981308411214953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7368410043418407 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8382425712687629 accuracy 0.6542056074766355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7827974408864975 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8573229483195713 accuracy 0.7009345794392523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.145380675792694 accuracy 0.2962962962962963\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8493305402142661 accuracy 0.6261682242990654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7242414206266403 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6493122705391475 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7475936412811279 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6061967398439135 accuracy 0.7663551401869159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9295025393366814 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6411887641463961 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7623032778501511 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6902811218585286 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4028305858373642 accuracy 0.4074074074074074\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6885100001735347 accuracy 0.6915887850467289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8441385328769684 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4664981301341738 accuracy 0.8317757009345794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9156804382801056 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.45811659949166433 accuracy 0.8504672897196262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9048725627362728 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3195799706237657 accuracy 0.9158878504672896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7797177284955978 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.261418381439788 accuracy 0.9158878504672896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.694009616971016 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2487851684646947 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8634217977523804 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.25560976485056536 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8907627612352371 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.24514782721442835 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0765009075403214 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.21916796885696904 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0221925526857376 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.23224238512505377 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9795492589473724 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.16028254106640816 accuracy 0.9532710280373831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0389393270015717 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.13041380626548613 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1912396401166916 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.17893266292022808 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1076552271842957 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.14580479967740498 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1251643002033234 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.13612571541619087 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.126000940799713 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.16853948193602264 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1147281229496 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1649805307720921 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.093470573425293 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11068028580796506 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.076444312930107 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.09708186164165714 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.089193642139435 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1011256666222055 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0850755721330643 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.071950992386389 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.138498470187187 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10538483121698457 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.179545968770981 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05852868451204683 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2124463617801666 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.057307462474065166 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.208320453763008 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05403719295281917 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1922924667596817 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.06706668379151129 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2298524975776672 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.06583052433727841 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.205811560153961 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05157757363381928 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2014868557453156 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0537129064572842 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3225922286510468 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05494026857195422 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3314004987478256 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08426174903122176 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3259859830141068 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04089928362684857 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2702510952949524 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.057928876469044814 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.253574550151825 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.06415657907408397 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.25448015332222 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05766950613386663 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2425142377614975 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05981133628769645 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2362343966960907 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05622637572066326 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.242139548063278 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.053279326347235055 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2471339106559753 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05706087488215417 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2481402903795242 accuracy 0.7037037037037037\n",
            "\n",
            "CPU times: user 2min 59s, sys: 1min 26s, total: 4min 25s\n",
            "Wall time: 5min 27s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "76210b7b-79d3-4ba0-9ff2-611d278727a9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB/MAAAWaCAYAAAAHDkSJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAB7CAAAewgFu0HU+AAEAAElEQVR4nOzdd3hUZfrG8XvSGyEEkgAhVCERQUGKBUXBBipKFTuKiKig67qI7K5tdxXE1d8K2BVQdm0gAoIiIIgi0qRJ7xBqCIGQXs/vjyHHmWQmmSSTzCT5fq6La+c9855znpwJwc19nvdYDMMwBAAAAAAAAAAAAAAAvIaPpwsAAAAAAAAAAAAAAAD2CPMBAAAAAAAAAAAAAPAyhPkAAAAAAAAAAAAAAHgZwnwAAAAAAAAAAAAAALwMYT4AAAAAAAAAAAAAAF6GMB8AAAAAAAAAAAAAAC9DmA8AAAAAAAAAAAAAgJchzAcAAAAAAAAAAAAAwMsQ5gMAAAAAAAAAAAAA4GUI8wEAAAAAAAAAAAAA8DKE+QAAAAAAAAAAAAAAeBnCfAAAAAAAAAAAAAAAvAxhPgAAAAAAAAAAAAAAXoYwHwAAAAAAAAAAAAAAL0OYDwAAAAAAAAAAAACAlyHMBwAAAAAAAAAAAADAyxDmAwAAAAAAAAAAAADgZQjzAQAAAAAAAAAAAADwMoT5AAAAAAAAAAAAAAB4GcJ8AAAAAACq0X333af4+HjFx8erd+/eni5Ha9asMeuJj4/XnDlzPF2S13r22WftrlVVOHLkiN05pkyZUiXnAQAAAAB4Pz9PFwAAAAAAqHuOHDmi6667rkrPMXr0aI0ZM6ZKzwEAAAAAAFBV6MwHAAAAAACAJFYGAAAAAABvQpgPAAAAAAAAAAAAAICXYZl9AAAAAEC1a9y4sX744QeX5v75z3/W5s2bzfEbb7yhSy65pMz9wsPDK1wfAAAAAACApxHmAwAAAACqnZ+fn5o1a+bS3MDAQLtxo0aNXN7XG82cOdPTJdi57LLLtGvXLk+XgfOaNWvG5wEAAAAAkMQy+wAAAAAAAAAAAAAAeB3CfAAAAAAAAAAAAAAAvAzL7AMAAAAA6ozdu3dr7969OnXqlLKyshQbG6t+/fo5nZ+Zmak9e/bowIEDOnPmjLKzs1WvXj1FRkaqQ4cOat68eTVWX1JiYqK2bdumEydOqKCgQA0bNlSXLl0UFxfnkXry8vK0fv16HTlyRCkpKapXr55atGihrl27lnhcQnlt27ZNu3btUnJyskJDQ9W4cWN17txZkZGRbqq+8pKSkrR582YdP35cOTk5ioyM1MUXX6y2bdtWy/lPnjyp7du369ixY0pPT5ckBQUFKSoqSnFxcYqPj1dAQEC11FLczp07tXv3bqWkpCg3N1cNGzZUs2bN1LlzZ7fXtGXLFh0+fFhJSUnKz89X27Zt1atXL7eeAwAAAACqA2E+AAAAAKDW6N27t44ePSpJ6t69u/l8+q+++krTp0/Xnj177ObXq1evRJh/9OhRLVy4UMuXL9fvv/+uvLw8p+eLjY3V/fffrzvvvFNBQUEu1Xjfffdp7dq15v7Lli0r99zNmzfrjTfe0Jo1a2QYRon9LrnkEo0fP16dO3cus541a9bo/vvvN8cTJkzQwIEDyzU3NzdXb7/9tr744gulpKSU2C8kJETDhg3TqFGjXL5ORebOnaspU6boyJEjJd7z9/fX9ddfr2eeeUZNmzYt19fiTvv379drr72mn376Sfn5+SXeb926tcaNG6drr722zGMdOXJE1113nTkePXq0xowZU+o+S5cu1YcffqiNGzeWOs/f31+dOnXSzTffrLvvvtvuPdvvNVtTp07V1KlTHR6vrO/f7OxszZgxQ5999plOnDjhcE5ISIj69OmjJ598Uo0bNy61/iLx8fHm6wEDBmjixIkqLCzU9OnT9emnn5b4XklISFCvXr105513mtcoMDBQP//8s+rXr+/SOYuMHj1aS5YskST5+Pho6dKlio2NLdcxAAAAAMBVLLMPAAAAAKi1cnNz9eSTT+qvf/1riSDfkYKCAl133XV6/fXXtWHDhlKDfMka/E+YMEFDhw41byKoajNnztQ999yj1atXOwzyJWvYf9999+nbb7+t8npOnDihu+66S++8847DIF+yrnDwzjvvaPjw4WbHeFny8vL0xBNPaNy4cQ6D/KI53333nQYMGKA1a9ZU+GuojEWLFmnQoEFatmyZwyBfsob9jzzyiGbMmOHWcxcUFGjcuHF6/PHHywzyJev1Wrdund544w231uHI3r17dfPNN+v//u//nAb5kvV7Y86cObrppps0f/78Cp0rNTVVw4YN06RJk5x+r0jSnXfeab7Oyckp9/mSk5P1448/muMrr7ySIB8AAABAlaIzHwAAAABQa7388statGiRJMlisah9+/aKjY2VxWJRYmJiieDPMAy7gNxisahZs2Zq0aKFwsPDZbFYdObMGe3YsUNnzpwx5+3cuVPDhw/XnDlzFBoaWmVfz7x58/Svf/3LHLdr107NmzdXQECADh8+rG3btpn15+Xlafz48Wrfvr1atmxZJfVkZWXpkUce0c6dOyVJYWFhuvjiixUZGamMjAxt2rTJ7jr99ttvmjBhgl5++eUyj/3000/r+++/t9sWFBSkSy65RFFRUTp37py2bt2qlJQUnT17VmPGjNFf//pX936BZVizZo2efvppM8Rv2bKlWrdurZCQEB07dkxbtmyxC/gnTpyoDh06qGvXrm45/+TJkzV37ly7bSEhIbrwwgsVFRUlf39/ZWRkKCkpSfv27VNWVpZbzluWnTt3atiwYTp79qzd9mbNmqlt27YKDAxUYmKitm/fbn6/Zmdn65lnnlFWVpaGDh3q8rkMw9DYsWPNVQX8/PzUsWNHNW7cWDk5OTp06JA5t0+fPnrllVeUmpoqSZo9e7buu+8+l8/19ddf293gM3jwYJf3BQAAAICKIMwHAAAAANRKW7duNQO+2267TU8//XSJZbwddfH6+fnpuuuuU58+fXT11VerXr16JeYUFhbql19+0aRJk7R7925J0sGDB/Xvf/9bL7zwQhV8NdKZM2f03HPPSZK5tHyLFi3s5uzbt09PPfWUdu3aJckakP7nP//Rf/7znyqpafLkyTp79qwiIiI0duxY9e/fX35+f/yqIT8/X9OmTdMbb7xhhrazZ8/Wgw8+qAsuuMDpcWfPnm0X5Pv6+uqRRx7Rww8/rJCQEHN7QUGBFi5cqJdffllnz57VhAkTquCrdO6JJ55Qfn6+unbtqr/+9a+66KKL7N4/fvy4xo0bZ64aYBiGXn31Vc2aNavS5z579qw++ugjcxwSEqLx48erf//+Dp9BX1BQoI0bN2rJkiXmMvG23njjDeXk5OjEiRO65557zO3333+/hg0b5rAG28+6SHZ2tv785z/bBfnNmzfXP/7xD11xxRV2cxMTE/XSSy/p559/lmS9Pv/61790ySWXKCEhofQLcN7ixYuVmZkpi8WiYcOG6dFHH1VERITdnKK/50FBQbrtttvMx2/s3LlTv//+uzp27OjSuWbPnm2+joyMtHscAgAAAABUBZbZBwAAAADUSpmZmZKkkSNH6rXXXnP4PO5mzZrZjX19fbVkyRJNnjxZN998s8MgX7I+K/vqq6/WF198oU6dOpnb58yZU6Ib2V0yMzOVk5Oje+65R1OnTi0R5EtSmzZtNG3aNIWHh5vbfvjhB7MT2d2KgvxPP/1UgwcPLhHu+vn5aeTIkRo5cqTd9jlz5jg9Zk5Ojl577TW7ba+88oqefPJJuyBfsn5et912mz7++GPVq1evyq69M2fPntX111+vGTNmlAjyJalJkyZ6//33FRcXZ27bsmWL9u7dW+lzr1q1yq5L/MUXX9Qdd9zhMMiXrNeqa9euGj9+vL777rsS70dFRalZs2Yl/p6Eh4erWbNmDv84+js1bdo07du3zxy3aNFCn3/+eYkgX5Li4uL0/vvvq0+fPua23Nxcvfjii2V+/UWK/p6/+OKLGj9+fIkgX7L/e2671L4kl2+sWLdunQ4ePGiOnd00AQAAAADuRJgPAAAAAKi1LrzwQv3pT39yeb7FYlHTpk1dnh8SEqKXXnrJHGdnZ2vZsmXlKbFc2rVrp/Hjx8tisTid06hRI911113mODc3V5s2baqymp577jm1adOm1DkPP/ywAgMDzfG6deuczv3uu+/sQvk+ffqof//+pR4/ISFBTz31lEv1ulPDhg01ceJE+fv7O50TFBSkhx9+2G5b0YoRlXHs2DG78Q033ODyvrafhTvl5eXps88+M8cWi0WTJk1Sw4YNne7j4+Ojl19+WdHR0ea2jRs36vfff3f5vL169SoR0jtzwQUX6NJLLzXHCxcudOnxA8VDf5bYBwAAAFAdCPMBAAAAALXWsGHD5OvrW6XnSEhIsOv83bx5c5Wda9iwYaUGx0V69uxpNy5adt/dYmNjdfPNN5c5r169enYB6q5du8xl94tbtGiR3bh4EO7MkCFDHHZlV6WhQ4c6Xb3B1jXXXGM33rlzp9trSUlJcfsxy2vNmjVKSkoyx1dffbXdyhXOhIWFacSIEXbb5s+f7/J5hw8f7vJcyfq5FUlPTy/xPVdcWlqa3WMfLr300jJvYAEAAAAAdyDMBwAAAADUWr169XLbsXJycnT69GkdPXpUR44csftjGyLv37/fbecs7uqrr3ZpXuvWre3GVRX09ujRQz4+rv1qwbamnJwcZWRkOJxnu4pAbGysOnTo4NLxAwICdO2117o0111c/TwaN25s94iAM2fOVPrcrVq1shu//vrrKigoqPRxK2Pjxo1241tuucXlfW+99Va7FSeKH8uZevXqqVu3bi6fR5L69u2r+vXrm+PZs2eXOv+bb75Rdna2Ob7jjjvKdT4AAAAAqCi/sqcAAAAAAFDzNG3atFKd2gcPHtSCBQu0Zs0a7d692+XnsZ87d67C5yxNWFiYYmJiXJpbvFs8PT29KkoqV3dy8ZoyMjIUFhZmty0pKcku6G7fvn256mnfvr3mzp1brn0qozxff1hYmPl8d3d8HldccYUaNGhgXq9vv/1WO3fu1NChQ3X99dfbrRZRXbZt22Y3vuSSS1zet2HDhmrWrJkSExMlWVcvKCgoKHNljYSEhFIfO+FIYGCgbr/9dn3yySeSpPXr1+vAgQMlbpAoYhv216tXT3369CnX+QAAAACgoujMBwAAAADUSg0aNKjQfufOndPf/vY39enTR1OmTNHatWtdDvKlqgvOXVnOvUjxpfjz8/PdXY4klQjjS+PnZ99PkJeXV2JO8evcuHHjctXTpEmTcs2vrIp+Ju74PEJCQvT888/bBdn79+/XhAkTdN1116l3794aO3asvvjiCx04cKDS53OF7QoQFotFLVq0KNf+tmF6Xl6e0tLSytwnMjKyXOcoYrvUviTNmjXL4bwdO3bY3aRwyy23KDg4uELnBAAAAIDyIswHAAAAANRKoaGh5d4nNTVVw4YN0+zZs50+070sFd2vLK4uZ1+d3F1T8fC2vJ9heW4ucAdPfyY333yz3n77bYc3PRw9elTz58/X888/rz59+uiWW27R9OnTlZWVVWX12K5KERwcXO7rU/zmCFdWubB9fEF5XHDBBerSpYs5njdvnsObLL788ku7MUvsAwAAAKhO3vebAAAAAAAAPGTixInavn27OQ4MDFT//v01adIkzZ07V6tWrdKmTZu0Y8cO7dq1y/zTvXt3D1Zde1R2RYHc3Fx3llMj9O7dW4sXL9arr76qa665xmm4vXfvXk2cOFF9+/Z1+Xn0tZ1td35ycrKWL19u9352drYWLFhgjtu3b6+LLrqo2uoDAAAAAL+ypwAAAAAAUPsdP35cX3/9tTmOjo7Wxx9/rNatW5e5b0ZGRlWWVmfUr1/fbuxKZ7at1NRUd5ZTYxTddNK/f3/l5+drx44d2rBhg9auXatVq1YpMzPTnHv8+HGNGDFCs2bNcul7uzzCw8PN11lZWSosLCxXd37xlRlsj1cV+vTpo1deecV8vMOsWbN0ww03mO8vWrTI7ntw8ODBVVoPAAAAABRHZz4AAAAAAJJWrFhht0T+2LFjXQ47T506VVVl1SnR0dHy9fU1x3v27CnX/nv37nV3STWOn5+fOnbsqGHDhumtt97SmjVrNGnSJDVp0sSck56ersmTJ7v93LbPrzcMQ4cPHy7X/gcPHjRf+/v7l1h2390CAwN1++23m+OVK1fq5MmT5virr74yXwcFBem2226r0noAAAAAoDjCfAAAAAAAJB06dMhufNVVV7m03/Hjx5WUlFQVJdU5wcHBatu2rTnevn270tPTXd5/3bp1VVFWjRYQEKDbb79d06dPV3BwsLl9xYoVKigoKDHfYrFU+FzFl6DfvHmzy/umpKQoMTHRHCckJNjd2FFVbJfaLygoMAP8Q4cOae3ateZ7ffr0qfKbCwAAAACgOMJ8AAAAAACkEqFxWFiYS/t98803VVFOnXXZZZeZr3NycvTtt9+6tN/+/ft5FnwpWrVqpU6dOpnjzMxMc3l5WwEBAXbjvLw8l8/RuXNnu/F3333n8r4LFiywWxnDttaq1KZNG3Xt2tUcz5kzR4ZhaNasWXbzhgwZUi31AAAAAIAtwnwAAAAAAKQSXbe2S347k5KSohkzZlRNQXVU8dB08uTJSk1NLXUfwzD0yiuvVGVZtULxG1T8/f1LzCn+96A8j5C47LLLFBUVZY5XrFihrVu3lrlfRkaGPvroI7tt1bmkvW13fmJiolauXKm5c+ea21q1amUX+AMAAABAdSHMBwAAAABAUrt27ezG06dPL3V+VlaWnnrqKZ0+fboqy6pz2rZtq169epnjU6dO6ZFHHtGZM2cczs/Ly9NLL72kn3/+ubpK9AqLFi3S3r17XZ6fnJysX3/91Rw3atRI4eHhJeYFBQWpSZMm5nj9+vUOl+N3xN/fX3feeac5Liws1DPPPOP0syua89xzz+nEiRPmtk6dOuniiy926Zzu0KdPH0VERJjj5557zu4mBrryAQAAAHgKYT4AAAAAAJJ69uxp90zxOXPmaMKECQ6f2b5+/XrdddddWr16tSwWi10QiMp78cUX7brIN27cqL59+2rKlClav369Dhw4oC1btui///2vBgwYoM8++0ySNZStK3788UfdeuuteuCBB/Tll18qKSnJ6dz169dr2LBhdt/L/fr1czrftgv98OHDeuKJJ7RixQrt379fR44cMf/YBvBFRowYoVatWpnjffv26a677rJ7/nyRxMREjRo1SgsXLjS3+fv768UXX3RaW1UICAhQ//79zfHx48ft6hkwYEC11gMAAAAARfw8XQAAAAAAAN4gMjJSDz74oN5++21z24wZM/Tll1+qU6dOatiwodLT07Vr1y4dO3bMnPPggw9q69atDsNKVEzjxo311ltvadSoUcrKypIknTlzRlOnTtXUqVMd7nPTTTfp7rvv1qJFi8xtFoulWur1FMMw9Ouvv5od9zExMWrdurXq168vf39/paamateuXTp58qTdfrGxsXr88cedHveee+6xe4b90qVLtXTp0hLzYmNjtWzZMrttQUFBeuONNzRs2DCdO3dOknTgwAHdd999at68udq2bauAgAAdOXJEW7duNc8hWT+vv/71r7rwwgsrdkEq4Y477nD4yIzevXsrMjKy2usBAAAAAIkwHwAAAAAA0+jRo7Vv3z59//335rbMzEytWrXK4fyhQ4dq7NixGjZsWHWVWGdcfvnlmjFjhsaPH6/9+/eXOnf48OH6y1/+opUrV9ptDwkJqcoSvc7JkydLBPfFtWvXTu+9957q1avndE7nzp01btw4vfbaay4vsW+rffv2+u9//6tRo0bZ3fhy+PBhHT582OE+gYGB+sc//mHXIV+d2rRpo27dumndunV22wcPHuyRegAAAABAIswHAAAAAMDk6+urN998UzNnztT7779v99xsW507d9bw4cN14403VnOFdUunTp00b948LVy4UIsWLdLu3buVnJys0NBQNWnSRN27d9fgwYPVtm1bSVJaWprd/qUF1jXdU089pQ4dOujHH3/Uxo0bHT4Owla7du00dOhQ3XnnnfLzK/vXQQ8++KCuvvpqzZkzRxs2bNChQ4eUnp6u3Nxcl+qLj4/Xt99+q+nTp+uzzz5z+hiAkJAQ3XTTTXriiSfUtGlTl45dVYYOHWoX5jdt2lRXXXWVBysCAAAAUNdZDNv1zAAAAAAAgCQpLy9PW7Zs0a5du3Tu3DmFhYUpKipK7du3V1xcnKfLgwOTJ0/WW2+9ZY7nz5+v+Ph4D1ZUPQoLC7V//34dPHhQJ06cUEZGhiQpNDRUjRs31oUXXqjY2FiP1rhjxw7t2rVLZ86cUV5enho0aKC4uDhdeumlCggI8GhtRX788Uc98sgj5njMmDEaPXq0BysCAAAAUNcR5gMAAAAAgFph2LBhWr16tSTrsu0bNmxwqQsdkKQnnnjCfMSGj4+Pli1bpiZNmni4KgAAAAB1mY+nCwAAAAAAAKisw4cPa82aNea4ffv2BPlwWXJyspYtW2aOr7rqKoJ8AAAAAB7H/6utJXJzc7V+/XodPXpUKSkpioyMVGxsrLp27eo1y9UBAAAAAFAVDMPQiy++KNvFB2+99VYPVoSa5n//+5/y8vLM8V133eXBagAAAADAijC/nHJzc7Vr1y5t3bpVv//+u37//Xft27dPBQUF5pxdu3ZVWz3Z2dmaPHmyvvrqK509e7bE+xERERo0aJCeeOIJBQUFVVtdAAAAAABUxvvvv6+IiAj179+/1JvU09PT9fe//12//PKLua1evXq67bbbqqNM1AJHjhzRjBkzzHFcXJyuueYazxUEAAAAAOcR5pfD4MGDtXPnTrs7tT3p6NGjGjlypPbu3et0ztmzZ/XRRx9pxYoVev/99xUbG1uNFQIAAAAAUDEnTpzQ66+/rtdff1033XSTunTpolatWql+/frKysrSiRMntGbNGs2ZM6fEze1/+9vfFB4e7pnC4fWOHDkiScrIyNDWrVs1depUZWZmmu8/9thj8vX19VR5AAAAAGCyGLZr0KFU8fHxLs2rjs789PR03XXXXdq9e7e5rU2bNrr55psVExOjEydO6Ntvv9X+/fvN99u1a6fPPvtMYWFhVV4fAAAAAACV8Y9//EP/+9//yr3fiBEjNHbs2CqoCLVFab/f6dy5sz799FP5+PhUY0UAAAAA4Bid+RUUFham9u3bq2PHjtqwYYM2btxYref/97//bRfkP/TQQxo7dqwsFou5bfTo0Zo0aZKmTZsmSdq9e7def/11vfDCC9VaKwAAAAAA5VW/fv1yzY+JidGf//xn9e/fv2oKQq3XrFkz/d///R9BPgAAAACvQWd+OfzrX/9Shw4d1LFjR7Vu3doMzp999ll9/fXX5ryq7sxPTExU3759zeX+e/XqpXfffdfp/FGjRmn58uWSJH9/f3333XeKi4ur0hoBAAAAAKisQ4cO6aefftLGjRu1f/9+nThxQhkZGTIMQ/Xq1VPDhg3VsWNHXXnllbrpppsUEBDg6ZJRA9h25gcFBalFixa6/vrr9eCDD6pevXoerAwAAAAA7BHmu0F1h/mTJk3SRx99JEmyWCxatGiRWrZs6XT+wYMHddNNN5njhx56SM8880yV1ggAAAAAAAAAAAAAqDjWDauBfvjhB/N1t27dSg3yJally5bq1q2bw/0BAAAAAAAAAAAAAN6HML+GOXTokA4ePGiOr7zySpf2s5138OBBHT582N2lAQAAAAAAAAAAAADchDC/htm9e7fduFOnTi7t17lz51KPAwAAAAAAAAAAAADwHoT5Ncy+ffvsxs2bN3dpv7i4uFKPAwAAAAAAAAAAAADwHoT5NcyRI0fM1z4+PoqJiXFpv5iYGPn4/PFxJyYmur02AAAAAAAAAAAAAIB7+Hm6AJRPenq6+To0NFR+fq59hP7+/goODlZGRoYkmf9bXXJzc3X27FlzHBgYKF9f32qtAQAAAAAAAAAAAACqQkFBgXJycsxxRESEAgICKnVMwvwaJjMz03wdGBhYrn2DgoLMEN/2ONXh7NmzrAYAAAAAAAAAAAAAoM6Ijo6u1P4ss1/D2N7N4e/vX659be/8yM7OdltNAAAAAAAAAAAAAAD3IsyvYWy78fPy8sq1b25urvk6KCjIbTUBAAAAAAAAAAAAANyLZfZrmJCQEPO1bZe+K2y78W2PUx2KPxIgLi6u2muobfbu3auCggL5+vrqggsu8HQ5AFCr8DMWAKoOP2MBoGrxcxYAqg4/YwGg6tSGn7GZmZl2jx0v7yPTHSHMr2HCwsLM15mZmcrPz5efX9kfY35+vrKyssxxaGholdTnjK+vr904JCTE7mtB+fn4+KigoEA+Pj5cSwBwM37GAkDV4WcsAFQtfs4CQNXhZywAVJ3a+DO2eD5aESyzX8M0a9bMfF1QUKCTJ0+6tN+JEydUWFhojuPi4txeGwAAAAAAAAAAAADAPQjza5jWrVvbjQ8fPuzSfrZLOjg6DgAAAAAAAAAAAADAexDm1zDx8fF2402bNrm038aNG+3G7dq1c1dJAAAAAAAAAAAAAAA3I8yvYVq0aKEWLVqY41WrVrm0n+28li1b2h0DAAAAAAAAAAAAAOBdCPNroOuuu858vW7dOh08eLDU+QcPHtS6devMce/evauqNAAAAAAAAAAAUEfkFRqeLgEAajXCfC/Ru3dvxcfHKz4+vsyw/a677pK/v78kyTAMvfrqq6XOnzhxovna399fd999d+ULBgAAAAAAAAAAddLhbEP9fzcUtEJqvsrQk3sM/XLWUKFBuA8A7kSYXwM1b95cAwcONMfLli3Ta6+9JqPYP5KGYWjSpElavny5uW3QoEGKi4urtloBAAAAAAAAAEDtYBiGPjhmqONaaX6yZEg6kiNNOSJdvVFq8av0J4J9AHAbP08XUJN88sknmjlzZontp0+fthvfcMMNJeY0btzY4b4V9cwzz+i3337T3r17JUkffvihfvzxR/Xt21cxMTE6efKkFi5cqP3795v7tG3bVmPHjnVbDQAAAAAAAAAAoG44nG3o4Z3SkjPO5xzNkSYfsf6JDZQGRRkaEiVdUV/ysViqr1gAqCUI88shNTVVhw8fLnOeozkFBQVurSUsLEzvvfeeHn74YTOw37t3r6ZMmeJwfuvWrfXuu+8qLCzMrXUAAAAAAAAAAIDayzAMfXhc+steKa0cUQfBPgBUHsvs12DNmjXT119/reHDh6t+/foO59SvX1/Dhw/X119/rWbNmlVzhQAAAAAAAAAAoKY6nG2o72bpkV2Og/wHGksvtJQuCi39OEXBvu1S/KtSWYofAMpCZ345jBkzRmPGjKmSYy9btqxC+wUFBWncuHF66qmntG7dOh09elRnzpxRgwYNFBsbq27duikgIMDN1QIAAAAAAAAAgNqqrG782EDp/Xipb0Nrh/0LraTtGYZmJUmzT0nbMpwfu3jH/uAoQ0OipcvD6dgHgOII82uJgIAA9ejRw9NlAAAAAAAAAACAGuxwtqGRO6XFZxy//2AT6fU2UoS/ffDePtSiF1rZB/uzkqTtmc7PdTRHevOI9Q/BPgCUxDL7AAAAAAAAAAAAdZxhGPrwmKGOax0H+bGB0sKLpY8SLCWC/OKswb5FWy+zaGt361L87UNKP39RsH/VBqnlr9JTLMUPAHTmo+bLz89XWlqa0tLSlJ+fr4ICB2v+1EL5+fnm/+7Zs8fD1QBA7cLP2LL5+vrKz89P9erVU7169eTnx39WAgAAAABQUyVmGxq5S/o+xfH7DzSW3rigZDe+K2w79rcVLcVfRsf+EZuO/WaB0iA69gHUUfzWFTVWYWGhjh8/rnPnznm6FI/w9fU1XxeFTgAA9+BnbNny8/OVk5OjjIwMnThxQuHh4WrSpIl8fFj4CQAAAACAmsIwDE07Lj29VzrnoE+uaYD0foJ0c0P3BOgXhVp0USvpRZtgf1aStKOcwf4d0dJlBPsA6gDCfNRIhYWFOnLkiDIyMuy2WywWuwCmNrPY/EdKXfmaAaC68DO2bAUFBTJslrk7d+6cCgoK1KxZMwJ9AAAAAABqgKrsxneFO4L9wec79gn2AdRWhPmokY4fP24G+T4+PmrQoIHCw8MVGBhoF8DUZpmZmTIMQxaLRSEhZTxsCABQLvyMLZthGMrJydG5c+d05swZFRYWKiMjQ8ePH1dsbKynywMAAIAHncu3BjJZhdLQaCkqoG78rqY0afmGZp2StqZ7uhLvE+kv9W0oXRqmOvN7PW+XU2hocYq0KlXKKfR0Nd4lJaOxWipD1/mWkjbXANXdje+Kigb7/zli/UOwb+9QtqH5ydKBLE9XgpqgaaB0Z7TULKhu/73xVoT5qHHy8/PNpfV9fHwUFxdH0AIAQDWzWCwKCgpSUFCQwsLClJiYqMLCQp07d04xMTHy8+M/MwEAAOqi708beniXNWCRpJcOSlPaGhoaXXeD2qUphkbslA7neLoS7/X8Aal1kDQ42hrEEexXv6IAf3aSNC/ZccALSYqSFKVXsg1dv9n6/dq/kdSgijrXq0JitqFHdkmLPNSN74riwf6XSdbvTVeD/bjzS/HXtWD/cLb1JojZp6Q1dfPpxKiE945JG7saCvOrG39fahJ+y4oaJy0tzXzdoEEDgnwAADwsJCREDRo00OnTpyVZ/61u0KCBh6sCAABAdUrNN/SXvdJHx+23n86T7t5uDRbeamcopg516Z/LNzR2n/TBMU9XUjPsz5YmHbb+IdivHgT4FZcvixalWAPxRyzSDQ0MDfbyYN+Vbvz34qVbGnlX/ReFWvRSK+nFloa2ZUizTpUd7Cc6CPbvOB/s17afJ4ezDc1Osl4XAnxUxr4saW+W1KmepytBcYT5qHFsw/zw8HAPVgIAAIqEh4cT5gMAANRRi893nh8ppfN8zilpxdm606VPN37lEOxXHQJ898s3pO9SrH+8Ndg/km1oZBnd+K9f4D31OmKxWNQhTOoQZh/sz0qSdpYj2B8cbWhIVM0O9osC/NmnpNUE+HCTuECpVbCnq4AjhPmocfLz8yVZ/6ENDAz0cDUAAECSAgMDZbFYZBiG+W81AAAAardz+YaedtCN70xd6NJPO9+N/76TbvwrwqWE0OqtyZsVGtLPZ63hvTOOgv07oqXOBPsuyyk0tCTFGnqWJ8DvUV9qx6KodvYln9PqvDDlysfh+7bB/iiLdL2Hg33DMDT9hPTnPTWrG78sjoL9L8+H22UF+/+XaP3TPFAaVIOC/YoE+A38pBsjpRDfqq0NNV/TAGlYY6k+S+x7JcJ81DgFBdb/6vD19fX6f2ABAKgrLBaLfH19lZ+fb/5bDQAAgNprcYqhh3dag5Hiwnyl19pIkf7S47ul5Dz794u69Ke2tYayteX3O6V144f6Sq+2kUY1rTvPbnaVYRjakG4NmmcnlS/YH3K+Y59gv6SiAH/2KWuAn+riPddX1ZcGR0uDoqTYQK5pcVu2HNKZ3AL9akRqbVBzfZci5RQ6npvnINgfEi3dXk3Bflnd+MMaS294eTe+K2yD/ZdauR7sH64BwX5itqHZ51cfKE+Af3sj6Y5oqXcDKcDHO74WABVHmA8AAAAAAADAJWV141/fQPogQWoRZA0Pro0wNHq3dSlkW6fzpLu2W7e/3c5QdA3u0i+rG//aCOmjBKlVcM39GquSxWJRl3pSl3rShNblC/ZfPWz9Q7BvVdEAv0d9aQgBvsvCLIW6OSBVz3a06Fy+oQWnrd+vrgb7/jZL8VdFsF9bu/FdUTzY35ph/Xky65S0q5zB/h1RUncPBPtFAf7sJOlXAnwAIswHAAAAAAAA4AJXuvFHNrUPPqICLPqigzQ4yaiVXfo/pBgasUs65CB0DvWVJraWHo2lG99VzoL9WUnSAReD/TbB0uCouhPsE+B7VrifRXfHSHfHyAz2ZyVZu+FLC/a/TbH+cXewfyTb0CO7rDcNOFJbuvFdYbFY1DFM6ljJYH/w+Y79qgz2KxPgD4mWriPAB2o1wnwAAAAAAAAATp3LN/SXvdKHTrrxr2sgfRAvtSyl83xItEXXnO/Sn+2kS3/2KemtGtKln5Zv6Jl90nuldON/mCC1phu/whwF+1+e79gvLdjfl1Uy2L8jWupUi4L93PMB/qwKBPiDo6wBfrOg2nEtvEnxYP+bZOvPteoI9g3D0IwT0p/3Ov5+aHK+G//WWtiN7wpHwX7RUvxlBftvJFr/tAiSBkW5L9g/YrOEvqsBfoSf1J8AH6hzCPMBAAAAAAAAOLTk/HPgnXXjT2ojPdLUtVAjOsCiLztIXyZZQ/3iXfpfnZJ+PGsN9O+I9t6AorRu/BAf6dU2dOO7m22wP7G1od/SrEF2XQr2CfBrlnA/i+5pLN3TuHLB/pDzwX5EKcH+0RxDj+y07ufI/Y2l/6sj3fiusA32/1GOYP9Qdslg/45oqVs913+eHLHpwF9FgA/ARYT5AAAAAAAAAOycO/8c+A+cdJ73jrB2npfWje/MHdEWXRthXXb/Kwdd+nduk2YnGZraTl7VpV9WN/41EdJHdONXOYvFoq7hUtfwygX7Q84vxe/NwX6uzRL6c8sR4F8Z/scS+gT4nucs2P/utJRrON6neLB/Y6ShwVH2wT7d+JVXPNj/PeOPR3vsznK+X/Fgv+jRHo6CfQJ8AJVFmA8AAAAAALxOTqGhfCe/4K5uwT502Horvk+qxpIUQw/vtC4vXFx5u/GdiQ6waFYpXfqzz3fpT/WSLv1lZww9tJNufG/jLNiflSQdLCPYn3jY+ueC4D+CuHYh1Ve7MwWG9PNZ69+BecnS2XIE+IOjrV34BPjey1GwP+uUtKiMYH/haeufomB/QJQ0J4lufHeyWCy6OEy6uALB/uuJ1j9Fwf6tDaVN6dZ9yxvgD46WrifAB2CDMB8AAAAAAHiFHRmGZiVZO3V/z/B0NX8I85VuaWjtiOvbUArx5ZernrQ70/p9MvuUtDnd09X8IdRX6htpfdbxLQ2l0Br4fVKV3fjOlNaln+wFXfp049ccjoL9oqWzSwv299oE+zUNAX7NZhvsp9ouxe9isO9IkwDp3XipH934leIo2P8yydpd72qw7woCfACuIMwHgCo2ZcoUTZ06VZLUvXt3zZw508MVAQAAAN5jZ4Zhhi1bvSjAt5VeIH2RZP0T6ivdSrBf7bw1wLeVUWCtb/Ypa5f+LQ2tnb4315Bgf2mKoRFOuvFDbbrxq6LzPDrAoi8vsv4sGL3HutS+raIu/bfaGRpSjV36y85Yr4mjIDjER5rYRnqMbnyvZBvsv9rG9WC/JigK8AdFSXEE+LVGfT+L7m0s3VuOYL+4+2Kk/2srRdKN71a2wf4/WxnaYtOxv6eUYN+Z+n7SAAJ8AOVAmA8AAAAAAKrVzgzDXAbZWwN8ZzIcBPtDoqW+kVJwDQhsa5I95wP8WV4c4DuTVfhHsB9yPtgf7KXBflq+ob9Ucze+IxaLRUNjpF4NnHfpD90mzaqGLv30893475bSjf9hgtSGbvwaoXiwvz5N5s1BNSXYvyLc+uxsAvy6obzBfuMA6T268auFxWLRJWHSJeUM9uuf78AfQoAPoAII8wF4nTVr1mjt2rWSpNjYWA0cONDDFQEAAACorKIAf3aSdy2hXxnFg/1+5wNbgv2K22PTgb+phgX4zmQWnn+GtxcG+57sxnfG0136dOPXbhaLRd3CpW7Fgv1Zp6zLY3uTK2yW0CfAr7scBfuzkqTvU6QCWbvx/30B3fie4CjYL1qKf0/WHwH+4CjphkgCfAAVR5gPwOusXbvWbll6wnwAAACgZqpIgN8kwNp5ODhaah5YtfW5Is+Qlp2x/uL8x7NSoZN5GQXS50nWPwT75VORAD8mQBoYZf0Feaugqq3PFfmG9ftjVpK07KxU4GRJZG8J9tPyDY3dJ73vpPO8V4S187yVhzrPi7r0rz3fpT/HSZf+7PNd+lFu6NJPzzc0br/0zlHH7/esL310Id34tUnxYP9ErpTj7Id8NYvwkyIIZ1GMbbCfW2gop1Cq58f3iTewDfb/1cpQviH5WrjxC4B7EOYDQBUbM2aMxowZ4+kyAAAAgGqxK9Mwu5LKG+APiZZ61Pe+X3y2DZEeiZWScg3NOX9zAsF+5VQmwL8jSroqQvL1su+TC0KkEU2l5FxDXydbv0/KG+wPOR/sh1Th90lZ3fivtpFGVXM3vjMxARbNusjQF0nSGAdd+rNOScvPVr5Lf/kZQw+V0o0/oY30ON34tZrFYlETL7iBDHBVgI9FAT6ergKOWCwWcS8OAHcizAcAAAAAAJWyq+jZ5rUowHckOsCiUbHSqAoG+2G+0q3nA9s+dTDY35tpXalhVlL5A/whUdLVEd4X4DvSKMCih5tKD1ci2L+1kaHBUe4N9tPOPwf+PSfd+NdGSB95sBvfGYvFojtjpF4NDD22S/o62f79ynTp040PAAAAb0eYDwAAAAAAyq2iAf7AKOmOGhTgO2Mb7J/MNfT1+ZB6xVnnwX56HQz260qA74yjYH9WkrWbvLRg/8sk6x93Bfs/pBgascvxM8G9rRvfmZgAi2Z3sHbpj94tpeTbvz/rlPXGmrfaGRrsQpf+8jPWFQoO0I0PAAAAL0aYD6BOKCws1MaNG3X48GGdOnVKQUFBuvrqq9WqVSuH85OTk7V7924dOnRIaWlpslgsioiIUOvWrXXxxRfL39+/WuvPzs7WmjVrdOTIEWVkZKhBgwbq1KmT2rZtW+Xnzs/P1549e7Rv3z4lJycrKytL9erVU8OGDXXppZcqJiam0udISUnRhg0bdOrUKaWmpiogIEDR0dGKj4/XBRdcIEs5f3mSnp6u3377TSdPntSZM2fk6+urRo0aqW3btkpISJCvr2+la3a3tLQ0rV27VklJSTp37pwiIyPVv39/h99rhmFo37592rt3r06cOKGsrCyFhISoYcOGuvjii9W8efNK11MTryEAAKh6RQH+7CRpSx0M8J2JcUOwX7QUf20I9osC/NlJ0kYXA/xof2lQdO0I8J3xRLDvSjf+hwlS6xrSeV5Wl/6pPOmObdIdpwxNaeu4S59ufAAAANQkhPkAvEZ8fHyJbWvXrnW4XZJGjx5t9yz6NWvW6P777zfHu3btkmEY+vjjjzV9+nSdOHHCbv/x48fbhfm7d+/WvHnztHz5cu3bt89pnSEhIbrjjjv0yCOPKDIyssyva8qUKZo6daokqXv37po5c6bL83JzczVlyhR9/vnnOnfuXIl9OnTooBdffFEdO3Yss47yyM7O1uLFi/Xtt99q7dq1yshw/pvaDh06aPTo0erVq1e5z7NixQq988472rRpkwzD8W+vGjVqpL59+2rEiBFq3LhxqcfbuHGjpk6dqtWrVys/P9/hnPDwcF1//fUaMWKE2rRpY/fekSNHdN1115njH374Qc2aNSvz63j22Wf19ddfS5IGDBigiRMnujwvOTlZEyZM0OLFi5Wbm2s3/6abbjLD/Pz8fP34449auHChVq1apbNnzzqtp1WrVho1apRuv/32ct8IUdFrmJ2drauuukppaWmSSv79LMvcuXM1btw4SdZf0C1dutSlaw8AAKpeRQL8xsWW0K+NwawzxYP9oqX4ywr2P0uy/qmpwX5FA/yiGz1qa4DvjG2wf8pmKf7yBvtDoqS+ToL9tXmhun2d8278ia2lR2to53lRl/7nSdIYB136XyZJy8+U7NL/8Yyhh5x04wef78YfXUOvCQAAAGonwnwAtVZeXp4ef/xxrVixwqX5zz77rLZt21bmvMzMTM2YMUOLFy/We++9p3bt2lW2VIdSU1P18MMPa/PmzU7nbN26Vffdd58++OADdevWzW3n/vXXXzV27FiX5m7dulWjRo3Sgw8+qHHjxrkUHmdlZekvf/mLli5dWubc5ORkzZw5U+3bt9fAgQMdzikoKNA///lPffbZZ2Ue79y5c5ozZ46aNm1arrC5Kmzbtk0jR45UcnJymXP379+vxx9/3KXjHjhwQOPGjdNPP/2kiRMnKiAgoMx9KnsNg4KCdMstt+jzzz+XJH399dcaPXq0yzcTzJkzx3x9+eWXE+QDAOBhuzMNfUmAX2kxARY9GmsNTGtjsF+ZAH9ItNQzgu8Tydo9PrKpNLJYsL/sjPPvE9tgP/T8IxsGnw/2MwwfvZEVp6/yohzuW9O68Z2xWCy6K0bq7UKX/sTW0r8TpbeddONfXV/6KEG6IKRmXxMAAADUPoT5ALxG0dLgqampSk1NlSQFBgY6Xca9fv36pR7v1VdfNYP8Dh066Nprr1Xjxo2VkZGh7du3KygoyOF+FotF7du3V6dOndS8eXPVq1dP2dnZOnDggJYtW6ajR63/7//YsWMaNWqU5s+fr7CwsAp9zc4UFhbqz3/+szZv3ixfX1/17NlTXbt2VUREhFJSUvTDDz9o06ZNkqzB+NixY7Vw4UKFhoa6tQ5JioiIUJcuXdS+fXs1bNhQ/v7+On36tDZu3KiffvpJBQUFkqTp06eradOmdqsjOJKTk6Nhw4bZ3aTg7++vK664Ql27dlXDhg2Vk5OjY8eOacOGDdq0aZMKC539Csu65PwTTzxhd2OAj4+Punbtqssuu0wxMTHKz8/XyZMntXnzZq1bt055eXmVvCqVl5qaqjFjxig5OVmBgYHq1auXOnfurNDQUCUnJ2v58uVOg/CQkBB16dJFHTp0UFRUlIKCgnT27Flt2bJFy5cvV05OjiRp4cKFioqK0vjx40utxV3XcMiQIWaYf/ToUa1evVpXXHFFmdfiyJEjWrt2rTkeNGhQmfsAAFBbZBUYWpQibUiT8p1041anXEP6IYUAvyq4I9i/taGhFo7/b0y1yjOsXc8E+O5XkWA/o0D6Isn6J9RXCi5sp2Sj5OO6QnykV9vU3G58Z1zp0v8yyfG+dOMDAADA2xHmA/AaS5YskWS/3Pwll1zidFn6ssycOVMBAQGaMGGCbr311jLnh4aGatSoURoyZIjTruDx48dr2rRpev3112UYho4ePap33nnH5S52V23YsEGFhYWKi4vT1KlTlZCQYPf+yJEj9c477+g///mPJOn48eP66quvygzSy6Nz5856+OGH1bNnT4fPbZesHeBPPvmkdu3aJUl6/fXX1a9fPzVo0MDpcV955RW7IL979+56+eWXnT7n/cSJE/r4448VHBzs8P0PPvjALoRu166dXn31VbVv397h/JSUFH355ZdVcuNDeSxbtkySdOGFF2rKlCmKi4uze//RRx8tsU/btm01cuRI3XDDDU6vR1JSkp5++mkzHP/44481ePBgtW3b1mkt7rqGHTp00IUXXqgdO3ZIsnbbuxLmz5kzx3zMQnh4uG688cYy9wEAoCYrCvBnJUkLTlsD25qkccAfS6MT4FeMo2B/VpL009nSg/3PnQSS3ogAv/IcBfuzzi8fX1qwn6GS///tmghr53lN78Z3pqhLv1eEocd2S3PLXvyMbnwAAADUCIT5AGq1f/7zny4F+ZL04YcfKjAwsNQ5vr6+evjhh5WZmam3335bkjR79mw9+eSTLi1l7qrCwkLVq1dPH3/8sWJjYx3OefTRR7Vy5UqtX79ekrUL211h/pVXXqlevXqVOa9Vq1aaNm2a+vXrp5SUFGVnZ+vrr7/W8OHDHc7fvn272bktWYP8sq5748aNzWepF3fq1ClNmTLFHLdp00b//e9/S121ITIyUqNGjSrrS6sWDRs21LRp0xQZGVnm3JYtW2r+/Pny8fEpdV50dLTee+89DRo0SPv375dhGPr888/13HPPOZzv7ms4ZMgQ/eMf/5BkvUEnPT291JUrDMPQ3LlzzfEtt9xS5t9DAABqoqIAf3aS9E0NDvCHRElXRRDMupNtsH8ix9Cc853YpQX73iraXxpw/kYPAnz3sg32k3INfX1Kmn2q9GBfsnbjT2wjPVZHOs8bB1r0VQdDnyVJTzjo0pes3fivtJbGNKsb1wQAAAA1G2E+6pQCw1CK51fXdovMPMkwJItFCsl173qckf6145cuHTt2VP/+/V2eX54AceTIkZoxY4YyMzN19uxZbd26VZdeemkFqiz9HM6C/CJDhgwxw/zt27crPz9ffn6V/9FenmvRqFEj3XPPPWYgvHLlSqdh/vTp0+3OMWHChEoFt//73/+Um5trjl955ZUyH7/gTR5//HGXgnxJ5bpZJCQkRI888oh5E8TKlSudznX3NezXr58mTZqk7OxsZWVl6dtvv9Udd9zhdP7q1avNR1dILLEPAKhdCPBRXo0DLXos1hq82gb7K85KXvAUBocI8KtfdIBFj8RKj8SWHux38UvX513D1KaWduM7Y7FYdHeM1DvC0KO7pXk2Xfp04wMAAKCmIcxHnTErydCY3VJSLQnzJcdLbLtDtL80pZ2hIdE1+//c3n777VV27ODgYHXq1EmrVq2SJG3bts3tYf6AAQPKnNOpUyfzdW5uro4ePaoWLVq4tQ5XXHHFFWaYv23bNodzCgoK7JZy79Onj9PHGbjq+++/N1937drV7np4O19fX5dXjagI2+XtDx065LRD3t3XsGiZ/Pnz50uyLqFfWpg/e/Zs83V8fLw6duxYqfMDAOBpFQnwfSRdVV+K84JnoUtSTIDUryEBvqc5CvbXn7M+r94bRPlLtzaSetaX/Hz4PvEUR8H+8kOn1cHnnG4NTleb4Is9XaLHNA60aE4HQ9+lSItTpCvCrY99oBsfAAAANQlhPuqMkbukVAfLq6GkpDzr9RoS7elKKqeqg92GDRuar0+ePOnWY8fGxioqKqrMedHR9h/SuXPn3FqHqxo1amS+Pnv2rHJyckp03O/YsUOZmZnm+Prrr6/UOVNSUnTgwAG3Ha+6tW7dukpXEbD9/jQMQydPniwR5lfVNRwyZIgZ5m/cuFH79+9X69atS8xLS0uzu8Fj4MCBbjk/AADVLft8gD+rnAF+zwhpcLQ0sJE1dAKcKQr2VfrCXajjioL9K04fU15ennws/p4uyeMsFotubijd3LDsuQAAAIA3IswHUGs1b968QvslJydr4cKFWr9+vXbv3q0zZ84oIyND+fnO7wZJS0uraJkO2YbjpQkJCbEbZ2VlubWOwsJCrVmzRkuXLtX27duVmJio9PT0Ms+TlpZWIszft2+f3fiiiy6qVG1Fz4N31/GqW1xcXIX33bJli7777jtt27ZNBw8eVFpamrKysuyuR3Hp6ekltlXVNezevbtatmypgwcPSrJ25//lL38pMW/hwoXKzs6WJPn7++u2225zy/kBAKgORQH+7FPS/GTXAnyLpGsiCPABAAAAAIBrCPNRZ7wfr1q2zH7VsS6z7+kqKi80NLRc83NzczV16lRNmzZNeXnl+0axfea4O1T0OfKlhbnltWXLFj333HPauXNnuffNyckpse3s2bN2Y1dWHihN8eO5egOEtyjv96ckHThwQM8//7zWrl1b7n1d+UzceQ0HDRqk119/XZI0b948PfXUU/L19bWb89VXX5mve/furcjISLedHwCAqmAb4H+TLKUR4AMAAAAAgCpEmI86Y0i0RQOjDKXUkjA/83wXrsViUUhwsFuPHelfO56N6efn+o+4goICPfHEE1q+fHmJ93x9fRUREaHAwEC7Y54+fVoZGRmS3Buie4M1a9Zo5MiRZte0rdDQUIWGhiowMFCW898nBQUFOnr0qDnH0fUoulaS9bMJCAioVI22xyuqqyYpz/enJO3du1f33nuvzpw5U+K94OBghYWFKTAwUD4+Pub2w4cPm6/L+kwk917DgQMH6s0331R+fr6SkpK0cuVKXXPNNeb7e/fu1ZYtW8zxoEGD3HZuAADcKbvA0Pcp0qxyBvg9I6yPrSLABwAAAAAAFUWYjzrF12JRVOXyQ6+RmS8ZhmSxSCEB/HKwsj7//HO7ID8hIUH33nuvLrvsMsXGxpboKJakcePGae7cudVYZfXIzs7Ws88+a7f8+Z133qkbbrhBF110UYnnrktSYmJimc9btw2K8/PzlZubW6lAv3jwXDyYrk0Mw9D48ePNIN9isej222/Xrbfeqg4dOqhBgwYO90lISCj1uFV5DRs1aqRrr71WS5culWTtwrcN82278mNiYnTVVVe57dwAAFRWUYBftIR+eQL8wVHSoCgCfAAAAAAAUHmE+QAg6ZNPPjFfX3nllXrvvffKDJrPnTtX1WV5xNKlS3Xs2DFJko+Pjz744ANdccUVpe6TlpZW5nEjIiLsxqdOnVJsbGyF6yx+vOTkZLVu3brCx5NkrjRQXo5WMHCnTZs22XWxv/zyy2V2srvy/VkV19DWkCFDzDB/2bJlOnPmjBo0aKD8/HzNnz/fnNe/f3+HN8wAAFCdCPABAAAAAIC38Sl7CgDUbidPntTBgwfN8Z/+9CeXOsaPHDlShVV5zurVq83XPXr0KDPIl1y7FhdccIHdeNu2beUvzkabNm3swvfKHk+yLldvy9WQ/vTp05U+d2lsP5PWrVu7tCS9K59JVVxDW1dffbUaN24sScrLy9OCBQskSStWrFBycrI5b+DAgW49LwAArsouMDQ/2dB92w3F/CIN2Cr972TpQb5F0jUR0pS20pErpeWdLXq8mYUgHwAAAAAAuB1hPgCvY/ss8cLCwio/38mTJ+3GZS1NLkkpKSnau3dvVZXkUUlJSeZrV66FJK1Zs6bMOQkJCXbLuhd1bFdUgwYN1KZNG7cdT1KJRwjYXgtn8vPztXXr1kqfuzRV9ZlUxTW05evrqwEDBpjjOXPm2P2vJHXt2lUtW7Z063kBAChNUYB///kAv//vrgX4PeuXDPCbEOADAAAAAIAqRJgPwOuEhISYr9PT06v9/Dk5OWXO+fTTT6vlRgNPMAzDfO3KtUhLS9O8efPKnOfr66sbb7zRHC9atEhHjx6tWJHn9enTx3y9fv16bd68uVLHCwgIsFv635XjLV68WJmZmZU6b1nK+5nk5+friy++cOnY7r6GxQ0aNMjs/t++fbt++eUXrVixwu59AACqmqMA/7/lDPB/vJQAHwAAAAAAVC/CfABexzZMPXTokHJzc6v0fEXLgBf58ccfS52/a9cuvf/++1VYkWc1adLEfP3zzz+XedPCSy+9pLS0NJeO/cADD5ivc3Jy9Oyzz1bq87377rsVGBhojsePH6/U1NQKH0+SLrnkEvP1vHnzlJ+f73RuWlqa/v3vf1fqfK6w/UzWr1+vjIyMUudPmTLF7tERpamKa2grLi5Ol19+uTl+5plnlJeXJ0kKDQ21u5kAAAB3yin8I8BvXM4AfzIBPgAAAAAA8AKE+QC8TseOHc1O3qysLL355psudSNXVHR0tNq2bWuOX331Ve3Zs8fh3F9//VUPPPCAcnJy5ONTO3+EXnnllebrAwcOaMKECSooKPlb7/T0dI0fP17ffPONy9ciISFB9957rzleu3atHnroISUmJjrdJykpSf/+97/13XfflXivYcOG+tOf/mSO9+3bp3vvvVc7duxwerzU1FS9//77mjlzpsP3b7nlFvP1gQMHNHHiRIc3NBw5ckTDhg3T0aNH7Z47XxVsP5PU1FSNHz/e4d+J3NxcvfHGG3r33Xdd/kyq4hoWN2TIEPN1cnKy+bpv3752K3EAAFBZOYWGvinqwF/5R4B/rpwB/mgCfAAAAAAA4AX8yp4CANUrJiZGPXr00MqVKyVJH374oWbOnKnY2FgFBASY8+68807dddddbjnniBEjNG7cOEnWsHHgwIG68cYb1blzZwUHByspKUm//PKL1q1bJ0lq166dWrdurUWLFrnl/N7k+uuvV8uWLc3O7k8++USrVq3STTfdpNjYWGVnZ2vXrl1avHixzpw5I0kaPXq0Jk+e7NLxn3nmGW3dulWbNm2SZA30+/btqx49eqhLly6KjIxUbm6ujh8/rk2bNmn9+vUqLCzUhAkTHB7vwQcf1MaNG7V48WJJ0u7duzVw4EB169ZNl112maKjo1VQUKCTJ0/q999/1+rVq5WXl6fRo0c7PF6vXr3Uvn17bd++XZI0c+ZMrVmzRn379lVMTIzS0tK0efNmLV26VLm5uWrXrp1atWql77//3tVLXG4dO3bU5ZdfrtWrV0uSvv/+e/3++++6+eab1bJlS+Xn52v//v1asmSJjh8/Lql8n4m7r2FxN9xwgyIiInT27Fm77SyxDwBwh5xCQ4tTpNlJ0rzk0oP7IhZJV9WXhkRLA6OkpgT3AAAAAADACxHmA/BKL774ou6//34dO3ZMknVJ9v3799vNse3wraz+/ftr7dq1+uqrryRZO5wXLFigBQsWlJgbFxenqVOn6p133nHb+b2Jn5+f3nzzTd133306d+6cJGnv3r3au3dvibkWi0WPPvqobr/9dpeD48DAQM2YMUNPPfWUli9fLknKy8vTjz/+WOYjDhyxWCz6z3/+oxdffFFffvmlJKmwsFBr1qzRmjVryn08X19fvfrqq7r//vvNmxV2796t3bt3l5jbokULvf3223rrrbfKfZ7ymjRpkoYOHWqG9ceOHdOHH37ocO6AAQP02GOPufyZuPsaFhcQEKDbbrtNn3zyibmtdevWuvTSSyt9bABA3USADwAAAAAA6oLauUY0gBovLi5O8+bN07hx43TFFVcoKirK7rneVeHll1/W+PHjFRER4fD9kJAQDR06VHPnzlWLFi2qtBZPS0hI0OzZs9WjR49S57z33nt68skny3384OBgvfvuu5o6daouuuiiUufGxMRo+PDhuuqqq5zO8fX11T//+U/NnDlT3bp1K3WJ+YiICA0dOlT9+vVzOqddu3b67LPPnH79gYGBGjJkiObMmaO4uLhS63eXmJgYffXVV+rbt6/Tr69FixaaOHGiJk6cWO6l/919DYvr37+/3XjgwIHlqg8AgJxCQwuSDQ07v4T+7b9LM11YQv/q+tKbbaXEK6UV55fQJ8gHAAAAAAA1gcUwDMPTRaD2S09P165du8xxfHy8wsLCKnSsPXv2KD8/X35+fnbPOa9rMjMzZRiGLBYLz5x2s5ycHP3222/au3evMjMz1aBBAzVu3Fjdu3dXcHCwp8urdomJifrtt9+UlJQkf39/RUVFKSEhQRdccIHbznHixAlt3LhRycnJSktLU0hIiKKjoxUfH682bdqU+3gpKSlmzampqQoKClKjRo3Utm1bxcfHu/w8ecn69a9fv16nTp1SYGCgmjZtqu7du6t+/frlrstdTp48qXXr1unEiROSpKioKLVp00YdOnRw2znceQ0lae7cueajLPz8/PTjjz8qKirKbfW6Gz9jK4Z/owG4YsuWLcrLy5O/v78uvvjiUufmFBpakiLNqkAH/uBoaRAd+ADqoPL8nAUAlA8/YwGg6tSGn7HuzEOLsMw+ABQTGBioK6+8UldeeaWnS/EKcXFxVd593rhxY/Xt29dtx4uMjNQNN9zglmNVx9dfXjExMbr11lur9BzuvIaSzEdYSFLPnj29OsgHAHhWUYA/+5Q1wE/NL3sfAnwAAAAAAFAbEeYDAIAqdeDAAa1bt84c33HHHR6sBgDgjSoa4PeoLw0hwAcAAAAAALUUYT4AAKhS7733noqe6tO0aVP17NnTwxUBALxBnmHRwmRDswjwAQAAAAAAHCLMBwAAVaKwsFCffvqp5s6da24bMWKEfH19PVcUgDphX5ah705LyXmersQqwCJdFi5dEyH5+dTt8Dm30NBPufX0fXY9rciPUHpK2fsUBfhFS+jHEuADAAAAAIA6gjAfAAC4zQ8//KDJkyersLBQx44dU3p6uvlemzZtNGTIEA9WB6A225dlaFaSNDtJ2pBe9nxPiPKXBkQZGhJVt4L93GJL6J/Nb1nmPgT4AAAAAAAAhPkAAMCNUlNTtXPnzhLbw8PD9cYbbyggIMADVQGorWpCgG/rVJ70/jHrn9oe7JcM8F3b7yoCfAAAAAAAABNhPgAAqBJ+fn6KiYnRVVddpVGjRqlp06aeLglALbD/fIA/q4YE+M44CvbviJZ61q+5wX5uoaGlZ6yfTXkC/B71pSEE+AAAAAAAACUQ5gMAALcZOHCgBg4c6OkyANQyRQH+7FPSb2mu7RPlbw2J/bwgG96fVfqNB8WD/YFRhobUkGC/KMCfnSTNLUeAf4lvum4MPKcnOjUlwAcAAAAAAHCCMB8AAACA16logD8gSl65dL2rjwQ4lSe9d8z6J7poKX4vC/YrGuD3qC8NjpLaJ+9QZGGW/P39FRsYW7XFAgAAAAAA1GCE+QAAAAC8Qm0L8G21Cbbo2RbSsy1cD/aTnAT710RIvpbq/TorG+APipKaBVlr3nImX3mFVVgsAAAAAABALUGYDwAAAMBjKhLgN/KXBtaAAN8ZdwX7d0RLPSOqLtivaIB/Zbg0JNo+wAcAAAAAAED5EeYDAAAAqFYHzgfYs+pQgO+MbbC/N9PQ7FPSrCRpYzmC/YFFS/FHVD7Yzy009MMZaw0E+AAAAAAAAJ5FmA8AAACgyh2w6cBfX44Af0CUdEctC/CduSDEPtifdcraFV9WsP/uMeufigb7lQnwB0dbl9EnwAcAAAAAAHA/wnwAAAAAVYIAv+IuCLFofAtpfAWD/ZgAaUAj58F+ZQP8QVFSHAE+AAAAAABAlSLMBwAAAOA2lQnwh0RJ10bU3QDfmYoE+ydzHQf72YXWAH9esnTGxQD/Cpsl9AnwAQAAAAAAqg9hPgAAAIBK25lhaPRuadlZ1+YT4FeMo2B/VpK0ycVg31VX2CyhT4APAAAAAADgGYT5AAAAACqswDD0RqL0/AEpp7D0uQT47lWRYL80BPgAAAAAAADehTAfAAAAQIXszDA0fKe0+pzzOQ39pYEE+FXONtjfk/nHow7KCvYvP7+EPgE+AAAAAACA9yHMBwAAAFAuZXXjN/SXBjSS7ogmwPeEtiEW/bWl9NeWjoP9y8Ot4f3gaKk5AT4AAAAAAIDXIswHAAAA4LLSuvEtkv4UJ/2zlRTiS0jsDWyD/bN5hnwsUrgfnw0AAAAAAEBNQJgPAAAAoEwFhqH/S5Sec9KN3zZYmpYg9YggKPZWEf58NgAAAAAAADUJYT4AAACAUu3KNDR8h/Srk278J5tJ/2pNNz4AAAAAAADgToT5AAAAABwqMAz953w3fraTbvyPEqSr6MYHAAAAAAAA3I4wHwAAAEAJdOMDAAAAAAAAnkWYDwAAAMBUVjf+BcHSNLrxAQAAAAAAgCrn4+kCAKCmmzNnjuLj4xUfH6/evXs7nbdmzRpzXnx8vNvrsD32mjVr3H78qlSTaweA2mRXpqFrNkhj95UM8ou68Td1I8gHAAAAAAAAqgOd+QAAAEAd50o3/kcJ0tWE+AAAAAAAAEC1IcwHALjFjh07tHTpUklSvXr19MADD3i2IACAS3ZnGhq+Q1p1ruR7FklPNJNebi2F+BLkAwAAAAAAANWJMB8A4BY7duzQ1KlTJUmxsbGE+QDg5QoMQ28mSn+nGx8AAAAAAADwSoT5AFBNLrvsMu3atcvTZXglrgsAVK+yuvHHNJNeoRsfAAAAAAAA8CjCfAAAAKCOKDAMTT4i/W2/4278NsHSNLrxAQAAAAAAAK9AmA8AAADUAbszDT20U/ol1fH7Rd34oXTjAwAAAAAAAF6BMB9AnZSamqpdu3bp4MGDOnv2rCQpIiJCcXFx6ty5s4KCgjxbYDE7d+7Utm3bdPr0aUVERKhZs2bq1q2b/P39K3XcmnYdiissLNSmTZt04MABnT59WoGBgWrUqJE6d+6spk2buuUcaWlpWrNmjY4fP67s7Gw1atRIXbt2VVxcnFuOX5rc3Fzt3LlT+/fvV0pKinJychQeHq6YmBhdeumlioyMrPQ5Tpw4oU2bNun06dM6d+6cgoOD1aRJEyUkJKhFixblPl5KSoo2bNigU6dOKTU1VQEBAYqOjlZ8fLwuuOACWSzeFxImJydrw4YNSkpKUkZGhpo2barrrrvO4dz8/Hzt2bNH+/btU3JysrKyslSvXj01bNhQl156qWJiYipdT028hvBuZXXjtw6Spl0o9aQbHwAAAAAAAPAqhPkAvMbw4cP1yy+/SJK6deum//73vy7ve+rUKV1zzTUqKCiQJP3jH//Q0KFD7eYkJiZq/vz5Wrp0qXbu3KnCQgeJhiR/f3/169dPo0ePVmxsbAW/mpLWrFmj+++/3xy78pz4jRs36qWXXtKOHTtKvNewYUM98MADevjhh8sV7rn7OvTu3VtHjx6123b06FHFx8c7nD9gwABNnDjRbpvt3E8++USXXXZZqV9Ddna2PvzwQ/33v//VmTNnHM7p0KGDnn76aV155ZWlHkuSnn32WX399dd29aWnp2vSpEmaN2+esrOzS+zTo0cPPf/882rZsmWZxy+Pc+fO6dtvv9WiRYu0YcMG5eTkOJxnsVh02WWX6YknnlCXLl3KdY7CwkItWLBAH3zwgXbv3u10XmxsrPr166fhw4erfv36pR5zxYoVeuedd7Rp0yYZhuFwTqNGjdS3b1+NGDFCjRs3tnuvIn8/JOm+++7T2rVrJUmjR4/WmDFjXJ536NAhvfzyy1q5cqX5s0OS6tWrZxfmZ2dna/Hixfr222+1du1aZWRkOK2nQ4cOGj16tHr16uVS/bYqeg2PHz+u3r17m3+XJ0yYoIEDB7p83rfeekuTJ0+WJIWGhmrlypUKCQkpd/3wTnsyDQ2nGx8AAAAAAACokXw8XQAAFOnXr5/5ev369Tp27JjL+y5cuNAM4/z9/dWnT58Sc1577TVNnjxZ27dvdxpgS1JeXp7mzJmjAQMGmOGfJ8yaNUt33323wyBfkk6fPq3XX39djz76qPLz810+bk27DsUdO3ZMt99+u6ZMmeI0yJekrVu36sEHH9S//vUvp8GoM0eOHNGgQYP0xRdfOAzyJemXX37RXXfdpX379pXr2GWZP3++XnjhBf36669Og3xJMgxDq1ev1r333qsZM2a4fPyUlBTdfffdGjt2bKlBvmS9KePdd9/Vzp07nc7JysrS448/rpEjR2rjxo2lXuvk5GTNnDlTq1atcrneqvLTTz9pwIABWrFihV2Q78ivv/6qsWPHavny5aUG+ZL1+27UqFGaOHGiy993lb2GTZo0UY8ePczxnDlzXDqvZP0+KrqRRZL69u1LkF9LFBiG/i/R0CXrHAf5rYOkHztLb7a1EOQDAAAAAAAAXorOfABe44YbbtCLL76o7OxsGYahBQsWaOTIkS7t+80335ivr7nmmjK7iC+44AJ16tRJbdq0UXh4uPLy8pSYmKgVK1Zo7969kqxL0D/22GOaP3++25Zsd9WKFSv0/PPP24Xt3bt319VXX60GDRro5MmT+v7777V7924tX75cU6ZMqdB53HEdYmNj5evrq4yMDJ0+fVqS5Ofn5/SaNWzYsEK1StYg+t5777VbCaBJkybq27evWrVqpaysLG3atElLly5Vbm6uJGnmzJmyWCz629/+5tI5srKy9Nhjj+ngwYMKDAxU79691alTJ4WFhenkyZNatGiRGYKnpKTomWee0axZs+Tj4/7746Kjo9WlSxclJCSoQYMG8vHx0cmTJ7V27VqtWbNGkrXLfsKECYqLi3O6NHyRlJQUDR06VIcPHza3hYSE6Oqrr1bHjh3VoEEDZWVl6fDhw/rtt9+0bdu2Uo+Xk5OjYcOGafPmzeY2f39/XXHFFeratasaNmyonJwcHTt2TBs2bNCmTZtKvYGkuiQmJuqTTz5RRkaGwsLCdOONNyohIUEhISE6ceKEuUKIIxEREerSpYvat2+vhg0byt/fX6dPn9bGjRv1008/mTcGTJ8+XU2bNrVbbcARd13DIUOG6Oeff5ZkvRnq8OHDat68eZnXYt26dUpMTDTHgwYNKnMfeL89mYYe2imtdNKNPzpWmtCGbnwAAAAAAADA2xHmA/AaYWFh6t27t7799ltJ1oDelTD/wIED2rp1qzm+7bbbHM7z9/fX3Xffrbvvvltt27Z1OOeZZ57R119/reeff165ublKS0vTpEmT9J///Kf8X1AFZWRk2AX5AQEBeu2110qsNvD444/rgw8+0Ouvv67333/f5eO7+zrMnDlTkrUbePz48ZKkmJgYLVmyxOWaXPXPf/7TLsgfOnSo/va3vykwMNDcNmzYMO3evVuPPfaYGVJ+8sknuvbaa+26l51ZvHixCgsL1aFDB7355ptq1qyZ3fujRo3SSy+9pC+++EKStRN7+fLlZQbprrJYLOrZs6ceeughde/e3elNAps3b9af/vQncwWLl156Sddcc438/Bz/024YhsaNG2cX5N9000167rnnFBUV5XCfAwcO6KOPPnJ6zFdeecUuhO7evbtefvllpyHyiRMn9PHHHys4ONjh+9Vl3rx5kqyPSnjttddK3GAyZswYZWZm2m3r3LmzHn74YfXs2VP+/v4Oj3vgwAE9+eST5iMCXn/9dfXr108NGjRwWou7rmHv3r3VsGFDnT59WoZhaM6cOfrTn/7k9LxFvvrqK/N169atdemll5a5D7xXoWFo8hHpb/ulLAf3zbQOkj5KkK5pQIgPAAAAAAAA1AQssw/Aq9gG8bt373bpudm2Xfn16tVz+qzqV155RS+88ILTALvIgAED9MILL5jjpUuX6tSpU2XW4S7/+9//dOLECXP8/PPPO3xsgMVi0ciRIzVs2LBydTvXlOtQ3LZt28wbPSTrSg4vvfSSXZBfpF27dvrwww/tlgufNGmSS+cpLCxUbGysZsyYUSLIlyRfX1/9/e9/twtbFy5cWJ4vpVSDBw/WBx98oMsvv7zUbv9LLrlEH374oRksnzx5Uj/88IPT+UuXLtVPP/1kjm+99Vb95z//cRrkS1KrVq30r3/9S126dCnx3vbt2/X555+b4+7du+vDDz8stRu8cePGGjdunPr27et0TnVp27at3nnnHZdWirjyyiv1+eef67rrrnMa5EvW6zVt2jRFRkZKkrKzs+2WsC/OndfQ399ft99+uzmeO3dumT8X0tPT9f3335vjgQMHljof3m1vpqFrN0p/3us4yB8dK23uTpAPAAAAAAAA1CR05qNuMQqkwhRPV+EehZmSYUgWi1Tg5ucb+0RKFl/3HtNFRcvIFz0L/ZtvvlF8fHyp+yxYsMB8fdNNNykgIMDhPEehrzODBg3Se++9p8OHDysvL0+rV69Wv379XN6/Mmw7ZS+66CINHjy41PlPPPGE5s+fX+rz423VlOtQnG3oGRAQoL/97W+yWJyHUi1bttSIESM0efJkSdLOnTu1ceNGde7cucxz/eUvf1G9evWcvh8QEKD+/fubx96yZYurX0aZyvP5tGnTRv369TOfkb5y5UrddNNNDudOnz7dfN2oUSO9+OKLlXo0gO3xAgMDNWHChHLV7mljx451ud7yfF2NGjXSPffcYz76YuXKlRo+fLjDue6+hkOGDNG0adMkScePH9evv/5a6moU3333nbKysiRZH43Rv3//Cp+7LsossC5l/32KlOv5p0cou1ByVAbd+AAAAAAAAEDNRZiPuiN9lnR6tFSQ5OlK3MLN8b0932ip4VQpbEhVnsUhPz8/9e3bV59++qkka8fz008/7TS03bJliw4dOmSO3RU0WywWXXbZZeaS5Nu2bauWEPvAgQM6ePCgOR48eHCpgbVkfTzBzTffrP/9739ur8dT18GRH3/80Xzds2dPNWnSpMx9hg4dqrfeest8jvmKFSvKDPNDQ0N14403lnnsTp06ma+PHDmivLy8Uru2q8oVV1xhhvnOnnGfnJys3377zRzfcccdpd6sUJaCggItXbrUHPfp08fhKgbeKjIyUldddVWVHf+KK64ww3xnn0lVXMPWrVurS5cu5mc9Z86cUsN82xuHrr766lJXaUBJz+6TvvDy/6R4PFaa2EYK9SXIBwAAAAAAAGoiltlH3ZH8cK0J8qtcQZL1enmI7VL7x44d0/r1653OnT9/vvm6cePG6t69u9vqsF1+++TJk247bml+//13u7Erz3gvz7yK8MR1KO7kyZNKSvrj7+/VV1/t0n6NGjVS+/btzXHx6+vIRRdd5PQZ8baio6PN14ZhKC0tzaWa3K1Ro0bma2efj22QL0nXX399pc65Y8cOu2fKV/Z41e3iiy+Wr2/VrT5i+5mcPXtWOTk5JeZU1TUcMuSPm7CWLFmic+fOOZx34MABbdy40RyXtQII7J3JMzTtuKercK5VkLSskzSlnYUgHwAAAAAAAKjB6MwH4HU6d+6suLg4JSYmSrIutd+tW7cS8woKCvTdd9+Z41tuucWlZcPPnTun77//Xr/++qt2796tU6dOKSMjQ3l5eU73qa6g1rYrPzAwUHFxcS7t165du3Kfy5uvQ3G210Uq39cbHx9vhvjFj+OIbRBbmuDgYLtx0XLl7pKXl6eff/5Zy5Yt086dO3Xs2DGlp6c7DIaLOPt89u3bZ7729/ev0PeLs+NJ1hsgahJX/14VV1hYqDVr1mjp0qXavn27EhMTlZ6eXuZnn5aWVmL5/Kq6hn369NHLL7+stLQ05eTkaOHChbrrrrtKzCtazUGy3rBz7bXXuuX8dcX041KmFyytX5yfRRrZVJrYWgrzI8QHAAAAAAAAajrCfNQdjT6oVcvsV6miZfY9qF+/fnr77bclSYsWLdLf//53BQQE2M1ZtWqVkpOTzbFtR78jhmFoxowZmjx5sl1HrCtKC1DdybaLNiIiwuVnmjdo0MDlc9SE61Bc8e7iyMhIl/e1neusS9lWRZ9ZbhhGhfZz5KefftJLL72kI0eOlGs/Z5/P2bNnzdcRERGVfhyA7fEk1bjl2UNDQ8u9z5YtW/Tcc89p586d5d7X0edSVdcwODhYt9xyiz7//HNJ1tC+eJhfUFCguXPnmuPbb7/dpdUoYFVgGHrrqP22WxtKf2/pkXLsxIdI9QnxAQAAAAAAgFqD39yi7ggbIoUOlApTPF2JW2RmZcowDFksFoUEh7j34D6RkqXqlqB2xW233WaG+ampqfrpp59KLEO9YMEC83W7du2UkJBQ6jFfeuklffbZZyW2WywWRUREKCgoyC7kTE1NVWpqamW+jHKz7fANCgpyeb/iXeKlqQnXobjiNx2U5+u1nVvemxc8YcGCBRo7dqwKC0u2/darV08hISF2NxxkZ2fbPYLAkYyMDPN1SEjlf17YHs/Pz6/EjTberrzB9Zo1azRy5EhlZ2eXeC80NFShoaEKDAyUxWINUQsKCnT06B9pr6MbParyGg4ZMsQM87ds2aK9e/fqggsuMN9fuXKl3ffMoEGD3HbuuuDb09KBYt8K45pL3cMJ0QEAAAAAAAC4F2E+6haLr+RbszpInfLJlAxDslgkXzeH+V6gVatW6tChg7Zu3SrJutS+bZifnZ2tJUuWmON+/fqVerwff/zRLsCOi4vT/fffryuvvFItWrRw2Kk8efJkvfXWW5X9UsrFNnh2FBw64+oS7zXlOhRXvJO6PEva2851R5BdlU6dOqXnn3/eDPLDwsJ07733qlevXoqPj3d4E8Pq1as1bNiwUo9re/3ccUOD7fHy8/OVm5tb4wJ9V2VnZ+vZZ581/z76+/vrzjvv1A033KCLLrpIYWFhJfZJTEwscfNRcVV5DTt06KALL7xQO3bskCR99dVXGjdunPn+V199Zb6+5JJL7IJ+lG1KsQUzOodJV9b3TC0AAAAAAAAAajfCfABe67bbbjPD/OXLlys9Pd0MzpYtW2Z2tlosFt16662lHmvmzJnm63bt2umzzz5zGMLZcmVJdncLDw83X6empqqwsNClpfbPnDnj0vFrynUozva6SFJKSopatmzp0r4pKX+sxlH8ON5mzpw55vd1cHCwPvvsszKfb5+WllbmcSMiIszXZ8+eVV5eXqWW2rc9nmS9CSE2NrbCx5NkdrWXV3lueqmI5cuX69ixY5IkHx8fffDBB7riiitK3ae8n4nknmtoa8iQIfrHP/4hSZo/f76efvpp+fn56cyZM1q2bJk5j6788tmeYWhpsR+3Y5pV/PsXAAAAAAAAAErj2sOYAcADbrnlFvn6Wpf7z8nJ0eLFi8335s+fb77u2rWrmjZt6vQ4hYWFWrNmjTl+9NFHywywJZX7eeXuYBtQZ2dnKzEx0aX9du/eXeacmnQdimvRooXdeNeuXS7vazvX1RsAPGX16tXm69tvv73MIF9y7fOx7bzOy8tz6fvF1eNJ0rZt2yp1PKnkYyVcXX3h9OnTlT53adatW2e+7tGjR5lBvlT+z0RyzzW01a9fP/OaJicn66effpJkXeUkLy9PkvWGkVtuucWt563tphb7aBv5S3dGe6YWAAAAAAAAALUfYT4Ar9WoUSO74Oybb76RZO0sXrlypbm9rCX2izqRi8THx5d57tzcXG3cuLG8JVdax44d7ca//PKLS/u5Mq+qr4Ptc8gdPe+9MmJiYhQTE2OObT//0iQnJ2v79u3m+OKLL3ZrXe5m+xzzhIQEl/axvUHDmS5dutiNly5dWr7CiklISLBbJr6yx5NKrppgey2cOXXqlN2z6avCqVOnzNfu/Eyq4hraCg8P14033miO58yZY/e/knTjjTe6dEMPrM7mGfrkhP22h5tKQb505QMAAAAAAACoGoT5ALzabbfdZr5evXq1kpKStGjRIjOU9vf3V58+fUo9hmEYduPc3Nwyz7tw4UKdPXu2/AVXUqtWrey6x22DN2cyMjL03XfflTmvqq+D7fPo09PTXdqnPK699lrz9U8//aTjx4+Xuc+sWbNUUFDg8BjeyPYzysnJKXN+YmKi2XFdmoYNG6p79+7meNasWZX6jHx9fe2C4kWLFlU6VI+NjbVb+n/z5s1l7vP1119X6pyuKO9nkpaWpnnz5pU5ryquYXGDBw82X//444/65ZdftGPHDnMbS+yXz/QTUqbNfUq+FulR54vCAAAAAAAAAEClEeYD8GrXX3+9goODJVm7vb/99luzQ1+SrrnmGtWvX7/UY0RERJjHkKyhVmlOnjypSZMmVbzoSrIN2H7//fcyA/2pU6faPRfemaq+DrbP+05LS9OJEydKmV1+Q4cONV/n5ubq5ZdfLnGDgq3Dhw/r/fffN8cXXnihLrnkErfW5G5NmjQxX69YsaLUuXl5efrrX/9qd7NCaR544AHz9alTp/TCCy+Uev3Kc7ycnBw9++yzLt0g4oy/v7/at29vjr/66qtS5x89etTu860qjRs3Nl///PPPZa468dJLLyktLc2lY7v7GhZ32WWXmY+oyMvL0zPPPGO+17x5c7sbPFC6AsPQW8WW2B/YSGoWRFc+AAAAAAAAgKpDmA/Aq4WGhuq6664zxzNnztRvv/1mjm07953x9fXVZZddZo7ff/99rV271uHcHTt26N5771VKSop8fDzzI/Kee+6xCxBfeOEFLV68uMQ8wzD04Ycfatq0aS7VWtXXoU2bNnbd+f/+97/d2qF/0UUX6eabbzbHS5Ys0Ysvvugw/Ny7d69GjBihzMxMc5ttkOmtrrzySvP1qlWrNG3aNIfzkpOT9dhjj2nt2rUufz7XXXedevXqZY4XLFigJ598UsnJyU73OXz4sJ5//nlt2LChxHsJCQm69957zfHatWv10EMPKTEx0enxkpKS9O9//9vpShK2n+/q1av10UcfOZy3c+dO3X///UpLS5PFUrVhqu3fmQMHDmjChAkOb6BIT0/X+PHj9c0337j8mVTFNSzOtjvf9rMeMGBAlV+72uTb09L+bPttY5p5phYAAAAAAAAAdYdf2VMAwLNuu+02LViwQJJ05MgfrZH16tWzCydLM2LECLMTPTMzU8OGDVOvXr3UvXt3hYeHKyUlRWvWrNHKlStVWFio6Oho9e7dW59//rnbv56yhIaG6qWXXtKjjz6qwsJC5ebmasyYMerevbt69uypBg0a6OTJk1q8eLF27twpSXrkkUf0zjvvlHnsqrwOAQEB6tevn7744gtJ0jfffKNFixYpNjZWQUFB5rzevXvrySefrMCVkZ577jlt3rzZXI78888/108//aS+ffuqZcuWys7O1qZNm7RkyRK7kP/++++3C8q91ZAhQ/T++++bjzZ49dVX9d1336l3796KiYlRenq6tm3bpiVLligjI0O+vr569NFHNXXqVJeO/8orr+iuu+7SwYMHJUnff/+9fv75Z/Xs2VMXX3yxIiIilJ2drcTERP3222/asmWLJOmWW25xeLxnnnlGW7du1aZNmyRZw+i+ffuqR48e6tKliyIjI5Wbm6vjx49r06ZNWr9+vQoLCzVhwgSHxxs8eLCmTZumkydPSpImTZqkJUuW6LrrrlNkZKTOnj2rdevW6aefflJBQYF69Oih7Oxsuxt83K1Xr15q2bKlec0++eQTrVq1SjfddJNiY2OVnZ2tXbt2afHixTpz5owkafTo0Zo8ebJLx3f3NSxuwIABevPNN5Wfn29u8/Hx0cCBA12/CNDUYl35ncKkHqUvCgMAAAAAAAAAlUaYD8Dr9ejRQw0bNtTp06fttt90000KCAhw6RjdunXTmDFjNGXKFEnWJft/+OEH/fDDDyXmRkZGaurUqS49i7yqXHvttfrHP/6h559/3lzWe+3atQ476Xv37q3Ro0e7FOZX9XX485//rI0bN2r37t2SrEt7F4WgRS688EKXj+eopv/+97968MEHzeMeO3bMaQe3JN13333661//WuFzVqfw8HC98cYbGjVqlHkzwpYtW8xQ3Za/v7+ee+45tWzZ0uXjR0ZG6rPPPtOoUaPMZ9JnZmZq0aJFWrRoUbnrDQwM1IwZM/TUU09p+fLlkqyf+Y8//ljmYxwcCQsL06RJk/TII48oO9vaBr1x40Zt3LixxNyOHTvq//7v/zR69Ohyn6c8/Pz89Oabb+q+++7TuXPnJFlXfti7d2+JuRaLRY8++qhuv/12l8N8d1/D4qKionTNNdfY/R2/8sor7Vb/QOl2ZBhacsZ+25hmYmUDAAAAAAAAAFWOZfYBeD0/Pz+75beL9OvXr1zHGT16tF577TW755LbCggI0M0336x58+Z5xbPVhwwZov/9739Ow+/IyEg9/fTTevvtt+Xn5/q9WVV5HSIiIjR79my99NJL6tmzpxo3bmzXle8OTZs21bx58zRmzBg1aNDA6byLLrpIH330kf7+97/XqNCtR48e+vTTT3XxxRc7nXPppZfqf//7n4YOHVru40dGRurzzz/Xyy+/XOaNAC1atNCYMWPsnmVfXHBwsN59911NnTpVF110UanHi4mJ0fDhw3XVVVc5nXP55Zdr5syZ6tixo8P3w8LCNGLECH366aeqX796WqMTEhI0e/Zs9ejRo9Q57733XoVWnXD3NSyuf//+duNBgwaVu8a6bOpR+3Ejf+muaM/UAgAAAAAAAKBusRiGYXi6CNR+6enp2rVrlzmOj49XWFhYhY61Z88e5efny8/PT23btnVXiTVOZmamDMOQxWKxe045ypafn69NmzZp165dSktLU3h4uGJiYtStWzeFh4d7ujyHdu7cqd9//10pKSmKiIhQs2bN1L17d/n7+1f4mDXxOhRXUFCgTZs2af/+/Tpz5owCAgLUqFEjde7cWbGxsZ4ur9L27NmjTZs2KSUlRUFBQYqKitLFF1+sZs3c97DuQ4cO6ffff1dycrIyMzMVGhqqpk2bKiEhQXFxceU+3okTJ7Rx40YlJycrLS1NISEhio6OVnx8vNq0aVOuY9l+/WFhYWratKkuv/xyBQcHl7uu8nL2M7boEQRJSUny9/dXVFSUEhISdMEFF7jt3O68hpI0depUczWOiIgI/fzzzy6valJete3f6LN5huJ+lTIK/tj2bHPplTY15wYhwBtt2bJFeXl58vf3L/XmNQBAxfBzFgCqDj9jAaDq1Iafse7MQ4uwzD6AOsfPz09du3ZV165dPV2KyxISEpSQkODWY9bE61Ccr6+vunTpoi5duni6lCrRtm3bKg9EW7RooRYtWrjteI0bN1bfvn3dcqzq+PrLKy4urkI3OZSHO6+hYRiaO3euOe7Xr1+VBfm10fQT9kG+r0V6tObfJwQAAAAAAACghmCZfQAAgFpq1apVSkxMNMd33HGHB6upWQoMQ28dsd82oJEUF0RXPgAAAAAAAIDqQZgPAABQS7377rvm60svvVTt2rXzYDU1y3enpf3Z9tvGuO8JFwAAAAAAAABQJpbZBwAAqGVyc3M1depUrV271tz2yCOPeLCimmdqsa78TmHSVfU9UwsAAAAAAACAuokwHwAAoBb47LPP9Pnnnys/P19Hjx5VVlaW+d4VV1yha6+91nPF1TA7MgwtPmO/bXQzyWJhiX0AAAAAAAAA1YcwHwAAoBZITk7Wzp07S2xv2rSpJk6c6IGKaq6pR+3HDf2lu6I9UwsAAAAAAACAuoswHwAAoJbx9/dXbGysevfurZEjR6pBgwaeLqnGSM039MkJ+20jmkjBvnTlAwAAAAAAAKhehPkAAAC1wJgxYzRmzBhPl1HjTT8uZRT8Mfa1SI/Geq4eAAAAAAAAAHWXj6cLAAAAALxBoWHorWJL7A9oJDUPoisfAAAAAAAAQPUjzAcAAAAkfXda2pdlv210M8/UAgAAAAAAAACE+QAAAICkKUfsx5eESVfX90wtAAAAAAAAAECYDwAAgDpvZ4ahxWfst42OlSwWltgHAAAAAAAA4BmE+QAAAKjzph61H0f6SXfHeKYWAAAAAAAAAJAI8wEAAFDHpeYb+uSE/baHm0rBvnTlAwAAAAAAAPAcwnwAAADUaTOOS+kFf4x9JD0a67FyAAAAAAAAAEASYT5qIB8f67dtYWGhhysBAAC2iv5tLvq3uiYoNAy9VWyJ/QFRUvMguvIBAAAAAAAAeFbN+U0rcJ6vr68ka2CQl5fn4WoAAIAk5eXlmWF+0b/VNcGiFGlvlv220XTlAwAAAAAAAPAChPmocUJCQszXGRkZHqwEAAAUsf03OTQ01IOVlM+UI/bji0OlnhEeKQUAAAAAAAAA7BDmo8YJCwszX6elpXmwEgAAIEmGYdj9m2z7b7U325Vp6PsU+21jmkkWC0vsAwAAAAAAAPA8wnzUOMHBwebyvenp6UpJSSljDwAAUJXOnDmj9PR0SdYl9oOCgjxckWumFuvKj/ST7o7xTC0AAAAAAAAAUBxhPmoci8Wi6Ohoc3zy5EkdO3ZMGRkZMgzDg5UBAFB3GIahjIwMHTt2TCdPnjS3R0dH14jO9nP5hj4+Yb9tRFMp2Nf7awcAAAAAAABQN/h5ugCgIiIiIpSXl6fk5GRJUmpqqlJTU2WxWOTj41MjQoTKKigoMF8XrVQAAHAPfsaWzjAMFRYWlriJrlGjRoqIiPBMUeU044SU/sfHLB9Jj8Z6rBwAAAAAAAAAKIEwHzVWo0aNZBiGzpw5o8LCQknWcME2gKnNcnNzzdcBAQEerAQAah9+xpaPj4+PGjRooEaNGnm6FJcUGkaJJfb7R0ktgmr/zYAAAAAAAAAAag7CfNRYRcvtN2rUSOnp6UpNTVVeXl6dCfOzsrJkGIYsFov8/PirDADuxM/Ysvn6+srf31/169dXWFiYfHxqztObvk+R9mbZbxtDVz4AAAAAAAAAL8Nvp1Hj+fj4KDw8XOHh4Z4upVpt2bJFeXl58vPzU9u2bT1dDgDUKvyMrd2mFOvK7xgq9YzwSCkAAAAAAAAA4FTNaaECAAAAKml3pqFFKfbbxjSzrvgDAAAAAAAAAN6EMB8AAAB1xtRiXfkN/KS7YzxTCwAAAAAAAACUhjAfAAAAdcK5fEMzTthvG9FUCvGlKx8AAAAAAACA9yHMBwAAQJ3w8QkpveCPsY+kx2I9Vg4AAAAAAAAAlIowHwAAALVeoWGUWGL/9kZSiyC68gEAAAAAAAB4J8J8AAAA1HqLU6Q9WfbbxjTzTC0AAAAAAAAA4ArCfAAAANR6U4p15XcIla6J8EgpAAAAAAAAAOASwnwAAADUarszDX2XYr9tTDPJYmGJfQAAAAAAAADeizAfAAAAtdpbR+3HDfyke2I8UwsAAAAAAAAAuIowHwAAALVWWr6hGcfttz3URArxpSsfAAAAAAAAgHcjzAcAAECt9fEJKa3gj7GPpMdiPVYOAAAAAAAAALiMMB8AAAC1UqFhaOoR+223N5JaBtOVDwAAAAAAAMD7EeYDAACgVlqcIu3Ost82uplnagEAAAAAAACA8iLMBwAAQK1UvCu/Q6h0bYRHSgEAAAAAAACAciPMBwAAQK2zJ9PQtyn220Y3kywWltgHAAAAAAAAUDMQ5gMAAKDWeeuo/biBn3RPjGdqAQAAAAAAAICKIMwHAABArZKWb2j6cfttDzWRQn3pygcAAAAAAABQcxDmAwAAoFb5+ISUVvDH2EfSY7EeKwcAAAAAAAAAKoQwHwAAALVGoWGUWGL/tkZSy2C68gEAAAAAAADULIT5AAAAqDWWpEi7Mu23jW7mmVoAAAAAAAAAoDII8wEAAFBrTC3WlX9RqNQrwiOlAAAAAAAAAEClEOYDAACgVtiTaWjhafttY5pJFgtL7AMAAAAAAACoeQjzAQAAUCu8VawrP8JPuifGM7UAAAAAAAAAQGUR5gMAAKDGS8s3NOO4/baHmkihvnTlAwAAAAAAAKiZCPMBAABQ431yQjpX8MfYIumxWI+VAwAAAAAAAACVRpgPAACAGq3QMEossX9bI6lVMF35AAAAAAAAAGouwnwAAADUaEvPSDsz7beNaeaZWgAAAAAAAADAXQjzAQAAUKNNOWI/vihU6hXhkVIAAAAAAAAAwG0I8wEAAFBj7c009O1p+22jYyWLhSX2AQAAAAAAANRshPkAAACosd46Khk24wg/6d7GHisHAAAAAAAAANyGMB8AAAA1Unq+oenH7bcNbyKF+tKVDwAAAAAAAKDmI8wHAABAjfTJSelcwR9ji6THYz1WDgAAAAAAAAC4FWE+AAAAahzDMDT1iP22fo2kVsF05QMAAAAAAACoHQjzAQAAUOMsPSPtzLTfNoaufAAAAAAAAAC1CGE+AAAAapwpxbry24dIvRt4phYAAAAAAAAAqAqE+QAAAKhR9mUZWnjaftvoZpLFwhL7AAAAAAAAAGoPwnwAAADUKG8dkQybcX0/6b7GHisHAAAAAAAAAKoEYT4AAABqjPR8Q9NP2G8b3kQK9aUrHwAAAAAAAEDtQpgPAACAGmPmSSk1/4+xRdLjsR4rBwAAAAAAAACqDGE+AAAAaoQNaYYmHrLfdmtDqXUwXfkAAAAAAAAAah/CfAAAAHi13EJDz+03dNlvUmKO/XtjmnmmJgAAAAAAAACoan6eLgAAAABwZkOaoQd3SL9nlHyvaz3pugbVXxMAAAAAAAAAVAfCfAAAAHid3EJD/zwoTTwsFRgl3+8UJs3uIFksLLEPAAAAAAAAoHYizAcAAIBXKa0b388i/a2F9NcWkr8PQT4AAAAAAACA2oswHwAAAF4ht9DQvw5KE5x0418SJk1PkDrVI8QHAAAAAAAAUPsR5gMAAMDjXOnGH99CCqAbHwAAAAAAAEAdQZgPAAAAj8ktNPTyIWnCISmfbnwAAAAAAAAAMBHmAwAAwCM2nu/G3+KkG/+vLax/6MYHAAAAAAAAUBcR5gMAAKBaldWNf3GoNONCuvEBAAAAAAAA1G2E+QAAAKg2m9IMPbhT2pxe8j0/izS+hfQ3uvEBAAAAAAAAgDAfAAAAVc+VbvzpF0qd6cYHAAAAAAAAAEmE+QAAAKhidOMDAAAAAAAAQPkR5gMAAKBK5BYaeuWQ9Ard+AAAAAAAAABQboT5AAAAcLvSuvF9LdL45tLfW9KNDwAAAAAAAADOEOYDAADAbcrqxu94vhv/UrrxAQAAAAAAAKBUhPkAAABwC7rxAQAAAAAAAMB9CPMBAABQKbmFhiYckl6mGx8AAAAAAAAA3IYwHwAAABW2Od3QAzucd+M/21x6riXd+AAAAAAAAABQXoT5AAAAKLe8QkOvlNKN3+F8N34XuvEBAAAAAAAAoEII8wEAAFAum9MNPbhD2lRKN/7fW0qBdOMDAAAAAAAAQIUR5gMAAMAldOMDAAAAAAAAQPUhzAcAAECZyurGH9dceq4l3fgAAAAAAAAA4C6E+QAAACjVL2cNXb9Zyiks+d5FodL0BKlrOCE+AAAAAAAAALgTYT4AAABK9eaRkkG+r0V6prn0fEu68QEAAAAAAACgKhDmAwAAoFRrztmP6cYHAAAAAAAAgKpHmA8AAACnTuUaSsyx3/ZZe6lDGEE+AAAAAAAAAFQlH08XAAAAAO/1W5r9ONhHSgjxTC0AAAAAAAAAUJcQ5gMAAMCp9cXC/M5hkp8PXfkAAAAAAAAAUNUI8wEAAODUhmJh/qX1PFMHAAAAAAAAANQ1hPkAAABwqvgy+10I8wEAAAAAAACgWhDmAwAAwKFTuYYSc+y3EeYDAAAAAAAAQPUgzAcAAIBDxbvyg32khBDP1AIAAAAAAAAAdQ1hPgAAABwqHuZ3CpP8fCyeKQYAAAAAAAAA6hjCfAAAADi0oViYfylL7AMAAAAAAABAtSHMBwAAgEPri4X5XQnzAQAAAAAAAKDaEOYDAACghFO5hhJz7Ld1IcwHAAAAAAAAgGpDmA8AAIASfivWlR/sIyWEeKYWAAAAAAAAAKiLCPMBAABQQvEwv1OY5Odj8UwxAAAAAAAAAFAHEeYDAACghA3FwvxLWWIfAAAAAAAAAKoVYT4AAABKKN6Z34UwHwAAAAAAAACqFWE+AAAA7JzKNXQ4x35bV8J8AAAAAAAAAKhWhPkAAACwU7wrP9hHSgjxTC0AAAAAAAAAUFcR5gMAAMBO8TC/U5jk52PxTDEAAAAAAAAAUEcR5gMAAMDOhmJh/qUssQ8AAAAAAAAA1Y4wHwAAAHaKd+Z3IcwHAAAAAAAAgGpHmA8AAABTcq6hwzn22wjzAQAAAAAAAKD6EeYDAADAVLwrP9hHujDEM7UAAAAAAAAAQF1GmA8AAABT8TC/U5jk52PxTDEAAAAAAAAAUIcR5gMAAMBUPMy/lCX2AQAAAAAAAMAj/DxdQE1WWFioDRs26PDhw0pOTlZ4eLiaNGmibt26KSSk+tajTUxM1O+//65Tp04pMzNTwcHBioyMVPv27dW6dWv5+HDPBgAAcE3xML8LYT4AAAAAAAAAeARhfgUUFBToo48+0syZM5WUlFTi/ZCQEN1yyy0aO3as6tevXyU1GIah2bNn6+OPP9aePXuczouNjdWdd96pBx54QAEBAVVSCwAAqB2Scw0dzrHfRpgPAAAAAAAAAJ5By3Y5nTt3Tvfee69ef/11h0G+JGVmZmrWrFm67bbbtH37drfXkJ6ervvvv19///vfSw3yJeno0aN6/fXXNXDgQB0/ftzttQAAgNqjeFd+sI90YfUtNgQAAAAAAAAAsEFnfjnk5+frySef1IYNG8xtTZs21W233abY2FilpKRo6dKl+v333yVJJ06c0KhRozRr1izFxMS4pQbDMPTYY49p7dq15jZ/f3/17t1bnTt3Vv369ZWWlqatW7dqyZIlysrKkiTt2bNHDzzwgObOnavg4GC31AIAAGqX4mH+JWGSn4/FM8UAAAAAAAAAQB1HmF8O06dP16pVq8zxrbfeqgkTJtgtXz9q1Ch98skneuWVV2QYhk6ePKnnnntO77//vltqWLBggdasWWOOW7ZsqXfffVetWrUqMffkyZN6/PHHzZsLDh48qI8++kijR492Sy0AAKB22ZBuP76UJfYBAAAAAAAAwGNYZt9F6enp+vDDD81x+/bt9eqrrzp8Dv3999+ve+65xxyvWLFCv/32m1vqmDdvnvnax8dHkydPdhjkS1JMTIzefvtthYT8sT7uN99845Y6AABA7bP+nP24K2E+AAAAAAAAAHgMYb6L5s2bp7Nnz5rjsWPHys/P+cIGf/rTn+yWs//kk0/cUsf27dvN1x07dlR8fHyp86Ojo9WzZ09zfPDgQWVnZ7ulFgAAUHsk5xo6nPP/7N13nFxl2f/x75m2bbZkWwihRAgBCQSkKSgIiIJSFKW3BHsBRJFH9BHF8iA8FBGw8UMJQZAQxEcpNqSIUiVAlB4CSYAkW7K72dmdmZ1yfn+cJDv3mdlky8ycKZ/36+XLva8958yVMJmdnetc123G9qWYDwAAAAAAAACeoZg/Tn/72982fz1z5kwdeOCBWzy+sbFRRx555Ob1I488opGRkSnnMTAwsPnr7bffflzn7LDDDmNeAwAAQJKeHjTXdT7pnfW5jwUAAAAAAAAAFB7F/HGIxWJ68sknN68POuggWZa11fMOOuigzV8PDQ3lZdR+U1PT5q+Hh4fHdU40Gt38td/vV0tLy5TzAAAAlcVdzN8rLAV8W3+/AwAAAAAAAAAoDIr547BixQolEonN67322mtc573rXe8y1i+//PKUc9l77703f/3ss8+Oq9v/iSee2Pz1nnvuqZqaminnAQAAKsvSiLnehxH7AAAAAAAAAOApivnj8NprrxnrHXfccVznzZw5U36/f/N6xYoVU87ltNNO2/z1+vXr9dOf/nSLxy9evFivvPLK5vXZZ5895RwAAEDlcXfm70sxHwAAAAAAAAA8RTF/HN58801jPWPGjHGd5/f71dHRsXm9evXqKedy8MEH66STTtq8/tnPfqZvfOMbWr58uXHc6tWrdemll+qSSy7ZHDv55JN11FFHTTkHAABQWXpGbK2MmbH9KOYDAAAAAAAAgKcCXidQDiIRc+5sc3PzuM9tamrS2rVrJUlDQ0N5yeeSSy5RW1ubbrzxRiUSCd11112666671NjYqKamJkUiEQ0MDGw+vrGxUV/84hfpygcAADm5u/LrfNI7673JBQAAAAAAAADgoJg/DsPDw8Z6InvO19bWjnmdyfL7/Tr//PP1iU98QhdffLEee+wxSdLg4KAGB81P4+fNm6f/+Z//0Zw5c/Ly2PmyfPly+XwMhpiKRCKx+f+XLVvmcTYAUFmq7TX23uEOSdtsXu/iG9YL/3lt7BMAYAqq7TUWAIqN11kAKBxeYwGgcCrhNTadTuf9mhTzxyEejxvrYDA47nNDodDmr2Ox2BaOnJjFixfr+uuvV1dX1xaPW7ZsmY4//ngdf/zxuuiiixQOh/OWw1SkUimlUimv06gYm17gAAD5Vw2vsc8nzBsVd7UiVfHnBuA9XmsAoLB4nQWAwuE1FgAKh9fYURTzx8HdiZ9IJMbdnT8yMrL568wu/clKp9O66KKL9Pvf/35z7OCDD9bpp5+uefPmqampSUNDQ3rhhRf029/+Vvfcc4+SyaSWLFmi5557TosWLdK0adOmnMdU+f1+OvOnKPOFbCI3mAAAtq7aXmNfSjcY67mhkar4cwPwRrW9xgJAsfE6CwCFw2ssABROJbzGptPpvDczU8wfh/p6c9PYeDw+7mJ+Zje++zqT8fOf/9wo5F944YX69Kc/bRzT0tKigw46SAcddJAOP/xwfe1rX1M6ndYrr7yib33rW/rJT34y5Tymavbs2SUzJaBcLVu2TIlEQsFgUPPmzfM6HQCoKNX0GtubsLXmH2bsY7tvp3nh7b1JCEDFq6bXWADwAq+zAFA4vMYCQOFUwmtsJBLRyy+/nNdr0ho9Du6i88DAwLjPzdzDvqGhYQtHbl1fX59+8YtfbF4fccQRWYV8t6OPPlpnnHHG5vX9999ftvtMAACA/Ht60FzX+qTdp37/IQAAAAAAAABgiijmj8N2221nrNesWTOu81KplLGn/fbbT63D7YEHHjA6/U8//fRxnec+7v77759SHgAAoHK4i/l7h6WAz/ImGQAAAAAAAADAZhTzx2GnnXYy1qtWrRrXeW+99ZaxL4L7OhPlHsuwxx57jOu8WbNmGdMFli9fPqU8AABA5XAX8/dp9CYPAAAAAAAAAICJYv447LTTTgoGg5vXzz777LjOe+aZZ4z1nDlzppRHNBo11nV1deM+t75+dF5uPB6fUh4AAKByuIv5+1LMBwAAAAAAAICSQDF/HOrq6rT//vtvXj/22GOybXur5z366KObv66vr9d+++03pTyampqMdW9v77jOSyQS6uvr27xubm6eUh4AAKAy9CZsrYyZMYr5AAAAAAAAAFAaKOaP0xFHHLH56zfffFOPPfbYFo8fHBzUn//8583rgw8+WKFQaEo57Ljjjsb6n//857jOe+qpp5RIJMa8DgAAqE7urvxan7R7fe5jAQAAAAAAAADFRTF/nI477jijo/3KK69UMpkc8/hrrrnGGIt/1llnjXns4Ycfrl133VW77rqrDj/88DGPO+igg4z1DTfcoKGhoS3mnUgk9OMf/9iIvfe9793iOQAAoDq4i/l7haWAz/ImGQAAAAAAAACAgWL+ODU2NurTn/705vXzzz+viy66yOh43+SWW27Rrbfeunl98MEHT3nEviRtt912xoSAN954Q5/73OfU1dWV8/iBgQGdd955evbZZzfH5s2bl5dcAABA+VvqKuYzYh8AAAAAAAAASkfA6wTKydlnn61//OMfeuKJJyRJd999t5YuXapjjz1W2223ndavX6/7779fy5Yt23xOR0eHfvCDH+Qth4suukhLly7V+vXrJTkj9I844ggdccQRmjdvnpqamjQ0NKQXXnhBf/7zn43O/fr6el1yySV5ywUAAJS3f1HMBwAAAAAAAICSRTF/AoLBoK677jp97nOf0zPPPCNJeuutt/Tzn/885/GdnZ362c9+pm222SZvOWy//fa68cYbde655+qtt96SJMXjcd1777269957xzyvtbVVV199tebOnZu3XAAAQPnqTdhaGTNjFPMBAAAAAAAAoHQwZn+Cmpubdeutt+orX/mKOjo6ch5TX1+vE044QXfffbf22GOPvOcwd+5c/eEPf9CXvvSlMXPYpKWlRWeffbbuvvtuHXjggXnPBQAAlKenXV35tT5p93pvcgEAAAAAAAAAZKMzfxL8fr8+//nP6zOf+YyWLl2qlStXqre3V01NTZoxY4YOOOAA1deP/9PwBx54YMI5hMNhnXfeeTr33HO1YsUKPf/881q/fr2Gh4dVV1enlpYW7bbbbpozZ478fv+Erw8AACqbu5i/V1gK+CxvkgEAAAAAAAAAZKGYPwV+v1/777+/9t9/f89ysCxLO++8s3beeWfPcgAAAOVnqauYvw8j9gEAAAAAAACgpDBmHwAAoAq5O/P3pZgPAAAAAAAAACWFYj4AAECV6U3YeiNmxvajmA8AAAAAAAAAJYViPgAAQJVxd+XX+qTd673JBQAAAAAAAACQG8V8AACAKuMu5u8VlgI+y5tkAAAAAAAAAAA5UcwHAACoMktdxfx9GLEPAAAAAAAAACWHYj4AAECVcXfm70sxHwAAAAAAAABKDsV8AACAKtKbsPVGzIxRzAcAAAAAAACA0kMxHwAAoIq4R+zX+KTd673JBQAAAAAAAAAwNor5AAAAVcQ9Yn/vsBT0Wd4kAwAAAAAAAAAYE8V8AACAKuIu5u/DiH0AAAAAAAAAKEkU8wEAAKqIu5i/L8V8AAAAAAAAAChJFPMBAACqRG/C1hsxM0YxHwAAAAAAAABKE8V8AACAKrHU1ZVf45N2r/cmFwAAAAAAAADAllHMBwAAqBLuEft7NUhBn+VNMgAAAAAAAACALaKYDwAAUCXcnfn7NnmTBwAAAAAAAABg6yjmAwAAVAl3Z/6+jd7kAQAAAAAAAADYOor5AAAAVaA3Yev1mBmjmA8AAAAAAAAApYtiPgAAQBVwj9iv8Um713uTCwAAAAAAAABg6yjmAwAAVAH3iP29GqSgz/ImGQAAAAAAAADAVlHMBwAAqALuzvx9GLEPAAAAAAAAACWNYj4AAEAVcHfm70sxHwAAAAAAAABKGsV8AACACrc+Yev1mBnbr8mbXAAAAAAAAAAA40MxHwAAoMK5u/JrfNLu9d7kAgAAAAAAAAAYH4r5AABUsbRt6+pVtua/YOuv622v00GBuIv5ezVIQZ/lTTIAAAAAAAAAgHGhmA8AQBW76DXpa69Jt6yTjnxOWtJFQb8SLXUV8/dp9CYPAAAAAAAAAMD4UcwHAKBK/Tti60dvmrFPvyQtH6agX2ncnfn7UswHAAAAAAAAgJJHMR8AgCpk27bOeUVKuer2gynplOeleJqCfqVYn7D1esyMUcwHAAAAAAAAgNJHMR8AgCp06zrpkYHc31sakb62vLj5oHDcI/ZrfNLcBm9yAQAAAAAAAACMH8V8AACqzEDS1n+9tuVjfvKWdGcX3fmVwD1if68GKeizvEkGAAAAAAAAADBuFPMBAKgyl7wurR0xY/+zk1Tnelfw6Zek16IU9Mudu5i/DyP2AQAAAAAAAKAsUMwHAKCK/Dti6/q3zNjRbdJFO0jX7mLGN6Skk/8jxdMU9MuZu5i/L8V8AAAAAAAAACgLFPMBAKgStm3rnFekVEZtvsYnXbOLZFmWPjlDOmO6ec7SiPS15cXNE/mzPmHr9ZgZo5gPAAAAAAAAAOWBYj4AAFXitnXSIwNm7L92kHauc/ZPtyxLP50j7VpvHvOTt6TfdtGdX46Wurrya3zS3AZvcgEAAAAAAAAATAzFfAAAqsCGpK0LXzNjs2qd8fqZwgFLd8yVal3vED71krQiSkG/3LhH7M9rkII+y5tkAAAAAAAAAAATQjEfAIAqcMnr0toRM3bNLlKdP7uwu2fY0nW7mLENKenk56V4moJ+OXF35jNiHwAAAAAAAADKB8V8AAAq3H8itq57y4x9pFU6tm3scz45Qzp9uhl7elC6cHn+80PhuDvzKeYDAAAAAAAAQPmgmA8AQAWzbVvnvCKlMhrqa3zSj+dIljX2uHXLsvSzOdKu9Wb8+rek33bRnV8O1idsrYiZMYr5AAAAAAAAAFA+KOYDAFDBftMl/X3AjF24vbRz3db3TQ8HLC2eK9W63i186iVpRZSCfqlzj9iv8UlzG7zJBQAAAAAAAAAwcRTzAQCoUBuStr7mGou/Y6100Y7jv8a8sKVrd3FdNyWd8rwUT1PQL2XuEfvzGqSgb+s3cQAAAAAAAAAASgPFfAAAKtR335DWjpixa2ZL9f6JFXQ/NUM6fboZ+9eg9F+vTS0/FJa7M38fRuwDAAAAAAAAQFmhmA8AQAX6T8TWtW+asQ+3Sse1T/xalmXpp3OkOXVm/Lo3pbu66c4vVe7O/H0p5gMAAAAAAABAWaGYDwBAhbFtW+e+KqUy6uwhS/rxLk5hfjIaA5bu2EOqdb1z+NRL0oooBf1S05ewtSJmxvajmA8AAAAAAAAAZYViPgAAFeY3XdLD/Wbswh2k2fVT2y99XtjSj3cxYwNJ6ZTnpXiagn4pcXfl1/ikuQ3e5AIAAAAAAAAAmByK+QAAVJANSVsXLjdjO9ZK39gxP9f/9AzptOlm7F+D0tdfy8/1kR/uYv68Binom9rNHAAAAAAAAACA4qKYDwBABfneG9KaETP2o9lSvT8/hVzLsvSzOdKcOjN+7ZvS77rpzi8VS13F/H0YsQ8AAAAAAAAAZYdiPgAAFeL5IVs/ftOMfbhV+mh7fh+nMWDpjj2kWte7iE++JL0epaBfCtyd+ftSzAcAAAAAAACAskMxHwCACmDbts59RUpl1NJDlvTjXZxu+nybF7Z0zS5mbCApnfK8NJKmoO+lvoStFTEzRjEfAAAAAAAAAMoPxXwAACrA7V3SQ/1m7MIdpNn1hdsn/TMzpFM7zdhTg9J/vVawh8Q4uEfs1/ikuQ3e5AIAAAAAAAAAmDyK+QAAlLnBpK2vLTdjO9ZK39ixsI9rWZZ+vqu0S50Zv/ZN6f+66c73invE/rwGKeQr3E0dAAAAAAAAAIDCoJgPAECZ++4b0poRM3b1bKneX/gCbmPA0h17ON3fmT75kvR6lIK+F9zF/H0YsQ8AAAAAAAAAZYliPgAAZez5IVvXvmnGjmqVPtZevBz2Clv68S5mrD8pnfK8NJKmoF9s7mL+vhTzAQAAAAAAAKAsUcwHAKBM2batc1+Rkhn18pAl/XgXZwR+MX1mhnRKpxl7alD6+mtFTaPq9SVsrYiZMYr5AAAAAAAAAFCeKOYDAFCmFndJD/Wbsa/tIO1SX/z90S3L0s93lXapM+M/flP6v26684tlqasrP2RJcxu8yQUAAAAAAAAAMDUU8wEAKEODSVtfW27GdqiRvrmjN/lIUlPA0uK5Uo3r3cUnX5LeiFLQLwb3iP15YSnkK/7NHQAAAAAAAACAqaOYDwBAGfreG9LbI2bsR7tI9X5vC7d7N1q6ZrYZ609KpzwvjaQp6Bfa0oi5ZsQ+AAAAAAAAAJQvivkAAJSZF4Zs/fhNM3Zkq/Sxdm/ycfvsttIpnWbsyUHpote8yaeauDvzKeYDAAAAAAAAQPmimA8AQBmxbVvnviIlM5rcQ5Z07S7OvvWlwLIs/XxXaXadGb/mTen33XTnF0pfwtZrUTNGMR8AAAAAAAAAyhfFfAAAysgdXdKD/Wbsgh2kXepLo5C/SVPA0uK5Uo3rncbZL0lvRCnoF8JSV1d+yJLmNniTCwAAAAAAAABg6ijmAwBQJgaTti5YbsZ2qJG+uaM3+WzNuxot/Wi2GetPSqe+II2kKejnm3vE/rywFPKV1k0eAAAAAAAAAIDxo5gPAECZ+P4b0tsjZuzqXaQGf+kWbD+3rXRypxl7YoP0jRXe5FPJlkbM9T6M2AcAAAAAAACAskYxHwCAMvDCkK1r3jRjH5omHd/uTT7jZVmWfrGrNLvOjP9otfT7brrz88ndmb8vxXwAAAAAAAAAKGsU8wEAKHG2beu8V6RkRu07aEnXznGK5aWuKWBp8VypxvWu4+yXpDeiFPTzoT9h67WoGduPYj4AAAAAAAAAlDWK+QAAlLg7uqQH+s3YBdtLc+pLv5C/ybsaLV0924z1J6VTX5BG0hT0p8o9Yj9kSXMbvMkFAAAAAAAAAJAfFPMBAChhg0lbFyw3Y9vXSP89y5N0puTz20ondZqxJzZI31zhTT6V5F8bzPW8sBTylc/NHgAAAAAAAACAbBTzAQAoYd9/Q3p7xIxdPVtq8JdfodayLN2wq7RznRm/erX0hx6686fC3Zm/DyP2AQAAAAAAAKDsUcwHAKBEvThk65o3zdiHpkkf7/Amn3xoCli6Y64zBj7T2S9KK2MU9Cfr6UFzvS/FfAAAAAAAAAAoexTzAQAoQbZt69xXpGRGfTtoSdfOcTrcy9m7Gi39aBcz1peUTnleGklT0J+o/oSt16JmjGI+AAAAAAAAAJQ/ivkAAJSgJd3SA/1m7ILtpTn15V3I3+Tz20onuiYMPLFB+uYKb/IpZ+4R+yFL2qPBm1wAAAAAAAAAAPlDMR8AgBITSdq6YLkZ275G+u9ZnqRTEJZl6YbdpJ3rzPjVq6W7e+jOnwj3iP15YSnkq4ybPgAAAAAAAACgmgW8TgAAAJi+v1J6K27Grp4tNfgrq0DbHLC0eK6tg56WRjLq9/NflA6f5m1Bf2BwB9XYSR1tb9A8TzPZOncxfx9G7AMAAAAAAABARaCYDwBACXlxyNaPVpuxD06TPt6R+/hyt0+jpat3sXXOK6Ox/qR0V7d3OTmaJUl/TLRq225bH+0o3Rsp3MX8fSnmAwAAAAAAAEBFYMw+AAAlwrZtnfeqlMxoSg9a0rVznLH0leoL20onlujNCrYsnf2S9Ea0NEf/9ydsvRY1YxTzAQAAAAAAAKAyUMwHAKBE3Nkt/a3PjH11e2nX+sot5EvOjQo37CbtXu91Jrn1J6VTX5BG0qVX0F8aMdchS9qjwZtcAAAAAAAAAAD5xZh9AABKQCRp66vLzdh2NdK3ZnmSTtE1Byz9Yx9bd3RL60a8zka6781BPZEYbXF/YoP0jRXSVbM9TCoH94j9PcNSyFfZN38AAAAAAAAAQLWgmA8AQAn4wUrprbgZu3q21OCvnsJsS9DSZ7f1OgvHB/pX6dSBnbU6Xbs59qPV0iHNtj7aUTr/TZa6ivmM2AcAAAAAAACAysGYfQAAPPbSkK2rV5uxI6ZJnyjRfeSrQdiX1g/rXldQaSN+9kvSyljpjNt3d+ZTzAcAAAAAAACAykExHwAAD9m2rfNelZIZ9eGgJV27i7OXPLyzqz+qCxvWGLH+pHTK89JI2vuCfn/C1vKoGaOYDwAAAAAAAACVg2I+AAAeurNbur/PjH1le2m3Bgr5peDEmvU6qdOMPbFB+uYKb/LJtDRirkOWtEeDN7kAAAAAAAAAAPKPYj4AAB6JJG1dsNyMbVcjfWtHb/JBNsuSbthV2rnOjF+9WvpDj7fd+e4R+3uGpZCPm0AAAAAAAAAAoFJQzAcAwCM/WCm9GTdjV82WwgEKsqWkKWDpjrlO53ums1+UVsa8K+gvdRXz92HEPgAAAAAAAABUFIr5AAB44OVhWz9abcaOmCad0OFNPtiydzVaunoXM9aXlE59XkqkvSnouzvz96OYDwAAAAAAAAAVhWI+AAAeOO8VKZFRAw5a0rW7SJZFV36p+sK20omumy0e3yB9c0XxcxlI2loeNWP7UswHAAAAAAAAgIpCMR8AgCJ7dtDWX/vM2PnbS7s1UMgvZZZl6YbdpJ3rzPhVq6W7e4rbne8esR+ypD0aipoCAAAAAAAAAKDAKOYDAFBkv+8x1zNC0sU7epMLJqY5YGnxXKd4nmnBi9KqWPEK+v9yFfP3DEshHzeDAAAAAAAAAEAloZgPAECR3dNrrk/ulMIBCrHlYp9GS1fvYsb6ktIpz0uJdHEK+u7O/H0YsQ8AAAAAAAAAFYdiPgAARfR23NbTrkLsse3e5ILJ+8K20gkdZuzxDdI3VxTn8d3PoX0p5gMAAAAAAABAxaGYDwBAEd3r6spvDkjva/YmF0yeZVn6f7tJO9Wa8atWS/f0FLY7fyBpa3nUjFHMBwAAAAAAAIDKQzEfAIAiuqfHXB/VKgXZ67wsNQcsLd5DCrn+8y14UVoVK1xB3z1iP2RJezQU7OEAAAAAAAAAAB6hmA8AQJFEU7bu7zNjx7R5kwvyY99GS1fNNmPrk9Kpz0uJdGEK+u4R+3uGpRpuCAEAAAAAAACAikMxHwCAInmgT4qmR9d+S/owxfyy98WZ0gkdZuyxDdJ/ryjM47mL+fswYh8AAAAAAAAAKhLFfAAAiuTuXnP93iapNUhHdbmzLEv/bzdpp1ozfuVq6d6e/Hfnu4v5+1LMBwAAAAAAAICKRDEfAIAisG1b97qK+Ue3e5ML8q85YGnxHs7+9ZnmvyitjuWvoD+QtLU8asYo5gMAAAAAAABAZaKYDwBAETwTkd6Km7FjGbFfUfZttHTlbDO2Pimd+ryUSOenoL/U1ZUftKQ9GvJyaQAAAAAAAABAiaGYDwBAEdzTY65n10m71nuTCwrnSzOlT3SYsUc3SN96PT/Xd4/Y37NBqvGxVQMAAAAAAAAAVCKK+QAAFME97hH7bc5e66gslmXpxt2knWrN+BWrpHt7pt6d7+7M37dpypcEAAAAAAAAAJQoivkAABTY23Fb/3IVYY9t9yYXFF5zwNLtc50R+Jnmvyitjk2toO/uzN+3cUqXAwAAAAAAAACUMIr5AAAU2L2urvzmgHRwsze5oDj2a7J05Wwztj4pnfq8lEhPrqA/kLT1atSMUcwHAAAAAAAAgMpFMR8AgAJzF/OPapWC7HNe8c6ZKX28w4w9ukG6+PXJXc89Yj9oSXs0TO5aAAAAAAAAAIDSRzEfAIACiqZs/XW9GTu6zZtcUFyWZenGXaV31Jrx/10l3dc78e5894j9PRukGm4KAQAAAAAAAICKRTEfAIACeqBPiqZH1z5JH6aYXzVagpYWz3W66DPNf1FaHZtYQd/dmb8PI/YBAAAAAAAAoKIFvE4AACpOcp0UuUXybyOFT5asoNcZIdPwvVL075JSRXm4UJ+tK1pG1zNrpLYNGZXdmn2lhhN4nkhSqlsa+p3ka5IaTpQsv9cZ5cV+TZaumG3r/FdHY70J6bQXpAf2tse95YK7M3+/pjwmCQBFVO9bppqapxXVgZLmeZ0OMqUHpcFfScnVXmcCYApmhLqVCqTl9/mk3o6tn4DqZAWl2g9I9Ud4nUlpiD8rDd0l2cNeZ+LwbyM1LpD87V5ngkwj/9b00E9lB4ZK4zXW3ymF50uB6d7mAWDiRl6Rhm6X0hu8zsTh39apZQRmep0JcqCYDwD5lHxbeusAKfWWsx55Vmq70tOUkGHwJqn7k0V9yA/6pQ82u4IDrnXTk1L7j4qVUmmy49Laj0jxfznr5qektqu8zSmPzp0pPdwn/a5nNPbPAenbr0s/3Hnr5w8kbb0aNWP70pkPoBwN3qqd6+bLstJK29dLww1S/dFeZwVJSkelNYeP/iwGULY6QhkL9+8egOEyqf0GqekzXifirehD0pojJY14nYlp8AZp2yck/zSvM4EkxR6T1hyu6aHYaKwUXmM3/Eya+aTk5+YtoGyM/Ft6672SPbj1Y4tpw8+k7Z6RfGGvM4ELY/YBIF/spNR16mghX5I2XC+l+rzLCabI7V5nkNuG66VUl9dZeGvoLrN4MPhLyZ74vvKlyrIs/XI3aVatGb98lfTH3q3/OZ9xvbcPWtIeDXlMEACKYeR5qeczsixn/xmflZS6zpQSKz1ODJKk3i9TyAeAatRzjhRf6nUW3kmucz7LKbVCviQlXpW6z66o343LVqpXWneyZMe2fmyxJd9w3lPb6a0eCqAEpAeldSeWXiFfkpLLpcRyr7NADhTzASBf+r4jxf5uxuy4My4HGk7ZGkl7/Atoap23jz+mpDR4q9dJeGtwoblOD5Tmm9opaAlaWjzXKcRnOutF6c3Ylv9t/Mv1V7Fng1QzzvH8AFAS0pGNH1i4xoyk+6SukyW7BD9AryaDv5YG/5/XWQAAPDHi/IxOl0KLcZHZKanrNCm11utMxjb8e2ngGq+zqG52Wuo6S0qV8DZE0T9L/Zd5nQWArbFtqefzUuJlrzPJzb+dFHyH11kgB8bsA0A+DP9R6r809/cGb5KavlDcfEqIbdv6+mvS1aulaUHp9t1tfaDVoyJkar25rvug5C/cPkD39ErdidH17vXSuzftcz7ytDNSaZPITVLz+ZJVhQXa5Gop+tcc8bVSqLI2ht+/ydIVs22d/+porDchnfqC9ODetgJjFOiXuor5+zBiH0A5sW2p5wtS4sXc348/IfV+nS1nvDLyotTzOTNm1UsNJ0qqwvclQAVY37de6bQtn89S67RWr9NBKUqulGIPZqxXSF2flKbfWV2/k/Z9T4o9YMZCezv/89Lw3VK6d3S9/r+k2gOl2vd4l1M1G/hfKXqfERpOzlbM3t3b19jofeaUx76LpdqDpLpDPUsJwFYM3iBFbjNjwTlSzUHe5JMpsK3UuEDyufeLRSmgmA8AU5Vc7YyzGkv8KWesbGhu8XIqIXd1S1duvHm5NyF96iXptQNt+b34gCDt2vJg2iXOLzoFsCZu67jnzdhft5O06UaG6APSmg+MfnPk39LIUqlm34LkU9IGF0nK0ZmeWitpTrGzKbhzZ0oP90m/6xmN/XNAuvh16Yc75z7naVcxf1+K+QDKyeAvpcivt3zMhmukukOkhuOLkhI2Sg9tnJgwbMbbfyE1nuFNTgCm7M21y5RIJBQMBtXaOc/rdFCK7IT09iFS/PHR2PBd0obrpObzvMurmIb/IvV/34z5Z0oz/ir5273JaZPhP0lrP5wRSErrTnL2Mfa3eZZWVYr+XVr/LSOUSLfp1cj1sgIzvH2NjT608XOlTeP1086WETOflQLTvcsLQG7xZ5ytzTL5mqVt/igFd/ImJ5QNxuwDwFTYCWfPrMw7piVl3Ss1eFPRUiolQylbX3Vts7MqLj3Yl/v4grJHJDtixnzTCvZw97qeEk1+6eCWjEDtoVJglnlQNT5PbDt7xP4mpTzqcAosy9KNu0mzas345aukP/Zm39QwkLT1qmsqNcV8AGUj/qzUe44RStlhvRa5XGk7ZB7bfbaUeK14uVU725Z6viglXHcfNn6GQj4AVDorKE1fLPlcXcW9X5NiT3iTUzEl35K6zpB5U7nf+TvxupAvSfVHSS3/bcZSq51R7+yLXjypLqnrFEmpjKBPq+KXKWmXwPOk7lBp2vfMWGqts3WEncp5CgCPpAc23kQdN+MdN1HIx7hQzAeAqVj/DSn+mBmrP15q/ooZi9ziFP6rzP+8Ia2OZ8dv9qJGm8pxB4H7g4s8usdVzD+qTQpljlC3fFJ4vnlQ5DYpHStYTiUp9g8puTz39yq0mC9J04KWbp8rBV0DKua/KL0ZMwv6z7i68oOWtGe4wAkCQD6kN+T8wGJ17LvqT3xAb8f/y3X8gNN1Vm0/C70yeJMUWWTGQntJbT/2Jh8AQHEFdpA6b3EFE1LXSdlb1FUSO+l0L6e7zXjrZVLte73JKZdplzhNAJmi9zkj31F4dkrqOl1KrTHj076rodQB3uSUS8s3pLojzVjsAWcLCQClwbal7k9JSdeN681fYTIdxo1iPgBM1tDvpYGrzFhgJ6njV1LjJ814qssZk1ZFXhm2ddXq3N+7q9vpNi4q94h9SfIXpjM/mrJ1v+uzj2NyTcJrdBXz033O3njVJLJw7O+5f2muMAc0Wfpf11j9noR02gtSMj3678M9Yn/PBqnGV0X7WAIoT7YtdX86+4atpi9rQ+oISdL65AlS+DTz+yNLpfUXFCnJKhZfJvV+yYxZjdL0JZKvzpucAADFV/8RqeUiM5ZcJXXPr9wO8L6LpdgjZqz+WKm5xN5/WAGp8zbJ7xqXvv5bzuh3FFb//0jR+81Y3Yeklm96k89YLJ/U+Wtni4hM/d+Xhv/qTU4ATBuul4Z+a8Zq3u3cRAaME8V8AJiMxOtS9wJXMOR8AOpvkUK7STXvMb9dRSPUbdvWea9IiTHq9dG0tKSruDkp7aquWw2SFcp97BQ92C8NZ3zu4ZP04VzF/OA7su+0r6LnidJDUuSOsb+frNzO/E3O2076mGs63z8GpG+/Prpe6irm78OIfQDlYMNPpaElZqzmAKkts5vMcvZmD+6WfW7k9oKnWLXSg1LXiZLtmoDQcaMU3MWbnAAA3pn2fan2YDM2fE9280IlGL5X6ncVTwI7Sh0LJasEb5gOzHAK+srMLeWMfk8V+0OVKhL9m9R3iRnzz3SK5lYJllP87c4WEfJnBG1nskDyLa+yAiBJsSelXtfNYr5WafodBftcGpWpBH/6AECJs+NS18lSut+Mt18j1ewzum482/z+8N1SyjXGrUL9rkf6i6sRvtb1E6foo/bdnfkFHLF/d4+5PqhZanPPU9/E/TyJ/rl6ftkaulOyI2N/v4LH7G9iWZZ+uZs0q9aMX7ZK+lOvczfMv1zF/H0p5gModfF/Sb1fNWO+aVLn4uwPLHxh52ZIy9UN3v0ZaeTlwuZZjWxb6v6slHjFjDedI4VP8iYnAIC3rIDUebvk6zDj678hxf7pTU6FkFzl7DlvCEqdd0j+wn0+MGV1h0vTvmvGUmucQi37oudfco2z57wyu1P80vTbJX/HWGd5r/a92V2+6W5nSwk76U1OQLVLrXe2rpFr693ORc5WN8AEUMwHgInqvVCKP2XGGk6WGj9vxsInS1ZmhS4pRW4teHpeG0rZ+sqrZmxmjXTDrmbsnwPSq8NFHLXv3vOvQCP2bdvWvb1mLOeI/U0aPuGMtd0sLUXc+xZWqKwpBEFzWQXFfEmaFrR0+1zJfb/HWS9KLwzZejVqxinmAyhpqT5p3YmSRsx4xyIpOCv3OaE9pPafmjE74nSPp6O5z8HkDP5CGnJNPajZT2q70pt8AAClIbBt7g7wdSdXRlOCPeL8WdwT+9qulGpLaP/zsbR8U6r7oBmL3u+Mgkf+2Emn+O2eetB6qVT7Pm9ymojmC5wtIzLFHnG2lgBQXLbtTPVNrjTjzV+X6o/2JCWUN4r5ADARkSXShuvMWHCO1PH/skey+Zqlho+bscGbnB/mFezSldLquBm7cmfp5E6pw1WrLWp3vvuX9gJ15j8Xkd50/fmPac99rJNHQ3YnXBU8T5RYIcUeNmONri6JKinmS9IBTZYu39mM9SSkI58zY0FL2jNcvLwAYEJsW+o+W0q+YcabL5QajtnyuY0LpPACMzbyb6n33DwmWOXiS6WeL5sxX7PTkWjVeJMTAKB01B8htXzbjKXekrrOlOx07nPKxfqLpPjjZqzhE1JTmbzPsPwb90Xf1oz3XeKMhEd+9H0n+3OK+mOk5q95k89EWZazZURgRzPef5mzxQSA4hm4ypnSm6n2YKn1B97kg7JHMR8AxiuxXOr+lBmzaqXOJZJvjFbZsGuE+sgyaeTZgqRXCl4ZtnXlKjN2eIt0UqcU9Fk6dbr5vUVrpVSxitap4ozZv9vVlb9TrfTO+q2c5B61n3hFij+W17xKzuDN5trXKjV+xoyluqpqbOCXt5M+6rrx4y3XjSF7NEg1vhLcyxEAJGngGmn492as5r1S6zi7xtp/IgX3MGODv5QGF+UlvaqWHhhjYsJCKfgOLzICAJSiaRdLdR8wY9E/S/0/9CaffBj6nTTwIzMW2Fnq+GV2U0Yp83c62yFk7Yt+mjMaHlMz/Eep/1IzFthB6rhZssqohOJvdW7UdE8+7DrL2WoCQOHF/uncRJbJ1yF1/sbZ2gaYhDL6SQQAHkpHnQ9Abdfm1W3XSzXzxj6v7vDsPXCyRotXBtu2dd4rUiKjNh+wpOvmOPuCS9KCbcxz3oxLD7pq7AXj7swv0Jj9e3rM9THto3/+MdUcJAV3MWODC/OaV0mx01LEVcwPn5Z997jSlTHScZwsy9KvdpN2rB37GEbsAyhZscek9f9lxnztzv6iVjD3OW6+emn6EslqMOM9X5BGns9PntXItqWuT0rJFWa8+atSw8c8SQkAUKIsv9Rxq+R3/fLe920p+qA3OU1FYoUzNSiTVSNNv8OZTlNu6g7Ovkky1cW+6FOVXO1MoDAEnaK4vzCNIAVVe0D2Fkrp9c5WE/ZI7nMA5Eeq2/m3pszmJEvqvFUKzPQqK1QAivkAMB6952d31IfPkho/ueXzLJ8Unm/GIrdKdjz38WXsdz3SX1yF+fO3k97ZMFrI3rvR0l6uEeFFG7WfLnxn/pq4radc93sc2zaOEy0re7Rw5HYpPZyv1EpL7MHsPaMaz5b8Hcp6a1JFo/YlaVrQ0uK5zjj9XCjmAyhJqd6NH1hkfohsSZ23SIHtJnat0G5Sxw1mzB52bqpMR6aaaXXacK00fJcZqzlQar3Mm3wAAKUtMH1jB3jm72bpjR3gZfT7mR2X1p3kTKfJ1PZjqWYfb3LKh+YLs/dbjj3sjIjHxNkJ531s2jVmse0Kqfbd3uSUD03nOltJZIo/nt0tDCB/7LRzY1DqLTPecrFU/0FvckLFoJgPAFszeKs06PpQObi71P7T8Y1ka3QV89PrpaG7cx9bpoZStr76qhnbNiRdPCv72PmuG/zv6pY2JIswaj/l6sz35b8z/z7X735NfunglnGe3HiWjB/L9qA0dNeYh5c193SK0Dwp9C6nC8TfYX6vyor5knRAk6XLds79PYr5AEqOnXbGdqZWm/GW/5bqj5rcNcOnSY2fM2OJF6WeLzpd5hi/2BNS74VmzNcqTV88/okJAIDqU/d+adr3zVhqrVPQL5et0HovkEaeNmMNp0qNn/Umn3yxfM7od//2Zrz/UmdUPCZm/Teztzms/7jUdJ43+eSLZTlbSQRcHy4M/MjZegJA/vVf5mxNk6n2cGnat73JBxWFYj4AbMnIS1KP68Nka+MIWF9D7nPcgjtLtYeYsQobtX/pSmmVa9jAVbOlxkD2zQ6nTXfG728STUtLugqcoJRjzH7+O/PvcRXzj2yVQuPd3zywnVTnukuzwp4nkpyuiKHfmrHGs0dvjHGPc6zCYr7kTLU4rt2MBS1pz3Du4wHAMwP/K0XvM2O1h0rTLpnadduukUJ7m7HILdLgL6d23WqSWi91nSQpYcY7b5EC2+c8BQCAzVoukupcN+bFHpT6vutNPhMRWSxt+IkZC+4qdfxifE0Zpc7f5mwVINfey11nOiPjMT5Df5AGXOPoAzs5RfBKeJ74mp3niVVjxrvPdragAJA/0YekvovNmH8bZ7y+5fckJVQWivkAMJb0sLTuBMkeMuPtv5BCu0/sWo2uPdqif5KSa6aWX4l4ZdjWVavM2OEt0kmduY/vDFk62jV6viij9gs8Zj+WsvVX1/0Cx7TnPnZM7udJ7AEp8cZU0io9kTskO5YRCEjh00eX/hnm8RXy72SiLMvSTbtJu9SNxs6eIdWM9+YQACiG6N+l9d8yY/7pUudtU//Awlfr3DxpuUaS9J4rxZ+b2rWrgZ2WuudLSdebtJaLpPqPeJMTAKC8WD7nBjC/a8uc/h9Iw3/xJqfxGHlF6v60GbPqNjZlVNCos9r3SK3/a8bSvdK6U5zR8diyxBvOeyVDyHme+Fs8SKhAavZxbpLNlB5wtqCowC1AAU8k10ldp0pKZwR9UudvpMA2Y50FTAjFfAAYS8+XpMTzZqzx01LjGRO/VsMJkpXZyZ92usvKnG3b+vKr0kjGxNuAJV07xylGjsU9av8fA9Ly4QKPzS3wmP0H+6XhjPdsPkkfnuj9AvUflXwtZiyyaGqJlRr3tIH6Y8zR+nTmbzYtaOnJ/aQfzZZ+tZt0/S5eZwQAGVJdUtcpkjJH7fqcQn5gxlhnTUxwttTxKzNmx6SuE6X0hvw8RqUauEoavseM1R6cPTIZAIAt8bc7W7MYHeC21HW6lHxrrLO8k4467xPsiBlv/4kU2tObnAqp+Xyp/mNmLP6oMzoeY7PjzvSidL8Zb7/GKX5XmsbPOVtMZBp52tmKAsDU2ClnCxr355fTvifVHepJSqhMFPMBIJfBm6TIQjMWmie1XTu56/nCUsNJ2Y9R5vu+/l+P9GdXjfzL20m7N2y5e/gjbVK7a5vWgnbn23Z2Z36ex+zf3WOuD2yW2kMT7KL21Uph1y9Ygwud7rpKMPJS9l507mkE7jtWq7iYL0nNAUtf3t7SghmWAnTlAygVdsr5ED/lmp4y7RKp7vD8Plb4BKnpXDOWeFXq/kzZv48qmNg/pPXfMGO+DqnzdskK5D4HAICx1B4ktV5mxtI9zk19dtKbnMbSe540ssyMhRdk/95ZKSxL6rhJCrzDjA9c6YyQR269F0rxp8xYwylS4+e9yafQLMvZYiK4qxnf8BNnSwoAk9f3PWeyaqa6I6WWb+Q+HpgkivkA4Dbyb6crP5MVljqXSL663OeMh/uXx8RLUvyJyV/PY8MpW1951YxtG5K+PWvr54Z8lk6bbsYWrZXShfpQ3o5Icn3IkMfOfNu2dW+vGTumLfexWxV2PU+Sr0uxv0/yYiVmcKG59ndK9R92xSjmA0DJ6/8fKXq/Gav7kNTy34V5vLYrpJr9zdjQHdKGnxXm8cpZqtsZr2tMTLA2TkzY1qusAADlrvmrUv1xZiz2j+ztdrw0eIs0eKMZC851uvIrmb/FGQ2vkBnvnl952/blQ+ROacN1Ziw4R+q4wSl6Vypf48YtrFyfa3Z/xtmaAsDEDf9V6ndNPvPPlDp/7WxVA+QRzygAyJQelNadKNlRM95xoxSaM7Vr175PCuxsxtwjx8vIpSulVa7tta6cLTUGxvfLzwJXzXZ1XHqwL/exU+YesS/ltTP/uYiTf6Zj2yd5sZr9nA8cMpXx82QzO5m9ZUD4TMlyjWigmA8ApS36N6nvEjPm37awH1hYNVLnHdlb0fR+RYr/qzCPWY7stNR1hpRyjT1u+bZUf4Q3OQEAKoNlSR0LpcAsMz5wuTR0T64zimvkBanH1VVtNTjFS1+9NzkVU82+UtuPzFi63xklz77ooxLLpe5PmjGrdmPzTqM3ORVTaM/sm1vswY1bWEVznwMgt+RbzrQ6ZTam+Z2tafyT/VAYGBvFfADYxLadX/4SL5vxpi9J4ZOnfn3LkhoXmLHI7WX5hvnVYVtXrjJjh7VIJ3eO/xp7N1qa12DGCjZq3z1iX37Jasrb5e9xdeW/o1Z652Q/L7Cs7CkOQ3c6N5qUs+hfs8cxu/89SJLftc9yck32MQAAbyTXOPsBuj+w6Lxd8ncU9rGDs6SOm13BEWndSVKqv7CPXS76L5WifzFjdR+Qpl3sTT4AgMrin+bcXCfXDdndZ0mJlZ6kJElKD21syhg24x03SKF3epOTF5q+IDW4PruKP+WMlIeUjm18nrg+W2n7iVQzz5ucvNB4trP1RKaRZc4WFQDGx05KXadK6W4z3nqZVPteb3JCxaOYDwCbDN4gRW4zY6F9pbar8vcYjfMlZXSu2xuk4d/l7/pFYNu2vvyqNJLxOX7Akq6dI1kTHEk231W3/W23tCFZgFH7aVdnvq8lr+PT7ukx18e0T/zvwhA+Q5J/dG0PS5Elk79eKXBPF6jZTwrtkX2cuzPfHnQ+nAEAeGvTBxapLjPe+j9S3cHFyaHhOKn5a2Ys+brUfbZzU2Y1iz4o9X3HjPm3kTpulSx/7nMAAJio2v2zPyNJ90ldJ0v2SPHzsW2p5wtS4gUz3vhZKXxa8fPxkmU5NzAEdzHjG65zRstXu97zpZFnzVj4rOxmimrQ/pMcEyFvdLaqALB1fRdLsUfMWP2xUvMF3uSDqkAxHwAkKf6M1PtlM+Zrlqbf4Yx2zZfA9lKda8xpmY1Q/32P9CdXbfy87aS5DRMvXp8+3bkRYJNoWlrSNfbxk5ZydebnccT+2ritJ103dh/bNsWLBqZL9R8xY5Hyep4YUuulod+bsfAYvzAHtsmOpdblPycAwMT0fUeKPWzG6o+Wmovc7dV6qVRzkBkb/j9p4Jri5lFKkmudGy2Uzgj6nIkJgeleZQUAqFRN50gNJ5ix+BPS+ouKn8vgr6SIqwAZ2ltq+3HxcykFviZnZLxVa8a7P+mMmK9WkdukwV+YseDuUvtP89roUTZ89c4WFJZrXGbP550tKwCMbfheqf8yMxbY0ZkiV42vJygaivkAkB7YOGrLtY9Yx01ScKf8P577rt/o36TkqtzHlpjhlK3zXzVj24ak78ya3PU6Q5Y+4ip8LyrEqP2szvxpebv0va4R+41+6ZCWPFzY/TyJ/UNKvJr72FIXuU1SRpeGVSOFT819rNUoWXVmLFWo/RcAAOMy/EdnhHumwA4bP7Ao8q+UVlCafrvkc72BWP9fUuzx4uZSCuyUs/WB+8a3ad+X6t7vTU4AgMpmWVLHjVJgZzM+8CNpqIiTB+PLpN5zXLk1OkVKX23uc6pBzV5S23VmzB50PvdKx7zJyUsjL0ndnzVj1sZitq8h9znVIPROqd11g4M9vPF5wnREIKfkKqnrLFcw6GxB48/fZ81ALhTzAVQ325a6PyUlXzPjzV+RGo4vzGPWf8zp+h9NQhp07wFbmn64UlrluufhitlSY2Dydx7OdzViPzIgLR/O86jcrGJ+/jrz3cX8I1ulkC8Pd2LWHy352s3Y4MKpX9cL7ukT9R8b+02uZWWP2qeYDwDeSa6Wus50BQNS52LJP9VRNJMU2F7q/LUrmJTWnSSlenOeUrH6vivFHjRjdUdJLR50RwIAqoeveWNnr2uSYffZUmJF4R8/vUHqOkGyXcXpjl9KwdmFf/xS1/gpKex6/zbyrDNqvpqkh6V1J0i2qzjd/gsptLs3OZWSxtOdLSkyJV5wtq6o9i2sADd7RFp3cvZnzG1XSrUHeJMTqgrFfADVbcP10tBvzVjNe6TWy3Ifnw++OqnhFDM2uLDk3yi/OmzrCtcAgUNbpFM6p3bdo9uktqAZy3t3foHG7MdStv7ieg93THvuYyfMCknhM8zY4M1OB145iS+TRpaasa3tSeefYa6Ta/KbEwBgfOyEtO4UKe0qkLddIdW+x5ucNqk/Smr5phlLrXY6Jex07nMqzfBfpP4fmDH/dlLnLcWfmAAAqD4175LarjVjmyYfFrID3LadTmv35Lqmc6XwiYV73HJiWVL7z5xR8pkGf7Fxcl6V6PmSlHjejDV+Rmo8I/fx1ajtx87WFJkitzhbWAAYtf4iKe6aBNfwCednD1AE/IYPoHrFnpR6LzBjvlZp+mKnkFpI7mJmcoUUe6SwjzkFtu2M1x/JuN8gYEnXzZGsKe4HFPJZOs21neuitVI6nzc3FGjM/oP90nBGvcAn6SP5a/rPfp6k3pKi9+fxAYogstBc+2dKdUds+Rw68wGgNKz/phR/1IzVHy81fdmbfNymfVeqdY2Sj94nDVzhTT7FlHxL6jpdUub7pYDzPtafrzsLAQDYisbPSOHTzNjIUmn9BbmPz4fBn0tDi81Yzf7OzYYY5WvYOD2h3ox3f9YZPV/pBm/K/jwitJdTvMYoX+3G50mjGe89x2nOAOBsITPwIzMW2NmZBjPFz8WB8aKYD6A6pdZLXSdJSpjxzkXOHrCFVnOAFHynGXOPIi8hv++R/uiqh5+3nTS3IT9vWBa4arer4tJD/Xm5tCPt6szP05j9u3vM9YHNUnsoj2/iauZJoXeZsXIatW8npEHXGOTGsyTLv+XzAhTzAcBzQ3+QBq40Y4F3SB2/Kp0PLKyA1Pkbye8aE7T+v6Vo6d4kOWV2Uuo6RUq73oi0XibVHuRNTgCA6mRZzsjy4G5mfMNPpcji3OdMRfxpqed8M+Zrcbb/cY/8hzNKvv3nZswe2jg9YdibnIph5D9OV34mq9HZ19pX501OpSw42ylKZrJjUteJUnrQm5yAUpFY4Wwhk8mqcW6CMbbRBQqLYj6A6mPbUvcCKbnSjLdc5OxTXgyWld11PbRESkeK8/gTMJyy9ZXlZmxGSPrOrPw9xt5haV6DGbs5n5PVU/nvzLdtW/e6pg4fXYitg93Pk+HfZW8bUKqG75XS3WYsvGDr59GZDwDeSrwhdc93BUPOBxb+Fg8S2oLADKnzNkmZNxiknGJ3qsurrApr/bek2D/MWP1xUvNXvckHAFDdfOGNnb2uImn3p6WRV/L3OKl+pwitETPesVAKviN/j1NpGs+UGj9lxhL/kXrO8SafQktHpHUnSHbUjHfcKIXmeJNTOQifKDW5nhOJV5xJDiW+LShQMHZcWneSs4VMprYfO1vNAEVEMR9A9Rm4Shq+24zVHixN+35x8wifISmjQ9kecgr6JeaHK6WVru3urpwtNQby15VnWZbmu7ZJv7Nb2pDM0y8M7jH7/ql35i8bklbHzdixhZhqGz5NUsa2D3ZcGrq9AA9UAO5pEzXvHd8vz+5ifjKfd3YAALbIHnGmF6X7zXjbj6SafT1JaavqPiBNu8SMpd52xtDbKU9SKpihe6SBy81YYJZTyCiViQkAgOoT2kNq/6kZsyMbO3ujuc+ZCNuWuj8pJV83480XSA0fnfr1K13bdVJonhmL3FTSEyInxbalns9JiZfNeNOXpPBJ3uRUTtqulGr2M2NDtztbWwDVqPcCaeRpMxY+TWr8rDf5oKpRzAdQXWL/lNZfZMZ8Hc6IVitQ3FwCM6T6o8xYiY1QXz5s64pVZuz9LdIpnTkPn5LTp0uZ9wdE005BPy8KMGbfPWL/HbXS7vW5j50Sf5vUcJwZK4dfuJPrnM78TO4pA2Pxu+7soDMfAIqn90Ip/pQZazhZavqCN/mMV8t/S3VHmLHo/VL//3iTTyEkVkrdZ7mCQWdkrH/qU4cAAJiSxgVS2PU738gyqfe8qV97w4+dKXWZag6UWn849WtXA1+d1LlEssJmvOdLzkj6SjF4gxS5zYyF9pXarvImn3Jj1WzciqDFjPec72xxAVSTyGJpw0/MWHBXZ2sZbqKGByjmA6geqW5p3cmSMju0LKnzVikw05uc3L/oxv4uJV7zJhcX27b15VelkYzmeL8lXbeL00mfb50hSx921djzNmrfPWY/Dx945xqxX4i/F0nZRfD4U9LI84V5rHyJ3Crj35pV54xtG4+Ae8z+OslO5y01AMAYIndKG641Y8FdpI4bSv8DC8vvvKdz3xDWd4kU/ZsnKeWVPSJ1nZx9g2LbVVLt/t7kBACAW/v1UnAPMzZ4ozR4y+SvGXvcudkwk69Nmr5YsoKTv261Cc1xRs1nsqPOSPoS3PJxwuLPSL1fNmO+5o1bQNR4k1M5Cr7DmfhkGHFGjaf6PUgI8MDIK1L3Z8yYVee8nvjCuc8BCoxiPoDqYKelrjOl1FtmvOViqf6D3uQkSQ3HOr+EZiqR7vw/9Eh/dNXAz9tO2iNcuA/z3aP2HxlwpgNMiZ2Q7EEzNsXO/HUjtp7cYMYKMmJ/k7oPZRcnSuR5kpNtZ08PaDhB8jWN73z3mH0ls7dKAADkV2K5M742k1XrdHGN9/Xba/5OqfN2GdsYyZa6Tiv/LVt6vy7FnzBjDSdk720KAICXfPUbi6cNZrzn89LICxO/XqrXuZlNSTPeeYsU2H7SaVat8MlS0xfNWOJlZzR9Oe+Lnh6Q1p3obEuYqWOhU5zGxDR81NnCIlNyhfO7Qjk/T4DxSEedLWLcnyW3/1QK7elNToAo5gOoFv2XSdE/m7Haw6Vp3/Ymn02skBQ+3YwN3uz5/q7DKVvnLzdj24Sk78wq7OMe0ya1uW6sXzTVCevuPX8lyTe1zvx7e6XMX18a/c72AwVjBaTwmWYscotzo0IpGnlaSrhG9Y13xL7kFGPcGLUPAIWTjm38ANT1gUXb9VLNXt7kNFl1h0itPzBjqS6p61TJTuY+p9QN/U7acI0ZC+zsdNeV+sQEAED1Ce3mTPXJZA9v7AAfGv917LTUPV9Kuvb+a/mGVP/hqedZrdqulkL7mLHIbdLg//Mmn6myban701LSNeWy+StSw8c8SakitP7Q2coi0/Dvsqd4AZWm98vOFjGZwgucrWQAD1HMB1D5og9JfRebMf82UudtzkhWr7nfDKRWS9EHPEllk8tWSitjZuzK2VJToLAfGId8lk511XFvWSelp3Lnr3vEvjTlYv49Peb6yFYn94JyF8NT66ThPxX2MSfL3ZUfmCXVvn/851uh7IkV5d5RCQClrPd8aeRZMxY+U2r8ZK6jS1/zf0l1HzFjsYedkfvlJvGa1O16D2DVbBzx2OxNTgAAbE34NKnxc2Ys8aLU84Xxd/YOXCkN32vGag+Rpn0vPzlWq7HeR/Se54yqLzcbrpeG7jRjNe+RWi/zJp9KYQWdrSzcn830fs3Z+gKoRIO3ZN/YFNxDav+JN/kAGSjmA6hsyXVOJ5Yy99v2SZ2/kQLTvcrKVPMuKeTqeoss9CQVyRlrf8VqM/b+FmUV2QtlgWua/MqY9HD/FC7o3lvWqpd8tZO+XCxl66+uSx7dlvvYvArt5vxCmsldNC8F6ZgU+Y0Za1wgWRN8y+HeVoDOfAAojMht0uAvzFhwd6n9Z+Xb9W35pM5Fkt81frf/f0r3Rrhc0jFnf9L0gBlvu9Z5/wgAQClru0YK7W3GIrdIg7/a+rnRR6T13zRj/k7nsxwrkK8Mq1dwJ6nD9XmCHXcmNbnfd5Sy2JNSr2scvK/VKUJbIW9yqiSB7Z0tLQxJZ+uLXI0zQDkbecHZEiaT1bDx5qd6b3ICMlDMB1C57JSzR6q7CDjte1LdoZ6kNCZ31/XQXVKqv+hp2Lat81+V4hn3Pvgt6bpdJKtIH+i/Kyzt6dpe7+ap1HHde61PsSv/oX5pKGMXBEvSR4pRzJeynyfDd0up7iI9+DgN/yH7BorwWRO/TmAbc00xHwDyb+QlqfuzZszauNetryH3OeXC3yZNv0OS6wP/rjOk5Oqcp5Sc9RdII0vNWPg0qfEz3uQDAMBE+Gqd9xRWoxnvPUeKL8t9jrRxe5xTJGVuP2g50xUD2xYi0+rUcLzUdL4ZS77mjKwvh33RU31S10mSXNsPdt4iBXbwJKWKVP9hZ2uLTMlVzhYYdjr3OUC5SQ9t3HZu2Ix33OA0VwElgGI+gMrV9z0p5hpXX3dk9pvQUhA+XVLGZvF2TBpaXPQ07u6V7nPVvs+dKe0RLl5nnmVZmu+q497ZJQ0mJ/nLZMpVWPa3Tu46G93da64PbJI6QkX6+wmfLFmZUwWSTkdlKXFPC6g9TAq+Y+LX8VPMB4CCSg9v/MDCtXdt+8+l0O7e5JRvte+RWv/XjKV7pXWnSHYi9zmlInK7tOGnZiy4m9T+i/KdmAAAqD7B2VKHqxPfjkldJ0jpDdnH2ymp60wp9bYZn/Ydqe4DhcuzWrVdLtW824wN3emMri9ltu0Uk5MrzXjLRVL9R3Kfg8mb9j1ni4tMw/c4W2EA5c62nS1gEi+Y8cbPOTdSAyWCYj6AyjT8V6n/+2bMP1Pq/PXEx30Xg79dqj/WjBV5hHo05XTlZ9omJF0yiTrsVJ2+jTMRYJPhtHTnZBvQ89iZb9u27ukxY8e0T/pyE+drlho+bsZKadR+8i0p+hcz5p4mMF4U8wGgsHrOkRL/MWONn5Yaz/Qmn0JpPl+q/5gZiz+aPbq3lIy8LHW7uu+tuo0TE8Le5AQAwGSFT5CazjNjiVed6UDuDvD+S7N/p6w7Qmr5VmFzrFZWyJlk5HM1PfRe4IywL1UDVzmTCjPVHixN+37u4zE1VsDZ4sLv2n9z/Tel2D+8yQnIl8FfOVvAZArt7WwVA5SQEqxoAcAUJd+Wuk6XlPlLod/ZM8tfzMrrBDUuMNfxJ6SRF4v28Jetkt6ImbErdpaaAsXv/poesvQR1++SN6+Z5MWyivmT78z/95C0Om7GjinWiP1Nwq7i+MhzUvyZIicxhsFFkjLGrFmNUsMnJnctdzE/OdknAAAgy+BCKeK6GSw0z9mLvdJYltMRGHDdnThwpTT0B29y2pJ0VOo6UbIjZrz9p1JoD29yAgBgqtqukGr2N2NDi6UNPxtdRx+Q+r5jHuOfIXXeKln+wudYrQI7SJ2LXMGEM8LePemwFMT+Ka2/yIz5OqTO252iMwojsK2z1YUyPyNMSetOLr3tH4Hxii9ztn7JZDVuvIm6Nvc5gEco5gOoLHbS2Vst7Xoj2XqZVPteb3Iar/oPS/7pZmxwYVEe+rWorf9dZcYOaZZOm577+GKYP8Nc/33AyXPC8jhm/25XV/6sWmlusbcUrjs8e/+3UujOt20pstCMhU+WfPWTu17A9QSgMx8A8mPkP1LPF82YFZY6l0i+Om9yKjT/NKfrTCEz3j1fSrzhRUZj6z1XGvm3GQufnX3TJwAA5cQKSZ13SL4WM977FSn+tHPzdtdpMpsyfE6B1t0NjPyrP1pq/roZS66UuhdkT0/wUqrHKR4rlRG0nBs+Att6lVX1qPuAs+VFptTbUtcZkp3OfQ5QqtKDG2+idnW2dfzK2SIGKDEU8wFUlr6LpdgjZqz+WKn5Am/ymQgrIIVdo20ji5wbFArItm19+RUpnvG+229J189x9q/3ytFtUqvrpupFk6nn5nHM/j295vqYNg/+jiyfFJ5vxiK3SnY89/HFEn9MSrxixqZSeGDMPgDkXzoirTtBsqNmvONGKTTHm5yKpWY/qe1qM5bud7rO7BFPUsoyuEga/KUZC+4htZf4vrUAAIxHcJbUcbMrOCKtO9FpykitM7817QdSnWufbhRO6w+k2veZseE/SANX5z6+2Oy01HWmlHrLjLdcLNV/0JucqlHLt5ytLzJF/+JskQGUC9t2tnpxf47ZdK6zNQxQgijmA6gcw/dK/ZeZscCOUsdCZ8RqOXDvL55aK0X/XNCHvLtXus9V7z53prRH2Nu/sxqfpVNdkwEWrZXSE70rPO3qzJ/kmP11I7ae3GDGjvFq14ZGVzE/vV4ausebXDZxTwcIzpFqDpr89dzF/HSf9zcsAEA5s22p53NS4mUz3vRFZ5JKNWj6otRwkhmLPyX1XuhNPplGnpd6vmDGrIaNIx4nOeUGAIBS03Cc1Pw1M5Z8XYr93YzVfVhqcXWKo7CsgDMJwef6oGP9153R9l7rv0yK/smM1R4uTfu2N/lUK8svdfza2QIjU993nK0ygHIw+HNp6HYzVrO/syUMUKLYSAZAZUiukrrOcgWDzhi3KYxVL7rQ7lLNAVL8ydHY4E3OyLMCiKZsnf+qGdsmJF3yjtzHF9uCGdJPMm66XhmTHu6XDptIc33KdaeCf3Kd+ff1mgP/wn7p/S2TutTUBXeWag8xP/CI3CSFJ7k//VSlh6TIYjMWXjC1m2jcxXzJ6dRwbzGA6jP8R6nv25KvWWr7sRSa63VG2MQekXrOkYbvK52bb4I7SW3XS7X7b/3YSjf4/6TIbWYstG92t3olsyyp4/9JI89IiYw3QBuudabcyMMbGe1IjhGPN0ih3bzJBwCAQmm9VIo9KsUfzf19//ZS5y3OVDoUV2CmM7J+7VEa/QQkJa35gLOPtJfSrlGJ/m2cPdwtvzf5VLPAdOfGjzWHSdo05jMtrfmw5GvyMjNgfLKmuLY4NQSrxpN0gPGgmA+gMqz/TvYP4rYrpdoDvMlnKhoXmMX8oT84+4L5898Gfvkq6Q3X58b/u7PUFCiNSQb7hKU9GqT/DI3GFq2dYDE/6w3a5G7uuKfHXB/Z6kwP8Ezj2WYxf/iPzj6D7r3mi2HoLskezAj4pEb3zTUT5JsmZ2/jjNHHyTUU86tdcp207iSn6CU5Izm3+w8f9JWKvu87BeNSEu+R1h4pzXxGCu7odTbeiT8j9Z5nxnzNzj7y1faBha9J6lwivf0es3ju/oDYa42fk8KneZ0FAAD5ZwWl6YulN/fO8fM34HzP3+ZFZpCk+g85o9T7vz8as+Olc7OuJMnnFJMD07d+KAqj7hBnK4y+b2YER6R0z5inACWr42ZnKxighPHJJ4DyZ6elYdeI8YZPOPvclKOGU1wfrCeyO+ny4LWorctXmbGDm6XTS+h3IcuyNN/VoH1ntxRJTmDUfh7G7MdStv7iuswxXn+20HCCM353s7QUucWbXAYXmuu6Dzl39E+FZUkB13/81NqpXRPlL3LLaCFfkhIvSrGHPEsHGeyENHiD11nklu6Tuk4unX3Riy094Nz44v4AtuMmZ3JBNarZS2q7zussxhbaW2q7xussAAAonMB2Uuevs+Otl0u1BxY/H5imfUeqPczrLMY27ftS3fu9zgItX3e2xADKWfPXnC1ggBJHMR9A+Us8n33nZ+sVUxvx7SX/NKn+eDPmLpbmwVdeleLp0bXfkq6f4xTQS8np053cNhlKOQX9cbHtvIzZf7jfedxNLEkf9rqY7wtn7/s7eJPzZy6mxBtSzLUvWuOC/FzbPWqfYn51s+3cr4UFeH3EJAz/UUp1eZ3F2OJPSOsv8jqL4rNtqfvTUvI1M950vtRwfM5Tqkbjp5y/h1ITmCVNv1Py1XqdCQAAhVV/lLNt1qbBsU1fkpq/4mlK2MjyOyPsgyW4pVn4dKmlCt/XlyLLJ3Uucm5EBcpR/THO1i9AGWDMPoDyF33IXAd2lIIlsun7ZDWeLQ3dProeeUaKP+d0kuXB3T227nFNsztnprRnuLQK+ZK0TY2lD7ea+d68Vlownmny9rCkhBmbRGf+3a6/q/c0SZ2hEvi7ajxbitw0uk685BSsat9TvBwiN5trX4tU/9H8XJtiPjLF/+XcvOU2dKeUvp69+bw2eJO5Du3rbHfjmbTU/TkpuXw0NPAjqfbg6ipib7je+TeSqebdUtvl3uRTSixLav+R1PwlKfmm19k4rFoptJfkq/M6EwAAiqP5PGfqnB0v/89xKk1gG2m7pc5nUfbQ1o8vBv90Kbhb+TbvVCJ/uzTzSWnkOSkd2frxQKnwtzk3LLFtI8oExXwA5S/6oLku5VFg41X3Acm/nZTK+HB58Cap5popXzqasnX+q2Zseki6pIR/b56/jYxi/sP90oqorZ3qtvILXHp9dsw3sc5827Z1j2vwwzHtE7pE4dS+TwrsbHZcDi4sXjHfTmd3RYdPy183obuYn6SYX9UiN+WO21EpcofU9Oni5oNRqa7s7W6aPifVHepJOptN37QvesZ4+e6znWJpNYyXjz0l9V5gxnyt0vQ7JCvkTU6lKDjb+R8AAPBGYFuvM8BYrJBUu7/XWaDUWUGpZj+vswCAisZtJwDKm52WYg+bsboKKOZbfqnxLDMWuTUv+/1evkp6PWbGrthZag6U7p3Nx7RLra7bzxaNp67rHrEvS/I1T+ix/z0krXJtM3yM1yP2N7Gs7JH2Q7dL6WhxHj/2sJR8w4w1np2/62d15q/J37VRXtIxKfKbsb/v7gpHcQ3eKik5urbqpPDJnqWzWc3eUtu1ZmzT/vHpWM5TKkaqT+o6UVnTaToXSYEdPEkJAAAAAAAAE0cxH0B5G/l3dve1152A+eIu0qZ7sjsfJ2hF1Nblq8zYwc3OvvSlrMZn6VRXjovWSumt7Q+f7jPXvmkTHp/k7srfsVbao2FClyisxvmSMm7ESA9Iw78rzmO7u/KDc53R2vkScO2lwJj96jX8f1K6f+zvxx+VRl4uVjbIZNvZUxMaPlE62x40fsaZGJJpZKm0/oLcx1cC25a6F0jJlWa8+etS/dGepAQAAAAAAIDJoZgPoLzFHjLXgZ0qp+MsuIszRj2Tu3g6Qee/KsXTo2u/JV03R7LKYL+xBa667hsx6e/9WznJfaPHBEfsS+Z4f8npyi+pv6/A9lLdEWasGF3K6cHsfZgbz87v3nVZnfkU86uW+7Wv9hDJ12HGIjcXLR1kGHnGubEuk/tmNC9ZltT+C2dvzUwbfipFFnuTU6ENXC0N/8GM1b5Pav2BN/kAAAAAAABg0ijmAyhv0QfNdaV05W8Sdo0sH75v0vuG391jZxWmvzRTmhcuocL0FuwTlua6OuJv3tpfRcrVme9vndBjdo3YemKDGTu2fUKXKA73aPvo36TkqtzH5kvkDskezgj4pfAZ+X2MXMX8rU1jQOVJvilF/2LGGj8rNbqeb4OLJDtVvLzgcN88FNhRqi2x7W58YWn6Emf8f6buT0sjr3iTU6HEHpXWf92M+dqlztslK5D7HAAAAAAAAJQsivkAypedcvbszlRqBYSpCp8oWfUZgZQU+fWELxNN2Tr/VTM2PSR99x1TS6+YLMvSfFdt985uKZLcQnF3ip359/ZKmVcP+6X3t0zoEsVR/zHJ15wRsJ3CZiG5C3j1R0uBPO/X4C7m23FnGwFUl8FFMv4lWk1Sw/FSeIF5XOotKfrXYmYGOy5FbjNj4fkT3s6kKEJ7SO0/NWN2xNlXPh31Jqd8S/VI606WlHlTiyV13ioFZnqVFQAAAAAAAKagBD9pA4BxGlmWvYdypXXm+xqlhhPM2OBNE+5O/t9V0usxV2xnqTlQHl35m5w+3dkaYJOhlPTb7i2ckFXMn1hn/r2uSQYfapVqfCX4d+arkxpOMWODCwvXxT7yihT/pxlzTwfIB3cxX5JSa/L/OChdtp1940j4ZMlXL9XMk0L7mN8rxhYTGDX0h+zX2VIase/WuCB74s3IMqn3PE/SySs7LXWdKaXeNOMt35LqP+RNTgAAAAAAAJgyivkAypd7xH5gthTYzptcCsldJE28IMWfGvfpK6K2LnNNXH9fs3RGnpuoi2FGjaWjXPX4LY7an8KY/Xja1l9cNapj2sZ9evG5nyfJ16TYI4V5LPfe5L52qf4j+X8cX63kazFjqcltM4EyFf+nlFxuxjKf6+7n/dD/SSnXP1wUjvvmidpDpWCJj3xpv14K7mHGBm+UBm/xJp986b9Miv7JjNUeJk37jjf5AAAAAAAAIC8o5gMoX7GHzHWldeVvUnuIFHAVRyILx336V16V4unRtd+Srp/jjK0vR+5R+w/1S69Hx+hAn8KY/Yf6pEjGpGJL0kdKuZhfc4AUfKcZK0SXsp2SBl3F/PAZkhXK/2NJ2d35FPOry+BCcx3cVap5z+g6fJqkzOfeiBS5vQiJQcm3peifzVgpd+Vv4quXpi+RrAYz3vN5aeQFb3KaqujDUt/FZsy/jdR5m2T5vckJAAAAAAAAeUExH0B5slNS7O9mrO4wb3IpNMuXXSCJ/EZKx3IenumeHlt3u0bFf3GmNC9cnoV8STq2XZoWMGOLxqrvpl2d+RMYs3+P6+/t3U1SZ6iE/94sK0eX8hIpHcnv40Tvd/Ymz1SIEfubuIv5SYr5VSM9JEUWm7HGs53n+ib+Vqnho+YxEUbtF0XkFkkZd4pZ4extYUpVaDep4wYzZg9L6050nnflJLlO6jpFxn8L+aTO30iBHFuVAAAAAAAAoKxQzAdQnkaeldIDZqz2UC8yKY7wfDm94Rul+6Xh/9viKbGUrfNfNWPTQ9J3Z+U5tyKr8Vk61bVFwKK1UjrX/vDucdv+8XXm27adVcwv6RH7m4TPkJTRhWkPSUN35vcx3N3+oX2cvcsLhc786jX0W8nOvBnFJ4XPzD7OfTNJ/F/SyH8KmlrVs+3s14LwSZKvIffxpSh8mtT4OTOWeEHq+YLz5ysHdkrqPj37dXHa9yp3WhEAAAAAAECVoZgPoDxFHzTXwTlSYFtvcimG4I5S3eFmbCsj1K9aLa1wNe9fvrPUEizh7vJxWuCq774ekx7pz3Fg1pj98XXm/2dIWun6uzu2fdzpeScwQ6o/yozlc9R+qi/7JpJCduVLOYr5awr7eCgd7udu3ZG5X+frPij5Z2z5XORX/HEp8bIZK/RrQSG0XSOF9jZjkVukwV95kc3E9X1fiv7NjNUdKbV8w5t8AAAAAAAAkHcU8wGUp9hD5rqSu/I3CS8w19G/SsnVOQ/tT9i6yvWt9zVLZ07PeXjZ2bdRmutqAL05V8P2JMfs391jrneokfYol4bTsKugFvu7lHgtP9ceul2y4xmBkBQ+NT/XHkvAVaSlM786JFZkv86PVSy2AlL4LDMW+bVkJwqSGpR9s0RgtlTzXm9ymQpfrTR9iWQ1mvHec6T4Mm9yGq/hv0r93zNj/plS5y3O9jwAAAAAAACoCHzSA6D82Ekp+nczVneYN7kUU8PHJaspI2BLg7fkPPTaN6X+pCu2i2RZ5d+VLzl/jvmuhu0l3VIkmTEa2U5lb8UwzjH797pH7LeX0d9dw7GSz7UnwODC/FzbXcBrOE7yF3j/AcbsV6fBReba1+o838biLvSnuqThP+Y/L0jpYSmy2Iw1LpDK5TXSLThb6nB14tsxqesEKb3Bm5y2Jvm21HW6pMztAPzS9MWSv8OrrAAAAAAAAFAAFPMBlJ/4M5I9aMaqoTPfVy+FTzZjgzdl7e3bn7B1zZvmYSd2SHs3lmmhZQynTzd/iA2lpN92ZwTS/dknjaMzv2vE1uOu+s2xBa5X55UVksKnm7HBm52bG6Zi5Hkp/pQZK8ZYbXcxP0kxv+LZaSmy0IyFT5OsmrHPCe0q1Rxoxhi1XxhDv5PszBdJS2o8a8zDy0L4BKnpPDOWeFXq/mzWz1jP2Ump6xQp3W3GW38o1ZbhdAQAAAAAAABsEcV8AOUn9qC5Du4mBbbJfWylcRdPk8ul+D+NUK6u/ItnFTYtL8yosXSUqzZvjNpPr88+ybf1zvz7es1exwa/dOj4GvpLR+MCc51aLUUfmNo13YVR/wyp7kNTu+Z4uIv56R7Gp1e62ENScqUZcz+nc3G/Pg7f43ToI78irteCug9Kge29ySWf2q6QavY3Y0OLpcGfe5PPWPq+LcUeMWP1x0rNF3iTDwAAAAAAAAqKYj6A8hN9yFxXw4j9TWreIwV3NWMZRdaxuvL3CFdWV/4m813bqT/UL70e3ViKT7mK+Vat5Kvb6jXvcY3Y/9A0qcZXZn9/Ne+SQnuZMXen80TYCSni2tIhfJazV3mhZd2oY1OgrXTuG0dCe0qhfbZ+Xvgkycr8N56UBm/Na2pVL7Ey+8agYkzoKAYrJHXeIflazHjP+VL8aS8yyjZ8n9T/QzMW2FHqWChZ/FoHAAAAAABQifjUB0B5sRPZHWnVMGJ/E8vK7lCN3CGlhyTl7sr/1qyiZOaJY9ukaa568i2buvPTfeY3xjFiP5629RfXPQDHtE8+P0+5C2xDd0mp/slda/hP2QX08XRK54OvXZLfjKUYtV+x0gPS0G/NWPjs8e3H7muWGj5uxiLZW5FgCiI3y5hd4muW6j/mVTb5F5wlddzsCo5I606c/OtnviRXSV1nuoJBqXOx5N/6zzcAAAAAAACUJ4r5AMpL/GnJjpixukM9ScUz4bNkvHzbEWnotzm78k/okPas0K58Sar1Wzpluhm7ea2Utu3sMfvjGLH/cL8Uydha3pJ0dNuU0/RG+HRJwdG1HXNGRk+Gu1O65j1SaLdJpzYhlk/yu/4jU8yvXJElkh3NCASkxjPGf777JpaRf0sjz+Qltapnp6XBhWas4VTJV+tJOgXTcJzU/DUzlnxd6v6kdzeG2CPSupOzf661XSnVvtubnAAAAAAAAFAUFPMBlJfYQ+Y6uLvk7/QkFc8EtpXqjjRjgzfl7Mq/eFbRsvLMAtcU9tdj0j8GJKVcnfnj6Fy8u8dcv7tJ6gyV6c0Q/nZnH+VM7qL8eKS6peG7zVixx2r7Xf+RkxTzK5b7OVp/jOTvGP/5tYc5Y8e3dE1MTuwRp6idqVJG7Lu1XirVHGTGhn8nbfixN/ms/4YUf9yMNXxCajrXm3wAAAAAAABQNBTzAZSX6IPmuu4wb/LwmruAEntIv1uzwghVelf+Jvs1SrvXm7GFazThznzbtnVPrxkr2678Tdyj8ONPSCMvTuwakVslZdwlYtVJ4ZOnmtnEuIv5dOZXppGXpfijZmyi2zlYPik834xFbpPs+JRSg7JvigjuLtXs700uhWYFpemLJZ/rh0DvhVLs8dznFMrQ76WBq81YYCep45fj234CAAAAAAAAZY1iPoDyYSek2D/MWO2hnqTiuYbjsorTx9ea+/xWQ1e+JFmWpfkzzNiSbmkk6arM+7bcmf/8kLQyZsaObc9Dgl6q/3D2iHr3mOwtse3sAl7Dx519sosp4C7mrynu46M4IgvNtb9Tqv/IxK/T6Crmp9dLQ3+YdFqQlB6UhpaYscazK7uYHNhO6vy1K5iUuk6WUr05T8m7xAqp2/V8VkiavqT4r8MAAAAAAADwBMV8AOUj/pRkD5uxuvd7k4vXrBopfJoROiu8SJbSkqqnK3+TM6abP9CGUtKq4X7zoK2M2b/bVZvZoUbasyEv6XnHCkjhM81YZJFkJ3Mf7zbyrDSyzIyFF+Qjs4nxu+7WoDO/8tgpaXCRGQuf4XRIT1RwJ6nW9bOBUftTE1ni+vnrd/77VLr6o6SWb5qx5CqnwG6nC/vYdlxad5KUHjDj7T+WavYp7GMDAAAAAACgZFDMB1A+og+Z6+AeE9tLudK4Ru3PCqzUobUPSaqervxNZtRYOspVq++KTWzM/j095vrodqfrv+y5t2RIrZWifx7fue4CaGAHqe7w/OQ1Ee4x+0mK+RUn+hcp9bYZm8p+7O5zo3+Wkm/nPhZb556aUP/h7IkZlWrad7NvDhm+Vxq4srCP2/s1aeRpM9ZwqtT4ucI+LgAAAAAAAEoKxXwA5SP2oLmuO8ybPEpFaB+lgnsaoQUNC6uuK38T96j9VKrPDGxhzH73iK3HN5ixY9tyH1t2QrtLNQeYsfF0KdtxKXKrGQvPd/YkLzZ3MZ/O/Mrj3v6hZj8ptMfkr9dwgmSFMwJpKXLL5K9XzRLLpdgjZmwqN1qUGysgdf7G2fYh0/pvZm/9ky+RO6QN15ux4Byp4xeVvbUBAAAAAAAAslDMB1Ae7BEp9k8zVneoJ6mUDMvS35ILjNAn6n+r7+wwkPv4Cndsm9QSGF23+lyd+f6xO/Pv65XsjHWDXzq0Ja/pectdeBv6g5TqyX3s5mPudvYaN66zIK9pjZu7A5hifmVJrZeG/s+MTXU7B1+DFD7JjA3eJNl27uMxNveNFr52qf4YT1LxTGCG1HmbpMxCekpad7KU6s7vYyVelbo/bcasWmn6nZKvMb+PBQAAAAAAgJJHMR9AeYg/KdnRjICVPfa2ygwkbZ3z9ulK2KMV7HpfVHO1xMOsvFPrt3RKRuNkVjF/C5359/Sa6w9Nc65XMRpOlqyajEBCivxmy+e4u/dr3+/sRe4Fd2e+PSSlB73JBfkX+Y2kkYxASAqfOvXrum8ISLwsxR+f+nWriZ2SBm82Y+HTJSvkTT5eqvuANO0SM5Z6W+o6w/l7yod0VFp3omS7Xt/afyqF9sx9DgAAAAAAACoaxXwA5SH6kLkOzZP8lTIHfXKufVNaPtKpe6NHm98Yzwj1CrVg86h9W9P84xuzH0/b+rOr7n90e95T85Z/mlR/vBnb0vMkuUaK/smMedWVL2UX8yW68yuJ+7nY8DHJP/bNN+NW+z4pMHvLj4Uti/5NSr1pxrx8LfBay39LdUeYsehfpP5L83P93i9LI8+ZsfD86trWAAAAAAAAAAaK+QDKQ/RBc117qCdplIqBpK1rVjtfL4wsML8Zf0waebnoOZWC/Ruld9ZLdVZUtVbc/OYYY/b/3i9FMpoqLUlHV+J9Iu5i0MgzUvy53MdGbpGUHl1bDc4e5F7xhV37n0tKUsyvCCP/lkaeNmP5KlxaVnbhObJYSg/n5/rVwD1iP7S3VLO3B4mUCMsvdd4q+WeY8b5LpOgDU7v24K+lwf9nxoJzpfafTO26AAAAAAAAKGsU8wGUPjsuxR81Y3WHeZNLibjuTakv6Xx9X/QjWpfqNA+ILCx6TqXAsizN30aa5uvL/uYYnfl3u7aOP6BJmh6qoBH7m9R9QPJvZ8ZydSnbdo5O6ZOcgrqX3N35dOZXBnex2L+tVPfB/F2/8SwZ+5zbG6Sh3+Xv+pUs1S8Nu/6u6BCX/J1S5+2S/BnBtNR12uRvMhp5Uer5nBmzGqTpSyRfw2QzBQAAAAAAQAWgmA+g9MWekOxYRsCSag/xLB2vDSRt/Wj16DqpoJ5Mn24eNLgof3v4lpkztpHafeuzv+FrzgrZtq17es3YMZXYlS85HaWN881Y5FbJHjFj8SekxEtmrBQKeAGK+RXHTkiRX5uxxrOc52q+BLbPvjkgwqj9cRm63fWzNyiFT/MsnZJSd4jU+gMzllondZ068Z+96SFp3YmS7ZoY0f5zKfTOqeUJAAAAAACAskcxH0Dpi7lG7If2HnNkejXI7MrfZNfpC8xA6m1nH98qtG2NpSNbzGL+oN2Ss0D4/JD0RsyMHdNewOS85i7mp3uk4XvMmLsrP7Czs/e417I689d4kwfyZ/g+KdVlxsIFuHHEfTNK9AEpsTL/j1NpsiZ0HCf5K/kFcoKa/0uq+4gZiz3kjNwfL9uWer4oJZ43442flRrPmGqGAAAAAAAAqAAU8wGUvuhD5rruUC+yKAnurnxJ+niHNKdlnhTa1/xGrhHqVeLYVnPMfleyVStjdtZx7q787WukeZU80Ti4S3ZhPnPMeToqRW43v9+4wNl73GvuPaonO84apcP9GlVzkBSak//Hqf+oazKHLUVuzv/jVJKRF6T4k2YsvMCTVEqW5ZM6F0n+7c14//9Iw38e3zUGb5Iii8xYaC+p7Zq8pAgAAAAAAIDyRzEfQGlLx6T4Y2as9jBvcikBubryL5618Qt39+nQ76VUjnHzVeDdDeafuy89TYty1H7v6THXx7RLVikUrgvJ3fk8fN9oYXz4d86e4ptZ2d38XsnqzKeYX9ZSXdLwvWasUNs5+OqkhlPN2OBCyU4X5vEqQeZNPpLz76/+KE9SKWn+Nmn6YkmBjKAtdZ0hJd/c8rnxZVLvl8yY1ShNX+I8ZwEAAAAAAABRzAdQ6uKPS3Y8I+CTag/2LB0vjdWVv1d4Y/E5fKqkUMZ3R6TIb4qVXkkJ2v3Gen26VTevkWx7tDu/e8TWYxvM845pK0JyXgufKFn1GYHU6L7l7k7puiOcPcdLAcX8yjJ4q6SMO5OsOil8UuEez32jQPJ1KfZI4R6vnNlJKXKLGQufKVmB3MdXu9oDpdb/NWPpHmndKZKdyH1OelDqOlGyXfu8dPzSmaACAAAAAAAAbEQxH0Bpiz5orkPvkvwtnqTitS125UuSv1Vq+Jh5QLWO2k9nd+aviEn/GBiN3dcrZQ7eb/BLh7UUJTtv+RqlhhPN2OBNUnKVFP2bGS9Up/RkBCjmVwzbliLu/dg/IfmaCveYNftLwd3NWLW+Pm7N8J+y/32V0mtBKWo+X6r/mBmL/1Na/9/Zx9q21P1ZKfGKGW86x7nZCgAAAAAAAMhAMR9AaYs9ZK7rDvUiC89t2FpX/ibugsvI09LIvwubXClKZRfzJWlhRn3q3l7zlA9Ok2r9FT5if5PGBeY68YLUc66M2xt8zdnFKS9ldeavk+yUN7lgakaWZr8uFbpYbFk5tiJZ4nRIw+S+yaHm3VLond7kUi4sS+r4lRR4hxkfuEIautuMDf5CGrrdjNXsJ7VdWdgcAQAAAAAAUJYo5gMoXemoFHvcjNUd5k0uHttqV/4mdR+U/NuasWrsPk33Gcv16VZJ0p1d0lDK1kja1p/Ner+OaS9WciWg9pDsotPwH8x1wymltW+zf4YrkJZSPZ6kgilyvyYFZkm1hxb+ccNnSPKPru1hKbKk8I9bTlI90rCr+Oy++Qe5+adJ0++Qud2NpO75UmKl83V8qdTzZfP7vhap8w7JqilGlgAAAAAAACgzFPMBlK74Y5JGMgI+qfZ9XmXjmQ1JW1ePpytfkiy/1HiWGRv89dj79laqHGP2JWkwJf2uW3q43/k600dai5RbKbB8Wy/QldpYbX+HJNdznlH75ScdkyK3mbHwfOc5WWiBbaT6D5uxyMLCP245idwmKePnhVXr3NiD8anZT2q72oyl+6Suk6RUt7TuRJnvayR1LJSCrpurAAAAAAAAgI0o5gMoXdEHzXXNvs7o7yoz7q78TcKuImy6Wxq+L99plTZ3Z35qtFJ/81rpHteI/QMapW1qqmTE/ibh+coqjm8SfKdUc0BR09kqK7CxoJ+BYn75Gb4769+nGucX7/HdN6nEHpESy4v3+KXOPTWh/njJ3+JJKmWr6YtSw0lmLP6ktHqulFxhxpu/KjV8tHi5AQAAAAAAoOxQzAdQumIPmetijGEuMbm68o9vH6Mrf5PQHKnmIDNWbaP2U7k78yXpgT7p9nXm4VU1Yn+T4I5S3eG5v9d4trMHdKnxb2Ouq6WYP/IfKfG611nkh/u1qPbQ4nYl1x8j+Vz/4AcXFu/xS1n8WWnkWTNWahM6yoFlSR3/TwruYsbT3ea65kCp9bLi5QUAAAAAAICyRDEfQGlKD0uxJ8xY3WHe5OKhCXflb+IuwAzfK6W68pVW6XON2Y9bo535tqRu164Dx7QVIadSFF6QI+jfuLd4Ccoq5q/xJo9i6v6U9Oae0urZUv/VWz++lCXfkqJ/NmPFLhZbISl8uhkbvFmyU7mPrybuGy382499ww+2zNckdS6RrJoxvt8mTV8sWcHi5gUAAAAAAICyQzEfQGmKPSpj3175pdr3eZWNJ8bqyt+7cRwd0+GTJKsuI5CUhv+Y1/xKlp2S0gNG6D0trWMcLG1fI+0VLnRSJarh45LVZMbqj5ICM7zJZ2v8rrySFd6Zn3hNGvzVxkVaWn9Bef87jtwiKT26thqlhk8UP4/GBeY69aYU/Vvx8ygl9ogUudWMNZ4lWX5v8qkENXtJbdfl/l7nLVJg++LmAwAAAAAAgLJEMR9AaYo9aK5r9pN8jd7k4pFJd+VLTldg7fvNWPLNfKRV+tIDcvrvRx3TMS33sZKObpOsUhwpXwy+eqnxk2as6RxvchmPahuzP/J8dqzrTCm5Ojte6mw7u/M7fJLkayh+LjV7S6G9zVi1j9ofvkdK95ox900PmLjGT2dPOmn5hlT/YW/yAQAAAAAAQNmhmA+gNEUfMtdVNmJ/Q9LWjybblb9JVuGzO/dxlSbdlxXau7lVu9XnPvzY9tzxqtF6qdT4WSm0r9T2Y6czv1QFqqyYn3wjO5buldadLNmJ7O+VsvjjUuIVM+blfuxZW5H8Tkr1e5JKSXDfaFF7sBSc7U0ulcSypPb/JzVfINW8W5r2fed/AAAAAAAAwDhRzAdQetIRKf6kGas91JNUvHL9m9L6yXblb+LvMNeprqmkVD5S612BkCxfveZvk31ovU86rKUYSZUwX53U8Qtpu39Jzed5nc2WVVtnfq5iviTFH5PWf6OoqUyZu1gc3EWqOcibXCQpfJqkjP3K7Zg0dLtn6XgquTZ7+wYvb7SoNL5aqe1Kaebj0rRvsXUBAAAAAAAAJoRiPoDSE/unpMxKdkCqfa9X2RTdhqStq6falS9J/k5zna6WznxXMd/fKlmWztgm+4feB1ulWn+VjtgvR+5ifnKNN3kUS+L1sb83cJU09Pvi5TIV6WEp4iqUhxc4Xcte8bdLDceZMfcNB9Uicouk1OjaapAaTvQsHQAAAAAAAACjKOYDKD2xh8x1zf6SL+xJKl7IS1e+VL2d+e4x+75WSdLMGktHtprfOt71V4QS559hru0NTqG4Uo3Vmb9J94ItF/xLxdBdkj2YEfBJjWd5ls5m7u7z+JPSyAve5OIV286+iaHhhKr6mQsAAAAAAACUMor5AEpP9EFzXXeYN3l4IFdX/scm05UvZXfmp6qkM989Zt83bfOXP5kjvaPW+foTHdLp04uYF6YukGOvhNS64udRLO5ifsMnzHW6X+o6WbLjxcpoctzF4roPSoHtvMnFyOPI7GkPgws9ScUz8aekxItmjBH7AAAAAAAAQMmgmA+gtKQHpfi/zFjtoZ6k4oW8deVLOTrzu50uzErn7sz3j7bjz6qztPw9Uu/7pCV7WPJ7OeYbE2c1SVatGUut9SaXQkv1O8X6TK2XSQ0nm7H4U1LvhcXKauISb0ixB8xYqRSLrYAUPtOMRW6R7GTu4yuR+0aLwE5S7SHe5AIAAAAAAAAgC8V8AKUl9g8Ze/cqKNUe5FU2RTVWV/67JtOVL2V35iuZXRysROmxO/MlybIsTQtSxC9LlpXdSV2pxfysEfuWFNhB6rhBCu5ifmvDdVLkzmJlNjGRReba1yLVf9STVHJy31iQWisN/8mbXIotHZWGfmPGGhc4/84AAAAAAAAAlASK+QBKS/Qhc11zgORr8CSVYstrV74k+XJsCJ/qmsIFy0TWmP3W3MehPLmL+ck13uRRaO5ivn+mZIUkX5PUuSR7QkH3J6XE8qKlNy52OntsffhUyVeb83BPhN4p1bzbjLm71SvV8P9J6YGMgCU1zvcqGwAAAAAAAAA5UMwHUFpiD5rrusO8yaPIBvPdlS9JvjrJCpuxdPfkr1cutjBmHxXAP8NcV0tnfnDW6Nc1e0lt15nftweldSdK6VihMxu/2N+l5OtmLFwiI/Yzubvzh++WUj3e5FJM7psW6g53pj8AAAAAAAAAKBkU8wGUjvQGKf60Gas71JNUiu36t/Lclb+Je9R+NXTmb2XMPspcoErG7CfeMNeBWea68VPZ+72PPCv1nl+4nCbKXSwOzpVq9vMmly1pONk16SAhRW71LJ2iSK6SovebsVK80QIAAAAAAACochTzAZSO2COS0hmBkFRzkFfZFM1g0tZVq8zYlLvyN/G7Ru2nqqAzP0VnfkVzj9mv1GK+u6M98A5zbVlS+8+k4DvN+OAvpMhthc1tPNKD0tCdZqzx7NLcj93fItUfb8bc2wNUmsFbJNmja6tJajh+zMMBAAAAAAAAeINiPoDSEX3IXNe+xxkVX+EK1pUv0Zkv0ZlfaaqmmP+GuXZ35kuSr0Gafqdk1Zvx7s9KIy8VKrPxiSyR7OGMgF8Kn+5ZOlvlHrU/8qwUf9aLTArPtrNvVgifIvnqcx4OAAAAAAAAwDsU8wGUjuiD5rr2UE/SKKZcXfkfzVdXvlSdnflZxXw68yuKu5ifXONNHoVk29lj9oOzch8b2l1q/7nr/CFp3QlSejj3OcUQcY3Yr/9I9hYJpaTucMm/vRlzbxNQKWL/kJLLzVjjAk9SAQAAAAAAALBlFPMBlIZUvzTyjBmrO8yTVIopV1f+t2fl8QGqrTM/HZXsmBljzH5l8c8w16l1kp3OfWy5SvdL9gYzlqszf5PGM6XGT5mxxPNSz5fyndn4JF51CsaZ3J3vpcbyS43zzVjkVske8SafQnLfpBDcVap5jze5AAAAAAAAANgiivkASkPsEUkZBTmrpuKLCwXvypckX5V15qf7smOM2a8sWd3didz/3ctZ8nVXwCcFts956GZt10mheWYsstCb7nL3CHdfu1R/dPHzmCh3MT/dKw3d7U0uhZKOSEN3mLHGsyUrjz93AAAAAAAAAOQNxXwApSHmGrFfc6Dkq/UmlyIpeFe+VIWd+bmK+S1FTwMF5H5OS1JqbfHzKKTkG+Y6sJ1kBbd8jq9O6lwiWWEz3vMlaeQ/eU1vi+yUNHizGQufIVmh4uUwWcHZUu3BZiyy0JNUCmbot842DJv5pPCZnqUDAAAAAAAAYMso5gMoDdGHzHXdoV5kUTSDSVtXrzZjee/KlyS/qzM/XeGd+an15tpqkqyAN7mgMKwayefaOqHSivmJN8z1lkbsZwrNkTpuNGN2VFp3gtORXQzRv0mpt8xYOe3H7t4OYPiPUrKCnl/uSQ11R0mBbb3JBQAAAAAAAMBWUcwH4L3UemnkWTNWe5gnqRTLT96SehNmLO9d+VKOzvyeyttfPFPaVcz3t+Y+DuXN7xq1n1zjTR6F4h6zH3jH+M8Nnyw1fdGMJV6Wej4n2fbUc9sad7E49C6pZq/CP26+NJwoWQ0ZgZQUucWzdPIqsUKKPWzGyulGCwAAAAAAAKAKUcwH4L3YI5IyikxWrVT7bs/SKbTBpK2ritGVL2V35itVefuLZ3L/2dwd3KgMgRnmutI687PG7M+a2PltV0uhfcxY5DZp8IapZLV1qT5p+HdmzN3pXup8Yaegn2nwpuLcCFFogwvNta9VajjOk1QAAAAAAAAAjA/FfADeiz5ormsOckZpV6hcXfkXzyrQg2UV8yWlugr0YCXAPWbfP82bPFBY7s78Sivmu8fsB2dN7HyrRpq+RPI1m/HeL0vxZ6aS2ZYN3S7Z8YxASAqfVrjHKxT3DQiJF6X4k97kki92WorcbMbCp1X0z1oAAAAAAACgElDMB+C92EPmuu5QL7Ioilxd+ce1S/sUoitfcgo1VpMZS3UX5rFKAZ351aGSi/m2PfXOfEkK7iR1uEbe23Fp3YlSemCy2W2Ze8R+w3GSv60wj1VItQdLgZ3MmLurvdzEHpSSq8xYuU1NAAAAAAAAAKpQwOsEyl06ndbSpUu1atUq9fT0qKmpSTNmzND++++v+vr6oufT1dWlZcuWqbu7W/39/aqtrdU222yjXXbZRTvvvLMsq0AFQ2CyUr3SyHNmrO4wb3Ipglxd+d+eVeAH9XdKyQ2j60ruzE+7OvN9dOZXpEou5qd7JTtixgLvmNy1Go6Xms6XNlwzGku+JnV/Wuq8Q8rne4KR56X4U2asXPdjtywn975vj8aGfuNsX+Cr8yytKXHfaBGaJ4Xe5U0uAAAAAAAAAMaNYv4kpVIp/fKXv9Qtt9yirq7swlh9fb2OPvpoXXjhhWpubs5xhfy6//77tXDhQj399NNKp9M5j2lpadHBBx+sK664gqI+Skfs7+baqpNq9vcmlwIrelf+Jv4OKbl8dJ2u4M78rDH7dOZXJP8Mc51c400eheDuypdfCsyc/PXaLpfij0nxJ0ZjQ3dKG66Xms+d/HXd3J3r/hlS3ZH5u36xNc6X+r4jyXbW6QFp+P+k8KleZjU56QFp6LdmLLwgvzdzAAAAAAAAACgIxuxPwoYNG3TGGWfoqquuylnIl6Th4WEtWbJExx13nF544YWC5TIwMKBzzjlHX/rSl/TUU0+NWciXpP7+ft19991KpVIFyweYsOiD5rr2vRW7h68nXfmS05mfqaI78xmzXxUCFdyZn3jDXAe2l6wp3HtphaTOxdlTKnovkGJP5T5nouyEFLnFjIXPnFreXgvsINV9wIy5u9vLRWSxZMcyAgGp8QzP0gEAAAAAAAAwfmX8Kas3ksmkvvzlL2vp0qWbY9tuu62OO+44zZw5U+vXr9f999+vf//735KktWvX6vOf/7yWLFmi6dOn5zWXwcFBfepTn9r8WJLU2tqqQw89VLNnz1ZLS4ui0ahWrlyp5557TsuWLZNt23nNAZiy2EPmurYyR+xHvOrKl5zO/EypCu7MZ8x+dXCP2U+vd/aDr4Qbgdyd+YFZU79mcEepY5G07tiMYELqOlGa+Yzkn+K/k+E/Sal1ZqwS9mNvPFuK3j+6jt7v7Dsf2MG7nCbDfRNC/THZPxcAAAAAAAAAlCSK+RN000036dFHH928PuaYY/TDH/5QoVBoc+zzn/+8Fi1apEsvvVS2bWvdunW6+OKLdcMNN+QtD9u2dc4552wu5AcCAZ1zzjn61Kc+ZeSSqaurS3fccYd8PgYyoESkuqWRf5uxukM9SaXQPOvKl6qrMz/l6sxnzH5lchfzJed5Hdi++LnkW/J1cx14R36u23CM1Px1aeDyjMdaKXUvkKb/39RGrruLxTXvkUK7Tf56paL+Y5LVJNkbNgZsafAWadp/e5nVxIy8JMUfN2OVcKMFAAAAAAAAUCWo6k5AJBLRjTfeuHm9++676/LLL89ZPD/rrLN0+umnb14//PDDevrpp/OWy5IlS/T4486Hsz6fT1dccYW+8IUvjFnIl6TOzk6dc845FPNROqJ/N9dWvVSzvze5FFAkaetKr7ryJTrzUXl8rZKCZixZIaP23WP2g7Pyd+3WH0i17zNjw3+QBq6e/DVT3dLw3WasccHkr1dKfPVS+BQzNrhQKqcpR4MLzbW/U6r/sCepAAAAAAAAAJg4qroT8Pvf/179/f2b1xdeeKECgbGHG5x//vmqq6vbvF60aFFe8hgaGtIVV1yxeX3CCSfoIx/5SF6uDRRV7EFzXfs+yQrmPraM5erKv3hWEROols58Oy2lXZ35PjrzK5JlZXfnp9Z4k0u+FWLM/iZWQOq8XfK1m/H1X5dij+Y+Z2sit0lKZjxGbXYBvJy5u9iTy6XYP7zJZaLspBRxvfcMn1GRP2cBAAAAAACASkUxfwL+9re/bf565syZOvDAA7d4fGNjo4488sjN60ceeUQjIyNTzuO+++7Thg3OyFe/369zzz13ytcEPBF1FfPrDvMmjwLK1ZV/bJu0b7G68iXJVyWd+ekNklwds4zZr1wBdzG/AjrzbbuwxXxJCsyUOm+VlPkalJLWnSyleiZ+PfeI/YaPS77mqWRYWmreLQVdWwa4/8ylKvqX7JtcGLEPAAAAAAAAlBWK+eMUi8X05JNPbl4fdNBBssaxv+xBBx20+euhoaG8jNr/7W9/u/nrAw44QJ2dnVs4GihRqS4p8YIZqz3Uk1QKKVdX/rfztAX2uLk789M9kp0qchJF4B6xLzFmv5JldeZXQDE/3S3Zw2YsWIAXjPoPSS3fMmOpN6WuM50JF+MVf0Yaec6MhSusWGxZ2QXwoTukdMSbfCbCfdNBzX5SaA9vcgEAAAAAAAAwKRTzx2nFihVKJEYrcnvttde4znvXu95lrF9++eUp5TE8PKxly5ZtXu+/f+XtL44qEX3IXFthqWZfT1IplJLoypckv6szX3buwne5c4/YIQdmXgAAropJREFUV1CyGjxJBUVQicX8xBuuQEDyb1uYx5r2HanWNQ0l+iep/7LxX8NdLPZvL9UdPvXcSk34DBlvme0haei3Yx5eElK90tAfzFil3WgBAAAAAAAAVIGxN3yH4bXXXjPWO+6447jOmzlzpvx+v1Ippwt2xYoVU8rj+eef33wtSdp1110lSf39/brrrrv0pz/9SatWrdLQ0JBaW1s1e/ZsHXLIIfrEJz6hcDg8pccG8ir2kLmufV/F7eNbEl35kuRvz46lunIU+ctcynWDgn+a01WLyuQu5icroJifNWJ/B8nyF+axLL/UeZv01t5Sat1ovO9iqfa9Ut37t3y+HZcit5qxxvmSVYH3iQa2leqOkqL3jcYGb3L+vKUq8htJmVs7haTwqV5lAwAAAAAAAGCSKvAT18J48803jfWMGTPGdZ7f71dHx2jBbPXq1Vs4euteeuklY93Z2am///3vOvroo3X55ZfrueeeU19fn0ZGRrR27Vr94x//0KWXXqojjjhC99133xhXBTwQfdBc1x2W+7gyVTJd+ZJkhSRfixlLdRc/j0JzTxvwtXqTB4oj4Po57N4bvBwlXzfXhRixnymwjdT5G5lvB9NS1ylSct1YZzmG7sn+N9e4IM8JlhD3qP3Yw1JiajdoFpR7akLDx5wbnAAAAAAAAACUFYr54xSJmHujNjc3j/vcpqamzV8PDQ1NKY++PnOM9HPPPacvfOEL6unpkeTcPNDZ2alp06ZlnffVr35Vt97q6qIDvJBcKyXMG1NUe6gnqRTKT0ulK38Tf6e5TnV5k0chucfsU8yvbNUwZj8wq/CPWXeYNO27Ziy1Vuo+XbJTuc+RpIirWFx7iBTcOf/5lYqGY7NfUwYXepLKVsWXSSNLzZj7ZgQAAAAAAAAAZYEx++M0PDxsrGtqasZ9bm1t7ZjXmagNGzYY68svv1zJZFINDQ0677zzdPzxx2++0eDtt9/WzTffrJtvvlm2bcu2bV166aWaO3eu9t577ynlMVXLly+Xz8e9JFORSCQ2//+yZcs8zmZimgN/1I6j/yyUshv0/CsBSeX15xjLsO3T5X27KvMl9pDgBgVfX+nZn3Dnuno1ZEzrfmv1M+pN7OZRNoXREXxBMzJemjcM+fVGmf3bwPjV+yKaXT+6TifW6D/LnpOUn+kXXrzGzqr9t5oy3pmt7alV15piPPYxekftH9UYeHQ0FP2b1r18jtaNfCHr6IDVrXfW/9HYxWJ1/xHq66nsf2/bho5Ue+g3m9cj62/US29+XKV2b+yM0BXqCI2uR9Kdemn5dFXKz1hUhnJ+HwsA5YDXWQAoHF5jAaBwKuE1Np1O5/2aFPPHKR6PG+tgcPx7e4dCo5+oxmKxKeURjUaNdSKRUG1trRYuXKh58+YZ39t22231jW98QzvvvLMuvvhiSVIymdSVV16pX//611PKY6pSqZRSqS10/GFCNr3AlYv64JPGOpLcW4mELam8/hxj+U18uvps8+X1U6G3Pf3vNBKaZhTzrXRv2T1vtsYK9BvrRKqx4v6MGBX1mRNyfFZcqUS/0grn/bGK9TwK1r1lrKPJ6UV77BXJ7+qdTacr5Bud2tEZ/IUG4ntoMPke49jWmt/LskbflKbsOvVED1W6Ql7Dx9KVPtoo5od8a1RrP6bB5AEeZmWylFBL/T1GrDd+tBKJtKT8/yIB5AM/qwGgsHidBYDC4TUWAAqH19hRFPPHyd2Jn0gkxt2dPzIysvnrzC79fOQhSZ///OezCvmZTjrpJN1///16+OGHJUlPPfWUXnnlFc2ZM2dKuUyF3++nM3+KMl/IJnJzSSloCj5trIfS7y67P0Muti3dN9KiX42Y478PCW7QXrUJSd79GdOWOR66JtBfEX/nmUL+QWNtWy0V92dEpm2yIvWhAcXt/OwLXvzXWFs1vjVGJGXtUMTncKdWxf5XO9d9Spbl3GxnWbZ2arhYr0TvUNLetFWHrfZas1g8kPyg/MFm+VXZktpD0dQc1flf2RzrqL1Hsfh7PczK1OR/REFfvxEbSH+M10KUnHJ+HwsA5YDXWQAoHF5jAaBwKuE1Np1O572ZmWL+ONXX1xvreDw+7mJ+Zje++zpTzcPv9+uUU07Z6nlnnHHG5mK+JD3++OOeFvNnz56tcDj/3ZPVZNmyZUokEgoGg1u8maPkJN+WVq00QtvudJq2rSmjP0MOa+K2vvCK9IdI9veunNekeU0e//nWv1PqH122taTVNr28/86zrJWUsZNJ+/Q5ap9WYX9GmN5oltIDm5e7zm6S6vLz37zor7HJtdIqcwrQ7N2OkAIzC//Ym82T+ruk9f+1ORLw9Wn3tu9JMx6QrIAUe0J6+3XjrNYdLlBrnv7eS97AF6Ter2xeTgs9oGm77Ci5JkV4Zu3Fxuugag7Sbjsd51k6wFjK9n0sAJQJXmcBoHB4jQWAwqmE19hIJKKXX345r9ekNXqc3IXngYGBMY7MNjg42i3a0NCQ1zxmz56tadO23oW47777Gp3wL7744pTyACYt9pC59jVLob29yCQvbNvWrWtt7fGk9Iee7O+f1Cnt15SfPbynxN9hrlNduY8rZ+k+c+1rzX0cKoff1Z2fWutNHvmQfMMVCEr+GcXPo/kCqf4YMxZ7ROr7tvP14E3m9wI7S7UHFye3UhA+Xca9sHZMiiz2LB1Dcp00fK8Zazzbm1wAAAAAAAAA5AXF/HHabrvtjPWaNWvGONKUSqXU1TVaNNt+++3zmse22247rvMaGhrU1NS0ed3X17eFo4ECij5krmsPkazyHM68Nm7r+P9IZ74o9SWzv39Kp/TL3YqfV07+TnOd6vYmj0JKrzfXvvyMW0cJq+RifmBHyfLgbZrlkzpulgI7mPH+H0pDd0lDt5vxxgWSVQI3LBWLv0OqP9aMuW9w8Erk15IyRnhZdVL4JM/SAQAAAAAAADB1FPPHaaeddjLWq1atGtd5b731lrE3gvs6EzV79mxjHQqFxn1u5rGZ+04ARRV90FzXHupJGlOxqRt/7hjd+J1B6c49pNvmWmrwl0iRqxo681Oum5T8dOZXPHcxP1nGxfyEObpewXd4k4fk/NvpvEOSa1+qdSca2xpIltR4VjEzKw3ubvf449LIS97ksoltS4MLzVjDCZKvKefhAAAAAAAAAMoDxfxx2mmnnRQMjn6o/eyzz47rvGeeecZYT3Wf+p122skoyk9k3P+GDRs2f93cXCJ7u6K6JN+UksvNWN1h3uQySWvjtj6+lW78/xwgfbyjRIr4m7g789PrJTvHH6Cc0ZlffSq6M3+WF1mMqn231HaFK5g2l3UfyO7grwb1R2W/proL6cU28rSU+I8Za1zgSSoAAAAAAAAA8iew9UMgSXV1ddp///316KOPSpIee+wx2bYtayujZTcdL0n19fXab7/9ppRHKBTSgQceqIcffliS9PLLL4/rvJUrVyoWi21eu8f1A0XhHrHva5FC87zIZMJs29Zt66TzXs1dxO8ISj/btQSL+Jv4OrJjqR4psE12vBzZcckeNmM+OvMrXsC1p3xqfFvglKRSK+ZLUtN5UvTv0vBdub9frfuxW0EpfKY0cNVobPCG7P+GxZR40VwHZv1/9v49zM6yvhe4v+swIQk5EUhCCEoAFatYj+CulqqoUEURFcVqayui4oFd7a5W222PdFu7rbWCh/qKurW8rcUDiGLxRVB0a7VbUFQ8AQlIgIQQEhJymlnref+Imcx6ZpLMYZ1m5vO5Li/nvudZz3PHKy69+K7vb03LyTcAAAAAQCth/gQ861nPGg7n77zzznz729/OU57ylP1ev3Xr1lx99dXD61NOOWVCY/H359nPfvZwmH///ffnu9/9bk4++eQDvmbkOZIc9HroiJ3lEftPSyq13pxlAu7ZVeQNP08uH2OkfpKcszy56OHJEXP6NMhPktoRo/ea9yaZIWF+ecR+Ysz+bDCTm/kDq3txilaVSrL8Y8md30+Gbmv9XXVxMv+FPTlWX1j4qtYwv3l/8uCne3eesgW/n1QM4AIAAACA6c4/5ZuAM888s2U8/Xve854MDe1/TPX73ve+7NixY3j9ylfu/3tlTz311Jxwwgk54YQTcuqppx7wHGeccUaWLdvXsn3ve9+bZrO53+s3bdqUj33sY8PrI488UphPb5Sb+fOe3otTjNueNn6RE787dpC/bCC57NHJvz660t9BfpJU6qOb6o0NvTlLJ5RH7Cd7Jj8ws82UML9oJoNrW/fqx/bkKKNUFycrLktS+jDioS9LqvN6cqS+MOfRySEn9foU+7fw93t9AgAAAACgDYT5E7Bw4cKcd955w+sf//jHefvb357BwcFR137qU5/KpZdeOrw+5ZRTpjxif6/58+fnDW94w/D6xhtvzNve9raWDw7stX79+px33nm5//59rdXXve51bZkQABMydMfoZufcZ/TmLONwz64iL/5R8rs3J5vG+MzOS5cnPzo5efHyPg/xRyp/x3Pj3t6coxOapWZ+ZeGeUdjMbKPC/HuTYv8fsutbjXuS7G7d64cx+3sd8oTkiA8m+dX7XeXQZMn/6OmR+sJhf5Ph/0z6ycLzkoE++TAIAAAAADAlxuxP0Kte9ap885vfzHe+850kyZVXXpkbbrghz3/+83P00Udn06ZNueaaa3LTTTcNv2bZsmW58MIL23qOl73sZfn2t7+dr3zlK8Pn+O53v5szzjgjxx57bAYHB3PzzTfnqquuyvbt+75H+lnPelZ+53d+p61ngXEpt/KrS5M5j+nJUQ6kKIr824bkgp+PHeIvG0g+8Ijk7OkU4u9VW5YM/nTfeiY18xulZn7tsN6cg+4qh/kp9gT69ZU9Oc6klUfsVw5Jait6cpT9WvTqZM4jk13/lcw/Ixl4eK9P1HvzT0+O+s9kx1eSYvfBr++GOb+eHPr8Xp8CAAAAAGgTYf4EDQwM5KKLLsrrXve63HjjjUmSdevW5cMf/vCY1y9fvjwf+tCHcuSR7f1e6mq1mv/9v/93du/ena997WtJ9rTwR47TL3vOc56Tv/u7v0ulMg1DSKa/Hde1ruc+re++z3f97iJv+Fny+TFG6id72vgXPTxZ1u8j9fdnRjfzS2F++SsFmJlqRySpJWns22vcPf3C/ME1rev66r57f0ySzH3qnn+xz9yT9/wLAAAAAKAD+vCfFPe/xYsX59JLL81b3vKWlu+uH2n+/Pk5++yzc+WVV+bEE0/syDnmzp2bf/7nf86FF16Y1atX7/e6448/Pv/wD/+Qf/zHf8zcuXM7chY4qJ1fa13Pe3ovTjGmoijyr+uLPPo7Ywf5ywaSf3908m+PrkzfID9JqqX3q5nUzC+P2Rfmzw6V2hgfUrmnN2eZinIzv59G7AMAAAAA0DOa+ZNUq9Vy/vnn5zWveU1uuOGG3H777bnvvvuyaNGirFy5MieffHLmz58/7vtde+21kz7LS17ykrzkJS/Jj3/849xyyy3ZsGFDarVali5dmsc97nEHDPqhKwbXjg6r5j2jFycZZca38Ueayc18Y/Znr9qRe9r4ew0J8wEAAAAAmBmE+VNUq9Vy0kkn5aSTTur1UfLoRz86j370o3t9DBit3MqvHp4M9PbvalEU+fSG5IJfJPcNjv79EQPJBx+RnL18BoT4e9U085mBaqWvsZkJzfyB1b04BQAAAAAAfUaYD3Tejuta1/Oe3tPvg16/u8gbf558bj/F9JcsSy5+xAxp449UbuY3Z1Azv1lq5lc182eNmRDmD65pXdeP7c05AAAAAADoK8J8oLOKYnQzf25vRuwXRZF/35C86QBt/A88InnJTGrjjzRqzP4MauaPGrOvmT9r1Fe2rkeO3J8OikYydEfrnjH7AAAAAABEmA902tCa0UHVvKd3/RgHa+Of/as2/vKZ1sYfqTxmv7k5KXYnlTk9OU5bGbM/e033Zn7j7iSlTxcJ8wEAAAAAiDAf6LTyiP3qsmTgUV17/Kxv449UbuYnSWNjUj+q+2dpN2P2Z69ymD80zcL8obWt68q8sf+7CgAAAADArCPMBzqrPGJ/3tOTSneC8w2/auN/dja38UeqLk1SSVLs22vcOzPC/EapmW/M/uwx3Zv5g2ta1/XVXXuPBAAAAACgvwnzgc4pitHN/HnP6Mqj/33DniB/f238ix+RvHQ2tPFHqtSS6hFJc8SnGxobeneedimamvmzWb0U5hfbkua2pLqgN+eZqHIz34h9AAAAAAB+RZgPdM7QrUljXeve3Kd39JEbdhd508+Tz+ynjf/iZXvG6s+aNn5ZbVlrmN/cz39Q00mxNUmzda+qmT9r1FaO3mvck1Qf1v2zTEY5zB9Y3YtTAAAAAADQh6q9PgAwg5Vb+bUVycAjO/a4yzYUOfG7Ywf5hw8k//bo5LITK7M3yE9Gfxf3TGjml0fsJ8bszybVBUnl0Na96TRqf3Bt61ozHwAAAACAX9HMBzpn59da13Of3rHvgv639UVefvPYv5v1bfyRasta140Z0Mwvj9hPLalMkxHrtEftyD2TQPYamkZh/tCa1nX92N6cAwAAAACAvqOZD3RGUYxu5s97RkceNdQs8rZbR+8fPpD866OSf3+0IH/YTGzmN0vN/OrSjn1ohD5VO7J1PV2a+cVQMvTL1j3NfAAAAAAAfkUzH+iMwV8kjbtb9+Y+vSOPunxjcueu1r0X/aqNv0KI32omNvMbpWZ+7bDenIPeqR+ZjHwPmC5hfuOuJEOtewOre3ESAAAAAAD6kDAf6IydpVZ+bWUy8IiOPOriO1vXT16UXPbopKKdPdqMbOaXwvzq0t6cg96prWxdlz9I1K8GSyP2K4cm1SN6cxYAAAAAAPqOMftAZ+z4Wut67tM7Mvr8+1uLXL+lde+/Hy3I36/qDGzmjzVmn9mlPGZ/aJo084fWtq7rq31FBAAAAAAAw4T5QPsVxehm/rxndORRF61rXR85J3nxsrGvJTOzmW/MPuUwf7qM2S+H+UbsAwAAAAAwgjAfaL/BnyWN9a17HQjzN+4u8q+lx5x/VDKnqtm6X7XSJx2KB5Ji19jXThea+dSnaZg/uLZ1XV/di1MAAAAAANCnhPlA+5Vb+bVVSf34tj/mo3cnO5v71gOV5LVHtf0xM0u5mZ9M/1H75WZ+VTN/1hnVzF+fFM2xr+0nQ2ta1/Vje3MOAAAAAAD6kjAfaL8dY4zYb/P3QA81i3yoNGL/nOXJkYdo5R9Q9bAktda96R7mN8tj9jXzZ53aytJGI2lu7MlRJqQ8Zl8zHwAAAACAEYT5QHsVRbLja617c5/e9sdcsTH5ZWk6/AVHt/0xM0+lmtSOaN1rbOjNWdrFmH1qy5KUPsgz1Oej9ouhZOjO1r2B1T05CgAAAAAA/UmYD7TX4M1Js9T0nveMtj/molIG9uRFyUmLtPLHpbqsdT3dm/nG7FMZSKrlD6n0eZg/dGeSRuueZj4AAAAAACN0Pcz/3ve+1+1HAt1UbuXXHtL274H+wbYi129p3dPKn4Da8tb1TGvmG7M/O9WPbF33fZi/pnVdWWiqBAAAAAAALboe5r/iFa/IGWeckY9//OPZtGnTwV8ATC87r2tdz3tGUmlvY77cyj9yTnL2srGvZQy10n9Y5UkK00mxOym2te5p5s9OtekW5q9tXQ+sbvt7JQAAAAAA01tPxuzfdttt+fu///s87WlPy5vf/OZ885vf7MUxgHYrmsmOr7fuzXt6Wx9x32CR/+/61r3XHZXMqQrBxm0mNfMb94/e026enWorW9dDd/fmHOM1uLZ1bcQ+AAAAAAAl9V4+fHBwMFdffXWuvvrqrFy5MmeffXZe/OIXZ8WKFb08FjBZgz9Omhtb9+Y+o62P+Ohdyc7mvvVAZU+YzwSUm/mNadzML4/YT5KaZv6sNN2b+cJ8AAAAAABKut7M//3f//0sWbIkRVEM7xVFkbvuuisXXXRRTj311Lz2ta/NNddck0aj0e3jAVOx42ut6/oxe0ZHt8lQs8gH17XuvXR5cuQhWvkTMpOa+c3S17VUDk0qc3pzFnpr2oX5a1rX9WN7cw4AAAAAAPpW18P8d7zjHbn++uvz3ve+N0996lNT+dX3w+7990ajkW984xu54IIL8rSnPS3/8A//kNtvv73bxwQmY8d1res2t/K/cF/yy12texcc3dZHzA4zuZlvxP7sVZ9mYX55zH4bP/gEAAAAAMDM0PUwP0kGBgby3Oc+N5dcckmuueaavP71r8+RRx45qq2/cePGfPSjH81v//Zv5/d+7/dy5ZVXZvfu3b04MnAwRTPZ+fXWvXlPb+sjLrqzdX3ywuTkRVr5EzaTmvmNUjPfiP3Zazo184vdSaM0ZsSYfQAAAAAASnoS5o901FFH5Q//8A9z7bXX5iMf+Uie/exnp1arJdnX1i+KIv/v//2/vO1tb8spp5ySCy+8MD/96U97eWygbPcPR488n9e+Zv5N24p8fXPrnlb+JFVLzfxiW9Lc0ZuzTFX575xm/uxVW9m6bm7u37/XQ79M0mzdM2YfAAAAAICSnof5e1UqlfzWb/1WLrroolx//fX54z/+46xevXpUW3/Lli259NJL88IXvjBnn312/v3f/z0PPvhgD08OJEl2fq11XT8uqT+0bbcvt/KPnJO8ZPnY13IQ5WZ+kjSn6aj9hjH7/Eq5mZ8kjfXdP8d4DK1tXVcXJ7UlvTgJAAAAAAB9rG/C/JGWLl2a8847L1/+8pfzL//yLznrrLMyd+7c4d8XRZGiKPKjH/0of/EXf5Hf/M3fzJ/92Z/lxhtv7OGpYZbbcV3ruo0j9u8bLHJpKZN77VHJnKoR+5NSXZKk3rrXmKZhfrmZb8z+7FVdnFQOad3r11H7g2tb10bsAwAAAAAwhr4M80d60pOelL/7u7/LN77xjfzFX/xFHv3oRydpHcG/Y8eOfO5zn8vLX/7yPO95z8ull16abdu29fLYMLsUjWTn11v35rZvxP4ldyU7R0ykHqgkrzuqbbeffSqVpFYatd/Y0JuzTFVTM59fqVRGt/P7NcwvN/OF+QAAAAAAjKHvw/y9FixYkLPOOiu/8zu/k5UrV6YoilQqleF/JXuC/VtuuSUXXnhhTj311HzgAx/Irl27enxymAV237Tn+6lHalMzf6hZ5IPrWvdeujxZeYhW/pTMlDC/UWrmVzXzZ7VpE+avaV3Xj+3NOQAAAAAA6Gv1g1/SezfddFMuu+yyXHXVVdm+fXuS1mb+SJVKJUVR5IEHHsjFF1+cL3zhC7nooovyiEc8ouvnhlmjPGK//rCkfnRbbv2F+5I7Sp/JedOqttx6dqstb13PmDH7mvmzWm1l63ro7t6c42DKY/YHVvfiFAAAAAAA9Lm+DfO3bNmSyy+/PJ/5zGdyyy23JBkd3M+dOze//du/nXPOOScLFy7MZz/72VxxxRXZtGnTcKh/++235w/+4A/yhS98IUcccUQv/igw8+38Wuu6Ta38JLn4ztb1yQuTJy/Wyp+y6gxp5huzz0jTppm/tnVtzD4AAAAAAGPouzD/W9/6Vi677LJ89atfzeDg4HCAv7eJnyQPf/jD89KXvjRnnXVWFi5cOLz/J3/yJ/mjP/qjXHHFFbn44otzzz17/iH+/fffn0suuSR/8id/0t0/DMwGRSPZeX3r3rxntOXWN20r8rXNrXtvak/hn5nSzDdmn5Hq0yDML3Yljbta94T5AAAAAACMoS/C/PXr1+czn/lMPve5z+Wuu/b8A+6iKFKpVIYb9nPmzBlu4T/hCU/Y770GBgZy9tln57TTTssrXvGK/OIXv0hRFPn6178uzIdO2P39pLmldW/u09ty63Irf8Wc5CXLx76WCarNgGZ+UYxu5huzP7tNh2b+0B1JWicNGbMPAAAAAMBYehbmNxqNfPWrX81ll12Wb33rW2k2m6Na+EVR5GEPe9hwC3/RokXjvv+iRYvy+te/Pn/0R3+UJFm3bl37/xBAsuO61vXAI5L6UVO+7X2DRS5d37r3uqOSQ6pG7LdFuZnfnIbN/GJbkqHWPc382W06hPmDa1vX1cOS6uKeHAUAAAAAgP7W9TD/tttuy2WXXZYvfOEL2bRpz3jksVr4p59+es4555w88YlPnPSzTjjhhOGfd+/ePeWzQ7+pZDCVFHvGNvfKjmtb121q5V9yV7KjuW9dr+wJ82mTmdDML4/YTzTzZ7vaytb10D17JjhU+uhDQENrW9dG7AMAAAAAsB9dD/Of+9znDof2SWsL//jjjx9u4S9ePPWW2ty5c6d8D+hLQ+ty/Lzfz6ELvr9nvaanp2k17xlTvsVQs8gHS8M0Xro8WXlIHwVy0125md+Yhs388oj91JLK+Ce4MAPVS8387N7z96SfPuQhzAcAAAAAYJx6NmZ/ZAv/tNNOyznnnJMnPelJbX1GvV7PUUep8jIDbfrTHFr7fq9PMba5T5vyLa68L7mjNGzgTaumfFtGKjfzi+1J88GkemhvzjMZzVIzv7qkvxrYdF9txei9xj39FeYPlj59NXBsb84BAAAAAEDf60mYXxRFjjvuuLz0pS/NC1/4wra08MeyYsWKXHvttQe/EKabXo7VP5A5j0/qKw9+3UFcfGfr+qSFyZMVrtur3MxP9rTzp1OY3yg18/spsKU3Kofs+Q76kVMbGvckeVTPjjSKZj4AAAAAAOPU9TD/ec97Xl72spe1vYUPs8phf5XdW6/PnOrdvT7JPrWjkiM+MOXb/HBbkes2t+5dcPS+r+SgTSqLkgwkGdy319iQDKzu0YEmYVQz/7DenIP+UjtyjDC/jwjzAQAAAAAYp66H+e95z3u6/UiYeeackJ9u/3IqjdszUK/mkY98ZI8PVEnqxyaV6pTvdFGplb98IHnJGCVypqhS2dPOb6zbt9e8t3fnmYxRYb5mPklqK5PBn+xbD/XRh56aO5JG6TzG7AMAAAAAsB89GbMPtEMlu5urUhQDycDDen2Yttg0WOTS9a17r1uVHFLVyu+Icpjf2NC7s0yGMfuMpX5k67qfmvlDd4zeqx/T/XMAAAAAADAtTL1GC9Aml9yd7GjuW9cryeuO6t15ZrzastZ1Y7o3843ZJ3vG7I/UV2H+2tZ19fCkurAnRwEAAAAAoP91vZl/zz335OMf//jw+nWve12WLp1Ym/K+++7LRz7ykeH1a17zmhxxxBFtOyPQfY2iyAfXte69ZFly1CFa+R1TK31/wXRr5jdLzXxj9kmmV5hfX92LUwAAAAAAME10Pcz/13/91/yf//N/UqlU8pjHPGbCQX6SHH744bnhhhvyox/9KEmyaNGivPGNb2z3UYEuunJjcvvO1r0Lju7NWWaN6d7Mb2jmM4ZymD/UR2H+4JrW9cCxvTkHAAAAAADTQtfH7P/Hf/zH8M/nnHPOpO9zzjnnpCiKFEWRL33pS+04GtBDF93Zun7SwuTJi3pzlllj2jfzS2F+TTOfJLWVrevG3b05x1g08wEAAAAAmICuhvl33XVXbr/99iRJpVLJs5/97Enf69nPfnaq1T3HX7NmTdavX9+WMwLd96NtRa7b3Lp3wdF73ifooOo0b+Ybs89Y6qVmfvO+pNjdm7OUCfMBAAAAAJiArob5P/3pT5PsCehWr16dRYsmX7tdvHhxVq9ePerewPRz0brW9fKB5KXLx76WNpruzfzymP2aMftk9Jj9pH/+bpfD/IHVvTgFAAAAAADTRFfD/HXr9iV2xxxzzJTvN/Ied9555wGuBPrVpsEi/1L6SuvXHpUcUtXK77haqZnfvDcpit6cZaKKwaTY2rqnmU/yq78H9da9xj1jXtpVze1JozRFqH5sb84CAAAAAMC00NUw/8EHHxz+ecGCBVO+38h7jLw3MH187O5kR3Pful5Jzl/Vu/PMKuVmfrEzKbb15iwT1dw8eq+qmU+SSjWprWjdG+qDMH/o9tF79al/sBEAAAAAgJmrq2H+vHnzhn/eunXrAa4cn23b9oVO9Xr9AFcC/ahRFPlgacT+2cuSow7Ryu+KcjM/SRr3dv8ck1EesZ8I89mnvrJ13bi7N+cYqTxiv7osqR7ak6MAAAAAADA9dDXMX7p03wjkO+64Y8r3G3mPkfcGpocvbkzW7mzdu+Do3pxlVqosSCpzW/f65bvFD6Z5f+u6Mj+pzh37Wmaf2pGt634Ys18O8wdW9+IUAAAAAABMI10N8/d+x31RFFmzZk3WrVt3kFfs37p163LrrbcOr1etMpcbppuL7mxdP3Fh8t8W9eYss1KlsqcdPNJ0aeY3S818rXxG6scwf3BN67p+bG/OAQAAAADAtNHVMP/EE0/MwoULU6nsGaH94Q9/eNL3+ud//ufhn+fNm5fHP/7xUz4f0D0/2lbk2s2texccneH3B7qktrx1PV2a+Y1SM79mOgsjlMP8oT4I88vN/PrqXpwCAAAAAIBppKthfrVazTOf+cwURZGiKPLZz342V1111YTvc9VVV+Wyyy5LpVJJpVLJM57xjNTr9Q6cGOiUi0uDOZYPJOcsH/taOqhWauY3NfOZAfqxmW/MPgAAAAAAE9TVMD9J3vCGN6Rer6dSqaTZbOZtb3tbPvCBD2RoaOigr200GvnQhz6Ut73tbUn2jOuvVqt5wxve0OljA210/2CRfylla685KjmkqpXfddO1mT8qzNfMZ4T6ytZ14+7enGMkY/YBAAAAAJigrtfZH/rQh+a8887Lhz/84VQqlQwNDeXiiy/Ov/7rv+ass87Kk570pBx//PHD4/gfeOCB3Hbbbfl//+//5fLLL8/GjRtTFMVwK//cc8/N8ccf3+0/BjAFH7s72d7ct65XkvNX9e48s1q5md+YJs18Y/Y5kLGa+UWR9OprPJrbkubG1j1j9gEAAAAAOIiezKZ/85vfnNtuuy1f+cpXUqlUUhRFNm7cmEsuuSSXXHLJfl9XFEWSDL/m9NNPz//4H/+jW8cG2qBRFPlAacT+2cuSVYdo5ffEjGnmG7PPCOUwv9iRFFuTyqLenGfo9tF79WO6fw4AAAAAAKaVro/Z3+t973tfXve61w2vK79qyxVFMea/Rl6TJOeff37+8R//sbuHBqbsixuTtTtb9950dG/OQqZvM79ZauYbs89ItRWj94buGb3XLUNrW9e1FUl1Xk+OAgAAAADA9NGzML9areYtb3lLPv3pT+eZz3xmkn3N+7HsHa1/2mmn5bLLLsub3/zmVKs9Oz4wSReXWvlPXJj8Ro/KsmT6NvMbpWZ+TTOfEaqHJpWFrXuNHob5g2ta1/Vje3MOAAAAAACmlZ6M2R/p13/91/OBD3wgmzZtyne/+9384Ac/yMaNG7N58+YkyeLFi7Ns2bI87nGPy0knnZSlS7UvYbr68YNFvloqVL9pVevUDbqsOkYzv5ffLT5eo8bs+98GSuork8Gt+9aNu3t3lnIzv766F6cAAAAAAGCa6XmYv9fSpUvz27/92/nt3/7tXh8F6JCL7mxdLxtIzlk+9rV0SbmZn91J8UBSWdyT44ybMfscTO3IZPDn+9a9bOaXw/yB1b04BQAAAAAA04w59UBX3D9Y5F9KWdprj0rm1vq8AT7T1ZaN3mvc2/1zTERRGLPPwdWObF33dMz+2ta1Zj4AAAAAAOMgzAe64mN3J9ub+9b1SnL+qt6dh1+pHppU5rfuNTb05izjVWxPMti6p5lPWTnMH+plM39N67p+bG/OAQAAAADAtCLMBzquURT54LrWvRcvS1YdopXfF8rt/H5v5jc3jd6rauZT0i/N/OYDo//OauYDAAAAADAOwnyg4750X7JmZ+vem7Ty+0dteeu635v55RH7qSTVxT05Cn2svrJ13bi7N+cYun30Xv2h3T8HAAAAAADTTr3XB9hr06ZNue2227Jly5Zs27YtRVFM6PVnnXVWZw4GTNlFd7aun7AgeYrstX9Up1sz//7WdfWwpOKzaZT0SzN/cG3rurYyqc7tyVEAAAAAAJheehrm33PPPbn00ktz1VVX5a677prSvYT50J9ufrDIV0vZ6wVHJ5WKEft9Y7o188sjy43YZyyjwvx7k6KRVGrdPcfQmtZ1/djuPh8AAAAAgGmrZ2H+pz/96bzrXe/Krl27JtzC36tSqaQoCqEg9LFyK/+IgeSc5WNfS4/USs38Zp838xulT4fUlvbmHPS3cpif5p5Av17e77Chta3rgdXdfT4AAAAAANNWT8L8j3/84/n7v//7MYP4ketyyF/+3WQ/BAB0x+bBIp8qTbZ+7VHJ3JoP4PQVzXxmotqyJNUkzX17jXu6H+aXx+zXV3f3+QAAAAAATFtdD/NvvvnmvOc970myr1l/2mmn5dRTT02tVstb3/rW4d998pOfzIMPPpiNGzfm+9//fq655pps2bIllUolS5cuzdve9rYcddRR3f4jAOP0sbuT7SNytFolOd9/ZftPuZnf6PNm/qgwXzOfMVRqez6o0hjxiaLG3Uke191zGLMPAAAAAMAkdT3M//CHP5xGo7Hn4fV63vve9+a0005Lkqxbt67l2pNPPnn455e85CV55zvfmY9+9KP58Ic/nPvvvz9///d/n0suuSS/9mu/1r0/ADAujaLIB1r/K50XL0uOnquV33emWzPfmH3Gq3ZkKcy/Z//Xdkp5zL5mPgAAAAAA41Tt5sN27tyZa6+9NpVKJZVKJeeee+5wkD8ec+fOzZve9KZcdNFFqdVq2bRpU1772tfm/vvvP/iLga666r5kzc7WvQtW9eYsHMRYzfx+/hoTY/YZr1pppP5Ql8P8xuakubl1b2B1d88AAAAAAMC01dUw//vf/36GhoZSFEVqtVp+//d/f1L3ecYznpHzzjsvSbJx48Z84AMfaOcxgTa46M7W9eMXJE9Z3JuzcBDlZn6GRgeQ/aRZ+gCXMfvsTznM73Yzf+j20kYlqT+ku2cAAAAAAGDa6mqYf+ede9K9SqWS448/PocffvgBrx8aGtrv784777zU6/UURZEvfvGLw6P7gd67+cEi15Ty1guO3vPfffpQddnovca93T/HeDVKzfyaZj77Ue91mL+mdV1blVQO6e4ZAAAAAACYtroa5m/ZsmX452OOOWbU7+v1est69+7d+73XggUL8tjHPnb4vt/73vfadEqYHu5ozMl3hhZmY7N+8Iu77OJSK/+IgeRl5fI3/aM6L6ksaN1rbujNWcZj1Jh9zXz2o7aydd24u7vPH1rbujZiHwAAAACACehqCjiyPT937txRvz/00ENb1vfdd1/mz5+/3/utWLFi+Oe77rqrDSeE6eGLG4u8ePPDM5hqKtuLPO3GImcvT150RHLkIb1tv28eLPLJUvn1NUclc2ta+X2ttiwZ2rZv3c/NfGP2Ga9ej9kfXNu6rq/u7vMBAAAAAJjWutrMHxnWb9++fczf12q14fXBAvqRHw7YuHFjG04I08P/565k8Ff/9S1Sydc2J2/6ebLqW8mpNxb54Loi9+wqenK2j9+TbG/uW9cqyeuP6slRmIhaaXRCo0+b+UUjaW5p3TNmn/0ph/lD3R6zv7Z1LcwHAAAAAGACuhrmr1q1avjn++67b9TvK5VKy/j9H/zgBwe83y9+8Yvhn8sj+mEme+ShY+8XyXCwf/SIYH/97u4E+42iyAdKI/ZfdERy9Fyt/L5XW9a67tcwv7l59J5mPvtTDvOLrUnzwe49f2hN67p+bPeeDQAAAADAtNfVMP/4449PkhRF0RLEj/SoRz1q+Ocrr7xyv/f63ve+l9tuu214PXLkPsx0f7k6+Z25GzM/jf1e08y+YH/V/90T7H+ow8H+Vfclt+1s3bvg6I49jnYa1czv0zH7zU2j96qa+exH/cjRe4313Xl2UYwesz+wujvPBgAAAABgRuhqmP+Qhzwky5fvCYwefPDB/PznPx91zemnnz788y233JL3vOc9o66544478ra3vS2Vyp62b6VSyZOe9KQOnRr6z7xaJX9y6N25euFNee/C2/M7y5MFtf1fvzfYf2OHg/2LS638xy1Inrq4rY+gU6rTpJnfKIX5lblJdV5vzkL/qyxMKvNb9xp3d+fZzc1J8UDrnjH7AAAAAABMQNdn0z/lKU/J5ZdfniS57rrr8ohHPKLl90972tOyatWq3HXXXSmKIpdcckm++tWv5qlPfWoOPfTQrF27Nl/72teye/fuFEWRSqWSpz3taVm2bNkYT4OZbW6lyKkDD+TNj65kR6PIf2xKPrMhufK+ZNt+Svt7g/2vbU4u+HnytCVFzl6evGhZsmLO5Mfh/+TBIv+/+1v3Ljg6wx+6oc9Nm2Z+6S+ZEfscSKWyZ9T+0L5JPhm6pzvPHlpb2qgm9Yd059kAAAAAAMwIXW3mJ8lznvOcJHtG7X/mM58Z9fs5c+bkne98Z5I9IWBRFFmzZk0uvfTSfOQjH8lXvvKV7Nq1a/j6BQsW5B3veEd3Dg99bF6tkhcuq+TSR1ey/qnJZ09Mfmd5cuhBGvvXbd7X2H/mFBr7F69rXR8xsOf5TBOjwvw+beaXx+wbsc/B1Eqj9hvdCvPXtK7rRyeVge48GwAAAACAGaHrzfynPvWpecMb3pBms5kkWb9+/ajvu3/605+ev/mbv8lf/dVfZXBwcFSzd2/Iv2TJklx88cV56EMf2rXzw3SwJ9hPXrgsLY39L9yXPHiAxv51m/f8a6KN/c2DRT5ZysfOW5nMrWnlTxu10nSTZp828xulZn5NM5+D6FWYP7i2dW3EPgAAAAAAE9T1ML9er+e///f/ftDrzj777Jx00kn5yEc+kq9//evZuHHj8O8e8pCH5PTTT8+5556bpUsFOXAgYwX7l/1qFP9Egv2X/CrYXz5GsP/xe1rvVaskr1/ViT8NHTOqmb8xKZpJpesDXA5MM5+Jqveqmb+2dI7V3XkuAAAAAAAzRtfD/Ik45phj8rd/+7dJkh07dmTr1q1ZtGhR5s6d2+OTwfRUDva//KvG/niD/TeNEew3iiIfuLP1NS86InnIXK38aaXczE9jz/fT1w7vyXH2q1EO832gi4OorWxdN+7uznNHjdk/tjvPBQAAAABgxujrMH+kefPmZd68eb0+BswY82qVvGjZnlB+ssH+05cUefSC5Ladrde96egOH572GxXmJ2ls6L8wv2nMPhNUHrM/1KMx+wOru/NcAAAAAABmjK6G+WvXrs31118/vH7uc5+bI444optHAMYwMtjfPmIU/xcPEuxfu3nPv0Z63ILkNxd3+MC0X+WQpLIoKR7Yt9e4N8mv9exIYzJmn4kqh/ndGLNfFMbsAwAAAAAwZV0N86+//vq8613vSpIsWbIkL3/5y7v5eGAc5peC/S/fl3zm3gMH+yO96eikUjFif1qqLU+GRob5G3p3lv0pN/ON2edg6uUwf31SNJNKtXPPbG5Kim2lc6zu3PMAAAAAAJiROvhPskfbuXNniqJIkjzqUY9KvT5tpvzDrDS/VsmLl1fyr4+uZP1Tk8senZyzPJm/n3eOwweS31ne3TPSRuVR+817e3OOA2mUmvk1zXwOotzMz9DoCQ/tNrSmfIik7vtHAAAAAACYmK6m6UuX7mtQHnaYAAamkz3BfvLi5a2N/Ss3JtubSSXJe47fM7KfaapW+iRGXzbzy2P2NfM5iNqK0XuNu5NaB7/mZ3Bt67r+kKTiA4wAAAAAAExMV//J8ooV+/6B+pYtW7r5aKCNysH+jVuTlYckx80T5E9r5WZ+o8+a+UVhzD4TVxlIqkckzY379obuSeY8pnPPHFrbujZiHwAAAACASejqmP0nPvGJmTdvXoqiyI9+9KPhkfvA9DW/VslTl1QE+TNBvzfzix1Jsat1z5h9xqM8ar9xT2efJ8wHAAAAAKANuhrmz58/P8985jOTJJs3b85XvvKVbj4egAPp92Z+uZWfaOYzPvUuh/mDa1rXA8d29nkAAAAAAMxIXQ3zk+Stb31rlixZkiT527/929x1113dPgIAY+n3Zn5z0+i96uLun4PpRzMfAAAAAIBpqOth/ooVK/Le9743hx56aDZs2JCXvexlueaaa7p9DADKqn3ezG+UwvzqkqRS68lRmGZqK1vXQ3d37llFIcwHAAAAAKAt6t1+4H/9139lYGAgf/Inf5J3vetd2bBhQy644II85CEPydOf/vT82q/9WpYuXZr58+dP6L4nnXRSh04MMEuUm/nNjUnR6J/AvDxm34h9xqubzfzmxqTY3ro3sLpzzwMAAAAAYMbqepj/e7/3e6lUKsPrSqWSoihyxx135FOf+tSk7lmpVHLzzTe364gAs1Ot1MxPsWe0/aj9HhnVzD+sN+dg+ql3McwfXFN+eFJb1bnnAQAAAAAwY3U9zN+rKIrhUH9kuF8URa+OBDC71Y4YvdfY0D9hfrmZX9PMZ5y62cwfNWL/of0z3QIAAAAAgGml2ouH7g3si6IY9S8AeqQyZ8/30I/UuLcnRxlTs9zMF+YzTuUwv3l/UuzqzLNGhfmrO/McAAAAAABmvK4389/1rnd1+5EAjFdtedLcvG/d2NCzo4xizD6TVVs5em/onmTgmPY/qzxmf+DY9j8DAAAAAIBZoeth/gtf+MJuPxKA8aouS/Lzfeu+auYbs88kVZckmZNk9769RofCfM18AAAAAADapCdj9gHoU7Xlret+auaPGrOvmc84VSpJvTRqv3FPZ54lzAcAAAAAoE2E+QDsU1vWum72cTO/qpnPBNS6EOYXxegwf2B1+58DAAAAAMCsIMwHYJ9+buY3Ss18Y/aZiNrK1vXQ3e1/RmN9Uuxs3asf2/7nAAAAAAAwKwjzAdin3Mxv9FMz35h9pqAbzfxyKz8Doz9EAAAAAAAA4yTMB2Cffm3mF42kuaV1TzOfiehFmF8/Jqn4v1oAAAAAAExOvdsPvPzyyzty37POOqsj9wWYVfq1md/ckqRo3dPMZyLqPQjzB1a3/xkAAAAAAMwaXQ/z3/72t6dSqbT9vsJ8gDYoN/Ob9yXFUFLp+v9clM5x/+i9qmY+E9CNZv7gmtZ1/dj2PwMAAAAAgFmjZ+lMURQHv+ggKpVKiqLoyIcDAGal6rLRe437kvqK7p+l5QybWteVQ5LKvN6chemp/N31Q3cnRZG08/9DjBqzv7p99wYAAAAAYNbpyRe5TiXIr1Qqw+F9Oz4QAMAItSNG7zU3dP8co85QCvOrh7U3hGXmKzfzsztpbm7vM4zZBwAAAACgjbrezP/kJz85oeubzWa2bt2aW265Jd/85jfzve99L0myePHivP3tb8+qVas6cUyA2alS3zO+fmR43ri3d+fZqzxm34h9Jqo2xnSJxj1J7bD23L9oJkO3t+5p5gMAAAAAMAVdD/NPPvnkSb3u2c9+dl7/+tfne9/7Xv7kT/4kd955Z/73//7f+djHPpZHPvKRbT4lwCxWW14K8/ugmV8es19tUwDL7FGdm1SXtLbxG/ck+bX23L9xT1Lsat2rH9ueewMAAAAAMCv1ZMz+VDzxiU/MpZdempUrV2bTpk157Wtfm02bNh38hQCMT21Z67ofm/k1zXwmoTxqv3FP++5dHrFfOWTsaQAAAAAAADBO0y7MT5IVK1bkHe94R5Lk3nvvzfvf//4enwhgBqktb133QzO/WW7mC/OZhNrK1vXQ3e27dznMrx+TVKbl/80CAAAAAKBPTNt/yvzsZz87S5cuTVEUufLKK7Njx45eHwlgZqj2YTPfmH3aoZPN/ME1rWsj9gEAAAAAmKJpG+ZXKpWceOKJSZLt27fnu9/9bo9PBDBD9GUz35h92qDexTH79dXtuzcAAAAAALPStA3zk2TRokXDP999dxtH5QLMZrVSM7/ZB838UWP2NfOZhE4288th/sDq9t0bAAAAAIBZaVqH+Vu2bBn++YEHHujhSQBmkH5s5jc082mDjo7ZX9u61swHAAAAAGCKpm2Yv2vXrtx4443D6yVLlvTuMAAzSbmZ3+jHZr4wn0morWxdD7Vpqk/RSIZub92rH9ueewMAAAAAMGtN2zD/fe97X7Zt2za8Pv7443t4GoAZpNzMb96fFIO9OcvwGYzZpw3qpWZ+c2N7/m437k5Suo9mPgAAAAAAU1Tv9QEm6o477sgHP/jBXHHFFalUKimKIocddlge//jH9/poADNDuZmfJI2NSX3l6P1uaO5Iip2te8bsMxnlMfvJnq+RqK+a2n2H1rauK3NHfygGAAAAAAAmqOth/jve8Y4Jv6bRaOSBBx7ImjVrcscddyRJiqJIklQqlbz+9a9PtTpthwwA9Jfq4UkqSYp9e40NPQzz7x+9p5nPZFQPT1JL0ti317hn6mH+4NrWdX11UqlM7Z4AAAAAAMx6XQ/zP//5z6cyyX/APTLA39vKf85znpPf+73fa+cRAWa3Sm1P6NncuG+vcW/vzjNmmL+k68dgBqhUk9qKpHHXvr3GPVO/79Ca1nX92KnfEwAAAACAWW9ajdnfG+AXRZG5c+fm9a9/fc4777xeHwtg5qktbw3zmxt6d5bGptZ1dXFSmVb/80U/qa1sDfOH7p76Pctj9gdWT/2eAAAAAADMej1JQ/Y27MerVqtlwYIFOeyww/LIRz4yT37yk3PGGWdk0aJFHTohwCxXW54M3rxv3ehhmN8sh/lG7DMF9SOT3SPW7WjmjzVmHwAAAAAApqjrYf5Pf/rTbj8SgImqLWtd99OY/erS3pyDmaF2ZOu6LWP217auhfkAAAAAALRBtdcHAKAP1Za3rnvZzC+P2a9p5jMF7Q7zi0YydEfrXv3Yqd0TAAAAAAAizAdgLJr5zFTlMH9oimF+Y12Soda9gdVTuycAAAAAAESYD8BY+qmZ3yw184X5TEVtZeu6cffU7je4tnVdmZ9Uj5jaPQEAAAAAIMJ8AMZS7aNmvjH7tFN9jDH7RTH5+w2tKd3/2KRSmfz9AAAAAADgV+rdfuDQ0FBuueWW4fUxxxyTefPmTege27dvzx137Pt+2kc84hGpVn0uAaBt+qqZb8w+bVQes19sT4ptSWXh5O43tLZ1bcQ+AAAAAABt0vUw/4tf/GLe8Y53JEmWLFmS6667bsL3qFQq+YM/+INs2bIlSfLe9743z3nOc9p6ToBZrVZq5hcPJMWupHJI988yasy+Zj5TUFsxeq9xT1KdZJhfHrNfXz25+wAAAAAAQEnX6+yf+9znUvxqnO1LX/rSzJ07d8L3mDdvXs4555wURZGiKPKZz3ym3ccEmN3Kzfykd6P2G6Vmfk0znymoLkgqC1r3hu6Z/P3KzXxhPgAAAAAAbdLVMP/BBx/MDTfcMLx+3vOeN+l7jXztf/3Xf2Xnzp1TOhsAI1QPS1Jr3etVmD+qmS/MZ4rqK1vXjbsnf6+hNaV7Hzv5ewEAAAAAwAhdDfN/8pOfZGhoKEmydOnSPPzhD5/0vR7+8Idn6dI9gc7g4GBuvvnmtpwRgCSValI7onWvsaH75yiaSbPUzDdmn6mqHdm6bkyymV8MJUN3tu4NrJ7cvQAAAAAAoKSrYf6aNXvaa5VKJSeccMKU7zfyHnvvDUCbVJe1rnvRzG8+kKRo3TNmn6lqV5g/dGeSRuueMfsAAAAAALRJV8P8zZs3D/982GFTb1bubeYnyZYtW6Z8PwBGqC1vXfeimV8esZ9o5jN15TB/aLJh/trWdWWBr4EAAAAAAKBtuhrmj7R33P5UNBr72nCDg4NTvh8AI9RKzfxmL5r5pRH7GUgqh3b/HMwsbWvml6YCDRybVCqTuxcAAAAAAJR0Ncwf2ca/996ph0Ij77FkyZIp3w+AEfqhmd8oNfNrS4WlTF19Zeu6cffk7jO4tnTf1ZO7DwAAAAAAjKGrYf6yZXtankVR5Mc//nF27do16Xvt3LkzP/zhD4fXhx9++JTPB8AI5WZ+oxfN/FKYb8Q+7dC2Zv7a1rUwHwAAAACANupqmP+EJzwhtVotlUolu3fvzhVXXDHpe33hC1/I7t27kySVSiVPeMIT2nVMAJL+aOaXx+z7PnLaYVSYvyEpGmNfeyDCfAAAAAAAOqirYf7ChQvzmMc8JkVRpCiKvP/978/69esnfJ/169fn/e9/fyqVSiqVSh71qEdl6VIBD0Bb9UMzf9SYfc182qAc5qeZNDZO/D6Da1rXA8dO+kgAAAAAAFDW1TA/Sc4999wke9r0GzduzLnnnps1a9Yc5FX73H777Xn1q1+djRs3piiKJMmrXvWqjpwVYFbTzGemqi1LUmndm+io/WJ30ljXuqeZDwAAAABAG3U9zD/ttNPyuMc9LkVRpFKp5NZbb82LXvSivPvd786tt96639fddtttefe7352zzjort95663Ar/8QTT8wZZ5zRxT8BwCxRLTXzi21Jc0d3z9AsNfOF+bRDpT7Gh1Xuntg9hu5M0mzdE+YDAAAAANBG9V489J/+6Z9y9tlnZ+PGjalUKtmxY0c+8YlP5BOf+ESWLFmS4447LgsXLkylUsnWrVtz22235f7797Qz934IoCiKrFixIhdffHEv/ggAM1857EyS5r1J9aHdO4Mx+3RK7cikMeKrfibazB8qTRWqLvb3EwAAAACAtupJmL9ixYp84hOfyBvf+MasXbs2lcqeUbdFUeT+++/PDTfc0HL93nH6e9v4RVHk2GOPzcUXX5wVK1Z0/fwAs0J1Sfb8z8TQvr3GvUm9i2G+Mft0Su3IJD/Yt55omD+4tnWtlQ8AAAAAQJt1fcz+Xscff3w++9nP5uUvf3nmzJnTEtiXjQz758yZk9/93d/NZz/72Rx//PFdPTPArFKp/Oq7xUdobOjuGUaN2dd8pk1qR7auhybazF/buhbmAwAAAADQZj1p5u916KGH5s///M/zxje+MVdccUW+853v5Ac/+EE2b97cct3ixYvz+Mc/Pk9+8pPzghe8IEuXamYCdEVtWet3iTfu7e7zG6Vmfs37P21SDvMnPGZ/betamA8AAAAAQJv1NMzf6/DDD8+5556bc889N0kyNDSULVu2JNkT5NfrfXFMgNmntrx13fNmvjCfNqmvbF2P/NDKeAyuaV0PHDu18wAAAAAAQElfpuT1ej2HH354r48BQLU8Zr+LzfxiV1JsL53HmH3aRDMfAAAAAIA+V+31AQDoY71s5pdH7CfG7NM+5TB/aAJhfrEradzVuifMBwAAAACgzYT5AOxfrdTMb3axmV8esZ8k1SXdez4zWznMLx5ImtvHvrZs6JdJita9gdXtOBUAAAAAAAzr+pj9oaGh3HLLLcPrY445JvPmzZvQPbZv35477rhjeP2IRzwi1arPJQC0XS+b+c1SM7+yMKkMdO/5zGz1I0fvNdYn1WMP/trBNa3r6mFJdXF7zgUAAAAAAL/S9TD/i1/8Yt7xjnckSZYsWZLrrrtuwveoVCr5gz/4g2zZsiVJ8t73vjfPec5z2npOADK6md/oYjO/UWrmG7FPO1UWJZV5SbFj317j7mRgHGH+0NrWtRH7AAAAAAB0QNfr7J/73OdSFHtG0770pS/N3LlzJ3yPefPm5ZxzzklRFCmKIp/5zGfafUwAkh4380thfvWw7j2bma9SGT1qv3HP+F4rzAcAAAAAoAu6GuY/+OCDueGGG4bXz3ve8yZ9r5Gv/a//+q/s3LlzSmcDYAzlZn6xPWk+2J1nl8fsVzXzabNymD80yTB/YHU7TgMAAAAAAC26Gub/5Cc/ydDQUJJk6dKlefjDHz7pez384Q/P0qV7gp3BwcHcfPPNbTkjACOUm/lJ90btjxqzr5lPm022mT+4pnVdH8dofgAAAAAAmKCuhvlr1uz5h9+VSiUnnHDClO838h577w1AG1UWJRlo3etWmK+ZT6fVjdkHAAAAAKB/dTXM37x58/DPhx029Ybl3mZ+kmzZsmXK9wOgpFIZ3c5vbujOs5ulZr4wn3arrWxdN+4++GuaO0dfZ8w+AAAAAAAd0NUwf6S94/anotFoDP88ODg45fsBMIbasta1MfvMFJMZsz90++g9zXwAAAAAADqgq2H+yDb+vfdOPQwaeY8lS5ZM+X4AjKHczG90q5lvzD4dVg7zh8YT5q9tXVcPT6oL23YkAAAAAADYq6th/rJle9qdRVHkxz/+cXbt2jXpe+3cuTM//OEPh9eHH374lM8HwBh61cwfNWZfM582G9XMX58UzQO/phzma+UDAAAAANAhXQ3zn/CEJ6RWq6VSqWT37t254oorJn2vL3zhC9m9e3eSpFKp5AlPeEK7jgnASL1q5jdKzfyaZj5tVi+F+RkcPRGirBzmD6xu44EAAAAAAGCfrob5CxcuzGMe85gURZGiKPL+978/69evn/B91q9fn/e///2pVCqpVCp51KMelaVLhTwAHVHtQTO/aI7RzPc+T5vVVozea9x94NcMrmld149t33kAAAAAAGCErob5SXLuuecm2dOm37hxY84999ysWbPmIK/a5/bbb8+rX/3qbNy4MUVRJEle9apXdeSsAKQ3zfxia5LSuHNj9mm3ypw933k/0tA9B36NMfsAAAAAAHRJ18P80047LY973ONSFEUqlUpuvfXWvOhFL8q73/3u3Hrrrft93W233ZZ3v/vdOeuss3LrrbcOt/JPPPHEnHHGGV38EwDMMuUwv9mFZn55xH5izD6dUSuN2m9MMMw3Zh8AAAAAgA6p9+Kh//RP/5Szzz47GzduTKVSyY4dO/KJT3win/jEJ7JkyZIcd9xxWbhwYSqVSrZu3Zrbbrst99+/J9jZ+yGAoiiyYsWKXHzxxb34IwDMHrXymP0NSVEklUrnnlkesZ9aUlnQuecxe9WPTAZ/vG99oDC/uSNplL4eSDMfAAAAAIAO6UmYv2LFinziE5/IG9/4xqxduzaVXwVCRVHk/vvvzw033NBy/d5x+nvb+EVR5Nhjj83FF1+cFSvG+L5bANqn3MwvdibFg50N15ulZn51aWc/PMDsNZFmfrmVnwjzAQAAAADomK6P2d/r+OOPz2c/+9m8/OUvz5w5c1oC+7KRYf+cOXPyu7/7u/nsZz+b448/vqtnBpiVys38ZE87v5MapWa+Eft0Sm1l67px9/6vLYf51WVJ9dC2HwkAAAAAAJIeNfP3OvTQQ/Pnf/7neeMb35grrrgi3/nOd/KDH/wgmzdvbrlu8eLFefzjH58nP/nJecELXpClS4U6AF1TWZBU5u5p5O/VuDcZOK5zzyyP2a8e1rlnMbuVm/lDE2jmD6xu92kAAAAAAGBYT8P8vQ4//PCce+65Offcc5MkQ0ND2bJlS5I9QX693hfHBJidKpU9DeTGL/ftdbqZP9aYfeiEiYzZH1zbujZiHwAAAACADurZmP0DqdfrOfzww3P44YcfMMhfv359PvKRj+S5z31uF08HMAvVlreuG/d29nmjxuxr5tMh9QmE+UNrSq89tv3nAQAAAACAX5l2lfedO3fmK1/5Sq644or853/+Z5rNZq+PBDDz1Za1rpua+cwQ5WZ+c1NS7Br7WmP2AQAAAADoomkT5v/Xf/1XPv/5z+fqq6/O9u3bkyRFUSRJKpVKL48GMPONauZ3OMwvN/OF+XRKbeXovcb6sa81Zh8AAAAAgC7q6zD/jjvuyOWXX54vfOELWbduXZLWAL9SqQyvAeigcjO/02P2m8bs0yXVw5IMJBnctzd0T5K5rdc1tyXN0t97Y/YBAAAAAOigvgvzt23bli9/+cv5/Oc/nxtvvDHJ2AF+URRZtmxZTj/99Dz3uc/t5ZEBZr5uN/ON2adbKpU9o/Ybv9y317gnyerW64ZuH/3a+jGdPBkAAAAAALNcX4T5RVHkG9/4Ri6//PJce+212bVr1/B+kpYA/4gjjshpp52W5zznOXnSk55kxD5AN3S7mT9qzL5mPh1UH0+Yv7Z1XVuRVOd1+GAAAAAAAMxmPQ3zf/GLX+Tzn/98rrzyymzcuDHJ/sfov/CFL8wLXvCCnHzyyalWqz07M8Cs1Otmfk0znw6qHdm6btwz+prBta3r+upOnQYAAAAAAJL0IMzftGlTvvjFL+byyy/PT37ykyT7H6M/snV/wQUX5Kijjur2cQFIkuoYzfyi2DOivN2K3UmxrfR8YT4dVFvZuh66e/Q1Q2ta1/VjO3ceAAAAAABIl8L8oaGhXHfddfn85z+f66+/Po1GY78B/jHHHJPnP//5OfPMM3Paaad143gAHEy5mZ/dSfFAUlnc/mc17h+9Z8w+nTSeZn55zP7A6k6dBgAAAAAAknQ4zL/pppty+eWX50tf+lIeeOCBJK0t/L0B/mGHHZbnPve5OfPMM/PYxz62k0cCYDJqy0bvNe5Nqh0I88sj9pOkJsyng+rG7AMAAAAA0H/aHuavX78+V1xxRS6//PKsWbNnJO3IAH+vOXPm5NRTT82ZZ56ZU045JfV61yf+AzBe1UOTyvyk2L5vr7EhGXhY+5/V3NS6rhyaVOa0/zmw12Sa+cJ8AAAAAAA6rO0J+jOe8Yzhxv1ee1v4SXLyySfnBS94QU4//fQsWLCg3Y8HoFNqy5Kh2/etG/d25jnlZn51aWeeA3uNGebv+/8xaW5Nmve1XlM/tuPHAgAAAABgdmt7mN9sNlOpVIZb+EVR5GEPe1jOPPPMPP/5z8+RRx55kDsA0Jdqy0th/obOPKdRaubXhPl0WG1l67rYmWq2Jpm3Z11u5SdJ/aGdPhUAAAAAALNcx2bbF0WRSqWSpz3taXnrW9+ahz2sA6OYAeie6rLWdcea+aUwv3pYZ54De9VWjNoaqNyXXTl6z2Jwben6lUl1bufPBQAAAADArFbt1I33NvOvv/76PP/5z88LX/jCfOITn8i993Yo/AGgs2rLW9cda+Ybs0+XVecl1cUtW/Xqxn2LcjO/vrrjRwIAAAAAgLaH+f/tv/23VCqVFMW+75otiiI/+clP8u53vztPf/rTc+655+byyy/P9u3b2/14ADqlVmrmN7vUzK9p5tMFtdavAapXRob5a1qvHTi2CwcCAAAAAGC2a3uY/4lPfCLXXntt3vzmN+eYY44ZDvX3NvUbjUa+/e1v5x3veEee+tSn5o/+6I/yta99LY1Go91HAaCdutXMb2rm0wOlMH+gct++RXnMvmY+AAAAAABd0JEx+0ceeWTOP//8/Md//Ec+/elP55xzzsmiRYtGtfV37NiRL3/5y3n961+fU045JRdeeGF+8IMfdOJIAExVuZnf6FAzv1Fu5gvz6YLaypZlvTLi77cx+wAAAAAA9EC90w947GMfm8c+9rH5sz/7s3z1q1/NFVdckW9+85sZGhoabusXRZFNmzbl0ksvzaWXXpqHPvShef7zn9/powEwEV1r5pfC/Kox+3TBqDH7I5r55TH7dWP2AQAAAADovI6H+XvNmTMnz3nOc/Kc5zwn9913X77whS/k8ssvz89+9rMkaQn2b7/99nzgAx9IpVIZbvMbww/QY2M184si+dX7d9sYs08v1Mtj9jcmSap5IGlubr12YHV3zgQAAAAAwKzWkTH7B3P44YfnVa96Va644opcfvnleeUrX5mlS5cOB/eVEcHQ3kD/BS94Qf7oj/4o11xzTXbv3t2LYwPMbuVmfoZGh5ztUB6zr5lPN+ynmT+nenfpwkpSf0iXDgUAAAAAwGzWkzB/pEc+8pH50z/901x//fX54Ac/mNNOOy31ej1FUbSE+9u3b8+Xv/zlXHDBBfmN3/iN/PEf/3GuvfbaDA4O9vhPADBLVJeN3mvcO3pvKopidDO/pplPF4wK8/c08+dU7ipdd1RSOaRbpwIAAAAAYBbr2pj9g6nVajn11FNz6qmnZsuWLfniF7+Yyy+/PD/84Q+TtI7hf/DBB/OlL30pX/rSl7JgwYI885nPzN/93d/18vgAM191XlJZkBTb9u01NyR5RPueUWxLMlR6rjCfLqitbFnWK/cnGcqc6rrW6waO7d6ZAAAAAACY1XrezB/L4sWL84pXvCKXXXZZvvSlL+W8887L8uXLR43hL4oiW7duzRVXXNHL4wLMHrVSO7/dzfzyiP0kqRmzTxfUW5v5lUqRgcr9GSg38+uru3cmAAAAAABmtb4M80c6/vjj88d//Mf52te+lksuuSRnnHFGDjnkkBRFMRzqA9AlteWt68aG9t6/PGI/taSyqL3PgLFUD09Sa9mqV+/LnKowHwAAAACA3uibMfsHU6lU8tSnPjVPfepTs23btnz5y1/OFVdcke9973u9PhrA7NHpZn6z1MyvLkl8cItuqNT2fFilcffw1kBlY+Zo5gMAAAAA0CPTJswfacGCBXnJS16Sl7zkJfnlL39pzD5At3S6md8oNfNrS9t7fziQ2pGtYX51Y+ZU17VeM3Bslw8FAAAAAMBs1fdj9g/mIQ95SN70pjf1+hgAs0O12818YT5dVFvZspxbW5taZVvrNZr5AAAAAAB0ybQP8wHook4380eF+Ye19/5wIPUjW5YL6j8sXVBN6kd37zwAAAAAAMxqwnwAxq9WauY329zMN2afXqq1hvnzaz8t/X5VUpnTxQMBAAAAADCbCfMBGD/NfGayUphfrexq/f3AsV08DAAAAAAAs50wH4DxKzfzGxuTotm++zdLzfyqZj5dVArzR6mv7soxAAAAAAAgEeYDMBHlZn4aowP4qWiUmvnG7NNN9ZUH+f3qrhwDAAAAAAASYT4AE1Fu5idJ49723d+YfXrpYM18Y/YBAAAAAOgiYT4A41c5JKksat1rbGjf/Y3Zp5eM2QcAAAAAoI8I8wGYmPKo/XY280eN2dfMp4uqC5LKofv/vTAfAAAAAIAuEuYDMDHlUfvNNjXzi8Gk2Nq6p5lPt+23nV9L6kd39SgAAAAAAMxuwnwAJqZTzfzm5tF7wny6rb5yP/sPSSr17p4FAAAAAIBZTZgPwMSUm/mNNjXzyyP2E2P26b79NfON2AcAAAAAoMuE+QBMTMea+fe3rivzk8oh7bk3jJcwHwAAAACAPiHMB2BiOtXMb5aa+VWtfHpgf2H+wOquHgMAAAAAAIT5AExMp5r5jVIzv7a0PfeFidhvM//Y7p4DAAAAAIBZT5gPwMRUu9XMF+bTA/WV+9lf3dVjAAAAAACAMB+AiSk385v3JUVj6vc1Zp9+YMw+AAAAAAB9ot7rA0x3zWYzN9xwQ+64445s3LgxixYtysqVK3PSSSdl/vz5vT4eQPvVSs38NPcE8aP2J8iYffrBmGF+Pamt6vpRAAAAAACY3YT5k9RoNHLJJZfkU5/6VDZsGD1iev78+TnjjDPy1re+NYsXL+76+f7xH/8xH/7wh1v23vWud+VFL3pR188CzDC1I0bvNe6depivmU8/qC1LUklS7NurPzSp1Hp1IgAAAAAAZilj9ifhgQceyO/+7u/mH/7hH8YM8pNk+/btueyyy3LmmWfm5ptv7ur5fvGLX+SSSy7p6jOBWaQyJ6kuad1rjP1eOCHNUjO/qplPD1QGkmrpAyv11T05CgAAAAAAs5tm/gQNDQ3lD//wD3PDDTcM7x111FE588wzs2rVqmzatCnXXHNNfvjDHyZJ7rnnnpx//vm57LLLsmLFio6fryiKvPOd78zg4GDHnwXMYrXlSXPzvnXj3qnfs1Fq5huzT6/UVya7R/ydHljds6MAAAAAADB7aeZP0Mc//vF861vfGl4/73nPy9VXX523vOUteelLX5rzzz8/n/nMZ/Jnf/ZnqVQqSZL169fnne98Z1fO92//9m+58cYbkyTHHXdcV54JzELV0kj9tjTzjdmnT9SOal3Xj+3NOQAAAAAAmNWE+ROwbdu2fPSjHx1eP+pRj8q73/3uzJkzZ9S1r3zlK/OKV7xieP31r3893/ve9zp6vg0bNuQf/uEfkiRLlizJm9/85o4+D5jFastb18bsM5Mc+qLhH4uikhz64h4eBgAAAACA2UqYPwFXXHFFNm/ePLx+61vfmnp9/99U8OY3vznz5s0bXn/yk5/s5PFy4YUXZuvWrcNnW7JkSUefB8xitVIzvznFMftFMcaYfc18emThefnlzr/Jhp3n5NYdH0vm/FqvTwQAAAAAwCwkzJ+Ar371q8M/r1q1Kr/xG79xwOsXLlyY008/fXj9jW98I7t37+7I2a677rpcffXVSZInPOEJefGLtQiBDmp3M7/YnmSwdU8zn16pVHL/0Jn55Y63ZnvzCb0+DQAAAAAAs5Qwf5x27tyZ7373u8PrpzzlKalUKgd93VOe8pThnx988MGOjNrfvn17/vqv/zpJUq/X85d/+ZfjOhvApJWb+Y0pNvObm0bvCfMBAAAAAIBZTJg/TrfddlsGB/e1Rh/72MeO63WPf/zjW9Y/+9nP2nquJPmnf/qn3HXXXUmSV77ylTnhhBPa/gyAFu1u5pdH7KeSVBdN7Z4AAAAAAADTmDB/nG699daW9THHHDOu161atSq1Wm14fdttt7X1XD/60Y/yqU99KkmycuXKXHDBBW29P8CY2t7Mv791XT0sqfifKAAAAAAAYPaSlIzTnXfe2bJeuXLluF5Xq9WybNm+0OuXv/xl287UaDTy53/+52k0GkmS//k//2fmz5/ftvsD7Fe5md+8LymGJn+/8pj96mGTvxcAAAAAAMAMIMwfp23btrWsFy9ePO7XLlq0b1T0gw8+2LYzffKTn8yPf/zjJMkznvGMPOtZz2rbvQEOqLps9F7jvsnfr1Fq5teWTv5eAAAAAAAAM0C91weYLrZv396yPuSQQ8b92rlz5+73PpO1bt26vP/97x++///8n/+zLfftlltuuSXVqs+STMXg4ODwv9900009Pg2zz1B+fUHrzs9/+s3sbD58UndbNvDjrBzxtrr1wYGs8feaHvIeC9A53mMBOsv7LEDneI8F6JyZ8B7bbDbbfk9h/jjt2rWrZT0wMDDu186ZM2f45507d7blPH/91389/MGAN7zhDTn66KPbct9uaTQaw18PwNTtfYODbhpqLk69umXfRuPeDA6tntzNaq3N/MHmAn+v6Rv+LgJ0jvdYgM7yPgvQOd5jATrHe+w+wvxxKjfxBwcHx93O37179/DPI1v6k3XVVVfla1/7WpLkYQ97WM4999wp37PbarWaZv4UjXwjm8iHS6BdhrI09ewL8w8Z2JKdlcn9XZxTb/0qk2YO8/eanvIeC9A53mMBOsv7LEDneI8F6JyZ8B7bbDbbXmYW5o/T/PnzW9a7du0ad5g/so1fvs9EPfDAA/lf/+t/Da//4i/+Ylr+hX7Ywx6WBQsWHPxC9uumm27K4OBgBgYG8uu//uu9Pg6z0V1HJzvXDC+PWTU/WTzJv4vrK8mD+5ZHLH9Yjljq7zW94z0WoHO8xwJ0lvdZgM7xHgvQOTPhPXbbtm352c9+1tZ7qkaPUzl43rJly36uHG3r1q3DPx966KFTOsd73vOe3HvvvUmSs846KyeffPKU7gcwabXlrevGhsnfq9k6Zj/VpZO/FwAAAAAAwAwgzB+n8nfS33333eN6XaPRyIYN+wKuhzzkIZM+w09+8pP8+7//e5Jk8eLFedvb3jbpewFMWXVZ67px7+Tv1djUuq4J8wEAAAAAgNnNmP1xOu6441rWd9xxx7ha8evWrWv5boTyfSZi3bp1KYoiyZ7vjXjZy152wOtHjvdP9rT6P/ShDw2v/+Vf/iUrVqyY9HmAWa6tzfxSmF89bPL3AgAAAAAAmAGE+eN03HHHZWBgIIODg0mS73//+zn77LMP+robb7yxZf2IRzyiLefZvn177rjjjgm95r777st99903vN77ZwGYlFqpmd+cQjPfmH0AAAAAAIAWxuyP07x583LSSScNr7/97W8Pt+QP5Fvf+tbwz/Pnz8+TnvSkjpwPoOva1cwvGklzS+nemvkAAAAAAMDsppk/Ac961rOGw/k777wz3/72t/OUpzxlv9dv3bo1V1999fD6lFNOyZw5c6b0/J/97Gfjvv473/lOXvnKVw6v3/Wud+VFL3rRpJ8P0KLczG9Mspnf3Dx6TzMfAAAAAACY5TTzJ+DMM8/M4sWLh9fvec97MjQ0tN/r3/e+92XHjh3D65HBetmpp56aE044ISeccEJOPfXU9hwYoJPKzfzm/Ukxia/vaG4avVfVzAcAAAAAAGY3Yf4ELFy4MOedd97w+sc//nHe/va3j/nd85/61Kdy6aWXDq9POeUUI/aBmaXczE+SxsaJ36dRCvMrc5PqvMmdCQAAAAAAYIYwZn+CXvWqV+Wb3/xmvvOd7yRJrrzyytxwww15/vOfn6OPPjqbNm3KNddck5tuumn4NcuWLcuFF17YqyMDdEb18CSVJMW+vcaGpL5yYvdp3l+6rxH7AAAAAAAAwvwJGhgYyEUXXZTXve51ufHGG5Mk69aty4c//OExr1++fHk+9KEP5cgjj+zmMQE6r1LbE+g3R7TxG/dO/D7lMftG7AMAAAAAABizPxmLFy/OpZdemre85S1ZtmyMMdNJ5s+fn7PPPjtXXnllTjzxxC6fEKBLastb180NE79Ho9TMr2nmAwAAAAAAaOZPUq1Wy/nnn5/XvOY1ueGGG3L77bfnvvvuy6JFi7Jy5cqcfPLJmT9//rjvd+2117b9jE9+8pPzs5/9rO33BRhWW5YMjli3pZkvzAcAAAAAABDmT1GtVstJJ52Uk046qddHAei+cjO/MZlmvjH7AAAAAAAAZcbsAzB5tdJXjUyqmW/MPgAAAAAAQJkwH4DJa0czf9SYfc18AAAAAAAAYT4AkzcqzG9DM7+qmQ8AAAAAACDMB2DyquUx+5No5jdKzXxj9gEAAAAAAIT5AExBuZnfnEwz35h9AAAAAACAMmE+AJNXKzXzm1uSYtf4X18UxuwDAAAAAACMQZgPwOSVm/lJ0tg4/tcXO0aH/zXNfAAAAAAAAGE+AJNXPSxJrXWvsWH8ry+38hPNfAAAAAAAgAjzAZiKSjWpHdG617h3/K9vbirfMKkunvKxAAAAAAAApjthPgBTU13Wup5IM79RCvOri5NKbexrAQAAAAAAZhFhPgBTU1veup5QM780Zt+IfQAAAAAAgCTCfACmqlZq5jen0sw/bOrnAQAAAAAAmAGE+QBMTTub+TXNfAAAAAAAgESYD8BUlZv5jQk085vlZr4wHwAAAAAAIBHmAzBVU2nmG7MPAAAAAAAwJmE+AFMzpWa+MfsAAAAAAABjEeYDMDVTaeaPGrOvmQ8AAAAAAJAI8wGYqmqpmV9sTZo7x/facjO/qpkPAAAAAACQCPMBmKpyMz9JmuNs5zdKzXxj9gEAAAAAAJII8wGYquqSJPXWvcaG8b3WmH0AAAAAAIAxCfMBmJpKJamVRu03xtHMLxpJc0vrnmY+AAAAAABAEmE+AO0wKswfRzO/uSVJ0bqnmQ8AAAAAAJBEmA9AO9SWt67HFebfP3qvqpkPAAAAAACQCPMBaIfqJMbsNza1riuHJJV57TsTAAAAAADANCbMB2DqJtXML4X51cOSSqV9ZwIAAAAAAJjGhPkATF2t1MxvjqOZXx6zb8Q+AAAAAADAMGE+AFM3mWZ+ecx+9bD2nQcAAAAAAGCaE+YDMHXlZn5jEs38mmY+AAAAAADAXsJ8AKZuMs38ZrmZL8wHAAAAAADYS5gPwNSVm/nF9qT54IFfY8w+AAAAAADAfgnzAZi6cjM/OfiofWP2AQAAAAAA9kuYD8DUVRYlGWjdO2iYr5kPAAAAAACwP8J8AKauUhndzm9uOPBrGpr5AAAAAAAA+yPMB6A9asta1xNu5gvzAQAAAAAA9hLmA9Ae5WZ+4yDNfGP2AQAAAAAA9kuYD0B7TKSZ39yRFDtLr9fMBwAAAAAA2EuYD0B7TKSZ37x/9J5mPgAAAAAAwDBhPgDtUZ1IM3+sMH9JW48DAAAAAAAwnQnzAWiPiTTzG5ta19XFSaXe/jMBAAAAAABMU8J8ANqjVmrmNw/UzC+H+UbsAwAAAAAAjCTMB6A9xmrmF8XY15bH7FeXduZMAAAAAAAA05QwH4D2KDfzi51J8eDY15bH7Nc08wEAAAAAAEYS5gPQHuVmfrKnnT8WzXwAAAAAAIADEuYD0B6VBUnlkNa9xr1jX9ssNfOF+QAAAAAAAC2E+QC0R6WSVEvt/P01843ZBwAAAAAAOCBhPgDtUx61v99mvjH7AAAAAAAAByLMB6B9asta1839NPNHjdnXzAcAAAAAABhJmA9A+4y3md8oNfNrmvkAAAAAAAAjCfMBaJ9yM78x3ma+MB8AAAAAAGAkYT4A7TOeZn7RTJqlZr4x+wAAAAAAAC2E+QC0z3ia+c0HkhSl12nmAwAAAAAAjCTMB6B9xtPML4/YTzTzAQAAAAAASoT5ALRPdYxmflFq4ZdH7GcgqRza0WMBAAAAAABMN8J8ANqn3MzP7qTY2rrVKDXza0uTSqWjxwIAAAAAAJhuhPkAtE9t2ei9xobWdXnMvhH7AAAAAAAAowjzAWif6qFJZX7rXuPe1nV5zH51aWfPBAAAAAAAMA0J8wFor3I7v9zMHzVmXzMfAAAAAACgTJgPQHvVlreuNfMBAAAAAAAmTJgPQHtVD9LMb5aa+cJ8AAAAAACAUYT5ALTXwZr5xuwDAAAAAAAclDAfgPaqlZr5zXIz35h9AAAAAACAgxHmA9BeB2vmjxqzr5kPAAAAAABQJswHoL3KzfxGqZnfKDXza5r5AAAAAAAAZcJ8ANprws18YT4AAAAAAECZMB+A9hrVzL83KYo9Pxe7kmJ76++N2QcAAAAAABhFmA9Ae5Wb+RlMmlv2/FgesZ8Ysw8AAAAAADAGYT4A7VVdNnqvsWHPv5dH7CdJdUlHjwMAAAAAADAdCfMBaK/qvKSyoHWvee+v/r3UzK8sTCoD3TkXAAAAAADANCLMB6D9aqV2/t5mfqPUzDdiHwAAAAAAYEzCfADar7a8dd3Y28wvhfnVw7pzHgAAAAAAgGlGmA9A++2vmV8es1/VzAcAAAAAABiLMB+A9hvVzN/fmH3NfAAAAAAAgLEI8wFov2q5mb93zL5mPgAAAAAAwHgI8wFov/0185ulZr4wHwAAAAAAYEzCfADar1Zq5jd/1cw3Zh8AAAAAAGBchPkAtN9+m/nG7AMAAAAAAIyHMB+A9is38xsbk6I5xph9zXwAAAAAAICxCPMBaL9yMz+NPa38RqmZX9PMBwAAAAAAGIswH4D2Kzfzk6SxfoxmvjAfAAAAAABgLMJ8ANqvckhSWdS6N3hbkmbrnjH7AAAAAAAAYxLmA9AZ5Xb+4M/GuEYzHwAAAAAAYCzCfAA6o7a8dT0qzK8llQVdOw4AAAAAAMB0IswHoDMO1syvLk0qle6dBwAAAAAAYBoR5gPQGaOa+T8t/d6IfQAAAAAAgP0R5gPQGeVmfmND67p6WPfOAgAAAAAAMM0I8wHojHIzv6yqmQ8AAAAAALA/wnwAOuNgYX5NMx8AAAAAAGB/hPkAdEZ12UF+r5kPAAAAAACwP8J8ADrDmH0AAAAAAIBJE+YD0Bm1gzTzjdkHAAAAAADYL2E+AJ1RO+LAv9fMBwAAAAAA2C9hPgCdUZmTVJfs//dVzXwAAAAAAID9EeYD0Dm15Qf4nWY+AAAAAADA/gjzAeic6rID/E6YDwAAAAAAsD/CfAA650DNfGP2AQAAAAAA9kuYD0Dn1A7QzK8J8wEAAAAAAPZHmA9A5+yvmV85NKnM6e5ZAAAAAAAAphFhPgCds79mfnVpd88BAAAAAAAwzQjzAeic/TXza8J8AAAAAACAAxHmA9A5+23mH9bdcwAAAAAAAEwzwnwAOmd/zXxj9gEAAAAAAA5ImA9A51T308yvaeYDAAAAAAAciDAfgM6pHTH2vmY+AAAAAADAAQnzAeicSn3s4L4mzAcAAAAAADgQYT4AnVVbPnqvasw+AAAAAADAgQjzAeis2rLRe8bsAwAAAAAAHJAwH4DO0swHAAAAAACYMGE+AJ1VHaOZX9PMBwAAAAAAOBBhPgCdNWYzX5gPAAAAAABwIMJ8ADqrNlYz35h9AAAAAACAAxHmA9BZo5r5taSyqCdHAQAAAAAAmC6E+QB0Vn1V67q2PKlUenMWAAAAAACAaUKYD0BnHfLfkvrD9q0X/G7vzgIAAAAAADBN1Ht9AABmuEotWfWdZNsn97TyD31Zr08EAAAAAADQ94T5AHRebWmy+M29PgUAAAAAAMC0Ycw+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9Jl6rw8w3TWbzdxwww254447snHjxixatCgrV67MSSedlPnz53f8+Tt37szPf/7z3Hrrrdm0aVMGBwezaNGirFq1Ko9//OOzaNGijp8BAAAAAAAAgPYS5k9So9HIJZdckk996lPZsGHDqN/Pnz8/Z5xxRt761rdm8eLFbX323Xffnauuuipf//rXc8MNN2RwcHDM6yqVSk455ZS89rWvzUknndTWMwAAAAAAAADQOcL8SXjggQfyute9LjfccMN+r9m+fXsuu+yyfOMb38iHPvShPOpRj2rLs7/5zW/mvPPOS1EUB722KIpcf/31+cY3vpFXvvKVefvb355q1TcrAAAAAAAAAPQ7Yf4EDQ0N5Q//8A9bgvyjjjoqZ555ZlatWpVNmzblmmuuyQ9/+MMkyT333JPzzz8/l112WVasWDHl5+/cubMlyB8YGMiJJ56YJz7xiTnyyCMzb968rF+/Pv/3//7ffO9730uyJ9T/P//n/2Tnzp3567/+6ymfAQAAAAAAAIDOEuZP0Mc//vF861vfGl4/73nPy7ve9a7MmTNneO/888/PJz/5yfyv//W/UhRF1q9fn3e+8535yEc+0rZzrF69Oi9/+cvzghe8IEuWLBn1+ze+8Y25/vrr88d//MfZsmVLkuTTn/50nvWsZ+W3fuu32nYOAAAAAAAAANrPzPUJ2LZtWz760Y8Orx/1qEfl3e9+d0uQv9crX/nKvOIVrxhef/3rXx9uyk/F0qVLc+GFF+aqq67K7//+748Z5O/1W7/1W7noootSqVSG99r5gQIAAAAAAAAAOkOYPwFXXHFFNm/ePLx+61vfmnp9/8MN3vzmN2fevHnD609+8pNTPsMTnvCEvOQlL0mtVhvX9U9+8pNzyimnDK9vuOGGbN26dcrnAAAAAAAAAKBzhPkT8NWvfnX451WrVuU3fuM3Dnj9woULc/rppw+vv/GNb2T37t0dO9/+PPnJTx7+udFo5K677ur6GQAAAAAAAAAYP2H+OO3cuTPf/e53h9dPecpTWsbX789TnvKU4Z8ffPDBtozan6hDDz20Zb1jx46unwEAAAAAAACA8RPmj9Ntt92WwcHB4fVjH/vYcb3u8Y9/fMv6Zz/7WVvPNR533nlny/rwww/v+hkAAAAAAAAAGD9h/jjdeuutLetjjjlmXK9btWpVy/fb33bbbW0913hcc801wz8vW7YsRx99dNfPAAAAAAAAAMD4CfPHqdxuX7ly5bheV6vVsmzZsuH1L3/5y7ae62Cuu+66rF27dnh9+umnj+vrAQAAAAAAAADoHWH+OG3btq1lvXjx4nG/dtGiRcM/P/jgg20708Fs27Ytf/M3fzO8PuSQQ/La1762a88HAAAAAAAAYHLqvT7AdLF9+/aW9SGHHDLu186dO3e/9+mUoijyp3/6p1m3bt3w3pve9KasWLGiK88/mFtuuSXVqs+STMXg4ODwv9900009Pg3AzOI9FqBzvMcCdJb3WYDO8R4L0Dkz4T222Wy2/Z7C/HHatWtXy3pgYGDcr50zZ87wzzt37mzbmQ7k4osvztVXXz28Pvnkk3Peeed15dnj0Wg00mg0en2MGWPvGxwA7ec9FqBzvMcCdJb3WYDO8R4L0DneY/cR5o9TuYk/ODg47nb+7t27h38e2dLvlE9/+tO5+OKLh9cPfehD84//+I991YSv1Wp9dZ7paOQb2UQ+XALAwXmPBegc77EAneV9FqBzvMcCdM5MeI9tNpttLzML88dp/vz5Letdu3aNO8wf2cYv36fdrrrqqvzlX/7l8HrZsmX52Mc+liOOOKKjz52ohz3sYVmwYEGvjzGt3XTTTRkcHMzAwEB+/dd/vdfHAZhRvMcCdI73WIDO8j4L0DneYwE6Zya8x27bti0/+9nP2npP1ehxKgfPW7ZsGfdrt27dOvzzoYce2rYzlX3961/P2972tuHvY1iyZEk+/vGP5yEPeUjHngkAAAAAAABA+wnzx+noo49uWd99993jel2j0ciGDRuG150K1v/zP/8zF1xwwfAIigULFuSjH/1oHv7wh3fkeQAAAAAAAAB0jjB/nI477riW9R133DGu161bt67luxHK92mHG2+8Ma9//euza9euJMm8efPyz//8z3nMYx7T9mcBAAAAAAAA0HnC/HE67rjjMjAwMLz+/ve/P67X3XjjjS3rRzziEe08Vm6++ea89rWvzfbt25MkAwMDufjii/OkJz2prc8BAAAAAAAAoHuE+eM0b968nHTSScPrb3/72ymK4qCv+9a3vjX88/z589sast9666159atfnQceeCBJUq/X8773vS+/+Zu/2bZnAAAAAAAAANB9wvwJeNaznjX885133plvf/vbB7x+69atufrqq4fXp5xySubMmdOWs/zyl7/Mq171qmzatClJUq1W8653vavljAAAAAAAAABMT8L8CTjzzDOzePHi4fV73vOeDA0N7ff6973vfdmxY8fw+pWvfOV+rz311FNzwgkn5IQTTsipp556wHOsX78+r3rVq7J+/frhvb/6q7/KmWeeOZ4/BgAAAAAAAAB9Tpg/AQsXLsx55503vP7xj3+ct7/97RkcHBx17ac+9alceumlw+tTTjmlLSP2N2/enFe/+tX55S9/Obz3jne8Iy996UunfG8AAAAAAAAA+kO91weYbl71qlflm9/8Zr7zne8kSa688srccMMNef7zn5+jjz46mzZtyjXXXJObbrpp+DXLli3LhRde2JbnX3rppfnFL34xvK7Varn00ktbPjhwML/3e793wCkBAAAAAAAAAPSWMH+CBgYGctFFF+V1r3tdbrzxxiTJunXr8uEPf3jM65cvX54PfehDOfLII9vy/Gaz2bJuNBq54447JnSPLVu2tOUsAAAAAAAAAHSGMfuTsHjx4lx66aV5y1vekmXLlo15zfz583P22WfnyiuvzIknntjlEwIAAAAAAAAwnWnmT1KtVsv555+f17zmNbnhhhty++2357777suiRYuycuXKnHzyyZk/f/6473fttdeO67oLLrggF1xwwWSPDQAAAAAAAMA0IMyfolqtlpNOOiknnXRSr48CAAAAAAAAwAxhzD4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAAAAAAAPQZYT4AAAAAAAAA9BlhPgAAAAAAAAD0GWE+AAAA///27j1Kq7LuH/9ngBlghAGBYYRBQUgJDwgqkppp4pNPHtDEQ2mY4gkLxVLUUh/TWiiGS9PM0jwAoSUeK/FromUeCEVQ0RRQziDn82lmmJnfH/64457jPTADW3m91nI992ff1772hbY+zzDvva8NAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMI02dUL+KIrKyuLKVOmxLx582L58uWRl5cXHTp0iD59+kRubu5OW0dxcXFMnjw5Fi5cGCtXrow2bdpEYWFhHH744ZGTk7PT1gEAAAAAAADAjhPmb6fS0tJ46KGHYsyYMbF06dJK3+fm5sbJJ58cw4YNi1atWjXYOjZv3hz33HNPPPXUU7F69epK37du3ToGDBgQV155ZTRr1qzB1gEAAAAAAABA/bHN/nZYu3ZtfP/7348777yzyiA/ImLjxo0xbty46N+/f/znP/9pkHUsXLgwBgwYEA899FCVQX5ExOrVq+Ohhx6KAQMGxMKFCxtkHQAAAAAAAADUL0/m19GWLVti6NChMWXKlNSxjh07Rv/+/aOwsDBWrlwZEyZMiGnTpkVExOLFi2Pw4MExbty4KCgoqLd1rF+/PgYPHhyffPJJ6li3bt3ipJNOioKCgli8eHGMHz8+Zs2aFRERn3zySQwePDgef/zxaNGiRb2tAwAAAAAAAID6J8yvo0ceeSTefPPNVH3KKafEbbfdlvZe+sGDB8fo0aNj+PDhUV5eHkuWLImbbropHnjggXpbx8iRI2PGjBmp+qKLLophw4ZFVlZW6tiQIUPijjvuiIcffjgiImbMmBF33nln3HzzzfW2DgAAAAAAAADqn23262D9+vXxhz/8IVUfcMABMWLEiLQgf6vzzz8/zjvvvFT96quvxjvvvFMv65g/f348+eSTqfqb3/xmXHvttWlBfkREVlZWXHfddfHNb34zdWzcuHExf/78elkHAAAAAAAAAA1DmF8Hzz33XNq76YcNGxZNmlS/ucFVV10VzZs3T9WjR4+ul3U8/vjjUVJSEhGfB/bXX399jeO3/b6kpCQef/zxelkHAAAAAAAAAA1DmF8HL7/8cupzYWFhHHnkkTWOb9myZZx44omp+rXXXovi4uJ6XUefPn2iS5cuNY7v0qVL9OnTp8rzAQAAAAAAAEgeYX6GNm/eHG+99VaqPuqooypta1+Vo446KvV5w4YNO7zV/ty5c2POnDlVzp/pOubMmRPz5s3boXUAAAAAAAAA0HCE+RmaNWtWamv7iIhDDjkko/N69+6dVk+fPn2H1jFjxoy0ulevXtu1jorzAAAAAAAAAJAcwvwMffrpp2l1586dMzqvsLAwGjdunKpnzZpVr+vYZ599Mjpv7733rnEeAAAAAAAAAJJDmJ+hBQsWpNUdOnTI6LzGjRtHfn5+qp4/f369raNRo0ZRUFCQ0XkFBQXRqNF//3Pv6DoAAAAAAAAAaDhNdvUCvijWr1+fVrdq1Srjc/Py8mLx4sUREbFhw4Z6W8cee+wRTZpk9p8wOzs7mjdvnrr+jq6jrkpLS9PqjRs37tTrfxmVlZWl/m/F/30CsGP0WICGo8cCNCx9FqDh6LEADefL0GMr5p8V89HtIczPUMV/+U2bNs343GbNmlU7z46soy5r2LqOrSH+zg7Ti4qK0mo7A9Sf0tLSmD59+q5eBsCXkh4L0HD0WICGpc8CNBw9FqDhfJl6bMV8dHvYZj9DFf9lZ2dnZ3xuTk5O6vPmzZvrbR11WUN9rwMAAAAAAACAhiPMz1DFp+BLSkoyPre4uDj1edun9Hd0HXVZQ32vAwAAAAAAAICGY5v9DOXm5qbVRUVFGW9zv+1T8BXn2ZF11HVrhvpcR121bt06rW7atGk0btx4p64BAAAAAAAAoCGUlpam5bcV89HtIczPUIsWLdLqNWvWRF5eXkbnrlu3LvV5jz32qLd1bNy4MbZs2RJNmtT+n3HLli2xadOmeltHXeXk5ET79u136jUBAAAAAAAAvqhss5+hTp06pdWfffZZRueVlpbG0qVLU/Xee+9db+soLS2NJUuWZHTe4sWLo6ysrN7WAQAAAAAAAEDDEeZnqGvXrmn1vHnzMjpv4cKFUVpaWu08O2sd8+fPr3EeAAAAAAAAAJJDmJ+hrl27RnZ2dqp+9913Mzpv6tSpafX++++/Q+vo3r17Wr2r1gEAAAAAAABAwxHmZ6h58+bRp0+fVD1x4sQoLy+v9bw333wz9Tk3NzcOP/zwHVpH586do3PnzlXOn+k6unTpkjYHAAAAAAAAAMkizK+DE044IfV5wYIFMXHixBrHr1u3Ll588cVUfcwxx0ROTs4Or6Nfv36pz2+//XbMmTOnxvFz5syJt99+O1Uff/zxO7wGAAAAAAAAABqOML8O+vfvH61atUrVI0eOjC1btlQ7/u67745Nmzal6vPPP7/asccff3x07949unfvXmvY/r3vfS+15X95eXmMGDGixvG333576nN2dnace+65NY4HAAAAAAAAYNcS5tdBy5Yt4+KLL07VH374YVx//fVRUlJSaeyYMWNi7NixqfqYY47Z4S32t9pnn33ijDPOSNWvvPJK/OpXv6q07X95eXnccccd8Y9//CN1bMCAAbH33nvXyzoAAAAAAAAAaBhZ5Zm8+J2UkpKSuOiii2LSpEmpY4WFhXHqqadGp06dYuXKlTFhwoR4//33U9/n5+fHk08+GXvttVe18x5//PGxcOHC1HyvvPJKjetYv359nHPOOfHJJ5+kjn3lK1+Jb3/721FQUBBLliyJ559/PmbNmpX6fr/99os//elP0aJFizr/uQEAAAAAAADYeYT522HNmjVx2WWXxdSpU2sd2759+7j//vvjoIMOqnFcXcP8iIgFCxbEJZdckhbYV6dr167x4IMPRqdOnWodCwAAAAAAAMCuZZv97dCqVasYO3Zs/PjHP478/Pwqx+Tm5saZZ54Zf/3rX2sN8rdXp06d4plnnolBgwZFq1atql3roEGD4plnnhHkAwAAAAAAAHxBeDJ/B5WWlsaUKVNi7ty5sWLFisjLy4sOHTrEEUccEbm5uTttHcXFxfH222/HwoULY9WqVbHnnntGYWFh9OnTJ3JycnbaOgAAAAAAAADYccJ8AAAAAAAAAEgY2+wDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkjDAfAAAAAAAAABJGmA8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwTXb1AoC6KSsriylTpsS8efNi+fLlkZeXFx06dIg+ffpEbm7url4ewG5lxowZMX369FiyZEnk5OREQUFB9O7dO9q3b7+rlwbQoIqLi+PTTz+NmTNnxooVK6KoqChatmwZBQUF0atXr2jXrt0OX0OPBXZXa9asiZkzZ8aiRYti5cqVsXHjxsjJyYlWrVpFt27dokePHtG8efMduoYeC9Bw9FiAhjN//vyYNm1aLFmyJCIiCgoK4uCDD4699957F6+s4Qjz4QuitLQ0HnrooRgzZkwsXbq00ve5ublx8sknx7Bhw6JVq1a7YIUAyVBcXBzTp0+PDz74IKZNmxbTpk2LTz/9NEpLS1Njpk+fvkPXmDBhQtx7773x8ccfV/qucePGceSRR8b1118f++233w5dByBJVq5cGf/v//2/+Mc//hGTJ0+OjRs3Vjv20EMPjYsuuihOOOGEOl9HjwV2R9OmTYtRo0bFlClTYuHChTWObdasWXzrW9+KwYMHR7du3ep0HT0WoGpPPPFE3HTTTWnHhgwZEldccUXGc+ixwO6qe/fu23Xe+PHjM/55dvLkyTFy5MiYOnVqld/37t07rrnmmjj88MO3ay1JllVeXl6+qxcB1Gzt2rVx2WWXxZQpU2odu9dee8X9998fBxxwwE5YGUCynHnmmfHxxx9HSUlJjeN2JMy/9dZbY+zYsbWOa9q0adx6661x+umnb/e1AJLi008/jf79+8eWLVvqdN7JJ58cw4cPj2bNmmU0Xo8FdlePPvpo3HbbbXU6Jzs7O4YNGxY/+MEPMhqvxwJUbfny5XHSSSfFmjVr0o7XJczXY4HdWUOH+Q888EDcddddUVZWVuO4xo0bx1VXXRWXXnrpdq0nqTyZDwm3ZcuWGDp0aFqQ37Fjx+jfv38UFhbGypUrY8KECTFt2rSIiFi8eHEMHjw4xo0bFwUFBbtq2QC7xNZe2FDuvffetL+c5+bmRv/+/aN79+5RVFQUkydPjldeeSXKysqiqKgobrjhhigoKIgjjzyyQdcF0NCKi4vTgvxGjRpFjx494vDDD4+OHTtGy5YtY8WKFfHWW2/F66+/HlvvGX/++edj/fr1cf/990fjxo1rvIYeC/C5wsLC6NmzZ+y7777Rrl27yM3NjQ0bNsTs2bPjn//8ZyxYsCAiIkpKSmL48OGRnZ0d5557bo1z6rEA1Rs+fHilIL8u9FiA/2rfvn3GN/Tn5OTUOubpp5+OO++8M1VnZ2fHySefHAcffHCUlZXFtGnT4oUXXoiSkpIoLS2NO++8M/Lz8+M73/nOdv8ZksaT+ZBwDz74YIwcOTJVn3LKKXHbbbdVanKjR4+O4cOHp35xeuyxx8YDDzywU9cKsKttexdoixYt4oADDoiDDz44pkyZkrYF0/Y8mf/ee+/F2WefnXatBx98sNKNU5MnT47LL7881q5dGxERbdu2jZdeein22GOPOl8TICk++uijOP3006OgoCC++93vxoABA6q9cfT999+PoUOHxqJFi1LHbr755hqDJj0W2N3961//irlz58bxxx8fhYWF1Y4rLy+PsWPHxvDhw1OvkcrNzY0XX3yx2ncx67EA1fvXv/4Vl1xySUREdO3aNWbNmpX6LpMn8/VYgPTfyY4ePTr69u1bL/MuWrQoTjzxxCguLo6IiA4dOsRDDz1U6Wn+Tz75JC6++OL47LPPIuLzmwT+/ve/R4cOHeplHbtao129AKB669evjz/84Q+p+oADDogRI0ZUebfS+eefH+edd16qfvXVV+Odd97ZKesESIqBAwfGiBEjYvz48TF58uQYM2ZMXHvttdGlS5cdnvuuu+5Kfc7NzY3f/e53VQZZhx9+ePzyl79M1StWrIjRo0fv8PUBdqXc3Ny47rrr4qWXXoof/vCHNe4A1bNnz3jooYeiadOmqWMPPvhgjfPrscDu7hvf+EYMHDiwxiA/IiIrKyu+//3vx5VXXpk6tnHjxhg/fny15+ixAFXbtGlT/PznP4+Iz5/0/NnPflbnOfRYgIZz3333pYL8xo0bxz333FPltvxf+cpX4p577kntCFhcXBz33XffTl1rQxLmQ4I999xzsXr16lQ9bNiwaNKk+rdjXHXVVdG8efNU7QdCYHdz4403xumnnx7dunWLrKysepv3k08+iYkTJ6bq888/Pzp27Fjt+BNPPDEOPfTQVP3HP/6x1nc6ASRZ586dY9CgQWkBfU26du0aZ5xxRqpetGhRzJw5s8qxeixA3Z177rlpry+p7nVTeixA9e65555YuHBhRERccsklse+++9bpfD0WoOGsXbs2nnvuuVR90kknRc+ePasd37NnzzjppJNS9bPPPhvr1q1r0DXuLMJ8SLCXX3459bmwsLDW9yi1bNkyTjzxxFT92muvpe5aAmD7TZgwIa0+66yzaj3nzDPPTH1evnx5vPfee/W+LoAkq7it3vz586scp8cC1F1eXl60adMmVa9atarKcXosQNU++uij1INQ++yzTwwePLjOc+ixAA3n1VdfjZKSklRd1x5bUlISr776aoOsbWcT5kNCbd68Od56661UfdRRR2X0lOlRRx2V+rxhwwZb7QPUg21/8OvcuXN06tSp1nOOPvroaucA2B1UfP/npk2bqhynxwLUXXl5eWzcuDFVt27duspxeixAZWVlZXHTTTfFli1bIiLipptuyngHqm3psQANZ9v+2KxZszjssMNqPeewww6LZs2aVTnHF5kwHxJq1qxZaXcdHXLIIRmd17t377R6+vTp9bougN3RjBkzUp8z7cd77bVX7LXXXlXOAbA7WLBgQVrdtm3bKsfpsQB1984778SGDRtS9bbbNm9LjwWo7I9//GPq9SQnnnhifOMb39iuefRYgIazbX888MADa3wF9VbZ2dlx4IEHVjnHF5kwHxLq008/Tas7d+6c0XmFhYVp782bNWtWva4LYHezZMmSWL9+farOtB9HfL5V31YV+zrAl922r4yq+BfqrfRYgLpbuXJl3HLLLam6TZs2cdppp1Uap8cCVLZ48eK4++67I+LznaRuuOGG7ZpHjwWo2qhRo2LAgAHRt2/fOOigg+JrX/tanHrqqXHTTTfFSy+9FGVlZbXOUVZWFnPmzEnV29tjZ8+endH1kq722xiAXaLik0wdOnTI6LzGjRtHfn5+LF68OCKqfzcpAJnZ3n4cEWl32y9cuLDe1gSQdB9//HG8+eabqfrrX/96tGzZstI4PRYgMxs2bIj58+fHa6+9Fo8++mgsX748IiJycnJi5MiReixAhm655ZbUziZXXnllFBQUbNc8eixA1ba9sT8iYtWqVbFq1aqYMWNGPPHEE9GlS5e46aab4utf/3q1cyxbtiyKiopS9fb22KKioli2bNl29/qkEOZDQm17Z2dERKtWrTI+Ny8vLxXmb7vtHgB1tyP9eNuxJSUlUVRUtF3v4QP4ItmyZUvceOONaXe//+hHP6pyrB4LULXrr78+nnnmmRrHHHjggfHzn/88evbsWeX3eixAur///e/xyiuvREREjx49YuDAgds9lx4LUL099tgjWrVqFUVFRbF69eooLS1NfTdnzpy45JJLYtiwYTFo0KAqz6/YY/Py8jK+dsV+vH79emE+0DA2btyYVtflB7pmzZpVOw8AdVOxj+bk5GR8bsXevWHDBn9BB770Ro4cmXoHaUTEOeecEwcffHCVY/VYgLrLysqKAQMGxDXXXBN77rlnteP0WID/Wr9+ffziF7+IiM/76M9//vO0V5XWlR4L8F85OTnxrW99K/r16xeHHXZYWni+cePGePvtt+PRRx9N7eBXVlYWI0aMiIKCgjj55JMrzVfxIdW69MiKY78MGZkwHxJq2y1EIj5/z2imtv3hcfPmzfW2JoDdUX3146rmAviyeeqpp+KRRx5J1fvuu2/89Kc/rXa8HgtQtbZt26be91lWVhbr16+P1atXR0REeXl5PPnkkzF+/Pi49NJL47LLLotGjRpVmkOPBfivO++8M5YuXRoREWeffXb06tVrh+bTYwH+69VXX402bdpU+V1ubm4ce+yxceyxx8ajjz4at912W+q7W2+9NY499tho0aJF2jnFxcVp9e7eYyv/pA8kQsW7h0pKSjI+d9tGt+1T+gDUXX3146rmAvgyefXVV+P//u//UnXr1q3jvvvui+bNm1d7jh4LULVhw4bFSy+9FC+99FK8/PLLMWnSpJg4cWLcfvvt0a1bt4j4/Cmju+++O4YNGxbl5eWV5tBjAT737rvvxp/+9KeIiGjTpk1cffXVOzynHgvwX9UF+RVdcMEFcf7556fq1atXx+OPP15pXMVAfnfvscJ8SKjc3Ny0ui53D237NH7FeQCom4p9tOIPhDWp2Lv32GOPelkTQNJMnjw5rrzyytiyZUtEfN7vHnzwwVTgVB09FiBzbdq0ie985zvx7LPPxoknnpg6/re//S0VUm1LjwWI2LJlS9x0001RVlYWERHXXXddnd5vXx09FmD7DBkyJK2H/vOf/6w0pmJfrEs+VnHslyEjE+ZDQlXcVmTNmjUZn7tu3brUZz8MAuyYHenHa9euTX3Ozs7+UtwJClDRBx98EJdddlnqhtKmTZvG/fffHz179qz1XD0WoO5ycnLijjvuiMLCwtSx3/3ud6mgais9FiDi4YcfjhkzZkRExBFHHBGnn356vcyrxwJsn1atWkWfPn1S9XvvvVdpTMUeu23frE3FsRXn+iIS5kNCderUKa3+7LPPMjqvtLQ09f6niIi99967XtcFsLvZ3n5ccey2v2wF+LKYMWNGXHTRRbF+/fqI+PyXkffcc0/07ds3o/P1WIDt06xZszjjjDNS9eLFi2P69OlpY/RYYHe3bNmyuO+++yLi859Tb7755nqbW48F2H6dO3dOfS4pKakUwOfn56fd6LS9PbZp06aRn5+/AytNhia7egFA1bp27ZpWz5s3L4444ohaz1u4cGGUlpZWOw8AdVNQUBAtWrRIBVXz5s3L+Nxtx+rHwJfNnDlzYtCgQbF69eqIiGjcuHHccccdcdxxx2U8hx4LsP2++tWvptXz5s2LHj16pGo9FtjdLV++PLV7VFZWVlx++eU1jt/2d6oREWPGjIm//OUvqXrkyJFxyCGHRIQeC7AjmjdvnlZv3rw58vLyUnWjRo2ic+fOqZ1VtrfHdunSJRo1+uI/1/7F/xPAl1TXrl0jOzs7Vb/77rsZnTd16tS0ev/996/PZQHslrbtpZn248WLF8fixYurnAPgi27RokVx4YUXxrJlyyLi81+O/uIXv4iTTjqpznPpsQDbJycnJ62uGEJF6LEAWxUXF8e8efNq/GfhwoVp56xZsybt+603BmylxwJsn+XLl6fVrVu3rjSme/fuqc8ffvhhbNmypdZ5S0pK4sMPP0zVX5YeK8yHhGrevHnae0MmTpwY5eXltZ735ptvpj7n5ubG4Ycf3iDrA9idfOMb30h9njt3bixYsKDWc9544420+thjj633dQHsCsuWLYsLLrggFi1alDp2ww03xIABA7ZrPj0WYPtU7Jft2rWrNEaPBWg4eizA9pkyZUrqc/v27SvdpBqR3mM3bdoU77zzTq3zvvPOO2k3Xn1ZeqwwHxLshBNOSH1esGBBTJw4scbx69atixdffDFVH3PMMVU2QQDqZtt+HBExbty4Ws958sknU5/btm0bvXr1qu9lAex0q1evjkGDBsXcuXNTx66++uoYOHDgds+pxwJsn5deein1uUmTJmlPL22lxwK7sx49esT06dMz/ufll19OO3/IkCFp3/ft2zftez0WoO4mTpwYs2fPTtVHHXVUleOOO+64aNLkv2+Lr2uPzc7OFuYDDa9///7RqlWrVD1y5MgatxK5++67Y9OmTan6/PPPb9D1Aewu9ttvv7S/tI8ePTrtidSKXnzxxbQ7TM8777wvxfuZgN3b+vXr4+KLL069sy4iYvDgwXHppZfu0Lx6LLC727x5c5SVldXpnPHjx6ftzNe3b9+03x9spccCNBw9FtjdlZSUZLT9/VYrV66MG2+8Me3YaaedVuXYvLy86N+/f6oeP358vP/++9XO/f7778f48eNTdf/+/SMvLy/jtSWZ/08BCdayZcu4+OKLU/WHH34Y119/fZSUlFQaO2bMmBg7dmyqPuaYY2yxD1CPfvKTn6Q+b9y4MS6//PJYunRppXGTJ09O+6G0TZs2ccEFF+yMJQI0mKKiorj88stj2rRpqWPnn39+/PjHP66X+fVYYHf23nvvRf/+/ePZZ5+NDRs21Di2qKgofv/738e1116bOtaoUaMa+7EeC9Bw9Fhgd7ZkyZL49re/HePGjYt169bVOPadd96Jc845J+2VJEcffXS1T+ZHfL5DSnZ2dkRElJaWxtChQ+PTTz+tNO6TTz6JK6+8MkpLSyPi86fyhwwZsj1/pETKKs/kJdzALlNSUhIXXXRRTJo0KXWssLAwTj311OjUqVOsXLkyJkyYkHZHUn5+fjz55JOx11577YolA+wyo0ePjjFjxlQ6vmLFirRfjO6zzz6Vxuy1115Vnrutu+66K373u9+l6j322CNOO+202H///aOoqCgmT54cL7/8curJqsaNG8fvf//7OOaYY7b3jwSQCM8++2xcd911acf23nvvyMrKyniOb33rWzFs2LBqv9djgd3VpEmTUjvrNWvWLHr16hUHHHBAFBQURMuWLaO0tDRWrlwZH3/8cbz++uuVflH605/+tNZASI8FqN2CBQuiX79+qXrIkCFxxRVX1HqeHgvsrrbtmzk5OXHooYdGjx49okOHDtGiRYsoLi6Ozz77LCZOnFjpqfp99tkn/vznP0ebNm1qvMa4cePSbobKycmJk08+OQ466KCIiJg2bVo8//zzaQ/B/vKXv4yzzjqrvv6Yu1yT2ocAu1J2dnbce++9cdlll8XUqVMjImLhwoVpPyBuq3379nH//fcL8oHd0po1a2LevHm1jqtqzNY7N2ty1VVXxerVq+NPf/pTRERs2LAhHnvssSrH5uTkxC233OIv58CXQlXbP8+fP79Oc6xYsaLG7/VYgM+33P/3v/8d//73v2sd27Jly/jpT38aAwYMqHWsHgvQcPRYgIji4uKMf47t27dv/OpXv6o1yI+IOOuss2L58uVxzz33RFlZWRQXF8czzzwTzzzzTKWxjRo1iqFDh36pgvwI2+zDF0KrVq1i7Nix8eMf/zjy8/OrHJObmxtnnnlm/PWvf03dkQRA/crKyopbbrklfvOb38T+++9f5ZhGjRrF0UcfHU899VScccYZO3mFAF9ceiywu+revXtcffXV0adPn2jatGmt4zt06BCDBw+OF154IaMgP0KPBWhIeiywu2rdunWce+650a1bt1p37svKyopDDz007rrrrnj00UejoKAg4+tcfvnlMXr06OjVq1e1Y3r37h2jR4+OwYMHZzzvF4Vt9uELprS0NKZMmRJz586NFStWRF5eXnTo0CGOOOKIyM3N3dXLA9itTJ8+PaZPnx5Lly6N7OzsKCgoiN69e9fph1EAqqbHArujkpKS+OSTT2LOnDmxdOnS2LhxYzRu3DhatmwZ+fn50aNHjygsLNzh6+ixAA1HjwV2R+vXr48ZM2bEggULYsWKFbFp06bIzs6OvLy86NixYxxyyCGRl5e3w9eZN29eTJs2LZYsWRIREQUFBXHwwQdX+VrVLwthPgAAAAAAAAAkjG32AQAAAAAAACBhhPkAAAAAAAAAkDDCfAAAAAAAAABIGGE+AAAAAAAAACSMMB8AAAAAAAAAEkaYDwAAAAAAAAAJI8wHAAAAAAAAgIQR5gMAAAAAAABAwgjzAQAAAAAAACBhhPkAAAAAAAAAkDDCfAAAAAAAAABIGGE+AAAAAAAAACSMMB8AAAAAAAAAEkaYDwAAAAAAAAAJI8wHAAAAAAAAgIQR5gMAAAAAAABAwgjzAQAAAAAAACBhhPkAAAAAO9mCBQuie/fuqX/uvffeXb0kAAAAEqbJrl4AAAAAsPMtWLAg+vXrVy9z3XfffXHCCSfUy1wAAADA5zyZDwAAAAAAAAAJI8wHAAAAAAAAgISxzT4AAAAQBQUF8dhjj23XuW3btq3n1QAAAADCfAAAACCaNGkSnTp12tXLAAAAAP5/ttkHAAAAAAAAgIQR5gMAAAAAAABAwthmHwAAANjpiouLY/LkybFw4cJYtWpVtG7dOrp06RKHHXZYNG7ceIfmLisri2nTpsXs2bNjxYoVUV5eHm3bto0uXbrEIYccEo0a1c+zDbNnz46PPvooVq1aFWvXro3mzZtHfn5+7LfffvGVr3xlh65TVlYWU6dOjXnz5sWyZcsiNzc3CgsLo0+fPtGiRYt6WT8AAADJJswHAAAA6t2CBQuiX79+qXrIkCFxxRVXxPr16+O+++6Lp59+OlavXl3pvLZt28aFF14YgwYNqnOov3bt2rj//vvjmWeeiVWrVlU5pnXr1nHaaafFD3/4w2jdunWd5t96jYcffjieffbZ+Oyzz6odt+eee8Y3v/nN+N73vhc9e/bMeP7y8vIYNWpUjBo1KhYtWlTp++zs7DjrrLNi6NCh27V+AAAAvjiE+QAAAMBO8dlnn8WFF14Ys2fPrnbMihUrYuTIkTFhwoT4wx/+EC1btsxo7rfffjuGDBlS5Q0C21q9enWMGjUqnn322fj1r38dRx55ZMbrf+mll+JnP/tZrF27ttaxq1atiqeffjr+85//xHPPPZfR/OvWrYurrroqXn/99WrHlJSUxGOPPRaTJk2KRx55JAoKCjJePwAAAF8swnwAAACgwRUVFcWll16aCvJzcnKiV69ekZ+fH2vWrIlp06bFmjVrUuPffffduPjii2P06NHRtGnTGud+44034vLLL4+ioqK04926dYuuXbtGVlZWzJ49O2bOnJn6bs2aNXHJJZfEb37zmzjuuONqXf+jjz4at99+e5SXl6cdz8/Pj+7du0fr1q1j8+bNsXjx4pgxY0YUFxfXOue2SktL04L8Zs2aRc+ePSM/Pz82b94cH3zwQSxZsiQ1/tNPP43rr78+HnnkkTpdBwAAgC8OYT4AAADQ4P785z/H2rVrIysrKwYOHBhXXnll2lP3xcXF8cQTT8TIkSNj06ZNEfF5oP+b3/wmrr766mrnXbFiRQwbNiwtyD/wwAPj1ltvjYMOOiht7Mcffxw33nhjTJs2LSI+f8r9uuuui7/85S81PuH+2muvxYgRI9KC/D59+sRPfvKT6N27d2RlZaWNLy4ujtdffz2eeeaZWLhwYQb/diIef/zxWL16dTRt2jSGDh0a5513XjRr1iz1fXl5eTz99NNx8803R0lJSUREvPnmm/Hqq6/Gsccem9E1AAAA+GLJKq94SzkAAADwpVfxnfYFBQXx2GOP1Xme5s2bR9u2bWudf6trr702Lrroomrne/3112Pw4MGpwLpJkybxwgsvxD777FPl+BtuuCGefPLJVN27d+945JFHonnz5lWO37x5cwwaNCjeeeed1LFTTjkl7rzzzirHb9q0Kfr16xcrVqxIHTvvvPPixhtvjEaNGlX759hq+fLl0a5du0rHq/r3k5OTE4888kgcfvjh1c735z//Of7v//4vVf/v//5v/PrXv651HQAAAHzxCPMBAABgN1Rd2F5X/fr1i9/+9rcZzX/EEUfEmDFjap1zxIgR8fDDD6fqiy66KK699tpK41atWhXHHnts6qn8Zs2axfPPPx+dOnWqcf5FixbFSSedlNoBIDs7O1555ZVo3759pbGjRo2K4cOHp+q+ffvGqFGjKj2NX1dV/fv5yU9+EpdddlmN55WVlcVxxx2X2nK/Xbt28cYbb+zQWgAAAEim2m8hBwAAAKgHP/zhDzMad+mll0Z2dnaq/utf/1rluL///e9p2+t/5zvfqTXIj4jo2LFjnH322am6pKQkxo8fX+XYcePGpdU/+9nPdjjIr0pubm6cd955tY5r1KhRHHPMMal6+fLlsWzZsnpfDwAAALueMB8AAABocG3atIm+fftmNHbPPfeMr33ta6l66dKlsWjRokrjpk6dmlafcsopGa+n4tiKc0VErFy5MmbOnJmqDz744PjqV7+a8TXqonfv3tGiRYuMxnbt2jWtXrlyZUMsCQAAgF2sya5eAAAAALDrFRYWxiuvvNJg8x9wwAEZvWN+q4MPPjhee+21VP3hhx9Gx44d08Z8+OGHqc+NGzeOgw46qE7rycnJieLi4kpzbfXee++l1TW9y35HVQzoa9KyZcu0ev369fW9HAAAABLAk/kAAABAg9tnn33qNL5z585p9YoVKyqN2faJ9IKCgmjWrFnG8zdp0iT23nvvKufaavny5Wl1t27dMp6/rioG9DVp0iT92YwtW7bU93IAAABIAGE+AAAA0OAy3UK+uvFr166tNGbbY3WdPyI9QN+wYUOlUHzVqlXVjq9vddm1AAAAgN2DvykCAAAAZCArK2tXLwEAAIDdiDAfAAAAaHB1fa97xfF5eXmVxmx7bHveG79u3brU5z322KPS9vWtW7dOq6vaHQAAAAAaijAfAAAAaHDz5s2r0/i5c+em1W3btq00pk2bNqnPS5Ysic2bN2c8/5YtW2LBggVVzrVVu3bt0upZs2ZlPD8AAADsKGE+AAAA0OA+/PDDKCsry3j8tGnT0uoDDzyw0phtj5WWlsYHH3yQ8fwfffRRFBUV1Th/r1690urJkydnPD8AAADsKGE+AAAA0OBWrVoVkyZNynjsv//971Tdvn376NixY6VxvXv3TqtfeOGFjNfzt7/9rca5Ij5/Wn///fdP1e+//35Mnz4942sAAADAjhDmAwAAADvFb3/724zGPfDAA1FSUpKqTz311CrH/c///E80bdo0VT/99NOxePHiWudfsmRJPPHEE6m6SZMm8e1vf7vKsWeffXZaffvtt0d5eXmt1wAAAIAdJcwHAAAAdoq33norHnrooRrHvPHGGzFmzJhU3aRJkzjnnHOqHNumTZs4+eSTU/XGjRvjmmuuSds+v6KioqK45pprYuPGjaljJ554YhQUFFQ5/swzz4x27dql6jfffDOGDx+ecaC/fPnyjMYBAABARcJ8AAAAILZs2RILFizYrn9WrFhR6/x5eXkREfGrX/0qhg8fHuvWrUv7vri4OMaOHRs/+tGP0p7KHzRoUHTu3Lnaea+++upo06ZNqn777bdj4MCB8dFHH1Ua+/HHH8fAgQPjrbfeSh1r1apVXHfdddXO37x58xgxYkQ0avTfX6GMHj06fvCDH8TUqVOrPKe4uDj+8Y9/xBVXXBGXXnpptXMDAABATZrs6gUAAAAAu96SJUuiX79+23Vuv379at1C/5xzzol//vOfMXPmzBg1alQ8/vjj0bt378jPz481a9bE+++/H2vWrEk7p1evXjFkyJAa523Xrl2MGDEifvSjH0VxcXFERLz33ntx+umnx3777Rf77rtvZGVlxezZs2PGjBlp52ZnZ8dtt91W7VP5W33961+P6667Lm2L/UmTJsV3v/vdyM/Pj+7du0fr1q2jqKgoFi9eHNOnT0+t5atf/WqNcwMAAEB1hPkAAABAg2vatGn8/ve/jwsvvDDmzp0bxcXFMWnSpGrH9+rVKx588MFo2rRprXN/4xvfiAcffDCGDh0aq1evTh2fOXNmzJw5s8pz8vLy4u67746jjz46o/VfcMEF0b59+7jxxhtjw4YNqePLli2LZcuWZTQHAAAA1IVt9gEAAICdorCwMJ566qn4wQ9+EK1atapyTNu2bePqq6+OsWPHprbmz8TXvva1ePHFF+PCCy+M1q1bVzuudevWMXDgwHjxxRczDvK3Oumkk2LChAkxaNCgaNeuXY1j27VrF+ecc06MGDGiTtcAAACArbLKt+4PBwAAAFBPFixYkLZt/5AhQ+KKK65I1cXFxfH222/HokWLYuXKldG6devo3Llz9OnTJxo3brxD1y4rK4v33nsvZs+eHStXroyIiDZt2kSXLl3ikEMO2eH5IyLKy8vj448/jpkzZ8bKlStj48aNkZubGwUFBbHffvtFt27dIisra4evAwAAwO7LNvsAAADATpeTk1PnJ+Mz1ahRo+jdu3f07t27QeaPiMjKyooePXpEjx49GuwaAAAA7N5ssw8AAAAAAAAACSPMBwAAAAAAAICEEeYDAAAAAAAAQMII8wEAAAAAAAAgYYT5AAAAAAAAAJAwwnwAAAAAAAAASBhhPgAAAAAAAAAkTFZ5eXn5rl4EAAAAAAAAAPBfnswHAAAAAAAAgIQR5gMAAAAAAABAwgjzAQAAAAAAACBhhPkAAAAAAAAAkDDCfAAAAAAAAABIGGE+AAAAAAAAACSMMB8AAAAAAAAAEkaYDwAAAAAAAAAJI8wHAAAAAAAAgIQR5gMAAAAAAABAwgjzAQAAAAAAACBhhPkAAAAAAAAAkDDCfAAAAAAAAABIGGE+AAAAAAAAACSMMB8AAAAAAAAAEkaYDwAAAAAAAAAJI8wHAAAAAAAAgIQR5gMAAAAAAABAwgjzAQAAAAAAACBh/j/Qi+yMx0nTQQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "ed126de0-9c24-4288-a740-6bf766194b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6764705882352942"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "41e2b9ff-7a6c-4c9f-de9d-024399a0f29f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "f3fb87ff-3228-4326-9683-f9eb3478aaa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.88      0.74      0.80        19\n",
            "     Faixa 2       0.33      0.25      0.29         8\n",
            "     Faixa 3       0.58      1.00      0.74         7\n",
            "\n",
            "    accuracy                           0.68        34\n",
            "   macro avg       0.60      0.66      0.61        34\n",
            "weighted avg       0.69      0.68      0.67        34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "HQ54xluu8RL3",
        "outputId": "e2a06c8b-2f1b-4c84-da71-6c4f7d712a21"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 730
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edb75653007d47649bbf8e85c1df47a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d0648a836034ed5b4a44de09fcca508",
              "IPY_MODEL_98ebe907c8b749e68cd869dc01abadcf",
              "IPY_MODEL_7cc242c87f2e453f989b3c7a22d4a2b2"
            ],
            "layout": "IPY_MODEL_f5c949f616704693aba29657593b7ed0"
          }
        },
        "4d0648a836034ed5b4a44de09fcca508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d6d6d983ba4cc98e048cc72f87b3b6",
            "placeholder": "​",
            "style": "IPY_MODEL_754a5df55fca4852ae13f9f97ff6ee29",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "98ebe907c8b749e68cd869dc01abadcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_839f3301e3b242daa9839ff187af227d",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35083988361e45b08fe66324e61ccf73",
            "value": 29
          }
        },
        "7cc242c87f2e453f989b3c7a22d4a2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ceef528280f4598be3da740e2d28d13",
            "placeholder": "​",
            "style": "IPY_MODEL_f2f374ff9a3744e6bafb2136c8192b28",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.13kB/s]"
          }
        },
        "f5c949f616704693aba29657593b7ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d6d6d983ba4cc98e048cc72f87b3b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "754a5df55fca4852ae13f9f97ff6ee29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "839f3301e3b242daa9839ff187af227d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35083988361e45b08fe66324e61ccf73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ceef528280f4598be3da740e2d28d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f374ff9a3744e6bafb2136c8192b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbeb4ec6168b4f949efd35a68576a084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_332c4ea1fe474e2590ab33e94b1c7ae8",
              "IPY_MODEL_056652c7f3f44ec5aef7e824f2cb630e",
              "IPY_MODEL_2f907107dd734887a8c299cd33144cd2"
            ],
            "layout": "IPY_MODEL_cf827a2b131740538823afc40b870d63"
          }
        },
        "332c4ea1fe474e2590ab33e94b1c7ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2aee3da1ff04af6abd58cdf8825a574",
            "placeholder": "​",
            "style": "IPY_MODEL_e81b0eed46de468fa20f330ca1e3d0dc",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "056652c7f3f44ec5aef7e824f2cb630e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03fe6bcc3cd6441d907a864412d95708",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f148eab0a25d476b8e356e6c39d9226f",
            "value": 995526
          }
        },
        "2f907107dd734887a8c299cd33144cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f414b085d7f3493f8c64875f77df8332",
            "placeholder": "​",
            "style": "IPY_MODEL_f0d4382a6eb54ed7ad9ce92b99d823e1",
            "value": " 996k/996k [00:00&lt;00:00, 19.2MB/s]"
          }
        },
        "cf827a2b131740538823afc40b870d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2aee3da1ff04af6abd58cdf8825a574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81b0eed46de468fa20f330ca1e3d0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03fe6bcc3cd6441d907a864412d95708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f148eab0a25d476b8e356e6c39d9226f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f414b085d7f3493f8c64875f77df8332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d4382a6eb54ed7ad9ce92b99d823e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae368b7b47fb4b5ab2f65092ecc83ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_567b8df7224043649e778fc82721e60a",
              "IPY_MODEL_9637b7056b90490f850ca77c44d7e8f3",
              "IPY_MODEL_44c0d165afd8453fad4a1f4675494c7e"
            ],
            "layout": "IPY_MODEL_ce617837dd794c759b2d19c4754e5897"
          }
        },
        "567b8df7224043649e778fc82721e60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4914f896b86e48d3b470544aa0fb0e13",
            "placeholder": "​",
            "style": "IPY_MODEL_af4bed8f7e0f478593b1bf6fdbd7ac60",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "9637b7056b90490f850ca77c44d7e8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a805c2ad5f114459bbfaed69eab26987",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e979cb3db6c449fbc09eab42b77c93c",
            "value": 1961828
          }
        },
        "44c0d165afd8453fad4a1f4675494c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a75bf893a4f041a9adecfab47257d42c",
            "placeholder": "​",
            "style": "IPY_MODEL_0af0e897518b4d15aa8f872de0fc7c46",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 2.16MB/s]"
          }
        },
        "ce617837dd794c759b2d19c4754e5897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4914f896b86e48d3b470544aa0fb0e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4bed8f7e0f478593b1bf6fdbd7ac60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a805c2ad5f114459bbfaed69eab26987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e979cb3db6c449fbc09eab42b77c93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a75bf893a4f041a9adecfab47257d42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af0e897518b4d15aa8f872de0fc7c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67a1e53200f54a60ac132b6bc60ce444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_994fd8925bf740e78b40accca272f8ad",
              "IPY_MODEL_ffeee6937d2a4870b02b878fa939a529",
              "IPY_MODEL_a98f631c3013453fb3298ea6cac10c38"
            ],
            "layout": "IPY_MODEL_c1e388cd522b43cd8c397cecd4f572bb"
          }
        },
        "994fd8925bf740e78b40accca272f8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b0dbd6feb6e42f88f8ff83cc17c1e70",
            "placeholder": "​",
            "style": "IPY_MODEL_64b3e38d750f4ea1a502c4dd454a6033",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ffeee6937d2a4870b02b878fa939a529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a40963caeba748c7917ea0fb0c0897f1",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_303d3b2b602b464798ba338aa58b8f34",
            "value": 625
          }
        },
        "a98f631c3013453fb3298ea6cac10c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9f387200e549d1b4ab2e5e7a325702",
            "placeholder": "​",
            "style": "IPY_MODEL_49403e4d2a884b7583076e3fb61fa1d3",
            "value": " 625/625 [00:00&lt;00:00, 41.5kB/s]"
          }
        },
        "c1e388cd522b43cd8c397cecd4f572bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b0dbd6feb6e42f88f8ff83cc17c1e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b3e38d750f4ea1a502c4dd454a6033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a40963caeba748c7917ea0fb0c0897f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303d3b2b602b464798ba338aa58b8f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc9f387200e549d1b4ab2e5e7a325702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49403e4d2a884b7583076e3fb61fa1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dde8afd86954a6c86ac9db92f28a0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_872b36807671473a8752e8554a06bdff",
              "IPY_MODEL_5bdc257dfd504040915da4a305f4f9f0",
              "IPY_MODEL_a48f3b68fffc4feaa0aff91f03f39549"
            ],
            "layout": "IPY_MODEL_df72b8f49f004399b658161fc5ccf564"
          }
        },
        "872b36807671473a8752e8554a06bdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c297d9905a6e490c985849d3004bbbdb",
            "placeholder": "​",
            "style": "IPY_MODEL_7e3e3cdff53847f2a3e00927f409e98c",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "5bdc257dfd504040915da4a305f4f9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b19f5eff3a4969bb62397cc0e2deb3",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a26492a2b434a97be819eaace6b9f78",
            "value": 714290682
          }
        },
        "a48f3b68fffc4feaa0aff91f03f39549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd58b9081464627b9f3488fa1c19ea3",
            "placeholder": "​",
            "style": "IPY_MODEL_c63b12d59015488ba1849056a8225809",
            "value": " 714M/714M [00:02&lt;00:00, 230MB/s]"
          }
        },
        "df72b8f49f004399b658161fc5ccf564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c297d9905a6e490c985849d3004bbbdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e3e3cdff53847f2a3e00927f409e98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16b19f5eff3a4969bb62397cc0e2deb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a26492a2b434a97be819eaace6b9f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffd58b9081464627b9f3488fa1c19ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c63b12d59015488ba1849056a8225809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}