{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural + 512 tokens [kfold][P2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 2**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 512 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "4e3a2634-1403-45da-809f-e483bca2dc10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=2  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lFCPPlujqL5L",
        "outputId": "a2f5f99e-82da-4b5c-b2d1-91ed4ce15ab0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_2.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZxPMZOfICS",
        "outputId": "968adb42-3eef-42c5-ce06-1cd40f0c8d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RDBcpVf0TS",
        "outputId": "8ead5aac-1fc3-4245-87e9-2fce5b8e2a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "c671bad1-ecc5-43be-cf36-b008b69c4c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 01:37:50 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "b9f72639-6941-4878-d2e2-ca3130b58982"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "66004f5e-554b-4d24-edb1-d40e3aecc733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "233696f882664221a7cfb639320c28a5",
            "d0bf600da55b41b794aec8b1655fcba1",
            "ac43d19ef5eb4df0978916bcc1968862",
            "e96672334bc24c1c8525d49667ca941c",
            "6d32af1a1f804bb9a2c6b93fec1a0df6",
            "96f39b4401e24f4b95feb4f12fb3054d",
            "00b54820e0124993bfaa7d03c98cc7b2",
            "60226ad6ff8a4212867bb517349665d0",
            "995eaa3845294f9088b49ab0636dbf29",
            "065ab5c4f5444f86bb481ba6d8bdb4c9",
            "037df700fd494a7bba9872cfac3ea702",
            "cda27ee605c24c7eaef8641bf1f389ef",
            "69700ab2ad0f40d3a99e675c40cca443",
            "44b2724f192c4c7fad911b43d8b7cdf7",
            "7e500460954d43d8811977ad2198794d",
            "34b58457ac364906b40265a86795c8f4",
            "9961d02db0f344c48e943507abe68da0",
            "3d656244a9f9403d8b9533c25120a92b",
            "7a468c79c5e74b4996aaa85367df653a",
            "8832c0588510447dab0b07bbec99e102",
            "b935378f000140b69fd63906c647a9db",
            "4f076837bd0245079cbab6f6f40d0d98",
            "b684cf33db2244d2a6692557e7f812e9",
            "798fc27bdaa647ee84100f5ed80b280a",
            "92e8c5172ba34961a8c06fba4237de39",
            "162376024f5f4379930ede0e15d95be0",
            "e150b44bfe974e5c8d41af9e9ebc76f6",
            "ff882d7f7fd6467a937b93dea62f5b1b",
            "a07a930b544b45709063270fabdacf8a",
            "dff8d9111b7043758e4494df890b4367",
            "d4d11e3fe35d40e7a53bf8f959695b2a",
            "b0a6e58c08e344f8a5fb6982d6ba6690",
            "3ffd106c93014276929f0d8286f2fcbe",
            "8dd6b497f2474ede9070e56ca562c1ef",
            "f561bed867e943d59b33725da8e12ddf",
            "6bf748838ec343539716e573b1c2999d",
            "f521dcf422404a7296262ce70f57351c",
            "1e6ea9450a1745ba9470a7ac6f236f0f",
            "fc3c20a6ef4f48ff9b95446aada3633b",
            "ff3c0ec0b64e4a1ca576760943b9f0d9",
            "ba774e96b953483a99daa43d1c80f97b",
            "63c0369a9d2d4198a395c5c1a41ad146",
            "72b8df1bb3f84b138e298a1dd80eb935",
            "d89035617eee4bd2ac6e1a63906de050"
          ]
        },
        "id": "WPj7c-IBgWRx",
        "outputId": "197ff497-cb76-4122-e071-15d4790d928f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "233696f882664221a7cfb639320c28a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cda27ee605c24c7eaef8641bf1f389ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b684cf33db2244d2a6692557e7f812e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dd6b497f2474ede9070e56ca562c1ef"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2a82513214d1423aa7f6b473a6636d04",
            "d87da6ac105542409f680890157cc7d6",
            "1c1940cf693f4c8cb8eca2236aebea6e",
            "6fd07c43ff1f41649764852b77317e13",
            "4367998d6eb94eae86b3c0a3a03be959",
            "3da522be68fa4a3fbbe9fb8a4367103e",
            "48f07d7a278f41b1909c235636845df2",
            "9bbaab5323264b5a8dee224d3d39b18b",
            "d397aa5f0b86479cac2e13e7e6b345c8",
            "f0ad0c21104b4036969b3e225e65545e",
            "4ea00095049745f086b0f9982b9742c1"
          ]
        },
        "id": "qSErznNMh4P5",
        "outputId": "10c8a56c-5832-48f9-dace-a3f75865ce29"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a82513214d1423aa7f6b473a6636d04"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "e4009d5d-e116-42fc-f203-4447b6258d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "0b1af5cf-9062-46e8-d702-6e17aa01f250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "041ef738-93f5-4a6b-d729-2abda6d22779"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d35e932-abfa-47c2-9f97-a0b1c30ce743\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d35e932-abfa-47c2-9f97-a0b1c30ce743')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d35e932-abfa-47c2-9f97-a0b1c30ce743 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d35e932-abfa-47c2-9f97-a0b1c30ce743');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52e0e284-e032-458f-96a5-d27f224a6564\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52e0e284-e032-458f-96a5-d27f224a6564')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52e0e284-e032-458f-96a5-d27f224a6564 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "ac06556a-adb1-4617-f89f-8b666990d8f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "5482fb57-985a-4f5f-c618-f129afbbde45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107, 2), (27, 2), (34, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "97e46b4e-d6ce-42d1-b7b3-5c820eebf898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "1a5a943c-8b72-489c-e470-0941c45dab6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "eb170898-b701-4747-aba3-46b6c338fcbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "2fa96114-172a-45b6-e590-96dc6d44e40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "c14ecad5-df2e-45d9-8d9a-5bf82243c19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "da8807d2-fed2-428a-d9e6-2d51320a58f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "ffa3ea43-9a70-411d-ec15-196e2d06034f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9571597533566611 accuracy 0.5607476635514018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7683531641960144 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.749492958188057 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6636264249682426 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7259955427476338 accuracy 0.6915887850467289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7529128715395927 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7554224740181651 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7442497536540031 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7595072729246957 accuracy 0.6915887850467289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1890703588724136 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8310054263898304 accuracy 0.6822429906542056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7318733856081963 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.694274263722556 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6567298322916031 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7169535266501563 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6555611938238144 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7633534478289741 accuracy 0.7009345794392523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6350337937474251 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7770035245588848 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6614281460642815 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7478837945631572 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6760217323899269 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7158002470220838 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.66238684207201 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.746987909078598 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6572569236159325 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7142287088291985 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6461343914270401 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7060033210686275 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.65761499106884 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6517433886017118 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6797431223094463 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5659347964184624 accuracy 0.7850467289719626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6398435272276402 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8562841841152736 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0781094133853912 accuracy 0.4074074074074074\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7180619048220771 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7112245559692383 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.43643791547843386 accuracy 0.7850467289719626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1505038477480412 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.38138095156422686 accuracy 0.8691588785046729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2058637738227844 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.21212039981037378 accuracy 0.925233644859813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.3507537340046838 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10983536871416229 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7033056165091693 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0846808957202094 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4618751354864798 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.024340558431244323 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.008902929839678 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.033529415751607825 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0169978695194004 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.019877816384126033 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.107301709605963 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05639285188434379 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1840039436210645 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01685009814017186 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0839368897286477 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0013077465451455542 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.173235809226753 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03954747741227038 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0792341800770373 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.001301013577696202 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.180021653759468 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.001104577477755291 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.405055714865739 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0008996371928203319 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6592615198533167 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0008656869634121124 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.672136313187366 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0007519388787581452 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.679946996329818 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0007303956372197717 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.689639139563951 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0007001040711267186 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.7013448666548356 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0007018958151872669 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.7093712386267725 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006851157065414425 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.720216304216592 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.000666106994945689 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.7289669121892075 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03805617771286052 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.634905279170198 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006570961476037544 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5984965370225837 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006449373364115932 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6015698819683166 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006488481282888513 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6134783240122488 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006517152422540155 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6244366580285714 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006363844212111351 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6303695257156505 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006353865111512798 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6343064225438866 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006234190035944007 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.63707712465839 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0006144463841337711 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6381687142056762 accuracy 0.5925925925925926\n",
            "\n",
            "CPU times: user 8min 25s, sys: 29.7 s, total: 8min 55s\n",
            "Wall time: 10min 3s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "aea8f8cd-da98-418b-eaeb-ca19fc36994d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "c6a9ec8b-fd36-47bd-a133-b8a177bd4fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6764705882352942"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "f58f5269-d2a9-4f50-9e75-1107353b7da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "394d6604-a97b-4fb5-f0c2-bbfa316c7d39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.70      0.84      0.76        19\n",
            "     Faixa 2       0.33      0.25      0.29         8\n",
            "     Faixa 3       1.00      0.71      0.83         7\n",
            "\n",
            "    accuracy                           0.68        34\n",
            "   macro avg       0.68      0.60      0.63        34\n",
            "weighted avg       0.67      0.68      0.66        34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "HQ54xluu8RL3",
        "outputId": "659771a0-ff40-40ff-8136-afbbda7a143f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB6oAAAW0CAYAAAB/qY1NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAB7CAAAewgFu0HU+AAEAAElEQVR4nOzdeZxXdb0/8PcZhn1E9mUEFVlEFA1ckZuaShZZ7nW9ppn3V6mh5U6KlUtpqZlK3kyvJi5pKWluuaHlboQLiwyiKAIii+wzA7N8f39w+cqww8ycMzLP533M457Pmc/5nNf3Pgav+JrPOUkul8sFAAAAAAAAAKSkIOsAAAAAAAAAADQuimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUlWYdQAAAAAAAAAA0rNy5coYP358fPzxxzFv3ryIiGjXrl307Nkz+vfvH61atar3DIpqAAAAAAAAgAytXLkySkpKYuLEiTFhwoSYMGFCvPfee1FVVZWfU1JSUuv7zJo1K0aNGhVPP/10LF26dL1zCgsLY+DAgXHhhRfGnnvuWet7boiiGgAAAAAAACAjxx9/fEyZMiUqKirq9T733HNPXHvttVFaWrrReZWVlfGvf/0rSkpKFNUAAAAAAAAA26IJEybU+z1uueWW+M1vfpMfN23aNPbdd9/YZ599olOnTpHL5WLevHnxzjvvxKuvvhrLli2r90yKagAAAAAAAIAGoKioKPr37x8DBgyI8ePHxxtvvFHrNR966KEaJfWBBx4Yl19+efTo0WO981euXBnPPvtsdOjQodb33pgkl8vl6vUOAAAAAAAAAKzXlVdeGXvssUcMGDAgdtlll0iSJCIiRowYEX/961/z87bmHdXz58+PYcOGxeLFiyMi4vDDD48bbrghCguz38+cfQIAAAAAAACARmrkyJH1tvZvf/vbfEndvn37uOqqqxpESR0RUZB1AAAAAAAAAADq1rJly+LRRx/Nj0877bRo06ZNholqUlQDAAAAAAAAbGMee+yxKCsri4iIJEniyCOPzDhRTYpqAAAAAAAAgG3Mq6++mj/u3r17dOvWLcM062oYDyAHAAAAAAAAoM68/fbb+eO+fftGREQul4vnnnsuxowZE5MnT465c+dGUVFRdOvWLQ444IA4+uijY9ddd00ln6IaAAAAAAAAaNRmz54ds2fPrtUaxcXFUVxcXEeJamfZsmUxc+bM/LhLly4xf/78uOiii+LFF1+sMXfhwoWxcOHCmDx5cvzxj3+MY489Nn72s59Fs2bN6jWjohoAAAAAAABo1B588MEYNWpUrdYYPnx4nHXWWXWUqHYWLlxYY5zL5eK73/1uTJ06NX+uTZs20apVq1iwYEFUVFRERER1dXU88MAD8cEHH8Qdd9xRr2W1ohoaiJYDh2cdAQDYQq8/cnXWEQCALdSna1HWEQCALdRCm5W6xthZ/Pq0dB53nZalS5fWGD/wwAP5MvqrX/1qDB8+PHr37h0REeXl5fHUU0/FNddcE3Pnzo2IiHHjxsWvfvWruPTSS+stY0G9rQwAAAAAAABA6kpLS2uMV5fUp512Wvz2t7/Nl9QRES1atIhvfOMbcd9990WnTp3y5++999748MMP6y2j30EBAAAAAAAAGrXjjjsuBg8eXKs1Gsr7qSMimjdvvs65Xr16xXnnnbfBa3bYYYe45JJL4sc//nFErHoM+H333RcXXXRRvWRUVAMAAAAAAACNWnFxcYMqmmurVatW65z71re+FYWFG6+Hv/zlL0fnzp3zjwB/9dVX6yVfhEd/AwAAAAAAAGxTioqK1jm37777bvK6Jk2axKBBg/LjkpKSqK6urtNsq9lRDQAAAAAAAHwmsdf1865Tp07RokWLKC8vz5/r1q3bZl275ryqqqpYsmRJtG3btq4j2lENAAAAAAAAsC0pKCiInj171jjXrFmzzbp27fdbr1y5ss5yrUlRDQAAAAAAALCN6devX43xkiVLNuu6xYsX1xjXx27qCEU1AAAAAAAAwDbn4IMPrjGeMmXKZl1XUlKSP+7UqdNm78TeUopqAAAAAAAA4DNJ0vi+tkEHHXRQjcd4P/XUU5u8Zs6cOfHWW2/lx/vvv3+9ZItQVAMAAAAAAABsc1q3bh0nnHBCfvzII49sclf19ddfH1VVVfnxN77xjXrLp6gGAAAAAAAA2AadeeaZ0apVq4iIqKioiNNPPz2mTp26zryqqqq4/vrr46GHHsqf22uvvdZ5fHhdKqy3lQEAAAAAAADYqNGjR8ddd921zvkFCxbUGA8dOnSdOV27dl3vtat16NAhfvWrX8WPfvSjqK6ujo8//jiOOeaYGDp0aAwaNChatmwZs2fPjr///e/x/vvv56/bfvvt47rrrqvFp9o0RTUAAAAAAABARhYvXhwzZszY5Lz1zVnzMd0b8uUvfzkuu+yyuOKKK2LlypVRWVkZTzzxRDzxxBPrnd+tW7f4/e9/Hz169Nh0+Frw6G8AAAAAAADgM0lB4/vaxn3zm9+MMWPGxEEHHRRNmjRZ75zWrVvHaaedFn/961+jX79+9Z4pyeVyuXq/C7BJLQcOzzoCALCFXn/k6qwjAABbqE/XoqwjAABbqIXnA6eu5T7nZB0hdWXjrs86QmoWLFgQ//73v+OTTz6J0tLSaNu2bfTs2TMGDhwYTZs2TS2HP9oAAAAAAAAAjUSHDh3iy1/+ctYxPPobAAAAAAAAgHQpqgEAAAAAAABIlUd/AwAAAAAAAJ9JkqwT0AjYUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKSqMOsAAAAAAAAAQAOS2OtK/fNTBgAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApKow6wAAAAAAAABAA5IkWSegEbCjGgAAAAAAAIBUKaoBAAAAAAAASJWiGgAAAAAAAIBUeUc1AAAAAAAA8JnEXlfqn58yAAAAAAAAAFKlqAYAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVYVZBwAAAAAAAAAakCTJOgGNgB3VAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqgqzDgAAAAAAAAA0IIm9rtQ/P2UAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqCrMOAAAAAAAAADQgSZJ1AhoBO6oBAAAAAAAASJWiGgAAAAAAAIBUKaoBAAAAAAAASJWiGgAAAAAAAIBUFWYdAAAAAAAAAGhAEntdqX9+ygAAAAAAAABIlaIaAAAAAAAAgFQpqgEAAAAAAABIlaIaAAAAAAAAgFQVZh0AAAAAAAAAaECSJOsENAJ2VAMAAAAAAACQKkU1AAAAAAAAAKlSVAMAAAAAAACQKu+oBgAAAAAAAD6T2OtK/fNTBgAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApKow6wAAAAAAAABAA5LY60r981MGAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkqjDrAAAAAAAAAEADUpBknYBGwI5qAAAAAAAAAFKlqAYAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVYVZBwAAAAAAAAAakMReV+qfnzIAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVhVkHAAAAAAAAABqQJMk6AY2AHdUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApMo7qgEAAAAAAIDPJPa6Uv/8lAEAAAAAAACQKkU1AAAAAAAAAKlSVAMAAAAAAACQKkU1AAAAAAAAAKkqzDoAAAAAAAAA0IAkSdYJaATsqAYAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVYpqAAAAAAAAAFJVmHUAAAAAAAAAoAFJ7HWl/vkpAwAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUlWYdQAAAAAAAACgAUmSrBPQCNhRDQAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApKow6wAAAAAAAABAA5LY60r981MGAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKq8oxoAAAAAAAD4TJJknYBGwI5qAAAAAAAAAFKlqAYAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVYVZBwAAAAAAAAAakMReV+qfnzIAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVhVkHAAAAAAAAABqQJMk6AY2AHdUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqCrMOAAAAAAAAADQgib2u1D8/ZQAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoKsw4AAAAAAAAANCCJva7UPz9lAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqgqzDgAAAAAAAAA0IEmSdQIaATuqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEiVd1QDAAAAAAAAn0nsdaX++SkDAAAAAAAAIFWKagAAAAAAAABS5dHfAAAAAAAAABlauXJllJSUxMSJE2PChAkxYcKEeO+996Kqqio/p6SkpM7vO23atDj66KOjoqIif26//faLu+66q87vtTZFNQAAAAAAAEBGjj/++JgyZUqNsjgNuVwuLr300tTvu5qiGgAAAAAAAPhMkmSdoFGZMGFCJve9//77Y/z48ZncO0JRDQAAAAAAANAgFBUVRf/+/WPAgAExfvz4eOONN+rlPvPmzYvrrrsuIiLatWsXuVwuFi1aVC/32hBFNQAAAAAAAEBGTj755Nhjjz1iwIABscsuu0TyfzvaR4wYUW9F9ZVXXhlLliyJiIgLL7wwRo0apagGAAAAAAAAaCxGjhyZ6v2ef/75+Pvf/x4REfvuu28ce+yxMWrUqFQzREQUpH5HAAAAAAAAAFJXWloal19+eURENG3aNH72s59llsWOagAAAAAAAOAzib2u26obb7wxZs2aFRERp556avTp0yezLH7KAAAAAAAAALZxkydPjtGjR0dExA477BA//OEPM82jqAYAAAAAAADYhlVVVcXIkSOjqqoqIla9F7tly5aZZvLobwAAAAAAAKBRmz17dsyePbtWaxQXF0dxcXEdJapbd911V0yaNCkiIg477LA49NBDM06kqAYAAAAAAAAauQcffDBGjRpVqzWGDx8eZ511Vh0lqjuzZ8+OG264ISIiWrVqFSNHjsw40SqKagAAAAAAAOAzSZJ1AurQ5ZdfHqWlpRERceaZZzaYXd/eUQ0AAAAAAACwDXriiSfiueeei4iIvn37xqmnnpptoDXYUQ0AAAAAAAA0ascdd1wMHjy4Vms0lJ3Kqy1dujR+8YtfREREkiTxs5/9LJo2bZpxqs8oqgEAAAAAAIBGrbi4uMEVzbV17bXXxrx58yIi4phjjol99tkn40Q1efQ3AAAAAAAAwDZk/Pjxcf/990dERNu2beOCCy7IONG67KgGAAAAAAAA8pIkyToCtXT55ZdHLpeLiIjzzz8/2rdvn3GidSmqAQAAAAAAALYhM2fOzB/fcsst8Yc//GGj8z/55JP88VtvvRVDhw7Nj08++eQ45ZRT6jyjohoAAAAAAABgG/XRRx9t0fwVK1bEjBkz8uPFixfXdaSI8I5qAAAAAAAAAFJmRzUAAAAAAACQ5x3Vn3/jxo3bovmHHnpozJo1KyIi9ttvv7jrrrvqI1YNdlQDAAAAAAAAkCpFNQAAAAAAAACp8uhvAAAAAAAAgIyMHj16vY/aXrBgQY3x0KFD15nTtWvXVB7TXR8U1QAAAAAAAAAZWbx4ccyYMWOT89Y3p6qqqj4ipUJRDQAAAAAAAHwmyToAjYGiGgAAAAAAACAjZ511Vpx11lmZZhg7dmzq9yxI/Y4AAAAAAAAANGqKagAAAAAAAABSpagGAAAAAAAAIFXeUQ0AAAAAAADkJUmSdQQaATuqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVBVmHQAAAAAAAABoOJIkyToCjYAd1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoKsw4AAAAAAAAANBxJkmQdgUbAjmoAAAAAAAAAUmVHNQA0IP17dYs9++4Q3TptH82aFcby0hUxe+7imDJ9Trzz/pzI5XJZRwSAbcrihZ/GzBnTY/7cObFk8aJYuaI8Cps2jdatt4tu3XeMXfr0i5atWmcdEwDYgMrKynjrzTdi9qxZMW/e3CgqKorOXbrGXl/4QrRr1z7reADARiiqAWA9kiSJfj27xD577Bx7775j7LP7TrFHn+Jo3qxpfs73fnpX3P3Ia7W+V1Gr5jH8pC/FacccGD26bfgv0UuWlcXzr0+Na+94Kv418cNa3xcAGqPKyop47ME/xTsT34xp70yMRQsXbHR+QUFBfGHfwTHs2BPjC/sMTiklALApZWVl8Yff3xwP/3VMLFgwf53vFxY2jf/44hdj+Nk/jj59d80gIQCwKYpqAFjDMYd/IU7/1sExcLcesV3rFvV+v8MO6Be3Xn5ydOu0/SbntilqGd84dK/418QPFNUAsJVWlJfHXX+4YbPnV1dXx/jXXorxr70UQ750RJxx3qXRomXLekwIAGzKtGnvxvnnnB3T339/g3MqKyvi+efGxisvvxTnX/ST+Oa3TkwxIcDnn3dUkwZF9Tbitddei1NOOSU/LikpyTANwOfXgV/oFQft0yeVe51y1AHxu5EnRmFhkxrnS6bPiQ9mL4iFi0ujqHWL2KV7x+i7U+d15gEAdWP7tu2jW/cdo03bdtGiRcsoLyuNObNnxswPp0d1dVV+3kvPPRkLP50fl149Kpo2a5ZhYgBovObNmxtnfP+/Y+4nn9Q433/33aN79x6xaNGimDRxQixfvjwiIlasWBG/uPznUdS6KIYd+fUMEgMAG6KoBoDNsGhpaSwvXRE7dGlXJ+t95T92j5sv/a9o0qQgIiKqqqrjf8e8FL8d/WxMn7nuI8u2a90ijhjSP779jf2jutp7qgGgNtps3zb2PuCL8YV9D4zdBgyM9h07rXfewk/nx6MP3BuP/OXufGE9+a1/x5h7b49vnXp6mpEBgIjI5XJx3o/PrlFS9+nbN3559TXRd9d++XNLliyJ3910Q9x37935cz//6SXRt1+/6N07nV9OBwA2TVG9mcaMGRM/+clPtvp6O5zTVVVVFdOmTYsJEybkv6ZOnRoVFRX5Oc8++2x07949w5RAQ1VatjLenjoz/j3pwxg3aUb8e9KH8e6Hc+OSHwyLkacPq/X6bbdrGf/zs5PyJXX5ior45rl/iKdffmeD1yxdXh4PPDU+HnhqfP46AGDLtWpdFLf+5alo0mTTTypp175jnPz9s2OnXXrHjVddmj//yF/ujqNPPDWaN6//14QAAJ959umn4q0338iPd+jePW7/493RZvuar9Nq06ZN/OSSS6OgIIl7774rIlbtrP7dTTfE9TeMSjUzALBhimq2OcOHD48XX3wxysrKso4CfA796n+fjBHX/zWqqqrr7R5X/ujo6NqxTX58xmX3bLSkXlt9ZgOAbV2SJJtVUq/poMOHxdgnHo6Jb46LiIjy8rKY+Ma/Yu8DvlgfEQGADfj9/9QsmS8e+dN1Suo1nf3j8+L5sWNj9uxZEREx9pmnY8o770S/3Xar15wAwOZRVG+lzp07R4sWDee35/fff3+7tv/P5MmTldTAVpu/cFm9rt+9S9s49ejB+fHzr5fEfU+Mq9d7AgC1t9c+g/NFdUTEJx/PyjANADQ+704tiXenTs2Pd9mlV/zHFw/e6DUtW7aM47/5n3Hjb6/Ln3visUcU1QCbI8k6AI2BonorXXvttbH//vtnHYNNaNGiRey2226xxx57xEcffRTPP/981pGARu7kow6o8ejum//0jwzTAACbq2i7NjXG5WWlGSUBgMbpH88/V2M87Mivb9Z1Xzvy6zWK6uefHxvnnH9hnWYDALaOopptzlFHHRXFxcUxYMCA6N27dxQWrvoxv+mmmxTVQOZO/voB+eMly8riyZcmZ5gGANhc8+fNqTFu175jRkkAoHF65eWXaowH7b3PZl3XtVu3KC7eIf/47w+mT485H38cXbt1q/OMAMCWUVRnaPny5VFSUhLTp0+PhQsXRlVVVbRp0yaKi4tj7733jqKioqwjbpXKysp4991347333ov58+dHWVlZbLfddtGhQ4cYNGhQdOnSpV7v/6Mf/ahe1wfYWjt0bhs9u3/2H7XfKpkZKysqM0wEAGyOysqKeOX5Z2qc223PgRmlAYDG6b33puWPCwoKov/ue2z2tQP22itfVEdEvDftXUU1ADQAiuqUzZs3Lx599NF48sknY8KECVFZuf6CokmTJnHooYfG2WefHX379t3kuq+99lqccsop+fH63ld99dVXxx133JEf33TTTfHlL395o+tWV1fHd77znXj99dcjYtWjtB988MHo3bt3jXnl5eXx1FNPxeOPPx6vv/56LF++fINr7rHHHjF8+PD40pe+tMnPBbAtGdR/xxrjSdM+zh/vtWv3+M7Rg+OLe/eJHl3bRWFhQcz7dGlMmvZxPP3yO3HvY6/H0uXlaUcGgEavqqoybrvxVzF75of5c3sf8MXoWtwjw1QA0LgsWbw4Fn76aX7coUOHaNmy5WZfv8MO3WuMP/hgegz54kF1lg8A2DqK6pTdfvvtcfvtt29yXlVVVTz99NPxz3/+M66++uoYNmxYre997rnnxiuvvBJTpkyJiIhLL7009tprr43ucL711lvzJXVExIUXXrhOSR0R8corr8QFF1ywWTkmTpwYp59+enz3u9+Niy66KJIk2cJPAvD5tFe/mn8xnjV3UbRo3jSuOueYOP1b6/4FufUOzWPnHTrG1w4eECNPHxY/G/VI3D7mpXXmAQB1q7ysLOZ98nFMnjA+nnz4zzFj+nv577Vt3yH+39kXZZgOABqfjz6aUWPcpeuW7Ybu0qVrjfGMGTM2MBOA1XQ3pEFRnaHu3bvH3nvvHX369Im2bdtGdXV1zJ49O1566aWYMGFCRESsWLEiLrzwwthxxx1jjz02/3E269OsWbO47rrr4thjj40VK1bEokWL4qKLLoo77rhjvf/AmTBhQtx000358SGHHBInnXTSJu/Ttm3b2HvvvaN///7RoUOHaNq0aSxYsCDeeOON+Oc//xlVVVUREXHHHXdEcXFxjZ3gANuyLh3a1BivWFERD97wgzh0/36bvLZju6L43aUnxq49u8RF142pr4gA0Cj9v+O/HIsWLtjkvJ177xrnjrwqOnXxqFAASNOyZctqjNu1b79F17dr326t9ZbWOhMAUHuK6pQVFBTEkUceGd/5zndizz33XO+cc845J/7xj3/EBRdcEIsXL46Kioq47LLL4i9/+Uut79+7d++48MIL44orroiIVTuh77jjjjjttNNqzCsrK4vzzz8/KioqImLV43R++ctfbnTtgQMHxve+97046KCDomnTpuudM3369PjRj36UfzT5ddddF1//+tejXbt2650PsC1pu13Nx5Kd/e1Do3vXVf/8Ky1bGbc+8EI88cKkmD13UbRp3SIGf2GXOP1bB0evHTvVuObdD+fGbQ+8mGp2AGjMeu+6exx5/Ekx+ODDo0mTJlnHAYBGp7S05msGmzdrvkXXN2/eYq31SmudCQCovYKsAzQ2Z599dlx33XUbLKlXO/jgg+OGG27Ij99+++2YOHFinWT49re/HQcd9NkjZn/zm9/kHwe+2i9/+cv44IMPaow7dOiwwTUPPPDAuO++++Kwww7bYEkdEdGzZ8+4/fbbo/3//dZjeXl5/PWvf93KTwLw+dKmqGZRvbqk/ujjT2P//7w6Rvzmr/GPf02Ndz+cG/+ePCNG3ft87H3CL+JvY9+qcd2vzj02unTYLrXcANDYvTd1cvz94fvj36++kHUUAGiUykrLaoybNW+2Rdc3b16z2F57PQAgG3ZUb6XNfVx1v3794uGHH86P1/6Xoo0ZPHhw7L///vHaa69FRMSLL75Y68d/r3bVVVfFN77xjViwYEFUVFTEeeedFw8++GC0aNEinnnmmfjzn/+cn3vSSSfFIYccstH1tuRzdezYMU466aT8Y8VffPHFdXZ0A2yLCgrWfc1CZWVVfPPcP8S0GXPXe82KlZVx8og74rX7RkS/XVa9U6tVy2Zxxn8eEj//3SP1mhcAGourbx4d1dXVERGRq66O5cuXxSezZ8bEN/8V/3zmiSgrXR5TJr4VUyaeF0O+dEQMv/Dn0bTZlv0HcgCg7mzpe1PXnp+LXF3GAQC2kh3VDdzgwYPzx5MmTaqzdTt27FjjUd7Tpk2LX//61zF37twYOXJk/vzqR4XXtfr6XAANWWnZynXO/eXJf8ebU2Zu9LqVFZVx2c2P1jh3whGD6jQbADRmHTt3jc5di6Nz1+LoUtw9dunTLwYffHh870c/iZvv/lvsM/izJ1K99NyTccMvR25kNQCgrrVsVfMJZSvKV2zR9eXl5TXGrVq1qnUmgG1dkiSN7ov0Kaq3UufOnWPHHXfc5Fe3bt1qdZ+OHTvmjz/55JPaxq7hkEMOif/6r//Kj++555747ne/GwsXLoyIiKZNm8Z1110XLVq02NASW23Nz7Vo0aJYsWLL/uUS4PNoWem6/6z7y5PjN+vaR//xdo3rd+nRKbp2bFNn2QCA9dtu+7ZxwWXXxIBB++XPvfrCs/Hi2CczTAUAjUvLljWL5RUrt+y/Ja5ca76iGgAaBo/+3krXXntt7L///lt9fVlZWTz77LPxwgsvRElJScyZMyeWL18eK1euu9tutaVLl271/Tbkoosuitdeey3ee++9iFi1s3q1c889N/r167dF61VXV8drr70WzzzzTEyePDk++uijWLZsWZSVbfy9L0uXLt2ix4cDfB4tWbbuPwv/PenDzbq2srI63i6ZGQcO7JU/12enLjFn/pI6ywcArF+TJoXx38MvjB+fdnz+3KMP3BP/cegRGaYCgMajqKioxnjR/2202VwLP/10rfW2q3UmAKD2FNUZeOihh+JXv/pVfLrWvyBtSn3sOm7RokVcd911ccIJJ0RFRUX+/ODBg+O73/3uFq319ttvx6WXXhpTpkzZ4hx2VAONwbQZ82qMq6qqY+6nm/9LSJ8sqFlKt9/eb4ADQFq679QzduzZK2ZMX/VLvu9NnRzLli6Jou084QQA6luPHjvWGM+Z8/EWXT9nzpy11utR60wAQO0pqlN26623xrXXXrve77Vt2zZatGgRzZo1y59bvnx5LFiwoF4zNWnSJAoKaj4F/sADD9yi5/G/9tpr8f3vf3+d971ERLRu3Tpat24dzZs3z69ZVVUVs2bNys/J5XJbmR7g82PK9Jp/Ma6orNqi61esrKwxbt7M/xsHgDR13WHHfFGdy+Vi7pzZimoASMH2bdtGu/bt8zujF8yfH2VlZdGyZctNXLnKrFkza4x79tylzjMCAFvOf+FO0ZQpU+L666/Pjzt27BinnHJKfPGLX4zevXvXKKhXe/DBB+Piiy+ut0wrV66M888/f50dzaNGjYovfelL0adPn02uUV5eHiNGjMiX1E2bNo3//M//jKFDh8buu+++zqN5IiI++uijOPzww+vmQwB8Tkx+r+ZvfLdo3jSaNS2MlRWVG7iipu23q/kX8E8Xl9ZZNgBg0woLa/4VunKNp1IBAPWrV6/eMe7T1yNi1esHJ0+aGHvvs+9mXTvh7bdqjHfp1bvO8wFsa7ZkMyNsrYJNT6Gu3HvvvVFVtWr3XKdOnWLMmDHxgx/8IPr377/ekjqift5LvabrrrsuSkpK8uNWrVY9RnbFihVx3nnnbfSd2as988wzMXv27IiIKCgoiFtvvTVGjhwZ+++//3pL6oj6/1wADdHH8xbHxHdn1zjXr2eXzb6+X8+u66wHAKTn0/lza4y3b9suoyQA0PgcMPjAGuPx/x63WdfN+fjjmL3Gkx137tkzuhUX12k2AGDrKKpT9Oqrr+aPTznllOjSZdPlxMyZMzc5Z2u9/PLLceedd+bHJ5xwQlx11VX5cUlJSfzmN7/Z5Dprfq4hQ4bE4MGDN3lNfX4ugIbsb8/V/C3uQ/fvt1nX9ezeMXp275gfL1xSus4ObQCg/pSVLo9pJZPz42bNmkf7jp0zTAQAjcshXzq0xvjxRx/ZrOseW2veIYccuoGZAEDaFNUpmjv3s9++79dv84qJ1157rV6yLFq0KC666KL8u6F32mmnuPjii+MrX/lKHHPMMfl5f/zjH+Pll1/e6FoN6XMBNHT3PzEuqqqq8+P/Pn5INC1sssnrfnjiwTXGz7zyTv6f4QBA/Xv4/tE1HvW9x8B9o+kGnowFANS9Pn13jd59+ubH77//Xrz4wj82ek15eXk88Of7apz76te+Xi/5AIAtp6hO0ZqFwuY8Uvv111+PqVOn1kuWSy+9NF8wFxYWxjXXXJN/7PfIkSOje/fuEbEq84gRI2LRokUbXGvNz7X2u67XZ+nSpfHwww/XIj3A59fUDz6JPz3+r/y4946d44qzv7HRaw7ap0/84JsH1Tj329HP1ks+ANjW/e3Pd0VZWekWXfPy80/FmHvvqHHuy0ceV5exAIDNcMaZw2uMr/rFFbFk8YZfi3Xj9dfF7NmfPfb7S4cdHv12263e8gEAW0ZRnaKuXT97t+jzzz+/0bnLli2Ln/3sZ/WS44EHHoinnnoqPz7zzDNjr732yo+LiorimmuuiSZNVu3w++STT+KnP/3pBtfr1q1b/viFF16I6urqDc6NiLjsssu8oxpo0Hbs1n69X223a1ljXse2Reud16XDdhtd//KbH41FSz/7D+Q/Ovmw+N2lJ0b77VvXmFdQkMSpxwyOB284PQrX2HV9z6OvxfjJM+rgkwJA4/PA3bfFD0/6etzxu2tj6uQJUVVVucG57099J2686tL4zRU/ierqqvz5Qfv/R+xz4EEbvA4AqB+HDf1y7PWFgfnxzI8+itNO/Xa8O7WkxrylS5fGVb+4Iu65e3T+XPPmzWP42T9OKyrA516SJI3ui/QVZh2gMRkyZEh88MEHERExZsyYOPDAA2PYsGHrzPvoo4/inHPOiffffz8KCgo2WfxuiRkzZsQvfvGL/HjgwIFx+umnrzNv0KBBcfrpp8fvfve7iIh48skn48EHH4zjjlt318CBBx4Y999/f0RETJ8+Pa666qoYMWJEvuhebdmyZfGLX/wiHnnkkTr/XAB1qeTxyzdr3lXnHhNXnXvMOuf/Oe7dOOJ7N2zwuo/mLIyTLrg9HrrpjGjadNU/K087dkicdOR+8fqED2L23MVR1Kp57LfnztGpXc3S+62SmXHWL+5b37IAwGZasnhRPDbmT/HYmD9Fs2bNo/vOu0Tbdh2iddF2UVlZEcuWLokP3383lixauM61vfvtHueM/GUGqQGAJEni2utviP/61vEx7/+eFvnu1KlxwrFHRf/+u8cOPXrE4kWLYuKEt2P58uU1rv3Z5VdG7959sogNAGyAojpFp556avz5z3+OioqKqKqqinPOOSf+/Oc/x3/8x39E+/btY8mSJTF+/Ph47rnnYuXKldGqVav4r//6r7jtttvq5P6VlZVx/vnnR2npql18rVu3rrFzem1nnnlmvPjii/HWW29FRMSVV14Z++67b+y444415h1++OGx884750v40aNHx8svvxxHHHFE7LDDDlFeXh4lJSXx1FNPxcKFq/5Dz/Dhw+PGG2+sk8+1tqeeeiquueaadc4vXusxQKeccsp6P/vTTz9dL7kA1jT2tSlx0oX/G//zs5OiQ9tVO6mbN2saX9x7w39pfvrld+KkC/83ysorNjgHANgyK1euiPenvrPJeUmSxJe/flx8+/s/ipYtW6WQDABYn86du8T//OF/4/xzzo4Ppk+PiFWvJpw0aWJMmjRxnfnNmzeP8y8cEV87cuOv3QIA0qeoTtGOO+4Yl19+eVxyySX53cSvvPJKvPLKK+vMbdWqVVx33XUbfTf0lrr55pvzpXNExE9/+tPo0aPHBuevfnf10UcfHaWlpVFaWhoXXHBB3HvvvTUK3sLCwrjhhhvi5JNPjiVLlkRExLRp02LatGnrrJkkSZxxxhlx1FFH1VtRvWzZspgxY9OPxJ01a9Ym5wDUp0eefzvGTfowfnrm1+KYwwbG9ms9Wny1t6fOjGv+96l44KnxKScEgG3P+T+/Jsa9/I+Y8Ma/YtaM6Zt80lOb7dvG4IOHxtAjj42de/VNKSUAsDF9+vSN+/7y17jlf34XDz80Jj5dsGCdOYWFTeM/vvjFGH72j6NP310zSAkAbIqiOmXHHntsdOrUKX75y1/G+++/v873mzRpEgceeGBccskl0bNnzxgzZkyd3PeNN96I3//+9/nxV77ylTj66KM3ed1OO+0Ul1xySVxyySUREfHmm2/G7373uzj77LNrzOvXr1888MADcdlll8VLL7203rX69esX5557bhx88MExc+bMrf8wAPWs5cDhqd3r43mL44zL7o0fX/XnOHBgr+jRtV107tAmSstWxNwFS+O1t6fHR3PWfewoALB19hy0X+w5aL+IiChdvixmfPBezP14VixetDBWriiPgoIm0aqoKLbfvl3s3LtvdC3e8C/3AgDZadmyZfz43PNj+Nk/jjffGB+zZs6M+fPnR1FR6+jSpWvs+YWB0b59+6xjAnx+eWUzKUhyuVwu6xCNUS6Xi4kTJ8akSZNi0aJFUVRUFJ07d46BAwdGp06dso5XKx999FH8+9//jrlz50bTpk2jU6dO0a9fv+jdu3fW0Rq0NIsxAKBuvP7I1VlHAAC2UJ+uRVlHAAC2UAvbLlPX4Tt/yjpC6hbceWLWERodf7QzkiRJDBgwIAYMGJB1lDrXo0ePjT5SHAAAAAAAAGjcCrIOAAAAAAAAAEDjoqgGAAAAAAAAIFUe/Q0AAAAAAADkJUmSdQQaATuqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVBVmHQAAAAAAAABoOJIkyToCjYAd1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoKsw4AAAAAAAAANBxJkmQdgUbAjmoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVhVkHAAAAAAAAABqQJOsANAZ2VAMAAAAAAACQKkU1AAAAAAAAAKlSVAMAAAAAAACQKu+oBgAAAAAAAPKSxEuqqX92VAMAAAAAAACQKkU1AAAAAAAAAKlSVAMAAAAAAACQKkU1AAAAAAAAAKkqzDoAAAAAAAAA0HAkSZJ1BBoBO6oBAAAAAAAASJWiGgAAAAAAAIBUKaoBAAAAAAAASJWiGgAAAAAAAIBUFWYdAAAAAAAAAGg4kiTJOgKNgB3VAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqgqzDgAAAAAAAAA0HEmSZB2BRsCOagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWFWQcAAAAAAAAAGpAk6wA0BnZUAwAAAAAAAJAqRTUAAAAAAAAAqVJUAwAAAAAAAJAq76gGAAAAAAAA8pLES6qpf3ZUAwAAAAAAAJAqRTUAAAAAAAAAqVJUAwAAAAAAAJAqRTUAAAAAAAAAqSrMOgAAAAAAAADQcCRJknUEGgE7qgEAAAAAAABIlaIaAAAAAAAAgFQpqgEAAAAAAABIlaIaAAAAAAAAgFQVZh0AAAAAAAAAaDiSJMk6Ao2AHdUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqCrMOAAAAAAAAADQgSdYBaAzsqAYAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVYpqAAAAAAAAAFJVmHUAAAAAAAAAoOFIkiTrCDQCdlQDAAAAAAAAkCpFNQAAAAAAAACpUlQDAAAAAAAAkCpFNQAAAAAAAACpKsw6AAAAAAAAANBwJEmSdQQaATuqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEiVd1QDAAAAAAAAed5RTRrsqAYAAAAAAAAgVXZUAwAAAAAAAGzDcrlczJgxI6ZOnRoff/xxLF++PFq1ahUdOnSIPfbYI3beeefUMymqAQAAAAAAADK0cuXKKCkpiYkTJ8aECRNiwoQJ8d5770VVVVV+TklJyRatuWLFinj++efj6aefjldeeSXmz5+/wbk9evSIb3/723HSSSdF06ZNt/pzbAlFNQAAAAAAAEBGjj/++JgyZUpUVFTU6bqHH354zJ07d7PmfvTRR3HVVVfFww8/HDfeeGP06NGjTrOsj6IaAAAAAAAAyEuSJOsIjcqECRPqZd2ysrIa4x133DH23Xff6NmzZ7Rr1y5KS0tj4sSJ8dRTT+XnTp48Ob7zne/EfffdF507d66XXKspqgEAAAAAAAAagKKioujfv38MGDAgxo8fH2+88Uat1mvZsmUcc8wx8c1vfjN222239c654IIL4rzzzovXXnstIiJmzZoVv/zlL+O3v/1tre69KYpqAAAAAAAAgIycfPLJsccee8SAAQNil112ye9oHzFiRK2K6hNPPDFOOeWU6NSp00bnderUKW655ZY44YQT4t13342IiCeeeCLOO++8en0EeEG9rQwAAAAAAADARo0cOTKOPvro6NWrV50+dv28887bZEm9WsuWLePMM8+sce6f//xnnWVZH0U1AAAAAAAAQCN3wAEH1Bh/9NFH9Xo/j/4GAAAAAAAAPlN3m3r5HGndunWNcWlpab3ez45qAAAAAAAAgEZu5syZNcYdO3as1/spqgEAAAAAAAAauWeeeabGeK+99qrX+3n0NwAAAAAAANCozZ49O2bPnl2rNYqLi6O4uLiOEqWrvLw8/vSnP+XH7dq1i8GDB9frPRXVAAAAAAAAQKP24IMPxqhRo2q1xvDhw+Oss86qo0Tp+s1vfhMff/xxfvz9738/mjVrVq/3VFQDAAAAAAAAeUmSZB2BFD377LMxevTo/HjXXXeNb3/72/V+X++oBgAAAAAAAGiEpkyZEhdccEHkcrmIiGjevHlcd9119b6bOsKOagAAAAAAAKCRO+6442r9TubP2/upZ86cGd/73vdi+fLlERFRUFAQV199dfTp0yeV+yuqAQAAAAAAgEatuLj4c1c018a8efPitNNOi7lz5+bP/fSnP41hw4allsGjvwEAAAAAAAAaiUWLFsVpp50WH374Yf7ceeedFyeeeGKqOeyoBgAAAAAAAPKSJMk6AvVk2bJl8f/+3/+LqVOn5s+dfvrp8f3vfz/1LHZUAwAAAAAAAGzjysrK4gc/+EFMmDAhf+7kk0+Oc845J5M8imoAAAAAAACAbdjKlStj+PDhMW7cuPy5Y489Ni655JLMMimqAQAAAAAAALZRlZWVcc4558SLL76YP/fVr341rrzyykwf8+4d1QAAAAAAAECeV1RvO3K5XPzkJz+JZ555Jn/uS1/6UlxzzTXRpEmTDJPZUQ0AAAAAAACwTbrsssvib3/7W348ePDguOGGG6Jp06YZplpFUQ0AAAAAAACwjbn22mvjT3/6U348aNCguPnmm6N58+YZpvqMR38DAAAAAAAAZGT06NFx1113rXN+wYIFNcZDhw5dZ07Xrl3Xe+3HH38ct956a41zM2fOjKOOOmqzc21o7bqiqAYAAAAAAADIyOLFi2PGjBmbnLe+OVVVVeudu77zc+fO3aJcG1q7riiqAQAAAAAAgLwkSbKOQCOgqAYAAAAAAADIyFlnnRVnnXVWna7ZvXv3KCkpqdM161pB1gEAAAAAAAAAaFwU1QAAAAAAAACkSlENAAAAAAAAQKq8oxoAAAAAAADIS5KsE9AY2FENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkqjDrAAAAAAAAAEDDkSRJ1hFoBOyoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUlWYdQAAAAAAAACg4UiSrBPQGNhRDQAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqvKMaAAAAAAAAyCso8JJq6p8d1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoKsw4AAAAAAAAANBxJknUCGgM7qgEAAAAAAABIlaIaAAAAAAAAgFQpqgEAAAAAAABIlaIaAAAAAAAAgFQVZh0AAAAAAAAAaDiSJMk6Ao2AHdUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqCrMOAAAAAAAAADQcSZJ1AhoDO6oBAAAAAAAASJWiGgAAAAAAAIBUKaoBAAAAAAAASJWiGgAAAAAAAIBUFWYdAAAAAAAAAGg4kiTJOgKNgB3VAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqgqzDgAAAAAAAAA0HEmSZB2BRsCOagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABS5R3VAAAAAAAAQJ5XVJMGO6oBAAAAAAAASJWiGgAAAAAAAIBUKaoBAAAAAAAASJWiGgAAAAAAAIBUFWYdAAAAAAAAAGg4kiTJOgKNgB3VAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqgqzDgAAAAAAAAA0HEmSdQIaAzuqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVBVmHQAAAAAAAABoOJIkyToCjYAd1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoKsw4AAAAAAAAANBxJknUCGgM7qgEAAAAAAABIlaIaAAAAAAAAgFQpqgEAAAAAAABIlXdUAwAAAAAAAHmJl1STAjuqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVBVmHQAAAAAAAABoOJIk6wQ0BnZUAwAAAAAAAJAqRTUAAAAAAAAAqVJUAwAAAAAAAJAqRTUAAAAAAAAAqSrMOgAAAAAAAADQcCRJknUEGgE7qgEAAAAAAABIlaIaAAAAAAAAgFQpqgEAAAAAAABIlaIaAAAAAAAAgFQVZh0AAAAAAAAAaDiSJOsENAaKamggfveHC7OOAABsoaIW/nUaAAAAALZGg/kvaxUVFfHOO+/E+++/H0uWLIlly5ZFdXX1Fq0xfPjwekoHAAAAAAAAQF3JvKh+++23449//GM888wzUVFRUau1FNUAAAAAAAAADV9mRXUul4vrr78+brvttsjlcpHL5dY7L1njIfjrm5MkSeRyuRrzAAAAAAAAAGi4Miuqf/3rX8cf//jH9ZbMGyun1/7ehgpuAAAAAAAAYMvZIEoaMimqX3vttbjjjjsiSZJIkiSaNm0aJ510Uhx22GFRXV0dp5xySkSs+kPw7LPPxvLly2P+/Pnx5ptvxqOPPhrvv/9+JEkS7du3j5///Oex++67Z/ExAAAAAAAAANgKmRTVt9xyS0Ss2hHdsmXLuOOOO+ILX/hCRETMmjWrxtwddtghIiL69u0bBx54YJx55pnx0EMPxZVXXhkLFy6Miy66KEaNGhVDhgxJ9TMAAAAAAAAAsHUK0r7hsmXL4tVXX83vpv7hD3+YL6k319FHHx233357tGzZMsrKyuLss89ep+AGAAAAAAAAoGFKvah+4403orq6OnK5XDRt2jT+8z//c6vW2XPPPePss8+OiIjS0tIYNWpUXcYEAAAAAACARilJGt8X6Uu9qP74448jYtX7p3fdddcoKira6PyKiooNfu/EE0+Mli1bRi6Xi6eeeipWrFhRp1kBAAAAAAAAqHupF9WLFi3KH3fr1m2d7zdt2rTGeGPlc/PmzWPPPfeMiFW7qseNG1c3IQEAAAAAAACoN6kX1Wtq0aLFOudat25dY7xgwYKNrtGxY8f88SeffFI3wQAAAAAAAACoN6kX1W3atMkfL1u2bJ3vt27dusau6o8++mij661cuTJ/PH/+/DpICAAAAAAAAEB9Sr2o7tGjR/543rx5652zyy675I/feOONja43adKk/PH6dmgDAAAAAAAAmy9Jkkb3RfpSL6p79+4dERG5XC6mTZsWuVxunTkDBgzIz3n44YejsrJyvWuNHTs2Zs+enR8XFxfXQ2IAAAAAAAAA6lLqRXWXLl3yu6rLy8vj7bffXmfOV77ylYhY9dsas2bNihEjRkR5eXmNOePGjYuLL744/xsOTZo0iX333bee0wMAAAAAAABQW4VZ3HTIkCFx3333RcSqXdF77bVXje8feOCB0adPn5g2bVpERDz22GPxz3/+MwYNGhRFRUXxwQcfxKRJk/K7sZMkia997Wux/fbbp/tBAAAAAAAAANhiqe+ojoj42te+FhGrHu394IMPRkVFRc1QBQVx+eWXR9OmTfPnlixZEv/4xz/isccey5fUq3dTd+rUKS688ML0PgAAAAAAAAAAWy2THdX77LNP/OIXv4jq6uqIWFVCd+jQocacgQMHxqhRo+LCCy+MRYsWrXedXC4XO+20U/zP//zPOtcDAAAAAAAAW+7/9opCvcqkqE6SJI477rhNzjvooIPiySefjHvuuSf++c9/xocffhhLly6NNm3aRN++feOII46I4447Lpo1a5ZCagAAAAAAAADqQiZF9ZbYfvvt48wzz4wzzzwz6ygAAAAAAAAA1IFM3lENAAAAAAAAQOOV+o7qyZMnx8MPP5wfn3baadGlS5e0YwAAAAAAAACQkdSL6tdffz3uvPPOSJIkOnfuHCNGjEg7AgAAAAAAALABSZJkHYFGIPVHf69cuTJ/3LdvXz/oAAAAAAAAAI1M6kV1p06d8sdt2rRJ+/YAAAAAAAAAZCz1orpr167544ULF6Z9ewAAAAAAAAAylnpRvffee0ebNm0il8vF22+/HZWVlWlHAAAAAAAAACBDqRfVzZo1i2HDhkVExPLly2PMmDFpRwAAAAAAAAA2IEmSRvdF+lIvqiMizjvvvCguLo5cLhfXXHNNvPPOO1nEAAAAAAAAACADmRTV2223Xdx8883RrVu3WLp0aZx00klx5513Rnl5eRZxAAAAAAAAAEhRksvlcmnf9KGHHoqIiE8//TRGjRoVpaWlkSRJtGrVKg444IDYbbfdol27dtG6destWvfoo4+u+7CQktv/NSPrCADAFvpSz85ZRwAAtlC3ti2yjgAAbKEWhVknaHwO+s1LWUdI3T/PHZJ1hEYnkz/aI0aMqPGs9yRJIpfLxfLly2Ps2LExduzYrVpXUQ0AAAAAAADQ8GX6Oyi5XC5fWK/vJeWbs9l7dcntJecAAAAAAABQe2o30pBZUb26hK7tk8czeHI5AAAAAAAAALWQSVE9evToLG4LAAAAAAAAQAOQSVG93377ZXFbAAAAAAAAABqATN9RDQAAAAAAADQsiZdUkwJFNQAAAAAAAEAjMXXq1CgpKYlPPvkkmjVrFl26dImBAwdG586dU82hqAYAAAAAAADI0MqVK6OkpCQmTpwYEyZMiAkTJsR7770XVVVV+TklJSW1usczzzwTN910U0yZMmWd7zVp0iQGDx4cI0aMiD59+tTqPptLUQ0AAAAAAACQkeOPPz6mTJkSFRUV9XaPyy+/PO65554Nfr+qqipefPHFOO644+Lyyy+Po48+ut6yrKaoBgAAAAAAAMjIhAkT6nX9m266qUZJ3apVq/jGN74Ru+66a6xYsSLGjRsXY8eOjerq6lixYkVccskl0aVLlxg8eHC95qrzovqhhx5a59zajfv65tSFNJp9AAAAAAAA2JYlSdYJGq+ioqLo379/DBgwIMaPHx9vvPFGrdZ76623YtSoUfnxrrvuGrfeemt06dIlf+673/1ujBs3Ls4444xYsmRJVFZWxnnnnRdPP/10tG7dulb335g6L6pHjBgRyVo/vWsXyOubUxcU1QAAAAAAAMDnycknnxx77LFHDBgwIHbZZZd8jzpixIhaF9XXX399/rhVq1bx+9//vkZJvdo+++wTV155ZZx99tkREbFgwYIYPXp0nHHGGbW6/8YU1NvKEZHL5Tb5/dp+bc59AAAAAAAAABqikSNHxtFHHx29evWq082+06ZNi1deeSU/PuWUU6K4uHiD84844ogYNGhQfnz33XdHdXV1neVZW70U1WuWyBubU1f3AgAAAAAAAOAzzzzzTI3xCSecsMlrjj/++Pzx/Pnz46233qrzXKvV+aO/R48eXSdzAAAAAAAAANg6//jHP/LHO+20U3Tv3n2T1wwZMmSdNQYOHFjn2SLqoajeb7/96mQOAAAAAAAAkL66fPw02Zk6dWr+eK+99tqsa7p27Rpdu3aNOXPmrLNGXavXd1QDAAAAAAAAkK5PPvkkli1blh/vtNNOm33tjjvumD9+77336jTXmhTVAAAAAAAAANuQmTNn1hh369Zts6/t2rVr/njWrFl1lmltdf7obwAAAAAAAIDPk9mzZ8fs2bNrtUZxcXEUFxfXUaLaWXM3dUTE9ttvv9nXrjm3oqIiVqxYEc2bN6+zbKspqgEAAAAAAIBG7cEHH4xRo0bVao3hw4fHWWedVUeJaqe0tLTGuFmzZpt97dql9PLly7ftonrOnDnxwgsvxPjx42PmzJmxePHi/P8Bn3nmmXXmV1dXR2VlZUREFBQURGFhg/koAAAAAAAA8LmVJFknoLZWrFhRY9y0adPNvnbtUnvttepK5u3uhx9+GNdff30888wzUVVVlT+fy+UiIiLZwJ+Exx9/PC644IKIiNhuu+3ihRdeqJcmHwAAAAAAAODzZO3etKKiYrOvXbly5UbXqiuZFtV/+9vf4uc//3mUlZVFLpeLJElqFNSrj9fnq1/9alx77bUxZ86cWLp0aTz55JPxjW98I63oAAAAAAAAwDbiuOOOi8GDB9dqjYbyfuqIiFatWtUYr10+b8zaO6hbt25dJ5nWlllR/dhjj8VFF12UL6gjVu2iLi4uju233z7eeeedjV7fpEmTOPLII+O2226LiFWPB1dUAwAAAAAAAFuquLi4QRXNtVVUVFRjvHjx4s2+dsmSJfnjpk2b1tuO6oJ6WXUTZs2aFT/5yU8iYtXO6YKCgjjttNPiueeei7Fjx8ZNN920WesMHTo0IlYV3K+99tpGd2ADAAAAAAAANAbdu3evMf744483+9o15+6www51lmltmeyovv766/Pby5s1axa33HJLja30G3ov9dr22GOPaNasWaxcuTKWLFkSH3zwQfTs2bNeMgMAAAAAAEBjULCZXR0NV5cuXaKoqCiWLVsWEREzZszY7GvXnLvLLrvUebbVUt9RvWLFinj66acjSZJIkiTOPffcrX7ee5MmTaJ379758XvvvVdXMQEAAAAAAAA+t/r27Zs/fvPNNzfrmjlz5sScOXPWu0ZdS72oHjduXKxYsSJyuVy0atUqTjrppFqt17lz5/zx3LlzaxsPAAAAAAAA4HPvoIMOyh9/+OGHMXPmzE1e89JLL9UYH3zwwXWea7XUi+rZs2dHxKrHe++1117RtGnTWq235ovAV29dBwAAAAAAAGjMDj/88Brjv/zlL5u85oEHHsgfd+jQIb7whS/Uday81IvqhQsX5o87dOhQ6/UqKyvzxwUFqX8cAAAAAAAA2KYkSeP72hb16dMn9t9///x49OjR+U3F6/Pkk0/G+PHj8+OTTjqpXvvX1JvdVq1a5Y9LS0trvd6CBQvyx23btq31egAAAAAAAADbgnPPPTd/XFpaGmecccZ6X6c8bty4GDlyZH7cvn37OPXUU+s1W2G9rr4e7du3zx9/8MEHtVqruro6Jk+enB936tSpVusBAAAAAAAApGn06NFx1113rXN+zQ27ERFDhw5dZ07Xrl3Xe+1qX/jCF+L000+P3//+9xERMWXKlPjKV74SRx11VPTt2zdWrFgR48aNi2effTaqq6sjIqJJkybx61//Olq3bl2bj7VJqRfVu+22W0RE5HK5eP/992PWrFmxww47bNVaL730UixfvjwiVj32e9CgQXWWEwAAAAAAAKC+LV68OGbMmLHJeeubU1VVtcnrfvzjH8eiRYvivvvui4iI5cuXx7333rveuc2aNYvLLrssvvjFL25y3dpK/dHfPXv2jO7du+fHq9v7LVVdXR2/+93vIiIiSZLYfffdY7vttquTjAAAAAAAAADbgiRJ4rLLLotRo0ZF37591zunoKAghgwZEg8++GAce+yxqeRKfUd1RMQJJ5wQ119/feRyuXjggQdi4MCBW/yBr7766njzzTfz45NPPrmOUwIAAAAAAEDjkyRJ1hEalbPOOivOOuuser/P0KFDY+jQoVFSUhIlJSUxd+7caNq0aXTp0iUGDhwYXbp0qfcMa8qkqD711FPj7rvvjvnz50cul4tLLrkkJk2aFD/84Q9rvMN6fd5777245ppr4h//+Ef+D0mvXr3iyCOPTCM6AAAAAAAAwOfWrrvuGrvuumvWMbIpqps3bx433HBDfPe7342VK1dGLpeLe++9N+6///7Ye++9o7i4uMb86667LhYuXBhvvfVWTJs2LSJWveM6IqJ169Zxww03+M0OAAAAAAAAgM+JTIrqiIhBgwbF9ddfH+eff36UlZVFRERlZWW8/vrrNeblcrm47bbb8scRnz1uoKioKG644Ybo1atXiskBAAAAAAAAqI2CLG9+6KGHxpgxY2LPPffMl9CrJUmS/1rzXMSqwrp///7x5z//OYYMGZJqZgAAAAAAAABqJ7Md1avtvPPOcf/998err74a9913X7z++uvx6aefrnduy5YtY7/99otvfetbceihh6acFAAAAAAAALZ9Bd64SwoyL6pXO+CAA+KAAw6IiIgPPvgg5syZE4sXL47KysrYfvvto0OHDtGnT58oLGwwkQEAAAAAAADYCg2y9d15551j5513zjoGAAAAAAAAAPUg03dUAwAAAAAAAND4KKoBAAAAAAAASFWDfPQ3AAAAAAAAkI0kSbKOQCNgRzUAAAAAAAAAqarzHdWnnHJKXS+5WZIkiTvvvDOTewMAAAAAAACw+eq8qH799ddTfxxALpfzCAIAAAAAAACAz4lM31Gdy+VqjDe3bF77OgAAAAAAAAA+P+q8qC4uLt6i+QsXLozy8vKIqFlAt2jRIoqKiiIiYtmyZfk5EZ8V2i1btoy2bdvWMjEAAAAAAACwmgcZk4Y6L6rHjh272XNvueWWuOmmmyKXy0VhYWEcccQRMWzYsBgwYEB07ty5xty5c+fGhAkT4vHHH48nn3wyKisro6KiIr75zW/G6aefXtcfAwAAAAAAAIB6ktmjv6+44oq49957IyJi9913j1//+tfRq1evDc7v3LlzHHbYYXHYYYfFmWeeGRdccEFMnjw5brjhhpgzZ078/Oc/Tyk5AAAAAAAAALVRkMVNH3/88bjnnnsil8vFbrvtFqNHj95oSb22Xr16xd133x277bZb5HK5uP/+++Oxxx6rx8QAAAAAAAAA1JVMiurbbrstIla9a/qKK66I1q1bb/EarVq1issvvzw/vvXWW+ssHwAAAAAAADRWSSP8H9KXelE9derUmDx5ciRJEr169Yrdd999q9caMGBA9O7dO3K5XJSUlERJSUkdJgUAAAAAAACgPqReVE+bNi1/vMsuu9R6vTXXWHNtAAAAAAAAABqm1IvqOXPm1Nvan3zySb2tDQAAAAAAAEDdSL2oLiwszB9Pnz691uutuUaTJk1qvR4AAAAAAAAA9atw01PqVteuXSMiIpfLxbRp02LKlCnRr1+/rVrrnXfeiXfffXedtQEAAAAAAICtU5BknYDGIPUd1fvtt18UFhZGkiSRy+Vi5MiRUV5evsXrlJWVxciRI/PjJk2axP7771+XUQEAAAAAAACoB6kX1W3bto1DDz00crlcJEkSkyZNilNPPTVmzJix2Wt8+OGHceqpp8akSZMiSZJIkiQOO+ywaNu2bf0FBwAAAAAAAKBOpP7o74iIiy++OF566aUoLS2NiIg333wzjjzyyBg2bFh85StfiQEDBkSHDh1qXLNgwYKYMGFCPPHEE/HEE09ERUVFfld2UVFR/OQnP8niowAAAAAAAACwhTIpqrt27Ro33nhj/PCHP4wVK1ZEkiSxcuXKePjhh+Phhx+OiIgWLVpEUVFRREQsW7asxuPBV+/GzuVy0aJFi7jxxhu9nxoAAAAAAADgcyL1R3+vNmTIkLj99ttjhx12yBfPEatK6FwuF2VlZTFv3ryYN29elJWV5c9HRL6k7tGjR9x+++1x4IEHZvUxAAAAAAAAYJuy+tW7jemL9GVWVEdEDBo0KB599NEYPnx4dOzYMV9Er7a+H4xcLhcdO3aM4cOHxyOPPBKDBg1KMzIAAAAAAAAAtZTJo7/X1KJFixg+fHicccYZ8eqrr8Ybb7wRkydPjgULFsSSJUsiIqJNmzbRoUOH6N+/fwwcODAOOOCAaNKkScbJAQAAAAAAANgamRfVqzVp0iSGDBkSQ4YMyToKAAAAAAAAAPUo00d/AwAAAAAAAND4NJgd1QAAAAAAAED2kiTrBDQGdlQDAAAAAAAAkCpFNQAAAAAAAACpalCP/s7lcjFnzpxYvHhxLFu2LHK53BZdv++++9ZTMgAAAAAAAADqSuZFdXl5eTz00EPx+OOPx8SJE6OsrGyr1kmSJCZPnlzH6QAAAAAAAACoa5kW1S+88EKMGDEiPv3004iILd5BDQAAAAAAANStgiTJOgKNQGZF9WOPPRYXXHBBVFdXr/O9ZI0f/rXL6419DwAAAAAAAICGL5Oi+sMPP4xLLrkkqqurI0mSyOVy0b9//zjssMOiWbNmcd1110XEqlL6qquuiuXLl8e8efPirbfeinHjxkVlZWUkSRLt27ePM844I4qKirL4GAAAAAAAAABshUyK6ltuuSXKy8vz4xEjRsSpp54aERGzZs3KF9UREcccc0yNaz/55JP47W9/G3/9619j4cKFcffdd8ftt98eO+ywQyrZAQAAAAAAAKidgrRvWFFREY8//ngkSRJJksQJJ5yQL6k3R5cuXeKqq66Kn/3sZ5HL5WLGjBnxve99L8rKyuovNAAAAAAAAAB1JvWiesKECVFeXh65XC6SJIkf/OAHW7XOiSeeGN/61rcil8vF9OnT4w9/+EMdJwUAAAAAAIDGJ0ka3xfpS72o/uCDDyJi1fund955500+sruqqmqD3zv77LOjoGDVRxgzZkydZQQAAAAAAACg/qReVC9evDh/3LNnz3W+36RJkxrjlStXbnCtDh06xB577BG5XC7mzp0bb775Zp3lBAAAAAAAAKB+pF5Ur1k8t27dep3vt2rVqsZ44cKFG12vuLg4f/zRRx/VMh0AAAAAAAAA9a0w7RuuWU6Xl5ev8/2ioqJIkiRyuVxERHz88cc1yui1rX70d0TEvHnz6jApAAAAAAAAND6JlzaTgtR3VHft2jV/vL7d0gUFBdGjR4/8eOLEiRtdb/r06XUXDgAAAAAAAIB6l3pRvcsuu0RERC6Xi3fffXe9c/r165c/fuKJJza41rvvvhvvvPNO/rc6OnbsWIdJAQAAAAAAAKgPmRTVbdu2jYiIxYsXx4wZM9aZc9hhh0XEqjL7rbfeinvuuWedOYsXL46LLrooPy8iYtCgQfWUGgAAAAAAAIC6knpRHRFxwAEH5I+fe+65db4/dOjQaNeuXf5d1VdeeWX893//d9xxxx3xl7/8JX7961/HsGHD8rupkySJffbZJ7p3757mxwAAAAAAAABgKxRmcdMjjjgi/v73v0cul4sxY8bEd77znRrfb9WqVVxwwQVx8cUX58vql19+OV5++eX8nFwul/9es2bN8rurAQAAAAAAgK33f2/dhXqVSVF96KGHxlFHHRXV1dURETFnzpzo2rVrjTnHHntszJw5M26++eb8O6jXtLqkbt68efzqV7+KPfbYI5XsAAAAAAAAANROJkX16nJ5U84+++w44IAD4uabb45x48ZFZWVl/nstW7aMQw45JIYPHx69evWqz7gAAAAAAAAA1KFMiuotsd9++8V+++0XpaWlMXv27Fi6dGm0adMmevToEc2aNcs6HgAAAAAAAABbqMEX1au1atUqevfunXUMAAAAAAAAAGrpc1NUAwAAAAAAAPWvIEmyjkAjUJB1AAAAAAAAAAAaF0U1AAAAAAAAAKlSVAMAAAAAAACQqjp/R/Upp5xS10tuliRJ4s4778zk3gAAAAAAAABsvjovql9//fVIUn7Bei6XS/2eAAAAAAAAsC3SupGGOi+qt0Qul6sx3tyyee3rAAAAAAAAAPj8qPOiuri4eIvmL1y4MMrLyyOiZgHdokWLKCoqioiIZcuW5edEfFZot2zZMtq2bVvLxAAAAAAAAACkqc6L6rFjx2723FtuuSVuuummyOVyUVhYGEcccUQMGzYsBgwYEJ07d64xd+7cuTFhwoR4/PHH48knn4zKysqoqKiIb37zm3H66afX9ccAAAAAAAAAoJ5k9ujvK664Iu69996IiNh9993j17/+dfTq1WuD8zt37hyHHXZYHHbYYXHmmWfGBRdcEJMnT44bbrgh5syZEz//+c9TSg4AAAAAAABAbRRkcdPHH3887rnnnsjlcrHbbrvF6NGjN1pSr61Xr15x9913x2677Ra5XC7uv//+eOyxx+oxMQAAAAAAADQOSZI0ui/Sl0lRfdttt0XEqh/yK664Ilq3br3Fa7Rq1Souv/zy/PjWW2+ts3wAAAAAAAAA1J/Ui+qpU6fG5MmTI0mS6NWrV+y+++5bvdaAAQOid+/ekcvloqSkJEpKSuowKQAAAAAAAAD1IfWietq0afnjXXbZpdbrrbnGmmsDAAAAAAAA0DAVpn3DOXPm1Nvan3zySb2tDQAAAAAAAI1BgVc2k4LUd1QXFn7WjU+fPr3W6625RpMmTWq9HgAAAAAAAAD1K/WiumvXrhERkcvlYtq0aTFlypStXuudd96Jd999d521AQAAAAAAAGi4Ui+q99tvvygsLIwkSSKXy8XIkSOjvLx8i9cpKyuLkSNH5sdNmjSJ/fffvy6jAgAAAAAAAFAPUi+q27ZtG4ceemjkcrlIkiQmTZoUp556asyYMWOz1/jwww/j1FNPjUmTJkWSJJEkSRx22GHRtm3b+gsOAAAAAAAAQJ0o3PSUunfxxRfHSy+9FKWlpRER8eabb8aRRx4Zw4YNi6985SsxYMCA6NChQ41rFixYEBMmTIgnnnginnjiiaioqMjvyi4qKoqf/OQnWXwUAAAAAAAA2KYkSZJ1BBqBTIrqrl27xo033hg//OEPY8WKFZEkSaxcuTIefvjhePjhhyMiokWLFlFUVBQREcuWLavxePDVu7FzuVy0aNEibrzxRu+nBgAAAAAAAPicSP3R36sNGTIkbr/99thhhx3yxXPEqhI6l8tFWVlZzJs3L+bNmxdlZWX58xGRL6l79OgRt99+exx44IFZfQwAAAAAAAAAtlBmRXVExKBBg+LRRx+N4cOHR8eOHfNF9Gqr3z+9plwuFx07dozhw4fHI488EoMGDUozMgAAAAAAAAC1lMmjv9fUokWLGD58eJxxxhnx6quvxhtvvBGTJ0+OBQsWxJIlSyIiok2bNtGhQ4fo379/DBw4MA444IBo0qRJxskBAAAAAAAA2BqZF9WrNWnSJIYMGRJDhgzJOgoAAAAAAAA0Wms98BjqRepF9eTJk+Phhx/Oj0877bTo0qVL2jEAAAAAAAAAyEjqRfXrr78ed955ZyRJEp07d44RI0akHQEAAAAAAACADBWkfcOVK1fmj/v27RuJZwcAAAAAAAAANCqpF9WdOnXKH7dp0ybt2wMAAAAAAACQsdQf/d21a9f88cKFC9O+PQAAAAAAALARnohMGlLfUb333ntHmzZtIpfLxdtvvx2VlZVpRwAAAAAAAAAgQ6kX1c2aNYthw4ZFRMTy5ctjzJgxaUcAAAAAAAAAIEOpF9UREeedd14UFxdHLpeLa665Jt55550sYgAAAAAAAACQgUyK6u222y5uvvnm6NatWyxdujROOumkuPPOO6O8vDyLOAAAAAAAAACkKMnlcrm0b/rQQw9FRMSnn34ao0aNitLS0kiSJFq1ahUHHHBA7LbbbtGuXbto3br1Fq179NFH131YSMnt/5qRdQQAYAt9qWfnrCMAAFuoW9sWWUcAALZQi8KsEzQ+p/7p7awjpO6PJ+6ZdYRGJ5M/2iNGjIgkSfLjJEkil8vF8uXLY+zYsTF27NitWldRDQAAAAAAANDwZfo7KLlcLl9Yr1lcr/n9TVldcq/vegAAAAAAAAAansyK6tUldG2fPJ7Bk8sBAAAAAAAAqIVMiurRo0dncVsAAAAAAABgEzzJmDRkUlTvt99+WdwWAAAAAAAAgAagIOsAAAAAAAAAADQuimoAAAAAAAAAUqWoBgAAAAAAACBVmbyjGgAAAAAAAGiYkqwD0Cg0mKL6zTffjOeeey7Gjx8fs2bNisWLF0dpaWkkSRKTJ09eZ/6nn34aixcvjoiI5s2bR3FxcdqRAQAAAAAAANgKmRfV//73v+Pqq6+OiRMn5s/lcrlNXvf222/HGWecERERLVq0iBdeeCGKiorqLScAAAAAAAAAdSPTd1T//ve/j1NOOSUmTpyYL6dX/+8k2fhDBQ455JDYaaedIpfLRXl5eTz66KP1nhcAAAAAAACA2susqL7jjjvit7/9bVRVVeXPtWjRIvbdd9845JBDNmtX9ZFHHpk/Hjt2bL3kBAAAAAAAAKBuZfLo75KSkrjmmmvyu6ZbtmwZ5513XpxwwgnRrFmzmDVrVjz//PObXGfo0KExatSoyOVy8a9//SsqKyujsDDzp5kDAAAAAADA51bBJp58DHUhk1b3+uuvj+rq6oiIaNOmTdx9993Rt2/fLV6nb9++0bJlyygrK4vy8vKYPn169OnTp67jAgAAAAAAAFCHUn/097Jly+LFF1+MJEkiSZK4+OKLt6qkjlj1Hus1i+n333+/rmICAAAAAAAAUE9SL6rHjRsXlZWVkcvlYvvtt4+jjjqqVut16NAhfzx//vzaxgMAAAAA/j979x0nZXWoD/wZelORIoIFCyr2rtdeE40lttgVS34aY5TE3rtRY0RjS6LmamKiSYyomGhixa4YWxRU7IqiNClSFliY3x9cJ6502JlZ2O/3fvhkzrvnfeeZG3EDz55zAACgzCpeVH/xxRdJZqyGXm+99UrnVC+odu3alV5PmDBhoZ4FAAAAAAAAQPlV/IzqsWPHll4vtdRSC/28yZMnl143a1aVI7cBAAAAAABgsbGQ60xhnlR8RfUSSyxRej1+/PiFft6IESNKr9u3b7/QzwMAAAAAAACgvCpeVH/zTOn33ntvoZ41derUvPXWW6Vx165dF+p5AAAAAAAAAJRfxYvqddddN0lSLBbz6aef5t13313gZz366KOpqalJMmPb7w033LBeMgIAAAAAAABQPhUvqrt165YePXqUxtdee+0CPWfy5Mm58cYbkySFQiEbbbRRWrVqVS8ZAQAAAAAAACifihfVSXLooYeWXj/22GO54YYb5uv+qVOn5swzz6yzdfhRRx1Vb/kAAAAAAACgsSoUCo3uF5VXlaL6gAMOyMorr5xkxhbgN954Y4477rg6503PSrFYzFNPPZUDDzww//rXv0r/4Gy44YbZfvvtK5AcAAAAAAAAgIXVrBpv2rRp09x44405+OCDM27cuBSLxTz55JN58skns9xyy2XFFVesM//kk0/O6NGjM2jQoHz11Vel68ViMZ06dco111xT6Y8AAAAAAAAAwAKqyorqJFlllVVyyy23pHPnzqVrxWIxn376aZ5//vk61/75z3/mhRdeKJXaX1/v2rVrbrnllnTp0qXi+QEAAAAAAABYMFVZUf219dZbL/fff38uvvji/Otf/yqV0ElmuRd8oVAozfnOd76Tiy66KB06dKhYXgCYX5MnTsjQ99/K6C8+S83E8WnSpGlatVsySy/TNct0XzWt2y1Z7YgAAACwyKqtrc1/Xns1Qz/7LCNGDE+7du2yTJdls/4GG2Tppf3dMQA0ZFUtqpOkffv2ufrqq3PSSSflL3/5SwYMGJC33nor06ZNm2nuSiutlC233DIHHHBAevbsWYW0ADBvhrz9egY88Ld8+Pq/M30W39OSJIVCOi3XPatttEW2PeDoygYEAEpqJk3Mxx++nyEff5SxY0dn6uQpadOuXTp06JTV11w7yyzbtdoRAYBvmTRpUm7+7a/T7957MmrUyJm+3qxZ82y9zTY5offPstrqa1QhIcCibRbrSaHeFYrfXMbcQNTU1GTEiBEZO3Zsamtrs9RSS6Vjx45Zckmrzlh83frvT6odAagHU2om5ZHfX5+Bzzwyz/c0bd48p972YBlTAeWyw8rLVDsCsIA+fP/dPNP/kbz84vN55+1Bs//BsiTLrbBi9tzvoOy6575p1ap1BVMC5dC1fatqRwAW0nvvvZtTT+qdDz/4YK5zW7ZsmVPPOCsHHHhwBZIB5dKq6ssuG58f3T2o2hEq7qYfrF3tCI1Og/yt3apVq6ywwgpZYYUVqh1lkTFgwID06tWrNB48eHAV0wA0TpPGj8tdvzgzX3z4bp3rLVq1zjLde6TtUkvPmPfV2Awf8kFqxn9VjZgA0Oj97NjD8/ag1+d5/mdDPslvf3Vl/nHPXTnjgsuzWs+1ypgOAJiTESOG58fH/jDDhw2rc32ttdfO8suvkDFjxmTQwDcyYcKEJMnkyZPz84svTLu27bLbHntWITEAMDsNsqiG+jBt2rR8+OGHeeeddzJ8+PBMmjQp7dq1S6dOnbL++uunW7du1Y4ILEam1dbmnqsvqFNSt1+ma7Y76P+lx4b/k2bNW8x0z7CP38vgF5/Om889XsmoANDoDf105t2MmjRtmpVX6ZGOnZdJ27ZLZOzY0XnnrYEZ/9V/f7Ds008+yhkn/r9ccd0tWX1NP2kPAJVWLBZzys961ympV1t99Vx2xS+z+hr/PSpy3LhxufH6a/OXO/9Uunbh+edk9Z4906PHahXNDADMXlWK6vfeey89evSoxlsvsHvuuSdnnXXWAt9vhXNljB8/Po8++mgee+yxvPDCCxk3btxs566xxho58sgjs88++6TgsAVgIb34wF359J2BpfHK626SfU66MM1btJztPV2690iX7j2y9b69ZjsHACifpk2bZfOttsl3dts762+0adq0bVvn69Nqa/Pov/6em6/vkwn/txPKxIkTctGZP83v/nx/WrdpU43YANBoPfbIw/nPa6+Wxsstv3xu/f2fsuRSS9WZt+SSS+asc85LkyaF3PmnPyaZsbL6xuuvzTXX3lDRzACLqiZ6EyqgKkX1HnvskXXXXTd777139thjjyz1rf8hAQti/Pjx2XLLLTN58uR5mj948OCcddZZuf/++3PNNddk6aWXLnNCYHE1Zvjnea7fnaVx5xVWzr4nXZRmLWZeRT0rTZo2LVc0AGAWmjZrlu/ttV8OPepH6dS5yxzn7bLHPum59no55cdHlFZXjxo5In3/cnsOO/q4SkUGAJL89jd1S+azzz1/ppL6m3r/7JQ88fjjGTr0syTJ448+krffeis911yzrDkBYGENGzYsb7zxRj7//POMHz8+LVu2zNJLL52ePXtmtdVWS7Nmi8em2VX7FAMHDszAgQPzi1/8Ittvv3322WefbLvttmm6iPxl/TLLLJNWrVpVO0bJ5ptv3uhXbU+fPn2mkrpHjx7ZbLPNssIKK2SppZbKuHHj8uqrr+bxxx/P1KlTkyTPP/98fvjDH+ZPf/pT2lgRASyA5+//c2qn/PffPzv3+sk8l9QAQOVde/OfssyyXed5fveVV80Pjz851/7iotK1/g8/qKgGgAp6953Befedd0rjVVZZNVtvs90c72ndunV+cMBBue5XfUrX/vnA3xXVADRYDz30UG699da89tprs53ToUOH/OAHP8iPfvSjtGvXrnLhyqCqdXuxWMyUKVPyyCOP5JFHHkmHDh3y/e9/P3vttVd69uw59wdU0VVXXZXNN9+82jGYhfbt22f//ffP/vvvn+7du8/09aOOOiofffRRevfuXSr3Bw0alBtvvDGnnXZapeMCi7gpNZPy9gtPlsbLrLhKVlxz/SomAgDmZn5K6q/ttMvu+e21v8jkmpokyWdDPs7oL0dl6Q4d6zseADALTz7Rv854tz32nKf7dt9jzzpF9RNPPJ6TTj29XrMBwMKaOnVqTj/99Dz44INznfvll1/m5ptvzv3335+bbrqpwXeqc9KkGm+65557zrQauVgsZtSoUfn973+fffbZJ/vss09uv/32fPnll9WIyCKoadOmOe644/Loo4/m1FNPnWVJ/bWVVlopt912Wzp16lS69qc//SmTJk2qRFRgMfLOv5/JlJqJpXHP/9m+emEAgLJp0bJlll+h7p8xRo0cXqU0AND4PP/cs3XGG228yTzdt2zXrunWbbnS+KMPP8wXn39er9kAYGGdf/75dUrqJk2aZLvttsupp56ayy67LOeff34OPPDAOscpf/HFFznyyCMzfPii+2fTqqyo/uUvf5kJEybkX//6V/r165d///vfSZLC/x3MXiwW89Zbb+Xtt9/OlVdemW233Tb77LNPdthhh8Vmz/UkmTBhQgYPHpwPP/wwo0ePzrRp07LkkkumW7du2XjjjRfZ5fq1tbV599138/7772fkyJGZNGlSllhiiXTs2DEbbbRRunSZ/RlwC6Nt27Y56aST5nl+x44dc+SRR+aqq65KktTU1GTAgAHZfvvty5IPWDwNefv1OuNuPWwfBgCLqyZN6/55dFptbZWSAEDj8/7775VeN2nSJGutvc4837vu+uuXzqlOkvffezfLdp3/HVYAGpP/q+yogFdeeSX33HNPadyhQ4fcdNNNWW+99Waae+qpp+bUU0/Nk0/O2OVz9OjRueaaa3L55ZdXLG99qlrr27Zt2+y3337Zb7/9MnTo0Nx77725//778/HHHyf5b2ldW1ub/v37p3///llqqaWyxx57ZJ999snaa69dregLZcSIEfnHP/6Rhx56KG+88UZqZ/MXG02bNs2OO+6Y3r17Z/XVV5/rcwcMGJBevXqVxrM6r/qKK67IbbfdVhpff/31+e53vzvH506fPj1HHHFEXnzxxSRJq1at0rdv3/To0aPOvJqamjz88MN58MEH8+KLL2bChAmzfeY666yTE044ITvssMNcP1e5fXv79iFDhlQpCbCo+uLDd+qMOy+/UpIZW4K/9cITeeuFJ/Ll50MyceyYtGzTNu2W7pgV11w/a2y2TZZffd7/UA0AVFexWMywzz+rc629bb8BoCLGjR2b0d/YebNjx45p3br1PN+/3HLL1xl/9NGH2WqbbestHwAsjH79+tUZX3755bMsqZNkySWXzLXXXptdd901X3zxRZLkX//6Vy666KK0aNGi7FnrW1W2/v62bt265Sc/+Ukeeuih/PnPf84BBxyQJZZYIsVisTSnWCxmzJgxueOOO/KDH/wge+65Z2677baMHDmyisnn36233porrrgir7766mxL6iSZNm1aHnnkkfzgBz+Yp/3o58XJJ59cZ5/68847L8OGDZvjPbfcckuppE6S008/faaSOkmef/75nHbaaenfv/8cS+okGThwYI477rhcccUVdf47roa2bdvWGdv6G5gf02qnZuRnH5fGTZs1T5sl22fI22/kf888Jv/63dX5eOAr+WrUiEyrnZqJ48Zk+Mfv56V/3ZM7Lj4pf/vl2Rk3akQVPwEAMK8G/ueVjBs7pjRuv3SHLNPFSiwAqIQhQz6pM+6y7Px9D+7SZdk6408++WQ2MwGg8t58883S686dO89159/WrVtn9913L40nTpy4yC7EbHD7aG+44YbZcMMNc+655+bRRx9Nv3798uyzz6a2trbO1uDvvvturrzyyvTp0ydbbbVV9tlnn+y6665VTj9/ll9++Wy88cZZbbXV0r59+0yfPj1Dhw7Ns88+mzfeeCNJMnny5Jx++ulZccUVs846C7fyrkWLFunTp0/23XffTJ48OWPGjMkZZ5yR2267rfT/22964403cv3115fG22+/fQ499NC5vk/79u2z8cYbZ6211krHjh3TvHnzjBo1Kq+++mqeeuqpTJs2LUly2223pVu3bnVWglfap59+WmfcsaMVEcC8m/TVuEz/v3+nJUmLVq3z4Rsv5+6rzqlzfXY++M+/88cLe+eAMy4vrcQGABqmfnf/uc54sy23meWfowCA+jd+/Pg646U7dJiv+5fusPS3nvfVQmcCgPoyduzY0uvll19+DjP/a8UVV5ztMxYlDa6o/lqLFi2y2267ZbfddsuoUaNy//3357777ittaV0oFFIsFlNbW5snn3wyTz/99CJRVDdp0iR77LFHjjjiiNku2z/ppJPy5JNP5rTTTsvYsWMzderUXHTRRfnb3/620O/fo0ePnH766bnkkkuSzFgJfdttt+Xoo4+uM2/SpEk59dRTM3Xq1CQzCtzLLrtsjs/ecMMNc8wxx2TbbbdN8+bNZznnww8/zE9/+tPSf499+vTJnnvumaWXXnqW88vtscceqzPeYIMNqpIDWDTVTKz7B+VptbXpd/0lpZK666o9s8GOu6dL9x5p2rx5xg7/Im8PeDKDnn0sxeL0JMn40SNz768uzJGX/iYtWs37tmUAQOW8+tKAPNP/kdK4UChkrx8cUsVEANC4TJxYdwfHli1aztf9LVu2+tbzJi50JgCoL0suuWTp9bx+j/r2DsEd5vOHuBqKBrH199x07NgxRx11VPr165f77rsvRxxxRGnl6zdXWS8KevfunT59+sy2pP7adtttl2uvvbY0fv311zNw4MB6yXDYYYdl223/ewbL1VdfnbfffrvOnMsuuywfffRRnfGcVhtvueWW+ctf/pKddtpptiV1kqy88sq59dZbS79hampqcu+99y7gJ1k4w4cPz9///vfSePXVV8+qq65alSzAomnypLp/UJ5SMzGT/+8Pz/+z50E5/MLrst52u6bLSj3SabnuWXXDzbP7cafngDMuT/Nv/CF59Bef5em7f1/J6ADAPBo3dkz6/Py8Ote+s/teWXX1nrO5AwCob5Mm1v3L+BYt5+8MzpYt6xbb334eADMrFAqN7le1fHMR5fvvv58vv/xyrvcMGDCg9Lpz587p3r17OaKV3SJRVH9Tz549c/LJJ+fUU0+t2ircJOnVq1fWWGONuf7aa6+96tz37f9RNCdbbLFFNt9889L4mWeeqbf8l19+eal4njp1ak455ZTU1NQkSR599NHcddddpbmHHnroXPfDn5/P1alTpzpbiNfn55ofF198cZ2fTDnhhBOqkgNYdBWnz/qHpFbfZKtsd+APZ/s/blZaZ6N898jeda69/sQ/UzPB1mMA0JBMmzYtl59/RkYOH1a61mmZLjn2hFOqmAoAmN8y4dvzi1k0Fj0B0DgceOCBadq0aZKktrY2V1xxxRznP/3003niiSdK46OOOmqRPZpqkSqqX3rppZx77rnZaqutctZZZ2XMmDHVjlR2W2yxRen1oEGD6u25nTp1qrOV93vvvZcrr7wyw4cPz7nnnlu6/vVW4fWtXJ9rXv3xj3/MI4/8d+u+rbfeOrvsskvFcwCLthbf2jrsa9sd9P/meu8623wnnb5xLvWUmkl579UX6isaAFAPfnPNFXn1pf9+f27evHnOuugXabfEknO4CwCob63b1D0qa3LN5Pm6/+sFOl9r06bNQmcCgPqy2mqrpXfv/y5s6tevX4477ri88cYbdXaUHj58eG688cYcf/zxpevbbrttjjzyyEpHrjcN9ozqrw0ZMqS05fdnn32W5L/bfH99TnUyo3itpGWWWSatWs26oPimrl27LtT7fPNzDRs2bA4z59/222+fQw45JHfeeWeS5I477siAAQMyevToJDP+EqZPnz7z9Dnn1zc/15gxYzJ58uT5WpW9MJ599tk6P43SoUOHuf50CsCsNJ/FmdLLrrxaOiy7/Dzdv9aWO+apu24tjT8dPCjrbP2dessHACy4P//hlvzj3v/uNNWkSZOceu6lWXu9DauYCgAap9at6xbLk6fMX1E95VvzFdUAzMrQoUMzdOjQhXpGt27d0q1bt/m+77jjjku7du3Sp0+fTJw4Mf3790///v3Tpk2bLL300pk0aVKdLcFbtmyZXr16pXfv3qXV2IuiBllUT5gwIf/85z9z33335eWXX05St5z+WvPmzbPDDjtk3333zdZbb13RjFdddVWdbbnn16RJk/LYY4/l6aefzuDBg/PFF19kwoQJmTJlymzv+eqr+t8S9owzzsiAAQPy/vvvJ5mxsvprJ598cnr2nL9z16ZPn54BAwbk0UcfzZtvvpkhQ4Zk/PjxMx3q/m1fffVVRYrqgQMH5sQTT0xtbW2SGb+Rr7/++nTu3Lns7w0sflq2aTvTtWVXWWOe7+/6rblffj5koTMBAAvvwX535w8331Dn2vEnn5Xtdt61SokAoHFr165dnfGY/1toM69Gf+usz3btlljoTAAsfvr27Zsbbrhh7hPn4IQTTsiJJ564QPcedthh+d73vpdLLrkk//znP5MkEydOrHOMbZKsvPLKufTSS7PJJpssVNaGoMEU1cViMc8++2zuvffePP7446XtWIrFYukQ82KxmGKxmPXWWy9777139thjjyy55KK35dp9992XX/ziF/N0GPo3TZ48fz8pOC9atWqVPn36ZP/998/UqVNL17fYYoscddRR8/Ws119/Peedd17efvvt+c5Rjs/2be+//36OOeaYTJgwIUnSrFmzXHvttYvFb2SgOtossVRatmmXyRPHl661XarDPN/fdqml64ydUQ0A1ffU4w/nhqt+XufakceemD32OaBKiQCAFVZYsc74iy8+n6/7v/jii289b4WFzgSwuFukzg5eTDz88MPp06dPPvrooznO+/DDD3PYYYdl5513zgUXXLBIL8aselH9/vvv5957783999+fESNGJJl59XSxWMwyyyyTvfbaK3vvvXdWXXXVquVdWLfcckuuuuqqWX6tffv2adWqVVq0aFG6NmHChIwaNaqsmZo2bZomTer+K2fLLbecr4PXBwwYkGOPPXam816SpG3btmnbtm1atmxZeua0adNKW7knqbPHfjl8+umnOeqoo0o/HNCkSZP84he/yA477FDW9wUWfx2XWzFD332zNG7WrPk839u0ed25077xA0MAQOW9NODZ/PLiszN9+vTStf0OPiIHHfH/qpgKAFiqffss3aFDaWX0qJEjM2nSpLRuPfORXLPy2Wef1hmvvPIq9Z4RABbGNddck9/+9rel8QYbbJAjjjgiG2+8cTp06JCampoMHjw4//jHP/K3v/0ttbW1eeSRR/L666/njjvuWGR/CKsqRfWYMWPywAMP5N57782gQYOSzHpr75YtW2annXbKPvvsky233HKmMnVR8/bbb+eaa64pjTt16pRevXplm222SY8ePeoU1F/r27dvzj777LJlmjJlSk499dSZVjTfcMMN2WGHHbLaaqvN9Rk1NTU588wzSyV18+bNc9BBB+U73/lO1l577Zm25klmnD2+884718+HmIthw4blyCOPrHPG94UXXpg99tijIu8PLN46L79SnaJ68qQJ83zv5Al157ay9RgAVM2g11/NJWefXGenqV333DfHnHByFVMBAF9bddUeeenLF5PMOH7wzUEDs/Emm87TvW+8/p8641VW7VHv+QBY9O23337ZYostFuoZC3I+db9+/eqU1IcddljOOeecOr1o8+bNs8kmm2STTTbJbrvtlmOOOSY1NTUZNmxYfvazn+Wuu+5aJM+qrkpRvfXWW2fatGl1yulvbu294YYbZt999833vve9WZaci6o777wz06ZNS5J07tw5ffv2TZcuXeZ4TznOpf6mPn36ZPDgwaVxmzZtMnHixEyePDmnnHJK7r777lkW6N/06KOPlg6Xb9KkSW655Za5/kYu9+f62pdffpkjjzwyQ4b899zXM844IwceeGBF3h9Y/K287ib5T/8HS+NRQz+Z53u/Pbfd0h3rLRcAMO/ee+etnH/aiZn8jR2itt3xu+l9+nlVTAUAfNP/bLFlXvr3i6XxKy+/NE9F9Reff56h39jZcaWVV07XBSgRAFj8devWbYGK5oUxderU9OnTpzRee+21Zyqpv22zzTbLSSedlMsvvzxJMnDgwDz88MP53ve+V/a89a0qS5Rra2uT1N3au2vXrjnuuOPy0EMP5c9//nP233//xaqkTpIXXnih9LpXr15zLamTGVtWl8tzzz2XP/zhD6Xx/vvvX/qHOkkGDx6cq6++eq7P+ebn2mqrrebpp03K+bm+Nm7cuBx99NH54IMPStdOPPHEHH300WV/b6DxWHm9TdKs+X9/oGfI4DcyrXbetvD+aNArdcbLrbZ2vWYDAOZuyMcf5ZyTfpwJ4//7w7Sb/s/WOf2Cyxb5Xb0AYHGy/Q471hk/+I+/z9N9D3xr3vbb7zibmQBQeS+//HKdHYEPPvjgefqz6AEHHJDm3zha8tFHHy1LvnKr2p+6i8ViWrVqlb322iu33XZbHn/88fzsZz9L9+7dqxWp7IYPH1563bNnz3m6Z8CAAWXJMmbMmJxxxhmlVe3du3fP2WefnV133TX77LNPad7vf//7PPfcc3N8VkP6XF+bMGFCjjnmmLz11lula0cffXROOOGEsr4v0Pi0aNU6q2+6dWlcM/6rDHr2sbne99WXIzP4xafrXFtl/XnbsgwAqB/Dv/g8Z5/0o4wdM7p0bd0NNs65l/VJs2bN53AnAFBpq62+Rnqstnpp/MEH7+eZp5+c4z01NTW5+66/1Ln2vd33LEs+gMXN17shN6Zf1fDNXY+TZJ111pmn+9q0aZNVVlmlNH7vvffqNVelVKWo3nTTTXPZZZflmWeeyS9+8YuF3u99UfF1KZzMOBt6bl588cW88847Zcly3nnnlQrmZs2a5Ze//GXatGmTJDn33HOz/PLLJ5mR+cwzz8yYMWNm+6xvfq5vn3U9K1999VX69eu3EOnnbPLkyTn++OPz2muvla4ddNBBOeOMM8r2nkDjttW+h6fJN87/eOIvv8uY4Z/Pdv602tr885Y+qZ3y339nrrrB5um03OL7w1oA0NCMGf1lzj7puIwY9kXp2mo9186FV16Xli1bVTEZADA7Pz6+7iKUy39+ScaNHTvb+ddd0ydDh/532+8ddto5Pddcs2z5AGB+TZo0qc64devW83zv171eMuOHsxZFVSmq//jHP2bfffdN27Ztq/H2VbPsssuWXj/xxBNznDt+/PhccMEFZclx99135+GHHy6Njz/++Ky//vqlcbt27fLLX/6ydOj6sGHDcv7558/2eV27di29fvrppzN9+vQ5vv9FF11UtjOqa2tr89Of/rTOduR77bVXLrzwwrK8H0CSdFh2+Wz0nb1K40lfjc2dl56S91+befeIMcM/z91XnZMP33ipdK1Zi5bZ7sAfViQrAJBMmDA+555yfD795KPSte4rr5qfX/3rtG27eB1BBQCLk52+892sv8GGpfGnQ4bk6CMPy7vv1F2N9tVXX+Xyn1+SO/50e+lay5Ytc0Lvn1UqKgDMkyWXXLLOeOTIkfN874gRI0qv27dvX1+RKqpZtQM0JltttVU++uijJMk999yTLbfcMrvttttM84YMGZKTTjopH3zwQZo0aTLX4nd+fPLJJ/n5z39eGm+44YY57rjjZpq30UYb5bjjjsuNN96YJHnooYfSt2/f7LfffjPN3XLLLfPXv/41SfLhhx/m8ssvz5lnnlkqur82fvz4/PznP8/f//73ev9cyYyV3WeccUb69+9furbLLrvk8ssvr9qWDUDjscPBx2bEpx/l44Ezzp3+6ssRufuqc7Nkpy7p0n3VNG3eImNHfJHPPxicfGMnihQK2fXon6XzCitXKTkANC5Tp07NRWf8NO8N/u8xQUu1Xzo/PfOCTJw4IRMnTpjnZy211NJp/Y2fYAcAyqtQKOSqa67NIQf+ICP+b7fId995J/vvu1fWWmvtLLfCChk7ZkwGvvF6Jkyo+z39gosvTY8eq1UjNgDM1rePRH7uueeyySabzPW+jz/+OJ9++ulsn7OoUFRX0JFHHpm77rorU6dOzbRp03LSSSflrrvuytZbb50OHTpk3LhxeeWVV9K/f/9MmTIlbdq0ySGHHJLf/e539fL+tbW1OfXUUzNx4sQkSdu2beusnP62448/Ps8880z+85//JEkuvfTSbLrppllxxRXrzNt5552z0korlUr422+/Pc8991x22WWXLLfccqmpqcngwYPz8MMPZ/ToGWe/nXDCCbnuuuvq5XN97eWXX84//vGPOtfeeOON7LrrrvP8jPXWWy99+vSp11xA49CkadPs0/v8PHjzL/POS8+Wro8bOSzjRg6b5T3NW7bK7sednjU23aZSMQGg0Rs1cnhef/WlOtfGjhmdk3/Ua76fdfLZF+e7u+8194kAQL1ZZpku+c3N/5tTT+qdjz78MMmMBSyDBg3MoEEDZ5rfsmXLnHr6mdl9j+9XOirAIq2J9X8VsfHGG6dVq1alrbvvuOOOHHTQQVlmmWXmeN+3u6ytttqqbBnLSVFdQSuuuGIuvvjinHPOOaXVxM8//3yef/75mea2adMmffr0mePZ0PPr17/+dal0TpLzzz8/K6ywwmznf3129d57752JEydm4sSJOe2003LnnXfWKbebNWuWa6+9NocffnjGjRuXZMah7bM6uL1QKOTHP/5x9tprr3ovqqdNmzbTtaFDh87XM765PTvA/GrZpm32+dmFGfTMo/n3v+7JsI/eneW8Fq1aZ80tdsyWex+aJTt2rnBKAAAAWLStttrq+cvf7s1Nv7kx/e67J1+OGjXTnGbNmmfrbbbJCb1/ltVWX6MKKQFg7lq1apUDDzwwf/jDH5IkY8aMyQ9/+MNcd911WXnlmXfhrKmpyWWXXZaHHnqodK1r16753ve+V7HM9UlRXWH77rtvOnfunMsuuywffPDBTF9v2rRpttxyy5xzzjlZeeWVc88999TL+7766qv57W9/Wxrvuuuu2Xvvved6X/fu3XPOOefknHPOSZK89tprufHGG9O7d+8683r27Jm77747F110UZ599tlZPSo9e/bMySefnO22267OdgQAi5u1t945a2+9c778/NMMH/JBxn85MrVTpqT1Ektm6S7LZbnV10rTZs2rHRMAAAAWWa1bt87PTj41J/T+WV579ZV89umnGTlyZNq1a5suXZbNehtsmA4dOlQ7JgDM1fHHH58nn3yytHPxO++8kz322CPbbrttNt5443To0CGTJk3KO++8k4cffjhffvll6d6mTZvmoosuSosWLaqUfuEUisVvHpRJpRSLxQwcODCDBg3KmDFj0q5duyyzzDLZcMMN07nzor26bsiQIXn55ZczfPjwNG/ePJ07d07Pnj3To0ePakdr0G799yfVjgAAzKcdVp7zNkwAQMPTtX2rakcAAOZTK8suK+5n/d6udoSK+9VePav23kOGDMlPfvKTDB48eJ7vadOmTS655JLsscceZUxWXn5rV0mhUMi6666bddddt9pR6t0KK6wwxy3FAQAAAAAAgBlWWGGF3H333bnjjjty55135pNPZr+4sU2bNtljjz1y7LHHLvJ9nKIaAAAAAAAAKGlSqHaCxqdFixY56qijctRRR+WTTz7JwIEDM3LkyEyYMCEtWrTIUkstldVWWy1rrrnmIrvV97cpqgEAAAAAAAAaiBVXXDErrrhitWOUXZNqBwAAAAAAAACgcVFUAwAAAAAAAFBRimoAAAAAAAAAKsoZ1QAAAAAAAEBJoVCodgQaASuqAQAAAAAAAKioRXpF9bBhw3LIIYckmfGTHY8++miVEwEAAAAAAAAwN4t0UV1bW5vPPvssiS0IAAAAAAAAABYVtv4GAAAAAAAAoKIW6RXVAAAAAAAAQP1qYiNjKsCKagAAAAAAAAAqSlENAAAAAAAAQEUpqgEAAAAAAACoKEU1AAAAAAAAABXVrNoBAAAAAAAAgIajUKh2AhoDK6oBAAAAAAAAqChFNQAAAAAAAAAVpagGAAAAAAAAoKKcUQ0AAAAAAACUNHFINRVgRTUAAAAAAAAAFVWWFdW9evUqx2NnMmXKlIq8DwAAAAAAAAD1pyxF9YsvvphChbYEKBQKKRaLFXkvAAAAAAAAABaerb8BAAAAAAAAqKiyrKhOYpUzAAAAAAAALIKsdKUSylJU33777eV4LAAAAAAAAACLgbIU1Ztttlk5HgsAAAAAAADAYsDKfQAAAAAAAAAqSlENAAAAAAAAQEWVZetvAAAAAAAAYNFUKFQ7AY3BYrGiesyYMfnVr35V7RgAAAAAAAAAzINFuqj+8ssv88tf/jI77rhjbrrppmrHAQAAAAAAAGAeLJJbfw8fPjy/+93v8re//S01NTUpFosp2IMAAAAAAAAAYJGwSBXVQ4cOzc0335x77rknU6dOVVADAAAAAAAALIIqUlQPHz48jzzySF588cV88cUXGTt2bFq2bJnlllsum266afbcc8906tRptvd//vnn+fWvf517770306ZNS7FYTJIUCoXS6+22264SHwUAAAAAAAAWa00sFKUCylpUF4vFXHPNNbn99tszefLkOteT5J133kn//v1z3XXXpXfv3jnqqKPq3D916tT89re/zf/+7/9m8uTJpRXUXxfUhUIh3/ve93LsscemZ8+e5fwoAAAAAAAAANSTshXV06dPz09+8pM88cQTdVZAf/M/kxml9aRJk3LllVdmzJgxOemkk5Ikn376aU444YQMHjx4poK6efPm2XvvvfP//t//S/fu3cv1EQAAAAAAAAAog7IV1b/73e/Sv3//UsGc/Hcl9Td982s333xztt9++3Tu3DkHH3xwRo4cWSqpi8ViWrdunQMOOCBHH310unTpUq7oAAAAAAAAAJRRWYrqiRMn5qabbqpTQnfq1Cl77bVX1l133Sy11FIZP3583nrrrfTr1y+fffZZae5NN92UiRMnZsSIEaVrrVu3zmGHHZajjz467du3L0dkAAAAAAAAACqkLEX1P//5z0yYMKFUNG+//fa5+uqr06ZNmzrzvvOd7+T444/PBRdckL59+6ZQKOSpp54qrbwuFovZYYcdcuGFF1pBDQAAAAAAABXwjVN8oWyalOOhL730UpIZRfOyyy6ba665ZqaS+mvNmjXLJZdcknXWWSfFYrH0q1Ao5KijjspvfvMbJTUAAAAAAADAYqQsRfWbb76ZZMb50wceeGBat2495xBNmuTwww+vc23FFVfMGWecUY54AAAAAAAAAFRRWYrqUaNGlV5vvPHG83TPpptuWnpdKBRmKq4BAAAAAAAAWDyUpageN25c6XXnzp3n6Z5OnTrVGa+22mr1mgkAAAAAAACAhqFZOR46ZcqU0usWLVrM0z1fz/v6fOquXbuWIxoAAAAAAAAwB00K1U5AY1CWFdX1oVmzsnToAAAAAAAAAFRZgy2qAQAAAAAAAFg8KaoBAAAAAAAAqKiy7689bNiwit3XrVu3BXovAAAAAAAAYIYmBYdUU35lK6oLhUKKxWIOOeSQ+b53Qe4rFAp588035/u9AAAAAAAAAKissq6o/rqsnp/5X5uf+wAAAAAAAABYdJR96+/CAm4NMD/3KbUBAAAAAAAAFh1lKaqdFQ0AAAAAAADA7JSlqH788cfL8VgAAAAAAACgzBZww2SYL02qHQAAAAAAAACAxkVRDQAAAAAAAEBFlWXr7/vuu6/0epdddknr1q3L8TYAAAAAAAAALILKUlSfeeaZKfzf5vWbbbaZohoAAAAAAACAkrIU1UlSLBZLZTUAAAAAAACwaGii4qMCnFENAAAAAAAAQEUpqgEAAAAAAACoKEU1AAAAAAAAABWlqAYAAAAAAACgoppVOwAAAAAAAADQcBRSqHYEGgErqgEAAAAAAACoKEU1AAAAAAAAABVV9q2/hw0bVu63KOnWrVvF3gsAAAAAAACABVO2orpQKKRYLOaQQw4p11vM9H5vvvlmRd4LAAAAAAAAgAVX9hXVxWKx3G8BAAAAAAAA1JMmhWonoDEoe1FdKJT/n2RlOAAAAAAAAMCio6xFdaFQyDLLLJOmTZuW820AAAAAAAAAWISUraguFospFAr585//nG7dupXrbQAAAAAAAABYxJR9628AAAAAAABg0eGMaiqhSbUDAAAAAAAAANC4KKoBAAAAAAAAqChFNQAAAAAAAAAVpagGAAAAAAAAoKKaVTsAAAAAAAAA0HAUCoVqR6ARsKIaAAAAAAAAgIoqW1HtJy0AAAAAAAAAmJWyFdXFYrFcjwYAAAAAAABgEVaWM6pvv/320utOnTqV4y0AAAAAAAAAWESVpajebLPNyvFYAAAAAAAAoMyaOOGXCijb1t8AAAAAAAAAMCuKagAAAAAAAAAqSlENAAAAAAAAQEUpqgEAAAAAAACoqGbVDgAAAAAAAAA0HIVCtRPQGFhRDQAAAAAAAEBFKaoBAAAAAAAAqChFNQAAAAAAAAAVpagGAAAAAAAAoKKaVTsAAAAAAAAA0HA0KRSqHYFGwIpqAAAAAAAAACpKUQ0AAAAAAABARSmqAQAAAAAAAKgoZ1QDAAAAAAAAJU0cUU0FNJiieurUqXnrrbfywQcfZNy4cRk/fnymT58+X8844YQTypQOAAAAAAAAgPpS9aL69ddfz+9///s8+uijmTp16kI9S1ENAAAAAAAA0PBVraguFou55ppr8rvf/S7FYjHFYnGW8wqFQp17ZvX1YrFYZx4AAAAAAAAADVfViuorr7wyv//972dZMs+pnP7212ZXcAMAAAAAAADQMFWlqB4wYEBuu+22FAqFFAqFNG/ePIceemh22mmnTJ8+Pb169Uoyo5R+7LHHMmHChIwcOTKvvfZa/vGPf+SDDz5IoVBIhw4dcuGFF2bttdeuxscAAAAAAACAxY6NjKmEqhTVN910U5IZK6Jbt26d2267LRtssEGS5LPPPqszd7nllkuSrL766tlyyy1z/PHH57777sull16a0aNH54wzzsgNN9yQrbbaqqKfAQAAAAAAAIAF06TSbzh+/Pi88MILpdXUP/nJT0ol9bzae++9c+utt6Z169aZNGlSevfuPVPBDQAAAAAAAEDDVPGi+tVXX8306dNTLBbTvHnzHHTQQQv0nPXWWy+9e/dOkkycODE33HBDfcYEAAAAAAAAoEwqXlR//vnnSWacP73GGmukXbt2c5w/derU2X7t4IMPTuvWrVMsFvPwww9n8uTJ9ZoVAAAAAAAAgPpX8aJ6zJgxpdddu3ad6evNmzevM55T+dyyZcust956SWasqn7ppZfqJyQAAAAAAAA0Uk1SaHS/qLyKF9Xf1KpVq5mutW3bts541KhRc3xGp06dSq+HDRtWP8EAAAAAAAAAKJuKF9VLLrlk6fX48eNn+nrbtm3rrKoeMmTIHJ83ZcqU0uuRI0fWQ0IAAAAAAAAAyqniRfUKK6xQej1ixIhZzllllVVKr1999dU5Pm/QoEGl17NaoQ0AAAAAAABAw1LxorpHjx5JkmKxmPfeey/FYnGmOeuuu25pTr9+/VJbWzvLZz3++OMZOnRoadytW7cyJAYAAAAAAACgPlW8qO7SpUtpVXVNTU1ef/31mebsuuuuSZJCoZDPPvssZ555ZmpqaurMeemll3L22WenUJhxuHnTpk2z6aabljk9AAAAAAAALN4Khcb3i8prVo033WqrrfKXv/wlyYxV0euvv36dr2+55ZZZbbXV8t577yVJHnjggTz11FPZaKON0q5du3z00UcZNGhQaTV2oVDI7rvvnqWWWqqyHwQAAAAAAACA+VbxFdVJsvvuuyeZsbV33759M3Xq1LqhmjTJxRdfnObNm5eujRs3Lk8++WQeeOCBUkn99Wrqzp075/TTT6/cBwAAAAAAAABggVVlRfUmm2ySn//855k+fXqSGSV0x44d68zZcMMNc8MNN+T000/PmDFjZvmcYrGY7t275ze/+c1M9wMAAAAAAADQMFWlqC4UCtlvv/3mOm/bbbfNQw89lDvuuCNPPfVUPv7443z11VdZcskls/rqq2eXXXbJfvvtlxYtWlQgNQAAAAAAAAD1oSpF9fxYaqmlcvzxx+f444+vdhQAAAAAAABY7DUpVDsBjUFVzqgGAAAAAAAAoPFSVAMAAAAAAABQUYtNUf3ll19WOwIAAAAAAAAA86AqRfUll1ySqVOn1tvznn/++ey999719jwAAAAAAAAAyqdZNd70jjvuyKuvvppf/epXWXHFFRf4OcViMdddd11uvvnmTJ8+vR4TAgAAAAAAQOPUpFCodgQagapt/f3WW29ln332yd///vcFun/YsGE5/PDD89vf/jbTpk2r53QAAAAAAAAAlEtVz6ieMGFCTj/99Jx99tmpqamZ5/sef/zxfP/738/LL79cutakyWJz3DYAAAAAAADAYq0q7e7uu++eYrGYQqGQYrGYe++9N/vtt1/eeeedOd43derUXHrppfnJT36SsWPHJpmx/Xfnzp1z6623ViI6AAAAAAAAAAupKkV1nz59cskll6Rly5Yp/N8e9++//34OOOCA/PWvf53lPR9//HEOPPDA3HHHHXVK7m233Tb9+vXL5ptvXsmPAAAAAAAAAIulQqHx/aLymlXrjffff/9ssMEGOemkk/Lee++lUCikpqYmF154YZ5//vlceumladeuXZKkX79+ufjiizNx4sTS/U2bNs3JJ5+co48+ulofAQAAAAAAAKAsxo4dm1dffTXDhw/Pl19+mebNm2eZZZbJqquumjXWWCNNmzatdsSFUrWiOklWW2219O3bN5dccknuvvvu0irphx56KIMGDcqll16a++67L/fdd1+dVdTLL798rr766qy33nrVjA8AAAAAAABQr1566aX89re/zQsvvJCpU6fOck6bNm2y1VZb5dJLL0379u0rG7CeFIrFYrHaIZLkgQceyPnnn58JEyaUrn29Lfg3I37ve9/LJZdcUlptDYuLW//9SbUjAADzaYeVl6l2BABgPnVt36raEQCA+dSqqssuG6dbBnxc7QgVd8zm3asdIVOmTMmll16au+66K/Na4T788MPp3r362RdEg/mtvfvuu2edddbJySefnEGDBpVWT3+tdevWOfvss7P//vtXMSUAAAAAAABA/ZoyZUp69+6d/v37l64tscQS2XbbbdOzZ8907NgxNTU1GTp0aF5//fW88sorqa2trWLihddgiuok6dSpU5ZbbrkMGjQoSUpldaFQyIYbbpjddtutygkBAAAAAABg8dbk/3Y9pnIuuOCCOiV1r1698tOf/nS2u0yPHTs299xzT9q0aVOpiPWuSbUDfG3QoEHZZ5998sgjj9TZ8vvr188//3z23XffUokNAAAAAAAAsKh79tlnc88995TGp59+es4555w5HoW81FJL5aijjkrnzp0rEbEsGkRR/Yc//CEHH3xwPvlkxhm9xWIxbdu2zbHHHpvWrVuX5n388cc56KCD8oc//KFaUQEAAAAAAADqRbFYzMUXX1wab7XVVvnhD39YxUSVU9Wiety4cTn++ONzxRVXZMqUKaWtvtdZZ53ce++9Ofnkk3PPPfekZ8+epdXVU6dOzRVXXJEf//jHGTNmTDXjAwAAAAAAACyw559/Ph999FFp/LOf/axqWSqtakX1q6++mr333jv9+/cvldDFYjG9evXKn//856ywwgpJkpVWWil//etfc9hhh9WZ98QTT2SfffbJyy+/XK2PAAAAAAAAALDA+vbtW3rdvXv3rLfeelVMU1lVKapvvvnmHH744Rk6dGjp2pJLLpkbb7wxZ599dpo3b15nfosWLXLuuefmhhtuyJJLLlk6t/rzzz/PEUcckd/85jcVzQ8AAAAAAACLq0Kh8f2qlhdeeKH0epNNNqlekCpoVo03vfrqq1MoFEqrozfccMNcffXV6dq16xzv23nnnbPWWmvl5JNPzmuvvZZCoZDa2tpcd911GTBgQH7/+99X5gMAAAAAAAAALIShQ4dm5MiRpfHqq6+eJJk0aVLuv//+/OMf/8iHH36YMWPGpH379ll55ZWz1VZbZf/990/Hjh2rFbveVPWM6iQ55phj8qc//WmuJfXXunXrljvuuCPHHntskpTK7gEDBpQzJgAAAAAAAEC9efvtt+uMu3Tpktdffz177bVXzj///Lz44osZMWJEpk6dmhEjRuTFF1/MNddck5133jm33357lVLXn6qsqE6SpZdeOldeeWW23nrr+b63adOmOfnkk7P55pvnjDPOqPOTBgAAAAAAAADzY+jQoXWOLV4Q3bp1S7du3eZ5/ujRo+uMP/3005xzzjmZMGFCkhkLdjt06JBCoZBRo0alWCwmSSZOnJif//zn+eKLL3L66acvVOZqqkpRvfnmm+eqq65K586dF+o5W221Vfr165dTTz21zv7tAAAAAAAAAPOqb9++ueGGGxbqGSeccEJOPPHEeZ7/1Vdf1Rlfe+21mTp1apo3b55jjz02Bx98cKlPHTVqVP7617/mN7/5TaZMmZIk+d///d+sv/762WWXXRYqd7VUpaj+/e9/n0I9nUresWPH3Hrrrbn55pvr5XkAAAAAAADQmFX97OBGYuLEiXXGU6dOTaFQyLXXXpuddtqpztc6duyY448/Puuuu26OPfbYTJ8+PUly5ZVXZuedd07Tpk0rlru+VOWfs/oqqb/5vB/96Ef1+kwAAAAAAACAcmnZsuVM137wgx/MVFJ/0zbbbJODDjqoNP7000/z1FNPlSVfuVXtjGoAAAAAAACAhmC//fbLFltssVDPmJ/zqZOkTZs2M1077LDD5nrfYYcdljvvvLM0fuGFF7LDDjvM13s3BIpqAAAAAAAAoFHr1q3bfBfNC6tdu3Z1xksssUTWWGONud636qqrpkOHDvnyyy+TJG+99VZZ8pWbLeYBAAAAAAAAKmz55ZevM+7ates8H6HctWvX0uvRo0fXa65KqfcV1f/+979nurbpppvOdU59+Pb7AAAAAAAAAPNnXstSFk6PHj3qjJs3bz7P97Zo0aL0esqUKfWWqZLqvag+/PDD6/zDWygU8uabb85xTn2Y1fsAAAAAAAAANERLLLFElltuuXz22WdJknHjxs3zvd+c2759+/qOVhFl2/q7WCyWfs3LnPr4BQAAAAAAALCo2G677UqvP/vss4wfP36u99TU1OTjjz8ujb+9hfiioixF9byUxoplAAAAAAAAoDH77ne/W3o9ffr0PPLII3O957HHHkttbW1pvNlmm5UlW7nV+9bfl19+eb3MAQAAAAAAACrPCdWV8z//8z9ZY401Mnjw4CTJjTfemF122SVt2rSZ5fzJkyfn+uuvL41bt26d73znOxXJWt/qvajeZ5996mUOAAAAAAAAwOKsUCjklFNOybHHHpskGTJkSI4//vhcc801WXrppevMHTduXE4++eR8+OGHpWuHHnpoOnToUNHM9aXei2oAAAAAAAAA5s12222XXr165fbbb0+SPP/889l1112z2267ZY011kiSvPvuu3nggQcyevTo0n3rrrtufvrTn1Ylc31QVAMAAAAAAABU0VlnnZVJkyblb3/7W5JkzJgxufPOO2c7f7PNNsv111+fFi1aVCpivWtS7QAAAAAAAAAAjVmTJk1y6aWX5sYbb8yaa64523ldu3bN+eefn1tvvTXt27evXMAysKIaAAAAAAAAKGlSKFQ7QqO18847Z+edd87777+ft956K8OHD8+0adPSsWPHrLXWWunZs2e1I9YbRTUAAAAAAABAA7Lqqqtm1VVXrXaMsmpQRXWxWMwXX3yRsWPHZvz48SkWi/N1/6abblqmZAAAAAAAAADUl6oX1TU1Nbnvvvvy4IMPZuDAgZk0adICPadQKOTNN9+s53QAAAAAAAAA1LeqFtVPP/10zjzzzHz55ZdJMt8rqAEAAAAAAABY9FStqH7ggQdy2mmnZfr06TN9rfCNA9q/XV7P6WsAAAAAAADAwinMfQostKoU1R9//HHOOeecTJ8+PYVCIcViMWuttVZ22mmntGjRIn369Ekyo5S+/PLLM2HChIwYMSL/+c9/8tJLL6W2tjaFQiEdOnTIj3/847Rr164aHwMAAAAAAACABVCVovqmm25KTU1NaXzmmWfmyCOPTJJ89tlnpaI6SfbZZ5869w4bNiy/+tWvcu+992b06NH505/+lFtvvTXLLbdcRbIDAAAAAAAAsHCaVPoNp06dmgcffDCFQiGFQiH7779/qaSeF126dMnll1+eCy64IMViMZ988kmOOeaYTJo0qXyhAQAAAAAAAKg3FS+q33jjjdTU1KRYLKZQKORHP/rRAj3n4IMPzoEHHphisZgPP/wwN998cz0nBQAAAAAAAKAcKl5Uf/TRR0lmnD+90korzXXL7mnTps32a717906TJjM+wj333FNvGQEAAAAAAKCxKhQa3y8qr+JF9dixY0uvV1555Zm+3rRp0zrjKVOmzPZZHTt2zDrrrJNisZjhw4fntddeq7ecAAAAAAAAAJRHxYvqbxbPbdu2nenrbdq0qTMePXr0HJ/XrVu30ushQ4YsZDoAAAAAAAAAyq3iRfU3y+mampqZvt6uXbsUvrG+/vPPP5/j877e+jtJRowYUQ8JAQAAAAAAACinihfVyy67bOn1rFZLN2nSJCussEJpPHDgwDk+78MPP6y/cAAAAAAAAACUXcWL6lVWWSVJUiwW8+67785yTs+ePUuv//nPf872We+++27eeuut0grsTp061WNSAAAAAAAAaHwKhUKj+0XlVaWobt++fZJk7Nix+eSTT2aas9NOOyWZUWb/5z//yR133DHTnLFjx+aMM84ozUuSjTbaqEypAQAAAAAAAKgvFS+qk+R//ud/Sq/79+8/09e/853vZOmll06hUEixWMyll16aH/7wh7ntttvyt7/9LVdeeWV222230mrqQqGQTTbZJMsvv3wlPwYAAAAAAAAAC6BZNd50l112yb/+9a8Ui8Xcc889OeKII+p8vU2bNjnttNNy9tlnl8rq5557Ls8991xpTrFYLH2tRYsWpdXVAAAAAAAAADRsVSmqd9xxx+y1116ZPn16kuSLL77IsssuW2fOvvvum08//TS//vWvZ7kv/NcldcuWLfOLX/wi66yzTkWyAwAAAAAAwOKsKlsy0+gUil8f8NxAvfjii/n1r3+dl156KbW1taXrrVu3zvbbb58TTjghq666ahUTQv249d8zn9cOADRsO6y8TLUjAADzqWv7VtWOAADMp1ZVWXbZuP311c+qHaHiDtxwuWpHaHQa/G/tzTbbLJtttlkmTpyYoUOH5quvvsqSSy6ZFVZYIS1atKh2PAAAAAAAAADmU1mK6rPOOqv0+owzzkj79u0X+plt2rRJjx49Fvo5AAAAAAAAAFRXWYrqe++9t3Su9IknnjjXovq+++4rvd5ll13SunXrcsQCAAAAAAAAoAEo29bfxWKxVFbPzZlnnlmau9lmmymqAQAAAAAAoErmteODhdGk2gG+ViwWqx0BAAAAAAAAgApoMEU1AAAAAAAAAI2DohoAAAAAAACAilJUAwAAAAAAAFBRzaodAAAAAAAAAGg4CtUOQKNgRTUAAAAAAAAAFaWoBgAAAAAAAKCiFNUAAAAAAAAAVJSiGgAAAAAAAICKalbuNygU5u+49fmdDwAAAAAAANQffR2VULai+ut/gA8++OA0bdp0nu+b3/nffL9HH310vu8DAAAAAAAAoLLKuqK6WCzmiy++KNv8b/KTHQAAAAAAAACLhrIW1ZUqj4vFYkXeB8ppzzW7VTsCAAAALPYeeWtYtSMAAPNpz3W7VDsCUAZlK6qVxwAAAAAAAADMSlmK6scee6wcjwUAAAAAAADKrEm1A9AolKWoXm655crxWAAAAAAAAAAWA34gAgAAAAAAAICKUlQDAAAAAAAAUFGKagAAAAAAAAAqqixnVAMAAAAAAACLpkKhUO0INAJWVAMAAAAAAABQUYpqAAAAAAAAACpKUQ0AAAAAAABARTmjGgAAAAAAAChxQjWVYEU1AAAAAAAAABWlqAYAAAAAAACgohTVAAAAAAAAAFSUohoAAAAAAACAimpW7QAAAAAAAABAw1EoVDsBjYEV1QAAAAAAAABUlKIaAAAAAAAAgIpSVAMAAAAAAABQUYpqAAAAAAAAACqqWbUDAAAAAAAAAA1HkxSqHYFGwIpqAAAAAAAAACpKUQ0AAAAAAABARSmqAQAAAAAAAKgoRTUAAAAAAAAAFdWs2gEAAAAAAACAhqNQqHYCGgMrqgEAAAAAAACoKEU1AAAAAAAAABWlqAYAAAAAAACgohTVAAAAAAAAAFRUs2oHAAAAAAAAABqOQgrVjkAjYEU1AAAAAAAAABWlqAYAAAAAAACgohTVAAAAAAAAAFSUM6oBAAAAAACAkoIjqqkAK6oBAAAAAAAAqChFNQAAAAAAAAAVpagGAAAAAAAAoKIU1QAAAAAAAABUVLNqBwAAAAAAAAAajiYpVDsCjYAV1QAAAAAAAABUlKIaAAAAAAAAgIpSVAMAAAAAAABQUYpqAAAAAAAAACqqWbUDAAAAAAAAAA1HoVDtBDQGVlQDAAAAAAAAUFGKagAAAAAAAAAqSlENAAAAAAAAQEUpqgEAAAAAAACoqGbVDgAAAAAAAAA0HIVCtRPQGFhRDQAAAAAAAEBFKaoBAAAAAAAAqChFNQAAAAAAAAAVpagGAAAAAAAAoKKaVTsAAAAAAAAA0HAUUqh2BBoBK6oBAAAAAAAAqChFNQAAAAAAAAAVpagGAAAAAAAAoKKcUQ0AAAAAAACUNHFENRVgRTUAAAAAAAAAFaWoBgAAAAAAAKCiFNUAAAAAAAAAVJSiGgAAAAAAAICKalbtAAAAAAAAAEDDUUih2hFoBKyoBgAAAAAAAKCiFNUAAAAAAAAAVJSiGgAAAAAAAICKUlQDAAAAAAAAUFHNqh0AAAAAAAAAaDgKhWonoDGwohoAAAAAAACAilJUAwAAAAAAAFBRimoAAAAAAAAAKkpRDQAAAAAAAEBFNat2AAAAAAAAAKDhKKRQ7Qg0AlZUAwAAAAAAAFBRimoAAAAAAAAAKkpRDQAAAAAAAEBFKaoBAAAAAAAAqKhm1Q4AAAAAAAAANBxNCtVOQGNgRTUAAAAAAAAAFaWoBgAAAAAAAKCiFNUAAAAAAAAAVJSiGgAAAAAAAICKalbtAAAAAAAAAEDDUUih2hFoBKyoBgAAAAAAAKCiFNUAAAAAAAAAVJSiGgAAAAAAAICKckY1AAAAAAAAUFJwRDUVYEU1AAAAAAAAABWlqAYAAAAAAACgohTVAAAAAAAAAA3YXXfdlTXWWKPOr+uvv77asRaKohoAAAAAAACggRo5cmSuuuqqaseod82qHQAAAAAAAABoOArVDkAdl112WcaOHVvtGPXOimoAAAAAAACABuipp57KAw88kCRZZZVVqpymfimqAQAAAAAAABqYSZMm5cILL0ySNG/ePGeffXZ1A9UzRTUAAAAAAABAA3Pdddfls88+S5Icc8wxWXnllaucqH4pqgEAAAAAAAAakLfeeiu33357kmTFFVfMcccdV+VE9a9ZtQMAAAAAAAAADUeTQqHaERq16dOn57zzzkttbW2S5LzzzkvLli2rnKr+WVENAAAAAAAA0ED86U9/yhtvvJEk2WWXXbLttttWOVF5KKoBAAAAAAAAGoAvvvgiv/rVr5Ikbdu2zTnnnFPdQGVk628AAAAAAACgURs6dGiGDh26UM/o1q1bunXrtlDPuOiiizJhwoQkSe/evdOlS5eFel5DpqgGAAAAAAAAGrW+ffvmhhtuWKhnnHDCCTnxxBMX+P6HH344jz/+eJJkzTXXzOGHH75QeRo6RTUAAAAAAABQUqh2gEZo/PjxueSSS5IkhUIhF154YZo2bVrlVOXljGoAAAAAAACAKurTp0+GDx+eJDnggAOywQYbVDdQBVhRDQAAAAAAADRq++23X7bYYouFesaCnk/92muv5S9/+UuSpEOHDjnllFMWKseiQlENAAAAAAAANGrdunVb4KJ5YdTW1ua8887L9OnTkyRnnHFGllpqqYrnqAZbfwMAAAAAAABUwa233pp33nknSbLZZptl7733rm6gCrKiGgAAAAAAAPivQrUDNA4jRozIjTfemCRp3rx5LrjggionqixFNQAAAAAAAECFjRw5MjU1NUmSQqGQH//4x3OcP23atDrjP/7xj7n//vtL46uuuirrr79+/QctE0U1AAAAAAAAQBVNmTIln3zyyXzdM3bs2IwdO7Y0/rr0XlQ4oxoAAAAAAACAirKiGgAAAAAAACgpOKS6ItZcc80MHjx4nud/+umn2WmnnUrjE044ISeeeGI5olWEFdUAAAAAAAAAVJSiGgAAAAAAAICKUlQDAAAAAAAAUFGKagAAAAAAAAAqqlm1AwAAAAAAAAANR6FQ7QQ0BopqAAAAAAAAgAZu+eWXz+DBg6sdo97Y+hsAAAAAAACAilJUAwAAAAAAAFBRimoAAAAAAAAAKsoZ1QAAAAAAAEBJodoBaBSsqAYAAAAAAACgohTVAAAAAAAAAFSUohoAAAAAAACAilJUAwAAAAAAAFBRzaodAAAAAAAAAGhACtUOQGNgRTUAAAAAAAAAFaWoBgAAAAAAAKCiFNUAAAAAAAAAVJSiGgAAAAAAAICKalbtAAAAAAAAAEDDUUih2hFoBKyoBgAAAAAAAKCiFNUAAAAAAAAAVJSiGgAAAAAAAICKckY1AAAAAAAAUFJwRDUVYEU1AAAAAAAAABWlqAYAAAAAAACgohTVAAAAAAAAAFSUohoAAAAAAACAimpW7QAAAAAAAABAw1GodgAaBSuqAQAAAAAAAKgoRTUAAAAAAAAAFaWoBgAAAAAAAKCiFNUAAAAAAAAAVFSzagcAAAAAAAAAGpBCtQPQGFhRDQAAAAAAAEBFKaoBAAAAAAAAqChFNQAAAAAAAAAVpagGAAAAAAAAoKKaVTsAAAAAAAAA0HAUUqh2BBoBK6oBAAAAAAAAqChFNQAAAAAAAAAVpagGAAAAAAAAoKIU1QAAAAAAAABUVLNqBwAAAAAAAAAajkKh2gloDKyoBgAAAAAAAKCiFNUAAAAAAAAAVJSiGgAAAAAAAICKUlQDAAAAAAAAUFHNqh0AAAAAAAAAaDgK1Q5Ao2BFNQAAAAAAAAAVpagGAAAAAAAAoKIU1QAAAAAAAABUlDOqAQAAAAAAgP9ySDUVYEU1AAAAAAAAABWlqAYAAAAAAACgohTVAAAAAAAAAFSUohoAAAAAAACAimpW7QAAAAAAAABAw1FIodoRaASsqAYAAAAAAACgohTVAAAAAAAAAFSUohoAAAAAAACAilJUAwAAAAAAAFBRzaodAAAAAAAAAGg4CoVqJ6AxsKIaAAAAAAAAgIpSVAMAAAAAAABQUYpqAAAAAAAAACpKUQ0AAAAAAABARTWrdgAAAAAAAACg4ShUOwCNghXVAAAAAAAAAFSUohoAAAAAAACAilJUAwAAAAAAAFBRimoAAAAAAAAAKqpZtQMAAAAAAAAADUih2gFoDKyoBgAAAAAAAKCirKgGgHoyffr0fPThB3lr0Bt5a9AbefvNgXn/3XcyderU0pyzL7g0u31/nyqmBAC+yfdvAAAAqA5F9WJiwIAB6dWrV2k8ePDgKqYBaFz6P/pQ+t715wx+a1AmTZxY7TgAwDzw/RsAFi1/ueGyvPTEvxbo3i4rrJzTrvlDPScCABaWoprF1oQJE/Lee+/ls88+y/DhwzNp0qQ0bdo0Sy21VLp375511lkn7dq1q3ZMYDHw+muv5LWX/13tGADAfPD9GwAAYPYKDqmmAhTV8+iee+7JWWedtcD3W+FcGR9//HFuuummvPzyy/n4449TLBZnO7dZs2bZbrvtcuyxx2aDDTaoXEig0WjXbom0btMmI4YPq3YUAGAe+f4NAAAAlaGoZrHy7rvvpm/fvvM0t7a2No899lgef/zx/PCHP8xpp51W5nTA4qxly1ZZbY2e6bnWOllz7XWy5lrrZIXuK+XWm3+d227+dbXjAQCz4Ps3ACy6zv71X+d5btNmzcuYBABYUIrqBbTMMsukVatW1Y5Rsvnmm1u1/S2dO3fO+uuvn1VWWSXLLrts2rRpk0mTJuWTTz7Js88+m3feeSdJUiwW87vf/S5JlNXAAun1wx/lJz87Lc2a+bYKAIsK378BYNHWYZmu1Y4AACwkfyJfQFdddVU233zzasfgW5ZZZpmccsop2WmnnbLqqqvOce6DDz6Ys88+O5MmTUqS3Hrrrdljjz2y5pprViIqsBhZeukO1Y4AAMwn378BAACguhTVLFbWW2+9rLfeevM0d7fddsu0adNy6qmnJkmmT5+evn375txzzy1nRAAAAAAAgAatUKh2AhoDRXUVTZgwIYMHD86HH36Y0aNHZ9q0aVlyySXTrVu3bLzxxmnXrl21Iy6Q2travPvuu3n//fczcuTITJo0KUsssUQ6duyYjTbaKF26dKl2xJLdd989P//5zzN69OgkycCBA6ucCAAAAAAAABZ/iuoKGzFiRP7xj3/koYceyhtvvJHa2tpZzmvatGl23HHH9O7dO6uvvvpcnztgwID06tWrNJ7VedVXXHFFbrvtttL4+uuvz3e/+905Pnf69Ok54ogj8uKLLyZJWrVqlb59+6ZHjx515tXU1OThhx/Ogw8+mBdffDETJkyY7TPXWWednHDCCdlhhx3m+rnKrUmTJunevXupqP76PwEAAAAAAIDyaVLtAI3NrbfemiuuuCKvvvrqbEvqJJk2bVoeeeSR/OAHP8iDDz5YL+998sknp2fPnqXxeeedl2HDhs3xnltuuaVUUifJ6aefPlNJnSTPP/98TjvttPTv33+OJXUyY9XycccdlyuuuCLFYnE+P0X9+2be9u3bVy8IAAAAAAAANBJWVFfR8ssvn4033jirrbZa2rdvn+nTp2fo0KF59tln88YbbyRJJk+enNNPPz0rrrhi1llnnYV6vxYtWqRPnz7Zd999M3ny5IwZMyZnnHFGbrvtthRmcdjAG2+8keuvv7403n777XPooYfO9X3at2+fjTfeOGuttVY6duyY5s2bZ9SoUXn11Vfz1FNPZdq0aUmS2267Ld26dauzErzSPvvss7z//vul8UYbbVS1LAAAAADAvLnvf6/NR4MHZvTIL1IzcUJatWmbtku2zwqr9Myq62yY9bfYPi1bt6l2TABgDhTVFdakSZPsscceOeKII7LeeuvNcs5JJ52UJ598MqeddlrGjh2bqVOn5qKLLsrf/va3hX7/Hj165PTTT88ll1ySZMZK6Ntuuy1HH310nXmTJk3KqaeemqlTpyZJOnbsmMsuu2yOz95www1zzDHHZNttt03z5s1nOefDDz/MT3/609LW5H369Mmee+6ZpZdeemE/2nyrqanJWWedlenTpydJWrZsmUMOOaTiOQAAAACA+fPMP/vWGU8YNzYTxo3N8E8/zstPPZR//PE32f77B2X7vQ5OkyY2FgWYXzMvb4T65zt0hfXu3Tt9+vSZbUn9te222y7XXnttafz6669n4MCB9ZLhsMMOy7bbblsaX3311Xn77bfrzLnsssvy0Ucf1Rl37Nhxts/ccsst85e//CU77bTTbEvqJFl55ZVz6623pkOHDklmlMX33nvvAn6S+VdTU5P3338/d9xxR/bcc88MGDAgSVIoFHLRRRdlhRVWqFgWAAAAAKA8Jn41Ng/ecVNuufTUTBz/VbXjAACzYEX1AprX7ap79uyZfv36lcYtW7ac5/fYYostsvnmm5fK1GeeeWaht//+2uWXX57vf//7GTVqVKZOnZpTTjklffv2TatWrfLoo4/mrrvuKs099NBDs/3228/xefPzuTp16pRDDz20tK34M888M9OK7vpy/fXX54YbbpjjnJVWWinnnntuttlmm7JkAAAAAADqR5flV8qaG2+R5VddI52WXS6tWrfNlMk1GT1yWN4f+Gr+/cQ/M+kbxfS7r7+UP1x1bo49r0+aNvXX4QDQkFhR3cBtscUWpdeDBg2qt+d26tSpzlbe7733Xq688soMHz485557bun611uF17dyfa75teOOO+a2225TUgMAAABAA7bGBpvnZ7+4Jaf96vbscfiPs8GWO2b5VdZIp67Lp9tKPbL2Jlvl+0eekHN+87dsvN0ude59f+CrefTu26uUHACYHT9CtoCWWWaZtGrVaq7zunbtulDv06lTp9LrYcOGLdSzvm377bfPIYcckjvvvDNJcscdd2TAgAEZPXp0kqR58+bp06fPPH3O+fXNzzVmzJhMnjx5vlZlz6ullloqK664YpKkWCxm/PjxGTNmTIrFYpLk8ccfz9NPP51DDjkkp5xySlkyAAAAAAALZ8Otd5qnea1at8nBJ56T5i1a5oVH7i9df+ofd2Xr3fZL2yWWKldEAGA+KaoX0FVXXZXNN998ge+fNGlSHnvssTz99NMZPHhwvvjii0yYMCFTpkyZ7T1ffVX/Z6mcccYZGTBgQN5///0kM1ZWf+3kk09Oz5495+t506dPz4ABA/Loo4/mzTffzJAhQzJ+/PhMmjRpjvd99dVXZSmJe/XqNdM27V999VWee+65/O///m/+85//ZOrUqfnDH/6Qt99+O7/73e/SokWLes8BAAAAAFTO3kf/NINfezGjR3yRJJk8aWJee+axbPW9faucDGARUah2ABoDW39XwX333Zcdd9wxp5xySu6777689dZbGT169BxL6iSZPHlyvWdp1apV+vTpk+bNm9e5vsUWW+Soo46ar2e9/vrr2WeffXLkkUfmT3/6U1555ZWMGDFiriV1Up7PNjtLLLFEdtlll/zlL3/J4YcfXro+YMCAXHfddRXLAQAAAACUR7PmzWcqpd994+UqpQEAZsWK6gq75ZZbctVVV83ya+3bt0+rVq3qrOidMGFCRo0aVdZMTZs2TZMmdX9mYcstt0yhMO8/LjNgwIAce+yxqampmelrbdu2Tdu2bdOyZcvSM6dNm5bPPvusNOfrrbgrqUmTJjnnnHPy+uuv5z//+U+S5E9/+lOOPfbYLLnkkhXPAwAAAADUn9XX26TO+PNPPqhSEgBgVhTVFfT222/nmmuuKY07deqUXr16ZZtttkmPHj1mueV03759c/bZZ5ct05QpU3LqqafOtKL5hhtuyA477JDVVlttrs+oqanJmWeeWSqpmzdvnoMOOijf+c53svbaa6ddu3Yz3TNkyJDsvPPO9fMhFkKhUMghhxxSKqonTZqUF198sUFkAwAAAAAW3NKdl60znjBubJWSAACzoqiuoDvvvDPTpk1LknTu3Dl9+/ZNly5d5nhPOc6l/qY+ffpk8ODBpXGbNm0yceLETJ48OaecckruvvvuuZ7Z/Oijj2bo0KFJZqxSvuWWW7LFFlvM8Z5yf6758e1zuD/55JMqJQEAAAAA6kvzFi3rjKdOqdzxgwDA3DmjuoJeeOGF0utevXrNtaROkk8//bRseZ577rn84Q9/KI3333//XH755aXx4MGDc/XVV8/1Od/8XFtttdVcS+qkvJ9rfn37fO6vf5gAAAAAAFh0Tfiq7grqtks47g9gXhUa4f9ReYrqCho+fHjp9bdX8c7OgAEDypJlzJgxOeOMM0pnQ3fv3j1nn312dt111+yzzz6leb///e/z3HPPzfFZDelzLYhvl+adOnWqUhIAAAAAoL4Mee+tOuMll/b3fgDQkCiqK+jrUjiZcTb03Lz44ot55513ypLlvPPOKxXMzZo1yy9/+cu0adMmSXLuuedm+eWXTzIj85lnnpkxY8bM9lnf/FzfPut6Vr766qv069dvIdLXr0ceeaTOeK211qpSEgAAAACgvvznuf51xqustX6VkgAAs6KorqBll1229PqJJ56Y49zx48fnggsuKEuOu+++Ow8//HBpfPzxx2f99f/7P9LatWuXX/7yl2natGmSZNiwYTn//PNn+7yuXbuWXj/99NOZPn36HN//oosuKssZ1VOnTs3UqVPn656XX3459957b2m80korZY011qjvaAAAAABABX3y7pt57bnH61xbc6O5H1kIAFSOorqCttpqq9Lre+65Jw8++OAs5w0ZMiRHHnlkPvjggzRpUr//FX3yySf5+c9/XhpvuOGGOe6442aat9FGG9W5/tBDD6Vv376zfOaWW25Zev3hhx/m8ssvn+U5z+PHj89ZZ52Vv//97/X+uZIZhfouu+ySO+64I6NHj57j3Nra2tx111055phjUltbW7p+yimn1HsuoHH4fOhns/w1/qtxdeaNGTNmlvNGjRxRpeQA0Hj5/g0Ai4YXHvl7aiZNnOf5Xwz5KL//5bkpfmNBTffV185q621cjngAi6VCofH9ovIKxW/u28xs3XPPPTnrrLNK49tvvz2bb775fD3jk08+yW677VZn1e8WW2yRrbfeOh06dMi4cePyyiuvpH///pkyZUratGmTQw45JL/73e+SJMstt1wef/zxWT57wIAB6dWrV2k8ePDgmebU1tbmkEMOyX/+858kSdu2bdOvX7+ssMIKs3zmt+e3adMm/fr1y4orrjjTvN133z0fffRR6VqPHj2yyy67ZLnllktNTU0GDx6chx9+uFQg9+7dO9ddd11p/mOPPVbabnxBffrpp9lpp52SzNjOfL311svaa6+d5ZZbLksssUSKxWLGjh2bd999N08//XRGjRpV5/7DDz8855577kJlWBgjxtfOfRLQYG298doLdf8GG2+aG27+ff2EAQDmie/f0Di98OGouU8CGpSf//iATJ40MRtt851ssNWOWWG1NdO0abOZ5k0c/1Wef7hfHr/nj5lcM6l0vVnzFjn+4uuy4mqO/INF1Z7rdql2hEZn8Bfz/gNCi4s1lm1T7QiNzszfzSmbFVdcMRdffHHOOeec0vbYzz//fJ5//vmZ5rZp0yZ9+vSZ49nQ8+vXv/51qXROkvPPP3+2JXXy37Or995770ycODETJ07MaaedljvvvLO0LfjX86699tocfvjhGTduxsqD9957L++9995MzywUCvnxj3+cvfbaq05RXd9qa2vzyiuv5JVXXpnr3JYtW+aEE07IscceW7Y8AAAAAMCCmzh+XJ75Z98888++adaiRZZdYZUs0b5DWrdpmymTazJ65LB8/tH7mT697k6PTZo0zUEnnq2kBoAGyNbfFbbvvvvm5ptvziqrrDLLrzdt2jTbbLNN7rnnnuy444719r6vvvpqfvvb35bGu+66a/bee++53te9e/ecc845pfFrr72WG2+8caZ5PXv2zN13311ne/NZzbnpppvy05/+dP7Cz6POnTvn7LPPztZbb522bdvOdX6HDh3Sq1ev/P3vf1dSAwAAAMAionbKlHz6/tt56+Xn8srTj2Tgi0/nsw/emamkbt9pmfz4omuzwZb19/esAED9sfV3lRSLxQwcODCDBg3KmDFj0q5duyyzzDLZcMMN07lz52rHWyhDhgzJyy+/nOHDh6d58+bp3LlzevbsmR49elQsw/Tp0/PBBx/ko48+yueff54JEyakUCikXbt26dChQ9Zcc8107949hQZ06ICtvwEAAKD8bP0Ni54Bj/0jb770XD4a/EYmjBs7x7mFQiFdu6+a//nOXtlk+13SomWrCqUEysnW35Vn628qQVENDYSiGgAAAMpPUQ2LtjEjh2X40CEZM3J4Jn41NrVTp6RZ8xZp3W6JLNWhc1Zcba20abdEtWMC9UxRXXnvNMKienVFdcU5oxoAAAAAgEVC+05d0r6TwgoAFgfOqAYAAAAAAACgohTVAAAAAAAAAFSUohoAAAAAAACAinJGNQAAAAAAAPBfhWoHoDGwohoAAAAAAACAilJUAwAAAAAAAFBRimoAAAAAAAAAKkpRDQAAAAAAAEBFNat2AAAAAAAAAKDhKKRQ7Qg0AlZUAwAAAAAAAFBRimoAAAAAAAAAKkpRDQAAAAAAAEBFKaoBAAAAAAAAqKhm1Q4AAAAAAAAANByFQrUT0BhYUQ0AAAAAAABARSmqAQAAAAAAAKgoRTUAAAAAAAAAFaWoBgAAAAAAAKCimlU7AAAAAAAAANBwFKodgEbBimoAAAAAAAAAKkpRDQAAAAAAAEBFKaoBAAAAAAAAqChnVAMAAAAAAAD/5ZBqKsCKagAAAAAAAAAqyopqAAAAAAAAgCqbMmVK3n///bz77rsZNWpUJk+enCWWWCJdunTJBhtskE6dOlU7Yr1SVAMAAAAAAABUwZdffpl//etf6d+/f1566aVMnDhxtnM32mij/PCHP8zOO+9cwYTlo6gGAAAAAAAAqLD3338/3//+91NbWztP81955ZW88sor2X333XPZZZelVatWZU5YXopqAAAAAAAAoKSQQrUjNApTpkypU1I3adIka665ZjbZZJN069YtSyyxREaNGpUXX3wxzzzzTIrFYpLkgQceyPjx4/Ob3/wmTZs2rVb8haaoBgAAAAAAAKiSLl265KCDDsp+++2XLl26zPT1Y489Nq+//np++tOfZujQoUmSJ598Mn/9619zyCGHVDpuvSkUv67egaoaMX7etnUAAAAAFtwLH46qdgQAYD7tue7MxR3l9cGImmpHqLhVOld+G+2PP/44jz32WA499NC0bNlyrvM/+OCD7L333pk8eXKSpFu3bunfv3+5Y5ZNk2oHAAAAAAAAAGhsunfvnqOPPnqeSuokWWWVVbLvvvuWxkOHDs27775brnhlp6gGAAAAAAAAWARsvvnmdcZDhgypUpKF54xqAAAAAAAAoKRQqHYCZqdt27Z1xpMmTapSkoVnRTUAAAAAAADAIuDTTz+tM+7YsWOVkiw8RTUAAAAAAADAIuCxxx4rvW7evHnWXnvtKqZZOLb+BgAAAAAAABq1oUOHZujQoQv1jG7duqVbt271lGhmb7/9dp577rnSeOutt84SSyxRtvcrN0U1AAAAAAAA0Kj17ds3N9xww0I944QTTsiJJ55YT4nqqq2tzbnnnpvp06eXrv3kJz8py3tViqIaAAAAAAAAKClUOwAzueqqq/LGG2+UxgceeGDWXXfdKiZaeM6oBgAAAAAAAGig+vbtm9tuu600XnnllXPWWWdVMVH9sKIaAAAAAAAAaNT222+/bLHFFgv1jHKcT/3kk0/m/PPPL43bt2+fG2+8Ma1bt67396o0RTUAAAAAAADQqHXr1q0sRfPCeOmll9K7d+/U1tYmSdq2bZtbbrklq666apWT1Q9bfwMAAAAAAAA0IAMHDsyPfvSj1NTUJElatmyZ3/zmN1lvvfWqnKz+WFENAAAAAAAA/Feh2gEat3feeSc//OEPM378+CRJ8+bNc91112XzzTevcrL6ZUU1AAAAAAAAQAPw0Ucf5eijj86YMWOSJE2bNs2VV16Z7bffvqq5ykFRDQAAAAAAAFBlQ4cOzVFHHZURI0YkSQqFQi655JLstttuVU5WHopqAAAAAAAAgCoaMWJEjjzyyAwdOrR07Zxzzsl+++1XxVTl5YxqAAAAAAAAoKTgkOqKGjNmTI4++uh8/PHHpWunnHJKDj/88CqmKj8rqgEAAAAAAACqYPz48fl//+//5Z133ildO+6443LsscdWMVVlKKoBAAAAAAAAKmzy5Mn58Y9/nDfeeKN0rVevXjnppJOqmKpybP0NAAAAAAAAUGH//Oc/8+KLL9a51r9//zzxxBPz/Izvfve7Oe200+o5WWUoqgEAAAAAAAAqbPr06TNdGzJkyHw9Y9SoUfUVp+IU1QAAAAAAAEBJoVDtBDQGhWKxWKx2CCAZMb622hEAAABgsffCh4vuihMAaKz2XLdLtSM0Op98ObnaESpuxQ4tqx2h0WlS7QAAAAAAAAAANC6KagAAAAAAAAAqSlENAAAAAAAAQEU1q3YAAAAAAAAAoOEoVDsAjYIV1QAAAAAAAABUlKIaAAAAAAAAgIpSVAMAAAAAAABQUYpqAAAAAAAAACqqWbUDAAAAAAAAAA1HoVDtBDQGVlQDAAAAAAAAUFGKagAAAAAAAAAqSlENAAAAAAAAQEUpqgEAAAAAAACoqGbVDgAAAAAAAAA0JIVqB6ARsKIaAAAAAAAAgIpSVAMAAAAAAABQUYpqgP/f3n3HR1Ht/x9/z+6mECChhRBCBCyAUSIoKB0EFIggioKFCwhXxSs2VBR7AaSIlarijxrFqwZUUFDAi0iXjgWQIiWEIpCQhJQtvz/y3TFLCARNZrPk9Xw8fLhn5szMZwLxePZzCgAAAAAAAAAAACzFHtUAAAAAAAAAAAAATAZbVMMCzKgGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwlMPfAQAAAAAAAAAAAAAoPQx/B4AygRnVAAAAAAAAAAAAAABLkagGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAlnL4OwAAAAAAAAAAAAAApYdh+DsClAXMqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALCUw98BAAAAAAAAAAAAACg9DBn+DgFlADOqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKVIVAMAAAAAAAAAAAAALOXwdwAAAAAAAAAAAAAAShHD3wGgLGBGNQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKUc/g4AAAAAAAAAAAAAQOlh+DsAlAnMqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWYo9qAAAAAAAAAAAAACaDTaphAWZUAwAAAAAAAAAAAAAsRaIaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWMrh7wAAAAAAAAAAAAAAlB6GDH+HgDKAGdUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWcvg7AAAAAAAAAAAAAACliOHvAFAWMKMaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUg5/BwAAAAAAAAAAAACg9DD8HQDKBGZUAwAAAAAAAAAAAAAsRaIaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWMrh7wAAAAAAAAAAAAAAlB6G4e8IUBYwoxoAAAAAAAAAAAAAYCkS1QAAAAAAAAAAAAAAS5GoBgAAAAAAAAAAAABYij2qAQAAAAAAAAAAAJgMsUk1Sh4zqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACzl8HcAAAAAAAAAAAAAAEoPw/B3BCgLmFENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKVIVAMAAAAAAAAAAAAALEWiGgAAAAAAAAAAAABgKRLVAAAAAAAAAAAAAABLkagGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwlMPfAQAAAAAAAAAAAAAoPQzD3xGgLGBGNQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKUc/g4AAAAAAAAAAAAAQOlhyPB3CCgDmFENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKVIVAMAAAAAAAAAAAAALMUe1QAAAAAAAAAAAABMBltUwwLMqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALCUw98BAAAAAAAAAAAAACg9DH8HgDKBGdUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWcvg7AAAAAAAAAAAAAACliOHvAFAWMKMaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUg5/BwAAAAAAAAAAAACg9DBk+DsElAHMqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALCUw98BAAAAAAAAAAAAACg9DMPfEaAsYEY1AAAAAAAAAAAAAMBSJKoBAAAAAAAAAAAAAJYiUQ0AAAAAAAAAAAAAsBSJagAAAAAAAAAAAACApRz+DgAAAAAAAAAAAABA6WH4OwCUCcyoBgAAAAAAAAAAAABYikQ1AAAAAAAAAAAAAMBSJKoBAAAAAAAAAAAAAJZij2oAAAAAAAAAAAAAf2GTaliAGdUAAAAAAAAAAAAAAEsxoxoAAAAAAAAAAAAASgm3263169dr7969Onr0qMLDwxUdHa2mTZsqLCzM3+EVGxLVAAAAAAAAAAAAAOBnLpdLH374oWbOnKnDhw8XOB8WFqabbrpJQ4YMUUREhB8iLF6Gx+Px+DsIANKRdKe/QwAAAAAA4IK3avef/g4BAACcp24No/wdQpmTmVv20odhQf7dmDstLU0DBw7U+vXrz1m3Ro0amjRpkuLi4iyIrOSQqAZKCRLVAAAAAACUPBLVAAAEHhLV1juV6+8IrFcuyH/Pdjqduu+++7RixQrzWM2aNXXzzTcrJiZGx44d06JFi7RlyxbzfFRUlD799FNFRQXu7weJaqCUIFENAAAAAEDJI1ENAEDgIVFtPRLV1vrggw80duxYs9y1a1eNHDlSwcHBPvVmzJih1157Td70btu2bfX+++9bGmtxsvk7AAAAAAAAAAAAAAAoi9LT0zVlyhSzHBcXp9GjRxdIUktS37591bt3b7O8dOlSrVu3zpI4SwKJagAAAAAAAAAAAADwgy+++EInTpwwy0OGDJHD4Si0/mOPPaZy5cqZ5RkzZpRkeCWKRDUAAAAAAAAAAAAA+MHixYvNzzExMWrevPlZ61esWFGdOnUyy8uWLVNOTk6JxVeSSFQDAAAAAAAAAAAAMBlG2fvHH7KysrRmzRqz3KJFCxlFCKZFixbm54yMjIBd/ptENQAAAAAAAAAAAABYbNeuXcrNzTXLV111VZGua9y4sU9527ZtxRqXVUhUAwAAAAAAAAAAAIDFdu7c6VOuXbt2ka6LiYmR3W43y7t27SrWuKxS+E7cAAAAAAAAAAAAAFAGJCcnKzk5+R/do2bNmqpZs2aR6+/fv9+nHB0dXaTr7Ha7IiMjlZKSIknat29f0YMsRUhUAwAAAAAAAAAAACjTPv/8c40fP/4f3eOhhx7Sww8/XOT66enpPuWIiIgiXxseHm4mqjMyMop8XWlCohooJSIr8OsIAAAAAEBJ69Ywyt8hAAAAlHqhpCwskZmZ6VMOCQkp8rWhoaGF3idQsEc1AAAAAAAAAAAAAFgsOzvbpxwUFFTka4ODg83PWVlZxRaTlRgPAQAAAAAAAAAAAKBMu+2229S8efN/dI/z2Z9aKjiDOjc3t8izqnNycszP+WdXBxIS1QAAAAAAAAAAAADKtJo1a553ovmfCgsL8ylnZ2cXOVGdfxb16fcJFCz9DQAAAAAAAAAAAAAWq1Chgk85NTW1yNeePHnS/Fy+fPlii8lKJKoBAAAAAAAAAAAAwGK1atXyKR88eLBI17lcLh0+fNgsx8bGFmtcViFRDQAAAAAAAAAAAAAWu/jii33Ke/fuLdJ1Bw4ckMvlKvQ+gYJENQAAAAAAAAAAAABY7OKLL1ZQUJBZ3rhxY5Gu27Bhg0+5Xr16xRmWZUhUAwAAAAAAAAAAAIDFypUrp6ZNm5rllStXyuPxnPO6FStWmJ/DwsLUpEmTEomvpJGoBgAAAAAAAAAAAAA/6Nixo/l5//79Wrly5Vnrnzx5UgsXLjTLrVu3VnBwcInFV5JIVAMAAAAAAAAAAACAH9x8882KiIgwy2PHjpXT6Sy0/ttvv61Tp06Z5b59+5ZofCWJRDUAAAAAAAAAAAAA+EHFihV17733muWff/5ZQ4cOVW5uboG6M2fOVGJiollu3bp1wC77LUmGpygLnQMAAAAAAAAAAAAAil1ubq7+/e9/a/Xq1eaxmJgYdevWTbVq1dKxY8e0aNEibd682TwfGRmpzz77TDVq1PBHyMWCRDUAAAAAAAAAAAAA+FFqaqoGDhyoDRs2nLNu9erVNWnSJF155ZUWRFZySFQDAAAAAAAAAAAAgJ+5XC598MEHmjVrlo4cOVLgfFhYmBISEjRkyBBVqlTJ+gCLGYlqAAAAAAAAAAAAACglXC6X1q9frz/++EN//vmnwsPDFR0drWuvvVZhYWH+Dq/YkKgGAAAAAAAAAAAAAFjK5u8AAAAAAAAAAAAAAABlC4lqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCkS1QAAAAAAAAAAAAAAS5GoBgAAAAAAAAAAAABYikQ1AAAAAAAAAAAAAMBSJKoBAAAAAAAAAAAAAJYiUQ0AAAAAAAAAAAAAsBSJagAAAAAAAAAAAACApUhUAwAAAAAAAAAAAAAsRaIaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAgIHg8Hp9/AwCA0s/j8RRow/MfAwAAZReJagBAmeLxeOR0Ov0dBgAAKKL8X2IbhuHz79PPAwCA0uH09tswDGVmZsowDOXk5JjHAABA2WZ46NUDAMoIp9Mph8MhScrKypLNZlNwcLCfowIAAGfi8XjML7DdbrfS09OVnp6uJUuWmF92X3HFFYqNjVVsbGyBawAAgPVOb78PHDiglJQULViwQLt375bH45Hb7VaTJk109dVXq2XLln6OGAAA+BOJagDABc/tdstm+2sRkcTERA0bNkyPPPKIHnzwQT9GBgAAzmXXrl1av369Vq5cqe+++045OTnmOYfDoUqVKum2225Tnz59VK1aNT9GCgAAvHbu3KmVK1dq+fLlWrFihbKzs2Wz2eR2u806hmHoscceU7du3VSzZs0CfXcAAHDhI1ENACgzVq9erVdeeUW7du2SJFWvXl0ff/yxYmJi/BwZAADw8s7EyszM1KpVq/TVV19p1apVOn78uE89u90uSXK5XJKk6667TsOGDdNFF11kecwAACCPt/2eN2+eVqxYoRMnTkjKS0rn/xra4XDI6XQqIiJCN954o4YNG+aniAEAgD+RqAYAXPAyMzM1Z84cTZgwQceOHZPD4ZDdbld2drb+9a9/6fnnn/d3iAAAQL6roHzxxReaMmWKduzYIUmqVKmS6tSpI4fDoYiICG3btk379+8367vdbvXq1Uv33nsvyWoAACzkcrnMAWSffvqpZs6cqe3bt0uSKleurMaNGysyMlJXX321Dh48qE2bNun77783rw8JCdGIESPUtWtXtvEAAKCMIVENALggeTvKTqdTc+bM0dSpU82Z1KeP5J49e7YaNWrkp0gBAEB+brdb7777riZPniwpb8ZVq1atlJCQoMsvv1yXXXaZWfe9997T119/rW3btkmSIiIiNGjQIPXu3dv8whwAAJS83NxcjR49WrNmzZKU1363adNGCQkJatiwoWrXru1Tf/To0Zo+fbq5FHiLFi00efJkBQcHWx47AADwHzb9AABckLxfTs+cOVOjRo0yk9QxMTFq06aNIiIizLqTJk2S0+n0S5wAAOAv6enpevvttzVlyhRJUlhYmG699VY9+OCD6tq1q5mkzs3NlSTdc889evLJJxUUFCRJSk1N1apVq/Tnn3/65wUAACiDtm/froEDB5pJ6ho1aqh37956+OGHlZCQYCapnU6nmZh++OGH1bRpU/Mef/75p5KTk60PHgAA+BWJagDABSkrK0vPP/+8Ro8erYyMDElSuXLl1LdvXw0aNEitWrWSlDe7eunSpfr222/9GS4AAJC0aNEizZ071xxA1rZtWz300EOKj483l/iWZCamQ0JC1Lp1a911113muWXLlpltPwAAKFlut1s///yzVqxYYR67+eabdf/99+vyyy/3ab8dDodsNpvcbrfCwsLUvXt389yOHTtUrlw5S2MHAAD+R6IaAHBBCg0N9dnXqlq1ahozZoz69eun+Ph4tWvXTrGxseYS4JMmTVJqaqq/wgUAoMxzOp164403dPjwYYWGhqpXr1566623FBUVdc5rW7ZsqYoVK8pmsyk3N9fny3IAAFBybDab6tSpo+joaDkcDo0ePVqPP/64qlatWug13r76VVddZSano6OjLYkXAACULiSqAQAXHJfLJUm67777VLVqVTVr1kwTJkzQDTfcYCamW7ZsqTZt2sgwDBmGoR07dmj27Nn+DBsAgDLL7XbL4XDoqaeekiRVrFhRt9xyi6S/2vWzqVChgjwej/nFd/ny5SXJbPcBAEDJqV+/vh566CENHjzYnCV9tvbb215v377d3M7jmmuuKdLgNAAAcGFx+DsAAACKm91ul9vt1kUXXaTnnntO5cuXV8OGDSX91SGuUqWKOnTooE2bNmnr1q2SpClTpqhTp06qU6eOv0IHAKBM8i4L2q1bN3333Xdq3bq1rr76akl57fq5NGzYUKGhoUpPT5ckHT9+XJJ8VlcBAAAlIywsTB07dvRZuruw9ts7sOzQoUP66KOPzO0+evXqZdZxu90+S4YDAIALFy0+AOCC5P1iOiEhQW3btvXp5HpnV11zzTVq166d2Zk+efKkpkyZYn2wAADAbJ+fe+45dejQQR6Pp8gzovfu3avc3FzzS/FLLrnE554AAKBkRUREKDg4uNC21+PxyOVymX31b775Rr/++quCgoLUvXt3hYaG6uOPP9aqVat04MAB8zq3221J/AAAwD+YUQ0AuCCdPoMq/3KghmHI4/EoJCRE7du318aNG/Xjjz9Kkj777DN169ZN1113neUxAwBQlnnb6b+z7KfT6VRubq55j7CwMJ97AgAAa5yp7XW5XLLb7bLb7Tp+/LhGjhypL7/80jy/fPlyffHFF2a5Zs2aat++vQYNGqTKlStbEjcAAPAPZlQDAMqE0zvL3nJcXJzat2+vatWqmecmTpyonJwcS+MDAAB/365du5SZmSm3262wsDDVrVvX3yEBAID/413x5MMPP1Tbtm19ktSSdPToUZ96ycnJmjVrlp5++mn9/vvv1gYLAAAsxYxqAECZ5Z1l3aZNG23YsEFfffWVDMPQ6tWrNW/ePPXo0cPfIQIAgCLYv3+/pLzlQa+++mpVqVLFzxEBAACvQ4cO6amnntLq1at9jrdt21ZdunRRbm6uJGnt2rX67rvvdOrUKRmGoR9++EHR0dG6//77FRMT44/QAQBACSNRDQAos7yzqmvVqqWOHTtq69at2r17tyRp0qRJatu2rapWrerPEAEAQBFs3brV/HzllVey5DcAAKWI3W5XrVq1tHbtWtlsNrVq1Ur333+/rr76ap96PXv21Ndff60PP/xQP//8syRp8eLFuuqqqxhIDgDABYqlvwEAZZrH45EkNWvWTG3atDGXGtu3b59mzZrlz9AAAEARZGRkaM2aNXI48sZhx8XFSfqrjQcAAP5VrVo13XTTTerSpYtGjBihyZMnm0lqt9stSeb2WzfeeKMeeeQR89qjR49q7dq1OnnypPWBAwCAEkeiGgBQpnlnXEVERKhDhw5q2LCheW7q1Knavn27v0IDAABF8Pvvv+vEiRNyu92qUKGCGjRoIEnMqgYAoBTwDhy77rrrNHr0aHXv3l2S5HK5JEk2W97X08HBwZIkh8OhVq1a6ZZbbjHvsWTJEmVnZ1sYNQAAsAqJagAA/k/jxo3Vvn17VahQQZKUlZWl999/v0A9j8djdqoBAIB/eL/43rFjh6S8GVn169dXZGRkofW9s7YAAIA1vAPH7Ha7HA6H2RZ7VzM7E5vNpuuuu07BwcFyOBxKTU3VunXrLIkXAABYi0Q1AADK+/I6KChI7dq1U9OmTc3j8+bN09KlS806TqdThmHIbrfr0KFDSktLM88BAADreL/4Xr58uXmsfv36KleuXIG6LpdLhmHIZrPp+PHjOnXqlGVxAgCAv3hnUBfG4/HIMAyVL19eOTk5Zl+7cuXKVoQHAAAsRqIaAAD99WV3vXr11KFDB9WoUcM8N2nSJJ08eVKGYcjhcMjlcmnGjBnq3LmzXnjhBX+FDABAmXfq1Cn99NNP5qys+Ph4SX/td+ldAcVut8vtdmvatGnq06ePZsyY4Z+AAQDAWXn75uHh4WbZ4XCcM8ENAAACEy08AAD/xztSu1WrVmrRooWkvE7xxo0btWjRIknSokWLdNddd2nMmDHKzs7WwoULtWrVKvbBBADAYh6PR3v27NHJkyfldrsVHh6u+vXrm+c8Ho+ZwF68eLHuuusuvf7669q5c6cSExP122+/+TN8AABwGu82HR6PR59++qkkyel06oorrtCVV17p5+gAAEBJcPg7AAAAvNxu9xlHSXuX/ipp3mfUqFFD7du315YtW8x9L8eOHasFCxZo9erVys7ONpPa9erVK3QvTAAAygJ/tN/ee2/btk1ZWVmSpOjoaF100UU+CerffvtNkyZN0tKlS33a7zp16igiIqJEYgMAIBD4u/99JoZhyDAMrVmzRmvXrjWPt2zZUqGhoYXGDAAAAheJagCA3+TvAHs7nEePHtXvv/+uypUrKzg4WHXr1rW0k+yNo3Xr1tq2bZt2794tp9OpP//8U8uXL5fT6ZQkVa9eXUOHDlVCQoJlsQEAUBqUhvbbe+8ffvjBPFavXj2VL19eknT8+HF98MEHSkpKUmpqqpmgpv0GAJRVpaH9PldcOTk5WrJkiUaNGqXDhw/LbrerXbt2uu+++ySde39rAAAQeEhUAwD8xtsZ3blzpzZu3KhVq1Zp4cKFCgoKUkZGhiIjI9WmTRslJCSoZcuWJR6Py+UyZ2CFhIQoIyNDDodDhmHI6XSaSepBgwbp4YcfLvF4AAAojUpD++3xeJSVlaVffvnFPNapUydJUmJiombMmKG9e/eadSXabwBA2VYa2u/8vMlyb1wHDhzQjz/+qDlz5ujQoUOSpLCwMN12220qV66cX2d6AwCAkmN4vL12AAAsduzYMf3www/69ttvtXbtWp08edI8Z7PZ5Ha7JUkOh0NPP/20br75ZkVERJTIcl/5O73Lli3T+++/rw0bNsjj8cjlckmSunTpoqFDhyoqKqpYnw0AQCApLe33zp07dffddys1NVWVK1dWr169tGnTJv30009yu91mHAkJCXr66adpvwEAZVppaL/PlGzet2+ftmzZoh9//FGLFi1SWlqaJKlp06Z64YUXVK9evWJ5NgAAKJ1IVAMALOWdtZyamqrExER9/vnnOnDggCSpUqVKCgoKUlhYmNLS0nTy5ElzFnNkZKRuvvlmDRkypMRi27lzpyZPnqzFixfr1KlT5gysuLg4Pfvss2rSpEmJPRsAgNKsNLbf8+bN05NPPinDMOTxeFSpUiWlpaWZX7THxcXpueee0zXXXFPszwYAIBCUxvZ79+7dkvIS5wsWLNDu3bv1+++/KyUlRZJUrVo1derUSXfddZcuvfTSYn8+AAAoXUhUAwAsl5GRoZdffllfffWVJKlcuXK6/vrr1axZMzVo0EDx8fFKSUnR1q1b9d5772nLli3mtZMnT1a7du2KfVbWoUOH9MILL/jsdRkREaEhQ4bo9ttvL7bnAAAQqEpb+/3CCy/o008/VVBQkDwej/nlOu03AAB/KU3t97Fjx3THHXfo1KlTOnr0qM+50NBQNWnSRJ06dVJCQoLKly//j58HAABKPxLVAABL7dq1SyNGjNDy5cslSfXr11f37t3Vvn171a5du8AyYFu2bNH48eO1dOlSSVKtWrU0d+5cVahQoVjjysrK0n//+1+99tprkqR///vfevTRRxUcHFyszwEAIBCVpvbb+2X5O++8o0mTJsnhcJhJ6gEDBuixxx6j/QYAQKWr/faaMWOGXnvtNXNFFEnq0KGD2rZtq7Zt27JVBwAAZQyJagCApcaPH6+JEyfK7XarcuXKGjx4sLp27aqwsDBJf+1Z5XQ6ZbfbZRiG9u3bp5tuukkul0sul0sDBw7U4MGDiz227du3a/HixUpISFDt2rWL/f4AAASq0th+79ixQwMHDlRycrI6dOigp59+WhdddFGx3R8AgEBXGtvv9PR0Pfvss8rIyFDdunXVs2dP1a5dWyEhIQUS5wAA4MLn8HcAAIALi8fjkdvtlt1uL3Du1KlTOnnypNxut6KjozVs2DC1atXKp463k+xw5DVRu3bt0qhRo5STk2Memzp1qrp06aIGDRoUa+z16tVTvXr1ivWeAAAEgkBsv2vXrq3HH39c4eHhatOmTbHcEwCAQBKI7XeFChU0fPhw5ebmqmrVqsVyTwAAELiKb3NPAECZ53Q6ZRiG7Ha7uQRnfuXKlVP37t0VFxenhIQEs5PsXdzD5XJJkhwOh7KzszVy5EglJCTohx9+kGEYcrlcstvtysnJ0eTJk8WiIAAA/HOB2n4HBwera9euJKkBAGVSoLbfkhQeHk6SGgAASCJRDQAoRt4R14mJiUpISNDBgwcL1KlTp46GDh2qRx55pMA57yjwzz77TK1atdL06dMl5Y3yjoyMVIcOHczO9IIFC/S///2vhN4EAICyg/YbAIDAQ/sNAAAuBOxRDQAoNtu2bdNTTz2lbdu2qUGDBpo9e7ZCQ0MLre92u2Wz/TVmavv27XrjjTe0dOlS81hYWJg6deqkBx54QLVr11afPn20du1aSdKVV16p6dOnq3z58iX3UgAAXOBovwEACDy03wAA4ELAjGoAQLFZuXKltm3bJilvmbGzdZIlyWazmSO0N2zYoBEjRmjFihXm+fj4eI0fP14jR45U7dq15XK5dPPNN0vKG+W9detWJSUlldDbAABQNtB+AwAQeGi/AQDAhYBENQCUccWxsIb3Hunp6eax2NhYSTrjXln52e12ZWVladq0aVq9erVyc3Nls9n0+OOP67///a9atGghSeb+WHXr1tVFF11kjgR/7733lJyc/I/fAQCAQEL7DQBA4KH9BgAA8EWiGgDKqDVr1hTbvQzDkCSdOHHCPBYUFCTpr32zzmbChAlauHChJOmSSy7RxIkTdf/990uSOeLbu3/WZZddptTUVLlcLgUFBeno0aOaNm1acb0KAAClGu03AACBh/YbAADgzEhUA0AZs2nTJt15553q27evfvzxRxmGcdZR1x6PR263u0j33rNnj9lpvvjiiyXpnNceO3ZMX3/9tXndjTfeqBYtWsjj8cjj8ZgdZEnKzc1VWFiYatasacYmSTNnztTmzZuLFCMAAIGI9hsAgMBD+w0AAHB2JKoBoAw5ceKERo4cqY0bN0qS3nrrLUmFj7p2Op0yDEM2m005OTlmp/f0jrV31LXb7ZbH45HNZlNISIgkmUuEFSYlJUVHjhyR3W5XTEyM+vXrp+DgYBmGYXaevYKCgpSSkqKUlBSVK1dOFSpUkJTXYR43btw5lzkDACAQ0X4DABB4aL8BAADOjUQ1AJQh4eHh+ve//212MH/++WclJiYWWt/bgR4/frwSEhI0cuRIHTx40Kdj7R11nZ6erv3790vK6zDXqFGjSDGdOnVKOTk5cjqdSk9PV1pamnnf/M/wWr58uY4fP64rrrhCQ4YMMY8vW7ZMu3btKtIzAQAIJLTfAAAEHtpvAACAcyNRDQBliM1mU9OmTdWqVStJUocOHdSxY8dC6//000+6/vrrNX78eO3fv18zZ85Uz5499cQTT5h7bHlHXWdlZZmjsIODg83lwc6lYsWKqlOnjqS8Edv57+sdQe59xm+//Wbuh1W9enV169ZNTZo0UZs2bbRkyRLVq1fv/H4gAAAEANpvAAACD+03AADAuZ15rRkAwAWrUqVKeuCBB9SvXz81btxYUt4I7DMtEZaTk6PWrVtr9erV+uOPPyTl7Wk1f/58LVy4UJ06dVKHDh2UkJCg4OBg7du3TzabTbm5uUWOJyIiQjExMdqzZ4+OHj2qZcuWKT4+XvXq1TNjysrK0pYtW5SYmKh9+/YpJCREN910k4KDgzVp0iRVrFixGH4yAACUXrTfAAAEHtpvAACAszM8+ddzAQCUKW63W7m5ueZ+VtJfy3zl358qPT1dM2bM0NKlS7Vp0yZJeaPDPR6PPB6Prr32WtWrV0/z5s3TiRMnVLNmTX322WeqUqVKkeKYNm2aJk+erBMnTig4OFgNGjTQAw88oLi4OP3222/atWuXFi1apPXr10uSmjdvrrfeekuVKlUqpp8EAACBg/YbAIDAQ/sNAABQEIlqAIAkadGiRWdchszlcslut0vK6zB/8803SkxM1K5du5STk1Ogvs1mU3R0tKZPn65atWr5XH8670jyEydO6LnnntOyZcvMe4aFhckwDNlsNp06dUpOp1OSdOONN+qll15S1apVi+vVAQAIWLTfAAAEHtpvAACAPCSqAaCM++GHHzRy5Ejt3r1b48ePV8eOHeV0OuVw+O4Okb/Dm5qaqi1btmjq1Klau3at2bl1OBxyOp2KjIzUHXfcoV69eql69ermPTwej89IcemvzvKGDRs0a9YszZ8/37yPzWYz98mKjY3VjTfeqD59+qhGjRol+SMBAKDUo/0GACDw0H4DAAD4IlENAGXYiRMnNGjQIK1bt06SVKdOHS1YsEDSmTu1Xt5zHo9HK1as0JIlS5SYmGiOwHa5XJKk6tWrq2XLlurVq5e5H5d09j253nrrLf3444/at2+fcnJyVK1aNV1//fVq166dWrZsqeDg4OL+MQAAEFBovwEACDy03wAAAAWRqAaAMszj8eiHH37Q448/royMDEnSU089pQEDBpx1ybAz6d+/v1auXGl2oCXJbrfL5XKpXLly6tq1qzp27Ki2bdue8fr8neeMjAylp6dr3759iouLU1BQkIKCgv7h2wIAcGGg/QYAIPDQfgMAABREohoAyri0tDS98cYb+uSTTyRJwcHBWrZsmSIiIgodeX26jIwM9ejRQ3v37pXH41HLli2VmZmpDRs2FKjbsmVL3XXXXbr66qtVpUoVs1Nd2OhxAABQEO03AACBh/YbAADA17n/7wcAcEELDw/XbbfdpujoaEl5y3+9/vrrRb7e4/HIbrfLbrfL4/GoUqVKuueee/Tuu+9q6NChql27tjky3DAMLV++XI8//rjuueceffPNN8rIyDA7yYydAgCgaGi/AQAIPLTfAAAAvphRDQAXmPNdMkySsrKyNH36dL311lvmsaSkJMXFxcnpdMrhcJz1+t27d6tHjx7Kzs6W2+3WvHnzdOmll0qSjh07pvXr12vq1KnavHmzcnNzzSXJJCkiIkJPPvmkevbseZ5vCgDAhYP2GwCAwEP7DQAA8M8woxoASqmijiM6vZ53ZPX27dv1559/Ki0t7Zz3DQ0NVefOnRUfH28eGzFihCSds5Ps8Xjkdrtlt9tlGIaqV6+uKlWqmB3hSpUqqWPHjpoyZYpef/11de7c2TxnGIb69OlDJxkAcMGg/QYAIPDQfgMAAPjH2f/vBwBgObfbLUk+e1Odba8q77JdKSkp+uWXX7R+/XrNmzdPHo9HaWlpql27tlq3bq2EhARdfvnlhe5FFRMTo7vvvlubN2+WJK1bt05ff/21EhISzjqq2zAMpaamKj093bx3/lHl3rjLlSunzp07q3Pnzlq5cqV+/vlnde/eXZGRkef7IwIAoNSh/QYAIPDQfgMAAPgXS38DQCmRf2S0JG3YsEEbNmzQgAEDztpRzsjI0OrVq7Vo0SKtWrVKycnJZ6xXsWJFDRs2TNdff71CQkLk8XgKdJqPHj2qV199Vd9++60kKSoqSkuXLjXjK6yTPWfOHL3wwgtyOp1q3LixPv744zPGfLb3AAAgENF+AwAQeGi/AQAASgf+bwUASgGn0ynDMGS323X8+HE9++yzuuuuuzRmzBht375dNpvNHOktyVy6Kzs7W19++aXGjRunpKQkJScnKyQkROXLl1dERITCwsLMa06ePKmRI0dq9uzZZqf39LFKVatW1Z133qkKFSpIkg4dOqTx48dLks/zvbzHnE6nnE6n2Ql2uVxn7FTTSQYAXEhovwEACDy03wAAAKUH/8cCAH7k7fB6l/WaMmWKWrduraSkJPPYe++9J8m3k+kd9T1hwgSNGDFCv/76qySpWbNmGjRokMaOHauFCxdq+vTpGjVqlKpVqya73a5Dhw7po48+0pdffimp4H5ZhmEoPj5ePXr0MI9NmDBBhw8flt1uN+P18sb0xx9/SMrrOEdHR5v7ZQEAcCGi/QYAIPDQfgMAAJQ+7FENAH7gHQnt7fAuXrxYI0eO1P79+yXldVjLly+vbt266d577y1wfUpKil5//XXNnz9fklSrVi117dpVN9xwgy677DIFBwdLkipVqqSGDRuqcuXKmjZtmlauXKn9+/frww8/VIsWLRQZGVlgObAKFSro1ltv1dKlS/XHH3/I4/Fo9OjReuONNwqMyPbuhZW/A12zZk1JZ1+qDACAQET7DQBA4KH9BgAAKL2YUQ0AFvJ4POYSXTabTb///rsGDBigQYMGaf/+/bLZbAoODlbbtm31wQcf6Pnnn1eNGjUKLPu1ePFi/e9//5OUt/dVr1691KdPH11xxRVmJ9nj8cjlcsnj8aht27Z64IEHVL16dblcLm3fvl2TJ0+WdOblwC655BLdddddkvI67fPnz9e6detkGIacTqdZz9vR37Fjh9kpDgoKMq8DAOBCQPsNAEDgof0GAAAo/UhUA4BFvPtgORwOZWZmavjw4eratatWrFghwzBks9lUv359jRo1SpMnT1Z8fLwkFRhxnZ6ers2bNysjI0MOh0NPPfWU7r//flWtWtXned7R1oZhKDc3V19++aUOHz4swzBkGIaSkpK0adMms25+wcHB6tixo5o0aWIuTzZixAhJfy2TJuV1xt1ut9xutzwejypUqKAmTZoU/w8PAAA/of0GACDw0H4DAAAEBhLVAGARbwczMTFRrVq10qxZsyTljXyuXr26Hn30Uc2ePVsJCQmS/uq8nj7iukKFCurcubPi4uLUu3dv9ezZU9Jfy5mdvu9WYmKirrvuOn3++efmPTwej06dOqXx48dL+mtkdn7R0dG6++67zZHZv/zyi3kP76huwzCUmpqqPXv2qFevXlq2bJlatmz5j35OAACUJrTfAAAEHtpvAACAwGB4vEP1AAAlasOGDXriiSeUnJwsKa8DHBYWpi5duuj+++9XbGyspL9GYp+Jd9+pU6dOad68eWrXrp0iIyPN8/lHf69cuVKvvfaaduzYISmvUxsWFqbLLrtMW7Zskcvlks1m05gxY9S1a9czPvfYsWMaOXKkvvrqK0lSRESEfvzxRwUFBZnPys3N1cmTJ1WlSpXi/YEBAFAK0H4DABB4aL8BAAACAzOqAcACWVlZWrp0qZKTk2Wz2RQUFKQaNWrozTff1LBhwxQbG2su4VVYJ1nK6+x6PB6VK1dOPXv2VGRkpPKPN7LZbDp69KhefPFF9e/f39y7KigoSM2bN9cHH3ygN998U61atZKU17F+7733lJ2dLbvdXmAvripVqqhXr16qVKmSJCk1NVWvv/66JJnPDQoKopMMALgg0X4DABB4aL8BAAACB4lqALBAaGioOnXqpJYtW8rtdis3N1cZGRmqVq2aPB6PPB6PbDZbgWXGvLxLfUkylwLLX/Z2cH/77Te99NJLmjNnjnm+Zs2aeumll/T//t//09VXX61q1aqpUaNGKleunCRpx44d+vDDDwuNPS4uTnfccYdZnjVrlk6ePHnWDj0AABcC2m8AAAIP7TcAAEDgIFENABa55JJL1LlzZ7ODmpqaqg8++EDHjh0r0Pn1crlc8ng85n5XCxYs0O7du81zXt4O9ieffKIff/xRubm5kqRevXpp7ty5uv322yVJubm5Cg4O1lVXXSW73W52dhMTE7Vv3z7ZbDaf+0pS+fLl1aVLF9WsWVPdu3fXihUrVLFixeL6sQAAUKrRfgMAEHhovwEAAAIDiWoAsEhwcLCaNWumDh06mMe++eYbrVq1qkDn1OPxmHtWGYah9evX67bbbtNjjz2mCRMmSJLZyfUuAfb+++/r448/VnZ2tmrUqKHXXntNr776qipWrGh2uIOCgiRJzZo1U6VKlcxn/Pnnn5o4caLPffO79NJL9dlnn2n06NHmMmQAAJQFtN8AAAQe2m8AAIDAQKIaACwUGxurLl26KDo62jyWmJio5ORks+x0OmUYhux2u44cOaInnnhCd999t37++WcZhqGVK1dq8+bNZn3DMJSZmaklS5aYx9q1a6cbbrhBksx9t7yjxl0ul9LS0lS+fHnzvGEY+vrrr7V69WqzTn4Oh4N9sAAAZRbtNwAAgYf2GwAAoPQjUQ0AFvGOvG7cuLE6d+5sHl+/fr2+/fZbZWRkSJK5zNiECRPUpk0bzZ8/X4ZhyGazKTY2VoMGDVJ8fLzPvX///Xf98ssvcjgcioiI0KOPPmouD3b6vlt2u13lypUzlzyLjo6Wx+OR0+ksMFocAICyjvYbAIDAQ/sNAAAQGEhUA4BFvCOqq1Spog4dOiguLs489/HHH+vYsWOS8pYja9u2rcaNGyePxyPDMBQREaF+/fpp9uzZuvvuuwvcOzg4WDk5OXI6nQoKCtLhw4cl/dU59/KWFy9erCNHjqhq1arq27evypUrJ5fLpTVr1mjVqlUl8v4AAAQi2m8AAAIP7TcAAEBgcPg7AAAoiy6//HLddNNN+vXXX+XxeLR//369/fbbOnDggDZu3Cgpr2MdEhKiNm3a6D//+Y8uv/xySXnLgtlsNrPjLUkZGRmqWbOmkpOT5XK5dPToUdWrV0+GYcjtdpujug3DUHJysmbNmiVJat68uZo3b67vv/9eR48e1bBhw3T11Vdb+8MAACBA0H4DABB4aL8BAABKLxLVAOAH5cuXV+vWrbVq1SotW7ZMkjR//nxJMjvBcXFxGjhwoDp27CgpbzS2x+M547JgV1xxhcLCwiRJx48f17x581SnTh3FxMSYnWSXy6UdO3Zo5syZ2rRpkySpTZs2ql+/vkaMGKFatWqV+HsDABDIaL8BAAg8tN8AAAClF4lqAPCTiy++WDfddJM2btyokydPym63y+12KzIyUv3799e//vUvc78sl8slu93uM4rby+VyKTQ0VL1799Yrr7wiSfrqq6+Um5uru+++W5dffrl+//137dixQ4sXL9bSpUvlcrkUFxenli1bShKdZAAAioj2GwCAwEP7DQAAUDoZntM3UAEAWCY5OVnjx49XUlKSbDab3G63hg4dqnvuuUeS5HQ6zc5yYbz7aElSz549tWXLFvNceHi4wsLCZLPZlJ6errS0NElS48aNNXz4cF1yySUl82IAAFzAaL8BAAg8tN8AAAClj83fAQBAWVazZk116tRJsbGxcrvdkqRvvvlGO3fulMfjOWcnWcrb98rpdEqSXnjhBV111VXm8YyMDKWkpCg5OVlpaWmqXLmyevbsqZdffplOMgAAfxPtNwAAgYf2GwAAoPRhRjUA+Il3JPbx48c1bdo0vffee+a5Rx99VP3791doaOh53/ePP/7QjBkz9N133+nw4cOSpNDQULVu3VqtWrVSQkKCKlasWGzvAQBAWUL7DQBA4KH9BgAAKJ1IVANAKbBx40aNHDlSmzZtkiRFRUVp3Lhxio+P/1v383g8OnjwoI4ePark5GRdccUVqly5sipUqFCcYQMAUKbRfgMAEHhovwEAAEqPc69pAwAocQ0aNFDXrl31888/y+l06tChQ/rss89Up04dhYeHn/f9DMNQzZo1VbNmzb/d2QYAAGdH+w0AQOCh/QYAACg92KMaAEqB0NBQtWjRQm3btjWPzZ07Vz/99JNY+AIAgNKJ9hsAgMBD+w0AAFB6kKgGgFKibt26uummm1S5cmVJUk5Ojj7++GNznysAAFD60H4DABB4aL8BAABKBxLVAFBK2Gw2XXPNNbrxxhvNY8uWLdP333+v3NxcP0YGAAAKQ/sNAEDgof0GAAAoHUhUA0ApEhUVpU6dOqlu3brmsY8++kh79+71Y1QAAOBsaL8BAAg8tN8AAAD+R6IaAEoJ715YV155pW666Sbz+Pbt2zVv3jydOnXKX6EBAIBC0H4DABB4aL8BAABKBxLVAFBKGIYhSQoPD1e7du3UtGlT89wnn3yijRs3+ikyAABQGNpvAAACD+03AABA6UCiGgBKoXr16qlbt24KCwuTJB07dky7du0yR30DAIDSh/YbAIDAQ/sNAADgPw5/BwAAKCg4OFhNmzZVo0aNdPDgQb366qs+I7wBAEDpQ/sNAEDgof0GAADwH8PD8EAAKLUOHDigmJgYf4cBAADOA+03AACBh/YbAADAeiSqAQAAAAAAAAAAAACWYo9qAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCkS1QAAAAAAAAAAAAAAS5GoBgAAAAAAAAAAAABYikQ1AAAAAAAAAAAAAMBSJKoBAAAAAAAAAAAAAJYiUQ0AAAAAAAAAAAAAsBSJagAAAAAAAAAAAACApUhUAwAAAAAAAAAAAAAsRaIaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKVIVAMAAAAAAAAAAAAALEWiGgAAAADOIikpSfXr1zf/Wb16tb9DAlAE+/fv9/ndHTduXLHUBQAAAAAUD4e/AwAAAABQtuzfv18dOnT4R/e49dZbNWrUqGKKCOdj9erV6tu3b4k+Y+TIkerRo4dZbt++vQ4cOHDWa4KDgxUeHq6qVasqLi5OTZo0UZcuXVS+fPnzevbp73fttddq5syZ5/cCAAAAAADgnJhRDQAAAAAIeDk5OTp69Ki2bdumOXPm6LnnnlPr1q31/vvvy+Vy+Ts8XGDyz74eOnSov8MBAAAAgIBEohoAAAAAcEHKyMjQG2+8oUGDBpGsBgAAAACglGHpbwAAAAB+FRUVpY8++ui8rgkLCyuhaHAujRo10uLFi4tU9+6779ahQ4fMcmJiomrUqHHO6ypXrnzW82e6T05Ojo4cOaJ169bpk08+UUpKinnu+++/11tvvaUnn3yySHEDAAAAAICSR6IaAAAAgF85HA7VqlXL32EUqkePHj77JZd1ISEhRf7zcjh8u5w1atQolj/rwu5z8cUX67rrrlO/fv30+OOP63//+595bsaMGerTp4+ioqL+8fNx4alVq5a2bdvm7zAAAAAAoExh6W8AAAAAwAWlfPnyevPNN1WtWjXzWHZ2tr799ls/RgUAAAAAAPIjUQ0AAAAAuOCUL19e3bt39zm2du1aP0UDAAAAAABOx9LfAAAAAC4YHo9Hu3bt0q5du5SSkqKMjAwFBwcrIiJCderUUcOGDRUcHOzvMIvNoUOHtGPHDu3bt08nT56UJEVERCg6OlqNGzdWxYoV/RyhfzVs2NCnfPDgQT9FUjIOHTqkzZs3KyUlRdnZ2apevbquuuoq1a5du1ifs3nzZu3du1eHDx+W0+nUZZddpuuvv/6s1+Tk5Gjjxo06cOCA/vzzT9lsNlWpUkUNGjRQgwYN/nFMe/bs0ebNm3X48GGFhISoRo0aio+PD8il3TMzM7Vjxw7t3r1bx48fV1ZWlipWrKgqVaroyiuv1EUXXeTvEAEAAACgRJCoBgAAABDQsrKytGTJEi1cuFCrVq3SiRMnCq0bGhqqhIQEDRw4UHXq1CnS/ZOSkvTMM8+Y5RkzZui6667zqeN2u3XPPfdo9erV5rHBgwfrgQceKNIznnjiCc2bN88s33333XrppZcK1HO73frpp580f/58LV++XPv27Sv0njabTc2aNdPAgQPVrFmzIsVxoYmIiPApp6Wl+SmSv2fcuHEaP368WV68eLFq1aqlrVu36t1339WPP/4ol8tV4LqrrrpKQ4cO1dVXX12k59SvX9/8fOutt2rUqFFyu92aOnWqPvroI+3fv9+nfoMGDQpNVO/atUsTJkzQkiVLlJmZecY6UVFR6t+/v3r37n3eA0fWrVunUaNGafPmzQXO2e12tWrVSo888oiuvPLK87rv/v371aFDB7P80EMP6eGHH/apM3ToUM2ZM6fAtXPmzDnjca8z7X194MABzZ8/X99//722bNmi3NzcQq+PiYlR3759deeddyo0NLQorwMAAAAAAYGlvwEAAAAEtBdffFGDBw/WggULzpqklvKS2klJSerevbtPYvifstlsGjt2rKpUqWIeGzdunNatW3fOaz/99FOfWBo0aOCTGM8vKSlJffr00ezZs8+apJbyktorVqxQv379NGrUqDMmNC906enpPuULYTb9l19+qTvvvFNLly4t9M9006ZN6t27t957772/9YzU1FT169dPY8aMKZCkLozH49E777yjbt26ad68eYUmqaW8meCjRo1Sjx49Q7Z19QAAFuBJREFUzmuW++TJk9W7d+8zJqklyeVyaenSpbrzzjv15ZdfFvm+VnO5XOrQoYPeeOMNrV+//qxJaikvqT1y5EjdcccdOnDggEVRAgAAAEDJY0Y1AAAAgIDmdrt9ypUqVdKll16qypUrKzQ0VBkZGdq9e7f27Nkjj8cjKS9h/eSTT6pixYpq27ZtscRRvXp1jRkzRvfdd588Ho+cTqeeeOIJzZ07V5UqVTrjNTt27NDw4cPNclhYmN5+++1CE6re+L1CQ0N16aWXKjIyUhUqVFB2draSk5O1bds2n+TX1KlT5XA49OSTT/7zFw0gv/76q085JibGT5EUj7Vr1+r555+X0+mUlDcz+fLLL1dYWJiSk5O1efNm8/fB7XbrzTffVEhIiO65554iP8Pj8WjIkCFas2aNJMnhcKhhw4aqUaOGsrOz9ccff5zxmqefflpffPGFz/HQ0FDFxcWpevXqkqS9e/fq119/Nf8e79ixQ3feeac+++wzRUZGnjWuadOm6a233vI5ZrfbFR8fr+joaGVkZOiXX37RkSNHlJubq2eeeUYjRowo8ntbyePx+PwuG4ahWrVqqXbt2goPD5dhGDp+/Lh+/fVXHT9+3Kz322+/acCAAUpKSlL58uX9EToAAAAAFCsS1QAAAAACXr169dSjRw9df/31hS7pvW/fPr333nv69NNPJeUli4YOHarFixcrLCysWOJo3bq17r33Xn3wwQeS8vZEHjp0qCZPnlygblZWlgYPHqysrCzz2EsvvaS6deue9RnVqlVTjx491L59e8XHx8tutxeok5aWptmzZ2vixIk6deqUJGnKlCm64YYbdNVVV/2TVwwYubm5BRKnTZs29VM0xeO1116T0+lU1apV9dJLL+mGG26QzfbXQmmHDh3S8OHD9e2335rHxo4dqxYtWqhevXpFesa3336rzMxMGYahfv366T//+U+BgRanz7L+4IMPfH7WERERGjx4sHr06KGQkBCfuvv27dNrr72mJUuWSJJSUlI0dOhQTZkyRYZhnDGmbdu2aezYsT7HunbtqqFDh/okuN1utxYsWKBhw4bp2LFjeu2114r0zkX11FNP6aGHHpIkn2XCO3XqpKeeeuq87uVwONShQwd17txZrVu3PuN+8m63W8uXL9eYMWO0fft2SXl7c48dO/aMWwMAAAAAQKAhUQ0AAADArw4cOOCzR+65jBw5Uj169DDLjz/+uGrWrHnO62JjYzV8+HBdcsklGjVqlCTp2LFjmjt3ru6+++7zD7wQjz32mH766Sdt2LBBkvT9999r2rRpBWa1Dh8+XDt27DDLt956q2655Zaz3rtdu3bq3r37OZewDg8P1/3336+mTZuqb9++ysnJkcfj0dSpU/X222//ndcKKC6XSy+//LLPMsmhoaHq1q2bH6P659LS0lSpUiXNnDlTl1xySYHzUVFRGjdunJ555hklJSVJykvYDxs2TDNnzizSM7xLdr/88su68847z1inVq1a5ucdO3bonXfeMcs1atRQYmKiT538YmNjNXHiRD377LNmjD/++KOWLl2qdu3anfGa4cOH+6wQ0Lt3b7344osF6tlsNiUkJOiyyy5T7969lZqaevaXPU9VqlTxWd7fKywsrND3PRO73a7vvvvunP/dstlsat26ta655hr1799fGzdulJS3BcCjjz5a6EoNAAAAABAo2KMaAAAAQEArSpI6v/79++uKK64wy998802xxuNwOPTmm28qIiLCPDZ27Fht2bLFLM+fP9+c2S1JdevWPWPi7XSRkZHntc9y48aN1bt3b7O8aNEi5eTkFPn6QJKTk6MDBw7oiy++UK9evfTZZ5/5nH/44YfNJagD2dNPP33GJHV+L774os/vxZo1a/T7778X+RnXX399oUnq002ZMsVcitwwDL3zzjvnTNoahqGXX35ZNWrUMI/NmDHjjHV37NhhLkMuSXXq1NHQoUPPev/LLrtMQ4YMKVL8/mAYxnn9dyssLEyvvPKKWc7KyjJnpAMAAABAICNRDQAAAKDMad++vfl569atcrlcxXr/mjVr+iw7nJubq8GDBys9PV1//PGHXnjhBfNcSEiI3n777WJbfvx0+Zcozs3NLbBvcyDq0KGD6tev7/NPw4YN1b59ez311FPaunWrT/377rtP9957r5+iLT41a9bUrbfees565cqVU//+/X2OffXVV0V+zoABA4pULy0tTfPnzzfL7dq1U6NGjYp0bUhIiHr16mWWV69ebS5Tn9/pcd97771FGqxx2223KSoqqkixBIIGDRr4DADYtGmTH6MBAAAAgOLB0t8AAAAA/CoqKkofffRRketXrly5SPVcLpfS09OVmZlZIBGdP9GVmZmplJQUxcTEFDmGoujYsaP69u1rzhTdt2+fnn32We3fv18ZGRlmvaFDh6pBgwb/6Fkej0cZGRnKyMjwWSLZey6/Xbt2lYl9qg3DUNu2bXXfffepSZMm/g6nWHTq1KnQfZxPl5CQoBEjRphl71L051KxYsUi7+W9fv16n79vnTp1KtJ1Xvn/XJxOpzZt2qRmzZr51Mkft81mK/IzbDabOnfurOnTp59XTP6WnZ2t9PR0ZWVlFfjdrVSpkrk/+K5du/wRHgAAAAAUKxLVAAAAAPzK4XCc1/6uhcnIyNB3332nxYsX67ffftO+ffsKJHoKk5aWVuyJakkaMmSI1q9fb87wXbhwoc/5Tp06/a39sV0ul1asWKEFCxZoy5Yt2rVrV4EEdWGKe9/e0srj8SgzM/OCmlXbsGHDItetVq2aoqOjdfDgQUnSzz//XKTrGjRoUORk+Pr1633K+ROpReF2u33K+fcU9/rll1/Mz7Vr11Z4eHiR738+Py9/2bNnj+bNm6fVq1dr+/btOnHiRJGuS0tLK9nAAAAAAMACJKoBAAAABLykpCSNGTNGx48f/1vXp6enF3NEeYKDg/X222/rlltuKfCMmJgYDR8+/LzvuWHDBr344ovavn3734qppN7VSomJiT77GzudTh08eFA7duzQrFmz9Mcff0jK25v5rrvu0scff6zY2Fh/hVtszvcdLrroIjNRnZ6erpycnHMum12lSpUi3z8lJcWn/MADD5xXfKc7fRCFd3ax10UXXXRe96tdu/Y/iqckpaWlafTo0fr888+LPKAmvwvh9xgAAAAA2KMaAAAAQEB799139cwzz/ztJLVUcGZncYqNjT3jrOkRI0ac1+xQSfrhhx/Ut2/fv52klgouBR6IatSooVq1apn/1KlTR82bN1ffvn21YMECn/2Zjxw5okGDBiknJ8ePERePChUqnFf9ihUr+pSLMgv3fPZKL+7Z+ZmZmT7l0+M93/c/3/pWSU1NVb9+/fTZZ5/97d/HC+H3GAAAAACYUQ0AAAAgYK1Zs0YTJkzwOdaoUSN16dJFV155pWrUqKHKlSsrODhYQUFBZp2kpCQ988wzlsS4Z88ezZo1q8DxuXPnqnnz5kW+z4kTJzRkyBCfhGtMTIy6d++uxo0bKzY2VtWqVVNISIjPrNn9+/erQ4cO/+wlAojNZtPTTz+tPXv26Pvvv5ckbdu2TZMmTdKjjz7q5+guLE6ns1jvV1aSr6NGjfJZ0jwkJERdunRRixYtVK9ePVWvXl1hYWEKCQmRzfbX/II+ffpozZo1/ggZAAAAAEoEiWoAAAAAAWvixIk+5eeff159+vQ553UZGRklFZKPnJwcDR48uMBMUemvRPUtt9xSpHt99NFHPvvX3nTTTRo1atQ5l3K26l1LE8Mw9Morr2j16tXmz/7DDz/U7bffXiJ7kVvlfJd7PnnypE/5fGfwn0tERIRP+euvv9Yll1xSbPc/Pd7zff/SuDz2wYMHNWfOHLNcvXp1TZ8+XRdffPE5ry2Lv8sAAAAALmws/Q0AAAAgIGVkZOinn34yyy1atChSklqSjh49WlJh+RgzZozPzMnmzZsrNDTULL/yyivavXt3ke61dOlS83PFihU1fPjwcyapJevetbSJiorSv/71L7OcnZ1dYGBDoNm3b9951d+7d6/5uUKFCkX6+3I+Tt/P+p8sv38mISEhPst353+fovDuVV6aLF261Gfm+JAhQ4qUpJbylrEHAAAAgAsJiWoAAAAAASk5OVm5ublmuVWrVkW+duPGjSUQka9FixZp5syZZjk2Nlbjx4/Xc889Zx7LzMzU4MGDi7R/cv6k2zXXXFPkvYSteNfSasCAAT4/p7lz52r//v1+jOif2bJlS5HrHjlyRAcPHjTLV1xxRbHH06hRI5/ypk2biv0ZcXFx5uc//vijSPtse53Pz8sqpyfPi/rfrYMHD+rw4cMlERIAAAAA+A2JagAAAAAB6fRljfPPvDyblJQUn5nYJSE5OVnPPvusWQ4KCtKbb76pChUqqFevXurSpYt57tdff9Xo0aPPec/8yxgX9V09Ho/mzZt3HpFfWCpXrqyePXuaZafTqffff9+PEf0zCxcuLPI+zt98841PuXHjxsUeT7NmzWQYRqHPLA7543a73Vq4cGGRrnO73VqwYEGxx+OVf3Z6/gEz53L6cuRF/V3+6quvivwMAAAAAAgUJKoBAAAABKTT96/ds2dPka5755135HQ6SyCiPE6nU48//rhSU1PNY0888YTi4+PN8rBhw1SrVi2zPGvWLC1atOis961YsaL5uajLhX/xxRfatWtXUUO/IP373/9WUFCQWU5KStKhQ4f8GNHfl5yc7LO/cWGysrI0depUn2PdunUr9niqVaumjh07muUtW7YUe7L69LinTJlSpBUIPv/88xL9c87/+3g+S3Lnv04q2n+3jh07pmnTphX5GQAAAAAQKEhUAwAAAAhIF110kcqVK2eW586de849cj/++GMlJSWVaFzvvvuuNmzYYJbbtWune+65x6dOxYoV9dZbb/kkUJ999lmfpZpPV69ePfPzzz//rDVr1pw1js2bN2vYsGHnGf2FJyoqSrfccotZzs3N1QcffOC/gP6h0aNHn3PwwSuvvKLk5GSzfO211+rSSy8tkXgGDRokm+2vrxaeffbZc/7dPN3hw4d99mDP77LLLtO1115rlvfs2aNRo0ad9X6///67Xn/99fOK4XzVrVvX/LxlyxZlZGQU6br8v8eSCgwoON2pU6c0ePBg/fnnn+cfJAAAAACUciSqAQAAAASk4OBgtWvXziwfO3ZMAwYM0Pbt2wvUPXr0qF566SW9/PLLkvKWhC4Jy5cv91laOioqSiNHjvRZHtkrPj5egwcPNsupqal64okn5HK5znjvTp06+ZQffvhhLV68uEC9rKwsTZs2Tf369VN6enqJvWsguffee32SqZ9++qmOHj1apGuzs7O1f//+8/4nJSWl2N8jPDxcJ06cUJ8+fbRw4UK53W6f84cOHdIjjzziMxgjKChIL7zwQrHH4nX55ZfrscceM8uZmZm65557NHz4cO3du7fQ69LS0vT111/rscceU/v27TV37txC6z7//PM+gzoSExP1xBNPFJjJ7Ha79c0336hPnz5KTU0tsOpCcWrSpIn5OTMzUwMHDtR3332nnTt3Fvi7kF+bNm18BtgkJSVp5MiRBZYEl6SffvpJd911l1atWiXDMFSpUqUSex8AAAAA8AeHvwMAAAAAgL/roYce0pIlS5SdnS1J+uWXX9StWzddfvnlqlu3rtxut5KTk7V161YzqVe7dm317t1br732WrHGcvToUT311FPmHsJ2u11vvPGGqlSpUug1AwYM0KpVq/TDDz9IktatW6d3333XJ4Htdfvtt2v69OnmUsEnTpzQgw8+qJiYGMXFxSkkJERHjhzR5s2bderUKUlSaGioXn75ZT366KPF+q6Bpk6dOurcubO+/vprSXnJ/A8//FBPP/30Oa/dtGmTOnTocN7PjImJ0ZIlS877urMZOnSoXnjhBR09elSPPPKIoqKiFBcXp7CwMCUnJ2vTpk0FktdPPvlkgVm8xW3gwIE6cOCAPvnkE0mSy+XSzJkzNXPmTNWqVUsXX3yxwsPD5XQ6dfLkSe3Zs0cHDhwo8v3r16+vJ598UiNHjjSPzZs3T998842uuuoqRUdHKzMzU1u3bjWT1w6HQ88884yeeeaZ4n3Z/9OzZ09NnTrV/G/P2rVrtXbt2jPW3bZtm/m5SpUq6t+/vyZOnGgemzZtmv773/+qUaNGqlq1qtLT07Vt2zafWfH9+/fX1q1bz3u2OgAAAACUZiSqAQAAAASsSy+9VKNHj9aQIUOUm5trHv/111/166+/Fqhfp04dTZkypdCE0t/ldrs1ZMgQn1m6Dz74oJo2bXrW6wzD0OjRo3XzzTebCbb3339fzZo1U/PmzX3qBgcHa+LEierXr5/PTNIDBw6cMekXFhamd955RxdffPE/ebULxsCBA81EtSTNnj1b991331kHEpQ21113nUaMGKHnnntOLpdLhw4dKnQfZsMwNHjw4ALLzpeUV199VfXr19eYMWOUlZVlHj/TrOIzOdfs53vuuUenTp3SO++8Yw4GcblcWr9+fYG6DodDI0aM8Jn1XNxq1aqlUaNG6ZlnnvF536J46KGHtHPnTi1cuNA8lpmZqRUrVpyx/h133KEhQ4aoX79+/yhmAAAAAChtWPobAAAAQEDr0qWLPvroo7MmpapXr64HHnhASUlJio2NLfYY3n//fZ8k07XXXqsHH3ywSNdWqVJFY8eONZem9ia9z7Qn7SWXXKI5c+bo5ptvlsNx5nHHYWFhuuWWW/Tll1+qTZs2f+NtLkwNGjRQ27ZtzXJmZqamT5/ux4j+nltvvVWzZ89Wq1atfJYzzy8+Pl6JiYkaOHCgpbH17t1bixcv1oABAxQVFXXO+nXq1NG//vUvzZ49W6+88so56//nP//RrFmzFB8ff8bzNptNrVq10scff+yzL3lJSUhI0Ndff62HHnpI1157rSIjIxUaGnrO6+x2u9555x0999xzioyMLLRe48aNNW7cOL366quF/lkDAAAAQCAzPN6hyAAAAAAQ4Pbt26d169aZM5sjIyMVGxurRo0aXXCJnuPHj+unn37SgQMHlJ2drapVqyoqKkpNmjTx2QMXgWvcuHEaP368WV68eLFq1aplllNSUrRp0yalpKQoJydHkZGRatSokerUqeOHaAvauXOntm3bpuPHjystLU3BwcEKDw9XbGysLr30UlWrVu1v33vPnj3auHGjjhw5opCQEEVFRSk+Pl7R0dHF+AYlLzc3V5s3b9a2bduUlpamChUqKDIyUnFxcSUyqAYAAAAAShMS1QAAAAAAlELnSlQDAAAAABDILqwpBQAAAAAAAAAAAACAUo9ENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKVIVAMAAAAAAAAAAAAALEWiGgAAAAAAAAAAAABgKcPj8Xj8HQQAAAAAAAAAAAAAoOxgRjUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCkS1QAAAAAAAAAAAAAAS5GoBgAAAAAAAAAAAABYikQ1AAAAAAAAAAAAAMBSJKoBAAAAAAAAAAAAAJYiUQ0AAAAAAAAAAAAAsBSJagAAAAAAAAAAAACApUhUAwAAAAAAAAAAAAAsRaIaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACW+v9h/oRFsZDQ2QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 730
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "233696f882664221a7cfb639320c28a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0bf600da55b41b794aec8b1655fcba1",
              "IPY_MODEL_ac43d19ef5eb4df0978916bcc1968862",
              "IPY_MODEL_e96672334bc24c1c8525d49667ca941c"
            ],
            "layout": "IPY_MODEL_6d32af1a1f804bb9a2c6b93fec1a0df6"
          }
        },
        "d0bf600da55b41b794aec8b1655fcba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96f39b4401e24f4b95feb4f12fb3054d",
            "placeholder": "​",
            "style": "IPY_MODEL_00b54820e0124993bfaa7d03c98cc7b2",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "ac43d19ef5eb4df0978916bcc1968862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60226ad6ff8a4212867bb517349665d0",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_995eaa3845294f9088b49ab0636dbf29",
            "value": 29
          }
        },
        "e96672334bc24c1c8525d49667ca941c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065ab5c4f5444f86bb481ba6d8bdb4c9",
            "placeholder": "​",
            "style": "IPY_MODEL_037df700fd494a7bba9872cfac3ea702",
            "value": " 29.0/29.0 [00:00&lt;00:00, 520B/s]"
          }
        },
        "6d32af1a1f804bb9a2c6b93fec1a0df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f39b4401e24f4b95feb4f12fb3054d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b54820e0124993bfaa7d03c98cc7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60226ad6ff8a4212867bb517349665d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "995eaa3845294f9088b49ab0636dbf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "065ab5c4f5444f86bb481ba6d8bdb4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "037df700fd494a7bba9872cfac3ea702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cda27ee605c24c7eaef8641bf1f389ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69700ab2ad0f40d3a99e675c40cca443",
              "IPY_MODEL_44b2724f192c4c7fad911b43d8b7cdf7",
              "IPY_MODEL_7e500460954d43d8811977ad2198794d"
            ],
            "layout": "IPY_MODEL_34b58457ac364906b40265a86795c8f4"
          }
        },
        "69700ab2ad0f40d3a99e675c40cca443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9961d02db0f344c48e943507abe68da0",
            "placeholder": "​",
            "style": "IPY_MODEL_3d656244a9f9403d8b9533c25120a92b",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "44b2724f192c4c7fad911b43d8b7cdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a468c79c5e74b4996aaa85367df653a",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8832c0588510447dab0b07bbec99e102",
            "value": 995526
          }
        },
        "7e500460954d43d8811977ad2198794d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b935378f000140b69fd63906c647a9db",
            "placeholder": "​",
            "style": "IPY_MODEL_4f076837bd0245079cbab6f6f40d0d98",
            "value": " 996k/996k [00:00&lt;00:00, 4.02MB/s]"
          }
        },
        "34b58457ac364906b40265a86795c8f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9961d02db0f344c48e943507abe68da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d656244a9f9403d8b9533c25120a92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a468c79c5e74b4996aaa85367df653a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8832c0588510447dab0b07bbec99e102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b935378f000140b69fd63906c647a9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f076837bd0245079cbab6f6f40d0d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b684cf33db2244d2a6692557e7f812e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_798fc27bdaa647ee84100f5ed80b280a",
              "IPY_MODEL_92e8c5172ba34961a8c06fba4237de39",
              "IPY_MODEL_162376024f5f4379930ede0e15d95be0"
            ],
            "layout": "IPY_MODEL_e150b44bfe974e5c8d41af9e9ebc76f6"
          }
        },
        "798fc27bdaa647ee84100f5ed80b280a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff882d7f7fd6467a937b93dea62f5b1b",
            "placeholder": "​",
            "style": "IPY_MODEL_a07a930b544b45709063270fabdacf8a",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "92e8c5172ba34961a8c06fba4237de39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dff8d9111b7043758e4494df890b4367",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4d11e3fe35d40e7a53bf8f959695b2a",
            "value": 1961828
          }
        },
        "162376024f5f4379930ede0e15d95be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0a6e58c08e344f8a5fb6982d6ba6690",
            "placeholder": "​",
            "style": "IPY_MODEL_3ffd106c93014276929f0d8286f2fcbe",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 19.5MB/s]"
          }
        },
        "e150b44bfe974e5c8d41af9e9ebc76f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff882d7f7fd6467a937b93dea62f5b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07a930b544b45709063270fabdacf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dff8d9111b7043758e4494df890b4367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d11e3fe35d40e7a53bf8f959695b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0a6e58c08e344f8a5fb6982d6ba6690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ffd106c93014276929f0d8286f2fcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dd6b497f2474ede9070e56ca562c1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f561bed867e943d59b33725da8e12ddf",
              "IPY_MODEL_6bf748838ec343539716e573b1c2999d",
              "IPY_MODEL_f521dcf422404a7296262ce70f57351c"
            ],
            "layout": "IPY_MODEL_1e6ea9450a1745ba9470a7ac6f236f0f"
          }
        },
        "f561bed867e943d59b33725da8e12ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc3c20a6ef4f48ff9b95446aada3633b",
            "placeholder": "​",
            "style": "IPY_MODEL_ff3c0ec0b64e4a1ca576760943b9f0d9",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "6bf748838ec343539716e573b1c2999d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba774e96b953483a99daa43d1c80f97b",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63c0369a9d2d4198a395c5c1a41ad146",
            "value": 625
          }
        },
        "f521dcf422404a7296262ce70f57351c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b8df1bb3f84b138e298a1dd80eb935",
            "placeholder": "​",
            "style": "IPY_MODEL_d89035617eee4bd2ac6e1a63906de050",
            "value": " 625/625 [00:00&lt;00:00, 50.1kB/s]"
          }
        },
        "1e6ea9450a1745ba9470a7ac6f236f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3c20a6ef4f48ff9b95446aada3633b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff3c0ec0b64e4a1ca576760943b9f0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba774e96b953483a99daa43d1c80f97b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63c0369a9d2d4198a395c5c1a41ad146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72b8df1bb3f84b138e298a1dd80eb935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89035617eee4bd2ac6e1a63906de050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a82513214d1423aa7f6b473a6636d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d87da6ac105542409f680890157cc7d6",
              "IPY_MODEL_1c1940cf693f4c8cb8eca2236aebea6e",
              "IPY_MODEL_6fd07c43ff1f41649764852b77317e13"
            ],
            "layout": "IPY_MODEL_4367998d6eb94eae86b3c0a3a03be959"
          }
        },
        "d87da6ac105542409f680890157cc7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3da522be68fa4a3fbbe9fb8a4367103e",
            "placeholder": "​",
            "style": "IPY_MODEL_48f07d7a278f41b1909c235636845df2",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "1c1940cf693f4c8cb8eca2236aebea6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bbaab5323264b5a8dee224d3d39b18b",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d397aa5f0b86479cac2e13e7e6b345c8",
            "value": 714290682
          }
        },
        "6fd07c43ff1f41649764852b77317e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0ad0c21104b4036969b3e225e65545e",
            "placeholder": "​",
            "style": "IPY_MODEL_4ea00095049745f086b0f9982b9742c1",
            "value": " 714M/714M [00:05&lt;00:00, 119MB/s]"
          }
        },
        "4367998d6eb94eae86b3c0a3a03be959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3da522be68fa4a3fbbe9fb8a4367103e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48f07d7a278f41b1909c235636845df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bbaab5323264b5a8dee224d3d39b18b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d397aa5f0b86479cac2e13e7e6b345c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0ad0c21104b4036969b3e225e65545e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ea00095049745f086b0f9982b9742c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}