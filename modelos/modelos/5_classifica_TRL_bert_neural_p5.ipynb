{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural [kfold][P5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 5**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 242 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "3d3ed268-241a-4561-eda0-ae7dbc157790"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=5  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "c20c7d50-fcdf-4455-b4e8-5865cf9ee6dc"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_5.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 242"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "9cZxPMZOfICS"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "h5RDBcpVf0TS"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "283a127c-2550-43d6-fb47-cad9279df5b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 24 01:57:24 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    27W /  70W |   5609MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "b19297e8-ac7f-402c-f318-6f00c419544a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "c1058cd8-458f-4a7c-e14f-e5d95bd66e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "WPj7c-IBgWRx"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "qSErznNMh4P5"
      },
      "outputs": [],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "64187b4d-0178-44ae-dc0e-48c762204000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "6a60d7d7-64ce-41a3-9b21-30b3bb25c66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-117-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "b93e7110-0140-434f-a890-235092bc2299"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50d84ece-ec74-4708-93fb-8b16bd34118d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50d84ece-ec74-4708-93fb-8b16bd34118d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50d84ece-ec74-4708-93fb-8b16bd34118d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50d84ece-ec74-4708-93fb-8b16bd34118d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a161e0e-f676-420c-82af-01040625ece0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a161e0e-f676-420c-82af-01040625ece0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a161e0e-f676-420c-82af-01040625ece0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "338c6a68-5161-45a1-c8a6-a1e5455b25ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "96ee46da-7fde-4558-b507-93d6192dbc63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((108, 2), (27, 2), (33, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "fc3107f9-3c36-4619-bba4-52d453ae26d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "567f06f6-a6ee-4187-e536-49d5c4ed004e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "59839798-4250-486d-f8c0-d005e3cce34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "a1f9afd1-433d-4305-cf45-4b0718f2d364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "68db7d24-ac74-4202-bb5d-2aabc9519392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "cc087bf0-99c4-4a98-8348-3c613cfdf476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "c54caa2a-e952-4a8c-e2f5-385f9059aa0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.1002428446497237 accuracy 0.537037037037037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9394871592521667 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9539880454540253 accuracy 0.5555555555555556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8652786612510681 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7347028063876289 accuracy 0.7407407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7564559057354927 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6490966315780368 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7918259277939796 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6625021461929593 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7973185256123543 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6546330217804227 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9555326253175735 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6677301334483283 accuracy 0.6296296296296295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7553562521934509 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5615725272468158 accuracy 0.8240740740740741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.81917579844594 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6216531438486916 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.838213324546814 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.48120408611638205 accuracy 0.8333333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0766431093215942 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.56197340041399 accuracy 0.8055555555555555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8402495756745338 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5366859521184649 accuracy 0.8055555555555555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0612433850765228 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.39593079526509556 accuracy 0.8796296296296295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1734270006418228 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3555068309817995 accuracy 0.9074074074074073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2109814882278442 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3388393947056362 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1585361510515213 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.38233770217214313 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.3911586552858353 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.21718020178377628 accuracy 0.9444444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1572713069617748 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.27532243582287 accuracy 0.9074074074074073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.560951441526413 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.30136289953121115 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1267065778374672 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2912074223692928 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2507685273885727 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.24379118625074625 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8930093050003052 accuracy 0.4444444444444444\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.22822343624596084 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5451792776584625 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.23362510052642652 accuracy 0.9444444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.326462950091809 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1511033199328397 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7685007154941559 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.20637589766244804 accuracy 0.9537037037037036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8988754451274872 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.13219800970650145 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7115632203640416 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.16205402141037797 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6472239326685667 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11347999583397593 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8529399782419205 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.07992286863736808 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1225119531154633 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1145404159157936 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8254195861518383 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.09163173737137445 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1302006244659424 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10809635810021843 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8103472143411636 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08626942268373179 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.12056428194046 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10597371614338565 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.885779857635498 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11048271039700401 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9537100858287886 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1234598361521161 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.804441406042315 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10164523119705596 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8835102748125792 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1040660102984735 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7631625831127167 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1002325524043824 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.879463717341423 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10390637904804732 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.00122606754303 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10670339344401977 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6590985264629126 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.09092050483117678 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9247920215129852 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.09574211849498429 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.669252896681428 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.09413836493955127 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8561530038714409 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08172375510912389 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0245278403162956 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08893073466606438 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8843245655298233 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10555544881416219 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8762044683098793 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.09684773892097708 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7841911390423775 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0845729689379888 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8154849708080292 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08684354837584708 accuracy 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8406234458088875 accuracy 0.5925925925925926\n",
            "\n",
            "CPU times: user 2min 58s, sys: 1min 30s, total: 4min 29s\n",
            "Wall time: 5min 36s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "42f84812-e50a-4795-da4d-59d02333a414"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "393e6b04-e86e-480d-9790-c1b980935d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6060606060606061"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "72538ab3-7144-4d34-ca83-6fc0b5000189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "e2ddba7f-790c-48ed-acf5-36bdd5713a87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.70      0.89      0.78        18\n",
            "     Faixa 2       0.00      0.00      0.00         9\n",
            "     Faixa 3       0.67      0.67      0.67         6\n",
            "\n",
            "    accuracy                           0.61        33\n",
            "   macro avg       0.45      0.52      0.48        33\n",
            "weighted avg       0.50      0.61      0.55        33\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "HQ54xluu8RL3",
        "outputId": "18b4f106-a930-47ce-d433-022305bc3012"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 730
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}