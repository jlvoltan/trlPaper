{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural + 512 tokens [kfold][P1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 1**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 512 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "37898fb1-8565-4608-af6f-8734771d40b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=1  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "21f0df73-dffa-4f2f-d8dc-71925606f9f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_1.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZxPMZOfICS",
        "outputId": "47e6acac-e85b-43b5-99a2-3598bc766bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RDBcpVf0TS",
        "outputId": "4b462ec5-754a-4b49-d07d-1937ab95b3f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "7c975851-d1f3-4f0f-d451-6b1c3325454c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 01:22:06 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "dd578cfe-7c55-46e7-8f1f-99afb7d443db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "ebe2120e-2d75-449c-ce71-a362614a2156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "0614991defb4465e82fd7faf8f387b9d",
            "31d0bb75b6914e94bde1e67c9ad0b7b6",
            "7ed22a65b51a4a46adaa65403f9c5cb0",
            "e2cbc0af9f2844adb153eb1910b0f5ed",
            "1b8278283b694a649c424443c88de07e",
            "efee79a2f98047639d251527865bc76d",
            "b7e7222e72084342b1862a015874ed43",
            "fe048b16a36048e6b302adbc488aaaab",
            "7ca22001c7cb40d884b673f65cd274ea",
            "67b8d85cbba54366a136cc59392dc25a",
            "01799deadfee4caa9bafece121c388cd",
            "f1906c5b2ef445bf8e003625ebbd4d2e",
            "f2ffb81cbd284a599211c8b921c0c2fa",
            "742b9a385987410f9098e44b3920ca2f",
            "47733a5f5272459c9dcf68ac31b8bbd8",
            "b14dfaada7c141a9891287273de89dda",
            "13a4b41182de445c971621e4dcc1dd56",
            "64bbac62a88848e09858a90995d7b1fc",
            "431f18480996405da33576a27a10fb7c",
            "e217c73dc8d6423fadbb7399251bd9ce",
            "c014686c7a9b4ae0b9afb2cd29f931be",
            "80618c0519d84861ab708fa2656d4534",
            "dbae793f4bc4451a9d7da8d88637ab44",
            "129d9a94d3424dfc9ec064a435bcfb4d",
            "ec5918c836f34eb99d663c207f9a8499",
            "cce4312f8743413ab96a06472de58d74",
            "72d6f5d099094a51afaec9962d00c323",
            "ee491ba47abc4445bd0c60d940ea8174",
            "e3264e5d17f54d6baf071853a5ecefa0",
            "279be527d5f24c54931c758689227b0f",
            "4cebead1db2a4ec6801590a500cd0fe9",
            "a7c3e6843f2b43a4881f724f8c8957ce",
            "bb13d34dc9b24e6a85997950200b13eb",
            "9ab29a1ffef943d18813be7fd05dd8d4",
            "c183058d58fe498aa0ec316663d2bcb1",
            "176ca209307a4ba89a2b2967212ea6ed",
            "219c29786d0c4a429cd21ecea4ccff8d",
            "c11c4ac1f3c64f18a3bda79ecbbcb7fc",
            "b2de3e3777a84040a513c263334b92c8",
            "f4877888a49c476f860f9e5d3a2fe966",
            "0dd5f473cdcf4184a816c5ee0c6cba4e",
            "67662a96168044c49018a811153222be",
            "ca81f7d5d89a4af0b87bb5bde9e63668",
            "82d014069e0f4d32a602bdf1058f7e1b"
          ]
        },
        "id": "WPj7c-IBgWRx",
        "outputId": "de3c1185-4b9e-4eb3-fbcc-cf90a7c96ed5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0614991defb4465e82fd7faf8f387b9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1906c5b2ef445bf8e003625ebbd4d2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbae793f4bc4451a9d7da8d88637ab44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ab29a1ffef943d18813be7fd05dd8d4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "49fb30e8b480416b97da14d04d9c876d",
            "056f22d1a37348948d18a210d0bc682c",
            "a150a48a599745fa9805b00b6ef74b65",
            "661a58967bb84ac4923742fd514040ae",
            "1038598d54f0437f889b690361817a6f",
            "2eb6c6b8459a40e386f429f26dd1b2d5",
            "38250fb974a443a29e339afcdfed3930",
            "fb577f41318543d9a79142f9e16c35cb",
            "8b0109d4bbbc4ebdab1eab71deffa2c3",
            "d1bb5d709fb24ff1b886003041155c3d",
            "6052dea4775b48849bae9901ddb5d9ad"
          ]
        },
        "id": "qSErznNMh4P5",
        "outputId": "bca3c251-ef8b-4490-b006-f59259faa1f0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49fb30e8b480416b97da14d04d9c876d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "8444f7aa-4be0-48ae-b7ce-41107ba36f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "a7d568bf-7753-4d39-bcc9-b3e5b4a7f337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "cab1fe23-1fda-4e7b-e1d7-56564c119ea0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92e75b41-25dc-4297-bf47-5adaa49d0e2c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92e75b41-25dc-4297-bf47-5adaa49d0e2c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92e75b41-25dc-4297-bf47-5adaa49d0e2c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92e75b41-25dc-4297-bf47-5adaa49d0e2c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cfacc1dc-d22f-4763-b8cc-9764c1f9cb2a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cfacc1dc-d22f-4763-b8cc-9764c1f9cb2a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cfacc1dc-d22f-4763-b8cc-9764c1f9cb2a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "92442c35-2e86-4240-c01b-02494fa55558"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "ebed6615-0296-419c-fcbc-2f990e1e2a0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107, 2), (27, 2), (34, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "36b7b451-3484-4218-e692-ed83c44a637e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "0490719a-0109-41cc-9988-89feaf484252"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "ecac8856-f4a9-4ab4-da13-9e80858b6e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "6ac154ba-522f-4ec8-f134-b7aa2cc54e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "69ae6dde-9abc-4d8b-80fd-e51c8e5021ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "89f0b56a-eece-49d1-b3b0-13e89207a9ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "6b2c15d2-d8f1-418a-de26-923df9fe4b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.085878197635923 accuracy 0.411214953271028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8743560388684273 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9127668568066188 accuracy 0.5981308411214953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6916260719299316 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.058786881821496 accuracy 0.514018691588785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1899819374084473 accuracy 0.18518518518518517\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.1280520856380463 accuracy 0.47663551401869153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0092985779047012 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8479805588722229 accuracy 0.616822429906542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9054111018776894 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.731261527964047 accuracy 0.6448598130841121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7973200529813766 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8730465173721313 accuracy 0.6355140186915887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.881374716758728 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8265146059649331 accuracy 0.6635514018691588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7610391974449158 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7559718787670135 accuracy 0.6635514018691588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7799934893846512 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7917183701481137 accuracy 0.6635514018691588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7354933023452759 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7211886090891702 accuracy 0.6915887850467289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7915018796920776 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6733603115592685 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7601734548807144 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7077885908739907 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8191083073616028 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7108482824904578 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8059796690940857 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7331675376210894 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9856494814157486 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7742504253983498 accuracy 0.6728971962616822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0925955027341843 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9209201974528176 accuracy 0.5887850467289719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.105858489871025 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8074589584554944 accuracy 0.616822429906542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9700645208358765 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7893680695976529 accuracy 0.6635514018691588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7729895561933517 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7265302347285407 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5673894137144089 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6847662648984364 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5571807473897934 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6983299170221601 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5615033209323883 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6919169074722699 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7532478868961334 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6513926014304161 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7642494738101959 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7157412629042353 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7665898501873016 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6841977685689926 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.5503826662898064 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6807612095560346 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6487057134509087 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6429924166628292 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6821931563317776 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6106844139950616 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7085774913430214 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6123544211898532 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0976195633411407 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6088163661105293 accuracy 0.7663551401869159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7434165999293327 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6059024536183902 accuracy 0.7850467289719626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7328913509845734 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5538398932133403 accuracy 0.8130841121495327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9127713441848755 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5541008700217519 accuracy 0.8037383177570093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7767488062381744 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5270584364022527 accuracy 0.822429906542056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8172682337462902 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.47884055227041245 accuracy 0.8317757009345794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8517859429121017 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5308786311319896 accuracy 0.8130841121495327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8621903918683529 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5009198635816574 accuracy 0.822429906542056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8699938952922821 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5100571204509053 accuracy 0.822429906542056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9494099020957947 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.502247650708471 accuracy 0.822429906542056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1370306015014648 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4539121591619083 accuracy 0.8411214953271028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1629882752895355 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4594819689435618 accuracy 0.8411214953271028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1850168704986572 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4970654078892299 accuracy 0.8317757009345794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1892342567443848 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5139602209840503 accuracy 0.822429906542056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.136417716741562 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4650121634559972 accuracy 0.8411214953271028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0891899913549423 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.49178577959537506 accuracy 0.8317757009345794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0903723984956741 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4940196488584791 accuracy 0.8317757009345794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0611001402139664 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4619505102080958 accuracy 0.8411214953271028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.05549256503582 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4597380283687796 accuracy 0.8411214953271028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.059132993221283 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4503248466977051 accuracy 0.8317757009345794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0596524327993393 accuracy 0.6296296296296295\n",
            "\n",
            "CPU times: user 8min 22s, sys: 29.7 s, total: 8min 52s\n",
            "Wall time: 9min 55s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "1e73dcf2-6b2b-4c72-d7a5-c99364d47271"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "9d5acca4-61fe-4c51-9765-c011205a4a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7058823529411764"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "12216d23-dba4-4fad-fab7-c7ee6ea8a5e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "f1f0ed90-acd1-4d2d-9a3c-d52bc20985ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.81      0.89      0.85        19\n",
            "     Faixa 2       0.00      0.00      0.00         8\n",
            "     Faixa 3       0.58      1.00      0.74         7\n",
            "\n",
            "    accuracy                           0.71        34\n",
            "   macro avg       0.46      0.63      0.53        34\n",
            "weighted avg       0.57      0.71      0.63        34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HQ54xluu8RL3",
        "outputId": "7981405d-d455-4cb7-ad18-160e7420f539"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 723
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0614991defb4465e82fd7faf8f387b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31d0bb75b6914e94bde1e67c9ad0b7b6",
              "IPY_MODEL_7ed22a65b51a4a46adaa65403f9c5cb0",
              "IPY_MODEL_e2cbc0af9f2844adb153eb1910b0f5ed"
            ],
            "layout": "IPY_MODEL_1b8278283b694a649c424443c88de07e"
          }
        },
        "31d0bb75b6914e94bde1e67c9ad0b7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efee79a2f98047639d251527865bc76d",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e7222e72084342b1862a015874ed43",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "7ed22a65b51a4a46adaa65403f9c5cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe048b16a36048e6b302adbc488aaaab",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ca22001c7cb40d884b673f65cd274ea",
            "value": 29
          }
        },
        "e2cbc0af9f2844adb153eb1910b0f5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b8d85cbba54366a136cc59392dc25a",
            "placeholder": "​",
            "style": "IPY_MODEL_01799deadfee4caa9bafece121c388cd",
            "value": " 29.0/29.0 [00:00&lt;00:00, 430B/s]"
          }
        },
        "1b8278283b694a649c424443c88de07e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efee79a2f98047639d251527865bc76d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e7222e72084342b1862a015874ed43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe048b16a36048e6b302adbc488aaaab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca22001c7cb40d884b673f65cd274ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67b8d85cbba54366a136cc59392dc25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01799deadfee4caa9bafece121c388cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1906c5b2ef445bf8e003625ebbd4d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2ffb81cbd284a599211c8b921c0c2fa",
              "IPY_MODEL_742b9a385987410f9098e44b3920ca2f",
              "IPY_MODEL_47733a5f5272459c9dcf68ac31b8bbd8"
            ],
            "layout": "IPY_MODEL_b14dfaada7c141a9891287273de89dda"
          }
        },
        "f2ffb81cbd284a599211c8b921c0c2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a4b41182de445c971621e4dcc1dd56",
            "placeholder": "​",
            "style": "IPY_MODEL_64bbac62a88848e09858a90995d7b1fc",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "742b9a385987410f9098e44b3920ca2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_431f18480996405da33576a27a10fb7c",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e217c73dc8d6423fadbb7399251bd9ce",
            "value": 995526
          }
        },
        "47733a5f5272459c9dcf68ac31b8bbd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c014686c7a9b4ae0b9afb2cd29f931be",
            "placeholder": "​",
            "style": "IPY_MODEL_80618c0519d84861ab708fa2656d4534",
            "value": " 996k/996k [00:00&lt;00:00, 3.74MB/s]"
          }
        },
        "b14dfaada7c141a9891287273de89dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a4b41182de445c971621e4dcc1dd56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64bbac62a88848e09858a90995d7b1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "431f18480996405da33576a27a10fb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e217c73dc8d6423fadbb7399251bd9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c014686c7a9b4ae0b9afb2cd29f931be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80618c0519d84861ab708fa2656d4534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbae793f4bc4451a9d7da8d88637ab44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_129d9a94d3424dfc9ec064a435bcfb4d",
              "IPY_MODEL_ec5918c836f34eb99d663c207f9a8499",
              "IPY_MODEL_cce4312f8743413ab96a06472de58d74"
            ],
            "layout": "IPY_MODEL_72d6f5d099094a51afaec9962d00c323"
          }
        },
        "129d9a94d3424dfc9ec064a435bcfb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee491ba47abc4445bd0c60d940ea8174",
            "placeholder": "​",
            "style": "IPY_MODEL_e3264e5d17f54d6baf071853a5ecefa0",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "ec5918c836f34eb99d663c207f9a8499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_279be527d5f24c54931c758689227b0f",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cebead1db2a4ec6801590a500cd0fe9",
            "value": 1961828
          }
        },
        "cce4312f8743413ab96a06472de58d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7c3e6843f2b43a4881f724f8c8957ce",
            "placeholder": "​",
            "style": "IPY_MODEL_bb13d34dc9b24e6a85997950200b13eb",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 6.37MB/s]"
          }
        },
        "72d6f5d099094a51afaec9962d00c323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee491ba47abc4445bd0c60d940ea8174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3264e5d17f54d6baf071853a5ecefa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "279be527d5f24c54931c758689227b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cebead1db2a4ec6801590a500cd0fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7c3e6843f2b43a4881f724f8c8957ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb13d34dc9b24e6a85997950200b13eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ab29a1ffef943d18813be7fd05dd8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c183058d58fe498aa0ec316663d2bcb1",
              "IPY_MODEL_176ca209307a4ba89a2b2967212ea6ed",
              "IPY_MODEL_219c29786d0c4a429cd21ecea4ccff8d"
            ],
            "layout": "IPY_MODEL_c11c4ac1f3c64f18a3bda79ecbbcb7fc"
          }
        },
        "c183058d58fe498aa0ec316663d2bcb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2de3e3777a84040a513c263334b92c8",
            "placeholder": "​",
            "style": "IPY_MODEL_f4877888a49c476f860f9e5d3a2fe966",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "176ca209307a4ba89a2b2967212ea6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dd5f473cdcf4184a816c5ee0c6cba4e",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67662a96168044c49018a811153222be",
            "value": 625
          }
        },
        "219c29786d0c4a429cd21ecea4ccff8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca81f7d5d89a4af0b87bb5bde9e63668",
            "placeholder": "​",
            "style": "IPY_MODEL_82d014069e0f4d32a602bdf1058f7e1b",
            "value": " 625/625 [00:00&lt;00:00, 42.9kB/s]"
          }
        },
        "c11c4ac1f3c64f18a3bda79ecbbcb7fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2de3e3777a84040a513c263334b92c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4877888a49c476f860f9e5d3a2fe966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dd5f473cdcf4184a816c5ee0c6cba4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67662a96168044c49018a811153222be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca81f7d5d89a4af0b87bb5bde9e63668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d014069e0f4d32a602bdf1058f7e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49fb30e8b480416b97da14d04d9c876d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_056f22d1a37348948d18a210d0bc682c",
              "IPY_MODEL_a150a48a599745fa9805b00b6ef74b65",
              "IPY_MODEL_661a58967bb84ac4923742fd514040ae"
            ],
            "layout": "IPY_MODEL_1038598d54f0437f889b690361817a6f"
          }
        },
        "056f22d1a37348948d18a210d0bc682c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb6c6b8459a40e386f429f26dd1b2d5",
            "placeholder": "​",
            "style": "IPY_MODEL_38250fb974a443a29e339afcdfed3930",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "a150a48a599745fa9805b00b6ef74b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb577f41318543d9a79142f9e16c35cb",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b0109d4bbbc4ebdab1eab71deffa2c3",
            "value": 714290682
          }
        },
        "661a58967bb84ac4923742fd514040ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1bb5d709fb24ff1b886003041155c3d",
            "placeholder": "​",
            "style": "IPY_MODEL_6052dea4775b48849bae9901ddb5d9ad",
            "value": " 714M/714M [00:07&lt;00:00, 85.0MB/s]"
          }
        },
        "1038598d54f0437f889b690361817a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb6c6b8459a40e386f429f26dd1b2d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38250fb974a443a29e339afcdfed3930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb577f41318543d9a79142f9e16c35cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0109d4bbbc4ebdab1eab71deffa2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1bb5d709fb24ff1b886003041155c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6052dea4775b48849bae9901ddb5d9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}