{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - GPT-2 + Rede Neural [kfold][P1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- https://huggingface.co/pierreguillou/gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 24 SET 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 1**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 242 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "NOeYJqHdTeHU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjJNdaXvTeze",
        "outputId": "6996b519-afe7-4c7d-e45b-a6a79a17d374"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=1  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_gpt2_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "95b6a98c-d979-493b-f1e0-7d27e9ff2d7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_gpt2_neural_1.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 242   #O GPT-2 o máximo é 1024"
      ],
      "metadata": {
        "id": "v7gLFBuBT6WO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9cZxPMZOfICS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2153f29-784d-424d-e5d4-7fb99ad5b903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h5RDBcpVf0TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2315f3-b48a-4ac2-9a2b-ff33b44d2ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.3/1.6 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "7972d77a-3638-4a23-faeb-61fcac6563eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 13:32:08 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "7eeec771-0c44-47ef-ad03-02849c8cbe02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "import torch\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from transformers import GPT2Model, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "OXAUnWshi1w7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "7e28056e-a0de-4bfe-c3b3-2c4ecfee4569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "e9850dfc-e91e-4d1d-dfd9-e76999687215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "c21afb89-8a4c-45e8-9dbf-4560bdb0f138"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-059622ff-d868-4554-9673-37e041f429b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-059622ff-d868-4554-9673-37e041f429b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-059622ff-d868-4554-9673-37e041f429b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-059622ff-d868-4554-9673-37e041f429b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96072b0d-4fe1-49da-9f60-9bb560499de3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96072b0d-4fe1-49da-9f60-9bb560499de3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96072b0d-4fe1-49da-9f60-9bb560499de3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/pierreguillou/gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "@inproceedings{pierre2020gpt2smallportuguese,\n",
        "  title={GPorTuguese-2 (Portuguese GPT-2 small): a Language Model for Portuguese text generation (and more NLP tasks...)},\n",
        "  author={Pierre Guillou},\n",
        "  year={2020}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Tokenizer**: No GPT-2, ao contrário do BERT, o preenchimento é feito à esquerda, uma vez que o último token é utilizado para a previsão."
      ],
      "metadata": {
        "id": "yLIJaQxyg7JM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WPj7c-IBgWRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "f9fe8148f259402bbd2a99588349a5da",
            "ebd223b7949e434ea6b502c16b71591f",
            "b8ba366fc20746139d5a54dd2719451e",
            "a9fc59958dde42938619e7c3be1805c0",
            "22e5d9571b4b4e9ba6d4a1c98b9363b0",
            "f4706c893530474d8cd90ac910a5049c",
            "bd4a10107b6e49759b77fac41f959033",
            "36adadb46a3f44e6953cd54f17ab1329",
            "1d1f6dced6164b5fa7287f51e512a365",
            "323239dc52f04623933bf122ff417a6f",
            "585c3749e6c944c4a28c5479d906b783",
            "4ae608470ddb4e82aac02858cb76ae84",
            "0ec311b4c6aa487988cfc582f07e6407",
            "2164a4b273f04de3a37233c57fdd468e",
            "4f1b9fb05ce746c1b030e02d8157a007",
            "4ca18ef9b7404d3dafb0caca78677372",
            "f2e5c02a90fd4a88b02ade11bd665f5b",
            "811ef1ba41774f948aeeb15541abbb54",
            "0989e34443f44f838a74478ac119970e",
            "85d67dce20f646379dc0ac93c32fefb9",
            "d7871440760243848152b1f4c30de774",
            "280b211638304b0ba4820eb53dd3d187",
            "d062330255c04d0dac70c3a3c8f3c3f3",
            "706134e14cfa45bda0104c2f7cabe195",
            "ec4b2c80cf0c47a39dcfdc4870542538",
            "38fa00238ac54008b2a1ee3b057851b1",
            "d75155c2df8d4e07bdd5e00d78e38ad3",
            "77e4021b0eb9406195fdefb47844325d",
            "c82edf79fab84d2e8ff6c573ee5d8506",
            "e1ff5ca33fca4502852598b3a382b675",
            "b523cf4cc687469581bf710a1ef60a2e",
            "9194f36b8c1c4286bad12938ce59ac9f",
            "9e24090a737143bca46d48062a1ede85",
            "1bf0beb7ea1e46c59194e961a9f49223",
            "fb894d9e3f2d43ceb20086ccba31b8e4",
            "b5d9f390618c421d91cb1edc0bef9e95",
            "c1f8071f17504aa28af0b7106f68bf34",
            "6665965b39a741039bf879e9d8918428",
            "1cdccc5ff6644c27adfb4883063e5d64",
            "d27efcad87cf48309862c1240b8853ff",
            "eeefd5ba4d6443ff8f5a950725af34f0",
            "c9f0e5e33cea4a66b89d92d55dff6a80",
            "b1ac4c5bc67044da8491400fdfab0d76",
            "7c652b6d2c944658a8ec2ef5afa3dd8d",
            "e099347a64c74516ba59fae9d0911318",
            "17c19613e9b741c5b91da0c4e8b5a068",
            "85a5165745ec447d9b73912554708b68",
            "841091dde446449e9f08ffef4ec02a2c",
            "2a6818f7f59b41c58fe454c605ebe2ae",
            "e72a0a3a523241a192059b3ae09308c5",
            "e05b3acbd93c44c7ac5ac9e26798e58f",
            "bf9a64724c3a455882e93b82bc46b37a",
            "aa7ebfb973c94641a4ebb8fc0df06510",
            "288043a07574419c91cbcf00cab39456",
            "f826c65178254fcc935e9bf690c35a88"
          ]
        },
        "outputId": "3ea66b22-f332-4a22-ee8e-a7216545734c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/92.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9fe8148f259402bbd2a99588349a5da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/850k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ae608470ddb4e82aac02858cb76ae84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/508k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d062330255c04d0dac70c3a3c8f3c3f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bf0beb7ea1e46c59194e961a9f49223"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e099347a64c74516ba59fae9d0911318"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = \"pierreguillou/gpt2-small-portuguese\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "# tokenizer.model_max_length=MAX_LEN\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qSErznNMh4P5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "17e03d4c43a945bd9a3f7b22b25085f0",
            "bc23432eef1a44099a2159fd4ece22c2",
            "646fc774ac1645bba77cbcc2d8b2891a",
            "cba1ac6fcdb24e41896180baedd7c84b",
            "10073cbcd4ac4ddba126c48286437b4d",
            "3bc3aa8a52dd423aadce9e4eb414b640",
            "77c95762d5c34efd981f8bb374e6943d",
            "981eedf881414f239344439936b37aa1",
            "ee2140388df2472fb29fb87019e27d90",
            "80b9e8f6b66a464ea55a85d43567a768",
            "f8e1bad65527469382e0e73d67d28d0b"
          ]
        },
        "outputId": "2e0854f8-fa45-453a-b93d-3ed333224645"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17e03d4c43a945bd9a3f7b22b25085f0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "# model = AutoModelWithLMHead.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "model = GPT2Model.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exemplo da tokenização no GPT2"
      ],
      "metadata": {
        "id": "VK2XSMUYiABq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "78tJbGMogWaZ"
      },
      "outputs": [],
      "source": [
        "gpt2_input = tokenizer(frase, padding=\"max_length\", max_length=16, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt2_input['input_ids'])\n",
        "print(gpt2_input[\"attention_mask\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES67iwbAh2Jz",
        "outputId": "10acdbe7-3340-43eb-f33e-a62d1dde6eaf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     0,     0,     0,     0,    33,  7912,   261,   374, 38198,\n",
            "         20142,   300,  9643,   261,  3325,  2303]])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tokenizer.decode(gpt2_input.input_ids[0])\n",
        "print(example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ6-184nh9hr",
        "outputId": "5b651268-0311-4efb-d136-ab0c61174cef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>A avaliação de prontidão tecnológica em tecnologias de interesse militar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Variáveis do modelo:"
      ],
      "metadata": {
        "id": "urxVLrRBZQhg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PSjRYlnghJRw"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Devemos construir uma class Dataset para ler os textos, tokenizar e armazenar em _containers_ para o treinamento em lote."
      ],
      "metadata": {
        "id": "RlAPjXSWkL56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      truncation = True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Estamos adicionando uma camada linear sobre as 12 camadas de decodificadores do GPT-2 com sua dimensão de saída igual ao nosso número de classes"
      ],
      "metadata": {
        "id": "sHe6lDI4lyhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2SequenceClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size: int,n_classes:int, max_seq_len:int):\n",
        "        super(GPT2SequenceClassifier,self).__init__()\n",
        "        self.gpt2model = GPT2Model.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.fc1 = nn.Linear(hidden_size*max_seq_len, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        gpt_out, _ = self.gpt2model(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "        batch_size = gpt_out.shape[0]\n",
        "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
        "        return linear_output"
      ],
      "metadata": {
        "id": "ik0pY8jfl9G6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = GPT2SequenceClassifier(hidden_size=768, n_classes=len(class_names), max_seq_len=MAX_LEN)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "ab184433-959a-4d77-af35-a347cbe4eb53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107, 2), (27, 2), (34, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "b3c51270-10b8-4982-8671-1ba82fcc3d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "0a0a35e7-500a-494c-b158-a08f1afec53b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "bd6c7c4b-4f68-4e2a-8b16-3401005d61d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "c41430b0-3974-48a8-d6a4-2e0801030147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "77541950-4a4b-41f0-d7b1-64fb931c71cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "6ee689de-4d4c-4e2f-a07a-796ca2fc60de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "d52bc4c9-3e0a-4531-b924-b9ba48a6450a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 2.3529908571924483 accuracy 0.49532710280373826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.899555591196986 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7445267167474542 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1100536659359932 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.2592237657310241 accuracy 0.6822429906542056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9752147644758224 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.48470394501438413 accuracy 0.8130841121495327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.2205965518951416 accuracy 0.3333333333333333\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2611097474655253 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0841099126264453 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.030427037757304883 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5285156220197678 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.07085578433202068 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9003395873587579 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.035893864716485764 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0029947359580547 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04979702075484983 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8809101819060743 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03137536961861238 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6482458133250475 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04567890799641004 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.547610331326723 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.023522454271706295 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.745853926986456 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03740789767043846 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8505735415965319 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0508979684632764 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7783813446294516 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0870230816669082 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.583769385702908 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.06270915376434084 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6716681448742747 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.016340978819961296 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.769481590948999 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02032617064676653 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8455286847893149 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05520666217033161 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.789797717705369 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03846794871671122 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5998102724552155 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.015668504073100768 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.601671289652586 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.019578066449387928 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6516628712415695 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05026946381220349 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.677130902186036 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.049357461794991356 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6349101420491934 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.039918681741401736 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6226116511970758 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03565107943352684 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5861806757748127 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.032695531419579184 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4902040604501963 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.015500344432236293 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4918713700026274 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02655009749139075 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5483107985928655 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.022525044499671663 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5549091016873717 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03950357672936532 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.636463395319879 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0267826131719683 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5994207644835114 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02556872833492006 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.55782999843359 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01824425256490057 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5730625158175826 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03716373539052802 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5254784971475601 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.024617745504047304 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5203641653060913 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.027326402920281163 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5107952132821083 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03607836217506539 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4727972615510225 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0266141097988774 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.49581746943295 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02523140096705642 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4940574569627643 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04461422515702803 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5554598048329353 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.025692162841591783 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5659915348514915 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02665996336551351 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5717031760141253 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0150562144708439 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5782031752169132 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013039188966705037 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6089805262163281 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.002923643943900243 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6135899126529694 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02148552623251021 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6453722640872002 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.020332407792965666 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.660781648941338 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.027692290838481477 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.669354080222547 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.022180329288033818 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6704415744170547 accuracy 0.7407407407407407\n",
            "\n",
            "CPU times: user 3min 11s, sys: 1min 30s, total: 4min 42s\n",
            "Wall time: 5min 39s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "163cb0e8-9a3c-433c-a581-ee4f94ad88bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "0cb22b46-e82e-4180-fbed-d32a2238ada0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7647058823529411"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "c3094f1c-df5c-4b78-cda0-cf98d4f4da90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrcGxmh_yKxU",
        "outputId": "711bb009-98de-48de-a311-65f7a19dec70"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.79      1.00      0.88        19\n",
            "     Faixa 2       0.00      0.00      0.00         8\n",
            "     Faixa 3       0.70      1.00      0.82         7\n",
            "\n",
            "    accuracy                           0.76        34\n",
            "   macro avg       0.50      0.67      0.57        34\n",
            "weighted avg       0.59      0.76      0.66        34\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HQ54xluu8RL3",
        "outputId": "3f6a9f8e-3d52-4b97-846b-ab418d98d7f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB80AAAWmCAYAAAACjDHUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAB7CAAAewgFu0HU+AAEAAElEQVR4nOzdeZzVdb0/8PeXGbZhZJVFFFFQEQQUXJE0159K5m5lJln31tUueW8qiktd026ahl6XvHrtapJ6LROlEsOFMleIQGWRQRBFQFbZYWAYzu8P48iwD8yc78D3+ewxj87nnM/3832dGjg6r/l8v0kul8sFAAAAAAAAAGRQvbQDAAAAAAAAAEBalOYAAAAAAAAAZJbSHAAAAAAAAIDMUpoDAAAAAAAAkFlKcwAAAAAAAAAyS2kOAAAAAAAAQGYpzQEAAAAAAADILKU5AAAAAAAAAJmlNAcAAAAAAAAgs5TmAAAAAAAAAGSW0hwAAAAAAACAzFKaAwAAAAAAAJBZSnMAAAAAAAAAMktpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOU5gAAAAAAAABkltIcAAAAAAAAgMwqTjsA8JnGvQakHQEAqKZFf7sv7QgAAACw22ukzSq4LHYWq8b5OU+W2WkOAAAAAAAAQGYpzQEAAAAAAADILKU5AAAAAAAAAJmlNAcAAAAAAAAgs4rTDgAAAAAAAADUIYl9t2SL73gAAAAAAAAAMktpDgAAAAAAAEBmKc0BAAAAAAAAyCz3NAcAAAAAAAA+lyRpJ4CCstMcAAAAAAAAgMxSmgMAAAAAAACQWUpzAAAAAAAAADJLaQ4AAAAAAABAZhWnHQAAAAAAAACoQxL7bskW3/EAAAAAAAAAZJbSHAAAAAAAAIDMUpoDAAAAAAAAkFlKcwAAAAAAAAAyqzjtAAAAAAAAAEAdkiRpJ4CCstMcAAAAAAAAgMxSmgMAAAAAAACQWUpzAAAAAAAAADJLaQ4AAAAAAABAZhWnHQAAAAAAAACoQxL7bskW3/EAAAAAAAAAZJbSHAAAAAAAAIDMUpoDAAAAAAAAkFlKcwAAAAAAAAAyqzjtAAAAAAAAAEAdkiRpJ4CCstMcAAAAAAAAgMxSmgMAAAAAAACQWUpzAAAAAAAAADLLPc0BAAAAAACAzyX23ZItvuMBAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOU5gAAAAAAAABkVnHaAQAAAAAAAIA6JEnSTgAFZac5AAAAAAAAAJmlNAcAAAAAAAAgs5TmAAAAAAAAAGSW0hwAAAAAAACAzCpOOwAAAAAAAABQhyT23ZItvuMBAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOU5gAAAAAAAABkVnHaAQAAAAAAAIA6JEnSTgAFZac5AAAAAAAAAJmlNAcAAAAAAAAgs5TmAAAAAAAAAGSW0hwAAAAAAACAzCpOOwAAAAAAAABQhyT23ZItvuMBAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOU5gAAAAAAAABkVnHaAQAAAAAAAIA6JEnSTgAFZac5AAAAAAAAAJmlNAcAAAAAAAAgs5TmAAAAAAAAAGSWe5oDAAAAAAAAn0vsuyVbfMcDAAAAAAAAkFlKcwAAAAAAAAAyS2kOAAAAAAAAQGYpzQEAAAAAAADIrOK0AwAAAAAAAAB1SGLfLdniOx4AAAAAAACAzFKaAwAAAAAAAJBZSnMAAAAAAAAAMktpDgAAAAAAAEBmFacdAAAAAAAAAKhD6iVpJ4CCstMcAAAAAAAAgMxSmgMAAAAAAACQWUpzAAAAAAAAADJLaQ4AAAAAAABAZhWnHQAAAAAAAACoQxL7bskW3/EAAAAAAAAAZJbSHAAAAAAAAIDMUpoDAAAAAAAAkFlKcwAAAAAAAAAyqzjtAAAAAAAAAEAdkiRpJ4CCstMcAAAAAAAAgMxSmgMAAAAAAACQWS7PDgAAAAAAAJCiNWvWRFlZWUyYMCHGjx8f48ePj2nTpkVlZWV+TllZWbXWvOSSS2L06NE7levWW2+N8847b6fWWO+kk06KWbNmVfu4hx56KI4//vgaybAlSnMAAAAAAADgc4mLVRfSBRdcEJMnT46Kioq0o2xijz32SDtCQSjNAQAAAAAAAFIyfvz4Wlm3TZs2se+++1brmBkzZuQf77HHHnHcccfVdKyIiGjVqlU0adJku+aWlJTUSoYNKc0BAAAAAAAA6oDS0tLo1q1b9OjRI8aOHRvjxo3b4bUGDx5crfkTJ06scin2fv36RaNGjXb4/Ftz9dVX19hl32uC0hwAAAAAAAAgJZdcckl07949evToEZ06dYokSSIiYtCgQTtVmlfX0KFDq4zrUqld25TmAAAAAAAAACm58cYb044Qa9asiT/+8Y/5cadOneKwww5LL1CBKc0BAAAAAACAz/1jpzPZMXLkyFi8eHF+nKVd5hER9dIOAAAAAAAAAEB6nnnmmfzjoqKiOPvss1NMU3hKcwAAAAAAAICMmjdvXrz66qv58XHHHRdt2rRJMVHhuTw7AAAAAAAAQEYNGzYsKisr8+NCXJr9D3/4Qzz11FPx4YcfxrJly6JJkybRokWL6NmzZ/Tt2zfOOOOMaNCgQa3nWE9pDgAAAAAAAGTa7NmzY/bs2Tu1Rvv27aN9+/Y1lKhwNrw0e/PmzePEE0+s9XO+8cYbVcaLFy+OxYsXx/Tp02PYsGHx85//PAYOHBhnnXVWrWeJUJoDAAAAAAAAG0qyd4fnp59+Ou67776dWmPAgAHx/e9/v4YSFcY777wT06ZNy4+//OUvF2yHd+PGjaNZs2ZRWVkZixcvjoqKivxr8+bNi4EDB8b48ePjhhtuqPUsSnMAAAAAAACADBo6dGiV8fnnn19r5yoqKooTTzwxTjvttDjyyCNjn332yb+2Zs2aePvtt+Oxxx6LESNG5J8fMmRItG7dOr773e/WWq4IpTkAAAAAAABA5qxevTqGDx+eH3ft2jW6du1aa+f7zW9+Ey1bttzsaw0aNIijjjoqjjrqqBg+fHgMHDgw1q5dGxER99xzT5xxxhnRoUOHWsumNAcAAAAAAAAy7fzzz48+ffrs1Bq72v3MX3zxxVi6dGl+fO6559bq+bZUmG+sX79+MW/evLj11lsjIqKioiL+93//N2666aZay6Y0BwAAAAAAADKtffv2u1zpvbOeeeaZ/OP69evHl7/85RTTVPWNb3wjHn300Zg9e3ZERLzyyiu1er56tbo6AAAAAAAAsGtJkux9ZcycOXPijTfeyI9PPPHE7d4JXgjFxcVxwgkn5MezZ8+OuXPn1tr5lOYAAAAAAAAAGfLss8/GunXr8uPzzjsvxTSb17FjxyrjTz/9tNbOpTQHAAAAAAAAyJANL83eunXrOO6441JMs3mNGzeuMi4vL6+1cynNAQAAAAAAADJizJgx8eGHH+bHZ511VhQXF6cXaAsWLFhQZdyiRYtaO5fSHAAAAAAAACAjNtxlHhFx/vnnp5Rk68aOHZt/XL9+/Wjbtm2tnavu/coAAAAAAAAAkJ7Evtvd1apVq+L555/Pjw899NDo3Llziok274MPPog333wzPz7ssMM2uVx7TfIdDwAAAAAAAJABI0aMiBUrVuTH55133g6vNWjQoOjSpUv+a+bMmVucW537ka9evTquvfbaqKyszD939tln73DO7aE0BwAAAAAAAMiAoUOH5h83atQovvSlLxXkvKeccko88sgjsXDhwq3Oe//99+Oiiy6Kd999N/9c586d49xzz63VfC7PDgAAAAAAAJCSIUOGxK9//etNnt+4YD711FM3mdOuXbvNHrs5M2fOjNGjR+fHp5xySuyxxx7VTLtj5s+fH7fddlvccccdceihh0a3bt2iQ4cOUVpaGpWVlTFv3rwYPXp0/O1vf4tcLpc/rkWLFnH//fdHcXHt1tpKcwAAAAAAAOBzSZJ2gkxZsmRJzJgxY5vzNjdnw0uYb8uzzz5bpZA+//zzt/vYmlJZWRljx46NsWPHbnPuwQcfHHfeeWfst99+tZ5LaQ4AAAAAAACwG8vlcvHMM8/kx3vttVccc8wxBTv/t771rRg1alSUlZVts+g/+OCD4+KLL45zzjknGjRoUJB8SW7DXycAUtO414C0IwAA1bTob/elHQEAAAB2e41sAS24xmfclXaEglv1/A/SjpAJ5eXlMWXKlJg5c2bMnz8/Vq5cGUVFRbHHHntE27Zt49BDD41WrVoVPJe/ZgAAAAAAAACodY0aNYqePXtGz549045SRb20AwAAAAAAAABAWuw0BwAAAAAAAD6X2HdLtviOBwAAAAAAACCzlOYAAAAAAAAAZJbSHAAAAAAAAIDMUpoDAAAAAAAAkFnFaQcAAAAAAAAA6pAkSTsBFJSd5gAAAAAAAABkltIcAAAAAAAAgMxSmgMAAAAAAACQWUpzAAAAAAAAADKrOO0AAAAAAAAAQB2S2HdLtviOBwAAAAAAACCzlOYAAAAAAAAAZJbSHAAAAAAAAIDMUpoDAAAAAAAAkFnFaQcAAAAAAAAA6pDEvluyxXc8AAAAAAAAAJmlNAcAAAAAAAAgs5TmAAAAAAAAAGSW0hwAAAAAAACAzCpOOwAAAAAAAABQhyRJ2gmgoOw0BwAAAAAAACCzlOYAAAAAAAAAZJbSHAAAAAAAAIDMck9zAAAAAAAA4HOJfbdki+94AAAAAAAAADJLaQ4AAAAAAABAZinNAQAAAAAAAMgspTkAAAAAAAAAmVWcdgAAAAAAAACgDkmStBNAQdlpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOK0w4AAAAAAAAA1CGJfbdki+94AAAAAAAAADJLaQ4AAAAAAABAZinNAQAAAAAAAMgspTkAAAAAAAAAmVWcdgAAAAAAAACgDkmStBNAQdlpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOK0w4AAAAAAAAA1B1JkqQdAQrKTnMAAAAAAAAAMktpDgAAAAAAAEBmKc0BAAAAAAAAyCz3NAcAAAAAAADy3NOcrLHTHAAAAAAAAIDMUpoDAAAAAAAAkFlKcwAAAAAAAAAyS2kOAAAAAAAAQGYVpx0AAAAAAAAAqEOStANAYdlpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOK0w4AAAAAAAAA1B1JkqQdAQrKTnMAAAAAAAAAMktpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZVZx2AAAAAAAAAKDuSJIk7QhQUHaaAwAAAAAAAJBZSnMAAAAAAAAAMktpDgAAAAAAAEBmKc0BAAAAAAAAyKzitAMAAAAAAAAAdUeSJGlHgIKy0xwAAAAAAACAzLLTHABS1qhh/Tj2sM7RsX3LaNWiNJYuWxWfzF8S496bETPnLk47HgBkxtq1a+Odt8fF7FmzYv78eVFaWhpt2raLQw87LFq0aJl2PABgM3x+AwA1QWkOAJuRJEkcvH/bOKL7fnH4IfvGEYd0jO4Hto+GDern53znR7+Ox/4waofPccC+beKHl/eLL5/QMxo3arDJ6+vWrYvXxk6LOx99MUa8NmmHzwMAbN2qVavifx64P4Y9MzQWLlywyevFxfXjC8cdFwOu+Pc48KAuKSQEADbm8xsAqElK893EqFGjon///vlxWVlZimkAdl3nnnJYXPbVL0avrh1ijyaNau08/3zBF+LOay6M+vWLtjinXr16cfwRB8bxRxwYD/3utbjyZ7+NtWvX1VomAMiiqVPfj6t/cEVM/+CDLc5Zu7Yi/vLnkfHmG6/H1ddeF1/56kUFTAgAbMznN0Dtc09zskZpDgAbOPawznH8EQfW6jmu/tapccsVZ1d5bu3ayvjbhA/j4zmLoknjhtG7276xV+tm+de/c8EXomH94viXmx6r1WwAkCXz58+Ly7/7TzFv7twqz3c75JDYZ58OsXjx4pg4YXysWLEiIiJWr14d/3nzTVHapDT6nfnlFBIDAD6/AYDaoDTfTkOHDo3rrrtuh4+387uwKisrY+rUqTF+/Pj815QpU6KioiI/5+WXX4599tknxZTArmTxspWxYuXq2Ltti51a54SjDoqb/rXqv6T/bsTf4+o7fhdzFy7LP5ckSXz19MPjzkFfiRZNSyIiov/Zx8Q7ZR/H/f/3yk5lAAAicrlcXPXvV1T5gfuBBx0UP73tjjioy8H555YuXRq/uPfuePKJz39x7aYf3RAHHXxwHHBA7f6iHQBQlc9vAKC2KM3Z7QwYMCBee+21WLVqVdpRgF3UylVr4t0pM+PvEz+KMRNnxN8nfhTvfzQvbviXfnHjZf12au3brzo/iorq5cdDhr212d3juVwunnx+TLz/0bx46eEfRKOGn91L/YZ/6ReP/2F0LFnu7zgA2Bkvv/hCvPP2uPx47332iYd/9Vg0bdasyrymTZvGdTf8MOrVS+KJx34dEZ/tWPvFvXfHXXffV9DMAJB1Pr8BgNqiNN9Bbdq0iUaNau9et9V19NFH283+D5MmTVKYAzvsZ/87Igbd9UxUVtb8vcNPPbZr9Dho7/x49rzFceXPfrvVY/4+aUbc8fAL8cPLvxQRES2bNYl/639S3Hz/czWeDwCy5IH/rvoD8+tv/NEmP3Df0BX/flX8ZeTImD17VkREjHzpxZj83ntxcNeutZoTAPicz28AoLYozXfQz3/+8zj66KPTjsE2NGrUKLp27Rrdu3ePjz/+OP7yl7+kHQmo4xYsWl5ra5/+hUOqjB955o1YsWrNNo978Ld/jWv/+bRoUP+zj+2L+h2pNAeAnfD+lLJ4f8qU/LhTp87xheO+uNVjGjduHBd85Wtxz38Nzj/3/HN/8EN3ACgQn98ABZakHQAKq962p8Cu5eyzz46f/OQnMWzYsPj73/8eTz75ZNx4443RvXv3tKMBGdfnsM5VxiPfmrxdxy1cvCLeLZuZH++3955xaJd9ajQbAGTJK3/5c5VxvzO/vF3HfWmjeX/5y8gaywQAbJ3PbwCgNtlpnqIVK1ZEWVlZTJ8+PRYtWhSVlZXRtGnTaN++fRx++OFRWlqadsQdsnbt2nj//fdj2rRpsWDBgli1alXsscce0apVq+jdu3e0bdu2Vs//b//2b7W6PsCO2qt11UvGTZ4+d7uPfe+DOXFE9/3y41P7dot3NijSAYDt9+Ybr1cZ9z78iO06rt1ee0X79nvnL/H64fTpMeeTT6LdXnvVeEYAoCqf3wBAbVKaF9j8+fPjj3/8Y4wYMSLGjx8fa9eu3ey8oqKiOOmkk+KKK66Igw46aJvrjho1Kvr3758fb+7+5rfddls88sgj+fG9994b/+///b+trrtu3br45je/GaNHj46Izy53/vTTT8cBBxxQZV55eXm88MILMXz48Bg9enSsWLFii2t27949BgwYECeeeOI23xfA7qRls5Iq4yXLV233sUs3mtutU7sayQQAWTRt2tT843r16kW3Q7b/qlQ9Dj00/0P3iIhpU9/3Q3cAKACf3wBAbXJ59gJ7+OGH47bbbotx48ZtsTCPiKisrIwXX3wxLrjgghg+fHiNnPvKK6+Mgw8+OD/+4Q9/GHPnbn2X40MPPZQvzCMirrnmmk0K84iIN998MwYOHBh//vOft1qYR0RMmDAhLrvssrjtttsil8tV810A7LpWr6n6937D+tv/u2sNG9SvMu6yv9IcAHbE0iVLYtGnn+bHrVq1isaNG2/38XvvXfUWKR9+OL3GsgEAm+fzGwCobXaap2ifffaJww8/PA488MBo3rx5rFu3LmbPnh2vv/56jB8/PiIiVq9eHddcc03su+++O31P7gYNGsTgwYPjvPPOi9WrV8fixYvj2muvjUceeSSSJNlk/vjx4+Pee+/Nj0844YS4+OKLt3me5s2bx+GHHx7dunWLVq1aRf369WPhwoUxbty4+Otf/xqVlZUREfHII49E+/btq+yQB9idLV66MvZo0ig/brtn05g+c8F2Hdt2z6ZVxgfs27pGswFAVnz88Ywq47btqrfLrG3bqr+4NmPGjC3MBABqis9vgMLbXG8EuzOleYHVq1cvzjzzzPjmN78ZPXv23OycH/zgB/HKK6/EwIEDY8mSJVFRURE//vGP46mnntrp8x9wwAFxzTXXxC233BIRn+0Qf+SRR+Lb3/52lXmrVq2Kq6++OioqKiLis9/e/OlPf7rVtXv16hXf+c534vjjj4/69etvds706dPj3/7t3/KXjx88eHB8+ctfjhYtWuzsWwOo88o+nBsd9mqZHx/ZveN2l+aHd9u3yri0pGEkSeKKHQBQTcuXL68ybtGy5RZmbl6LllX/3WX58mU7nQkA2Dqf3wBAbXN59gK74oorYvDgwVsszNf74he/GHfffXd+/O6778aECRNqJMM3vvGNOP744/PjO++8MyZPnlxlzk9/+tP48MMPq4xbtWq1xTWPPfbYePLJJ+Pkk0/eYmEeEbH//vvHww8/HC3/8Q+25eXl8cwzz+zgOwHYtbzx9rQq4wtPP2K7jvvC4QdE+zbNqzxXr169aNK4QU1FA4DMWLmy6u2kGjZoWK3jGzZsVGW8cuXKnc4EAGydz28AoLYpzXdQ//79o0uXLtv8Ovvss6sc17Dh9v8DXZ8+feLoo4/Oj1977bUay3/rrbfmS/CKioq46qqrory8PCIiXnrppfjtb3+bn3vxxRfHCSecsNX1qvO+9txzzyqXea/J9wVQlz39wrhYt25dftzvuEOib+/OWz0mSZL4yRVnb/a10pLq/ZAAAIhYtXJVlXGDhtX7JbSN/91n4/UAgJrn8xsAqG1K8zquT58++ccTJ06ssXX33HPPKpdbnzp1atx+++0xb968uPHGG/PPr7+ce02rrfcFUJdN+XBuDH/187/z6tWrF4/f/k/R/cD2m51fVFQv/vtHX4+je+6/2dddmh0Adl5179O38fxc+DwGgELz+Q0A1DT3NN9Bbdq0iUaNGm1z3l577bVT59lzzz3zj+fOnbtTa23shBNOiK9//evxxBNPRETE448/HqNGjYpFixZFRET9+vVj8ODB2/U+q2vD97V48eJYvXp1tXarA+yqrrztt3HsYZ2iZbMmERHRtlXTeO2xgfHw0Dfi939+J2bNXRxNGjeII7rvF5d99fg45IDPCvWZcxbFPu2q3oNt8TK/GQ8A1dW4pHGV8ery1dU6fv0VutYrKSnZ6UwAwNb5/AYovOr+ghLs6pTmO+jnP/95lUunV9eqVavi5ZdfjldffTXKyspizpw5sWLFilizZs0Wj1m2bNkOn29Lrr322hg1alRMm/bZfXanTp2af+3KK6+Mgw8+uFrrrVu3LkaNGhUvvfRSTJo0KT7++ONYvnx5rFq19WJn2bJlSnMgEz6esyguuvqX8dRd342mpZ/9S3/DBvXj8q99MS7/2hc3e8yyFeXxzeseiZcfuTL/XPnqili9Zm1BMgPA7qRx46o/JF+9pno/dF+z0Xw/dAeA2ufzGwCobUrzFDz77LPxs5/9LD799NNqHbd6dfX+YXB7NGrUKAYPHhwXXnhhVFRU5J/v06dPfOtb36rWWu+++2788Ic/jMmTJ1c7R228N4C66q9j3o+Tv31X/PePvh5HdN9vq3PfnTIzvnX9o7F46coqz8/7tOZ/kQoAsqC0tLTKePE/rrS1vRZt9O9xpaV77HQmAGDrfH4DALVNaV5gDz30UPz85z/f7GvNmzePRo0aRYMGDfLPrVixIhYuXFirmYqKiqJevaq3tz/22GOrdemNUaNGxXe/+91NLnUUEdGkSZNo0qRJNGzYML9mZWVlzJo1Kz/HfXmBrJnw/uw47pKfx2lf6BZnnXho9DmsU7Rt1TRKGjWIOQuWxMSpn8Rvnh8Tz778dlSsrYwjDulY5fh3Jn+cUnIA2LV16LBvlfGcOZ9U6/g5c+ZstF6Hnc4EAGydz28AoLYpzQto8uTJcdddd+XHe+65Z/Tv3z+OO+64OOCAA6qU5es9/fTTcf3119dapjVr1sTVV1+9yU7v++67L0488cQ48MADt7lGeXl5DBo0KF+Y169fP772ta/FqaeeGocccsgmvwkaEfHxxx/HKaecUjNvAmAXNuK1STHitUnbnHfIge2rjP8+aUZtRQKA3Vqz5s2jRcuW+R1nCxcsiFWrVkXjxo23ceRnZs2aWWW8//6dajwjAFCVz28AoLYpzQvoiSeeiMrKyoiIaN26dTz99NPRtm3brR5TG/cx39DgwYOjrKwsPy4pKYmVK1fG6tWr46qrrorf/e53my3zN/TSSy/F7NmzIyKiXr168dBDD0WfPn22ekxtvy+A3c2RG13G/bWxU9MJAgC7gc6dD4gxn46OiIh169bFpIkT4vAjjtyuY8e/+06VcafOB9R4PgBgUz6/AQqrOlcjht1BvW1Poaa89dZb+cf9+/ffZmEeETFz5sxtztlRb7zxRjz66KP58YUXXhi33nprflxWVhZ33nnnNtfZ8H317dt3m4V5RO2+L4DdTXFxvTj7pEPz4w8+nh+vj52WYiIA2LUd0+fYKuOxfx+zXcfN+eSTmL3Bbab223//2Kt9+60cAQDUFJ/fAEBtUpoX0Lx58/KPDz744O06ZtSoUbWSZfHixXHttdfm7yXesWPHuP766+P000+Pc889Nz/vV7/6VbzxxhtbXasuvS+A3dHXzjgy9mzx+a0uHh321lZmAwDbcsKJJ1UZD//jH7bruOc2mnfCCSdtYSYAUNN8fgMAtUlpXkDrC+qIz+4lvi2jR4+OKVOm1EqWH/7wh/myu7i4OO64444oKSmJiIgbb7wx9tlnn4j4LPOgQYNi8eLFW1xrw/e18b3RN2fZsmUxbNiwnUgPkB0tmzWJW644Oz+eu3Bp/M9v/5piIgDY9R14UJc44MCD8uMPPpgWr736ylaPKS8vj9/99skqz53xpS/XSj4AYFM+vwGA2qQ0L6B27drlH//lL3/Z6tzly5fHf/zHf9RKjt/97nfxwgsv5Mff+9734tBDP7/sb2lpadxxxx1RVFQUERFz586NH/3oR1tcb6+99so/fvXVV2PdunVbPf+Pf/xj9zQHMqs69wJq0bQk/vjfA6Ldnk3zzw0aPDQWL1tVG9EAIFMu/96AKuNb//OWWLpkyRbn33PX4Jg9+/NLu5548ilxcNeutZYPANiUz28AoLYozQuob9+++cdDhw6N4cOHb3bexx9/HJdeeml88MEHUa9ezf5fNGPGjPjP//zP/LhXr15x2WWXbTKvd+/eVZ4fMWJEPP3005td89hjP7+f0PTp0+PWW2+NysrKTeYtX748rrvuuvjDH/5Q4+8LoCbtu1fLzX4136NxlXl7Ni/d7Ly2rfbY4trtWzeL8cN+FFd+85TovG/rzc5p0rhB9D/7mBj79I3Rq2uH/PNDXxwbTz6/ffdsAwC27uRT/18celiv/Hjmxx/Hty/9Rrw/pazKvGXLlsWt/3lLPP7YkPxzDRs2jAFX/HuhogIA/+DzG6BwkiTJ3BfZluQ2vLY2WzR06NC47rrr8uMhQ4bE0UcfXa01ZsyYEf369YuKior8c3369IkvfOEL0bJly1i6dGmMHTs2/vznP8eaNWuipKQkvv71r8cvf/nLiIjYe++9Y+TIkZtde9SoUdG/f//8uKysbJM5a9euja9//evxzjvvREREkyZNYtiwYdGhQ4dN5m5ufklJSQwbNiz23XffTeZ96Utfig8//DD/3AEHHBCnnXZa7L333lFeXh5lZWXxwgsvxKJFiyIi4oorroh77rknP//ll1/OXxJ+Z73wwgtxxx13bPL8kiVLYskGv3m6995753fTb+jFF1+skRzV1bjXgG1PAgpi1bj7dur4v455P077zt2bfW3vNs1j6oif5MefzF8SE6fOjoWLV0TDBsXRbs+mcdjBHaJRw/pVjnvxjffiK1f+T5Svrth4SSBFi/62c39fAOmaN29ufP2rF8T8f9y6KuKzHwx163ZI7N2hQyxZvDgmjH83VqxYUeW4n/7sjvjSmWcVOi4AED6/IasaFaedIHta9f+/tCMU3MIhF6UdgRT5a6aA9t1337j55pvjhhtuyF/C/M0334w333xzk7klJSUxePDgrd5LvLruv//+fAEeEfGjH/1oi4V5xOf3Oj/nnHNi5cqVsXLlyhg4cGA88cQTVcrm4uLiuPvuu+OSSy6JpUuXRkTE1KlTY+rUqZusmSRJXH755XH22WdXKc1r0vLly2PGjBnbnDdr1qxtzgGobXu1bhZ7tW62xdfXrVsXv3jiL3HD3cOiYu2mV/EAAHZcmzZt47//53/j6h9cER9Onx4REblcLiZOnBATJ07YZH7Dhg3j6msG+YE7AKTI5zcAUBtcI7vAzjvvvPif//mf6NSp02ZfLyoqiuOOOy6GDh0aJ510Uo2dd9y4cfHAAw/kx6effnqcc8452zyuY8eOccMNN+THb7/9dvziF7/YZN7BBx8cv/vd76pcgn5zcx588MH4t3/7t+qFB9iNLFq6Mh548pX4cNaCrc5bvaYinn5hbBz79dvjmsFDFeYAUEsOPPCgePKpZ+Jb//SdaNmq1WbnFBfXjxNOPCkef/Kp+MrXvl7ghADAxnx+AwA1zeXZU5LL5WLChAkxceLEWLx4cZSWlkabNm2iV69e0br15u9xu6v4+OOP4+9//3vMmzcv6tevH61bt46DDz44DjjggLSj1Wkuzw7Zs3eb5tHjoL1j371aRrN/3C99ybJVMeWjuTH63Q9jZfmalBMC2+Ly7LB7Wbt2bbw9bmzMmjkzFixYEKWlTaJt23bR87Be0bJly7TjAQCb4fMbssHl2Quv1TczeHn2R12ePcuU5lBHKM0BYNejNAcAAIDapzQvPKU5WePy7AAAAAAAAABkltIcAAAAAAAAgMxSmgMAAAAAAACQWe4CAQAAAAAAAOQlSZJ2BCgoO80BAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOU5gAAAAAAAABkVnHaAQAAAAAAAIC6I0mStCNAQdlpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOK0w4AAAAAAAAA1B1JkqQdAQrKTnMAAAAAAAAAMktpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZVZx2AAAAAAAAAKAOSdIOAIVlpzkAAAAAAAAAmaU0BwAAAAAAACCzlOYAAAAAAAAAZJZ7mgMAAAAAAAB5SeKm5mSLneYAAAAAAAAAZJbSHAAAAAAAAIDMUpoDAAAAAAAAkFlKcwAAAAAAAAAyqzjtAAAAAAAAAEDdkSRJ2hHIiClTpkRZWVnMnTs3GjRoEG3bto1evXpFmzZtCppDaQ4AAAAAAACQojVr1kRZWVlMmDAhxo8fH+PHj49p06ZFZWVlfk5ZWVm1173kkkti9OjR1T7upptuiosuuqjax22vl156Ke69996YPHnyJq8VFRVFnz59YtCgQXHggQfWWoYNKc0BAAAAAAAAUnLBBRfE5MmTo6KiIu0oBXHzzTfH448/vsXXKysr47XXXovzzz8/br755jjnnHNqPZPSHAAAAAAAACAl48ePL8h5mjVrFs2aNduuuXvssUetZLj33nurFOYlJSVx1llnRZcuXWL16tUxZsyYGDlyZKxbty5Wr14dN9xwQ7Rt2zb69OlTK3nWU5oDAAAAAAAA1AGlpaXRrVu36NGjR4wdOzbGjRtXY2tfcskl8f3vf7/G1quud955J+677778uEuXLvHQQw9F27Zt889961vfijFjxsTll18eS5cujbVr18ZVV10VL774YjRp0qTWsinNAQAAAAAAgLwkSdKOkCmXXHJJdO/ePXr06BGdOnXK/+8/aNCgGi3N03bXXXflH5eUlMQDDzxQpTBf74gjjoif/OQnccUVV0RExMKFC2PIkCFx+eWX11q2erW2MgAAAAAAAABbdeONN8Y555wTnTt33m1/YWHq1Knx5ptv5sf9+/eP9u3bb3H+aaedFr17986PH3vssVi3bl2t5VOaAwAAAAAAAFBrXnrppSrjCy+8cJvHXHDBBfnHCxYsiHfeeafGc62nNAcAAAAAAACg1rzyyiv5xx07dox99tlnm8f07dt3i2vUNKU5AAAAAAAAALVmypQp+ceHHnrodh3Trl27aNeu3WbXqGnFtbYyAAAAAAAAsMvZXe+rnXWvvfZa/P3vf4/3338/lixZEo0bN44WLVpE165do0+fPnHmmWdGaWlpjZ937ty5sXz58vy4Y8eO233svvvuG3PmzImIiGnTptV4tvWU5gAAAAAAAAC7ubfffrvKuKKiIpYuXRofffRR/OlPf4o777wzvve978Wll15ao+edOXNmlfFee+213cduuNN81qxZNZZpY0pzAAAAAAAAINNmz54ds2fP3qk12rdvH+3bt6+hRLWjYcOG0axZs0iSJBYtWhRr1qzJv7ZkyZK49dZbY+zYsXHnnXdGcXHNVMkb7jKPiGjWrNl2H7vh3IqKili9enU0bNiwRnJtSGkOAAAAAAAAZNrTTz8d9913306tMWDAgPj+979fQ4lqztFHHx2nn3569OnTJzp27Bj16tWLiIjKysqYOHFi/Pa3v42hQ4dGZWVlRESMGDEibrnllvjxj39cI+dfuXJllXGDBg22+9iNC/IVK1YozQEAAAAAAADYPnfffXe0bNlys68VFRVFz549o2fPnnHWWWfF5Zdfnt8V/uSTT8ZZZ50Vhx9++E5nWL16dZVx/fr1t/vYjQv2jdeqKfVqZVUAAAAAAABg15Rk8Gs3taXCfGNHHXVU/OxnP6vy3AMPPFAjGTbeGV5RUbHdx254+fjNrVVT7DQHAAAAAAAAMu3888+PPn367NQadf1+5ttyyimnRK9evWLcuHEREfHWW29FeXl5NGrUaKfWLSkpqTLeuAjfmo13ljdp0mSnsmyJ0hwAAAAAAADItPbt2+/ypXdNOOWUU/Kl+Zo1a2LSpEnRu3fvnVqztLS0ynjJkiXbfezSpUvzj+vXr19rO81dnh0AAAAAAACA2G+//aqMP/30051ec5999qky/uSTT7b72A3n7r333judZUvsNAcAAAAAAADykmQ3vsk3W7XxpdjLy8t3es22bdtGaWlpLF++PCIiZsyYsd3Hbji3U6dOO51lS+w0BwAAAAAAACAWLFhQZdyiRYsaWfeggw7KP3777be365g5c+bEnDlzNrtGTVOaAwAAAAAAABBjx46tMq6pS6Iff/zx+ccfffRRzJw5c5vHvP7661XGX/ziF2sky+YozQEAAAAAAAAybvHixfHcc8/lx+3bt9/kHuc76pRTTqkyfuqpp7Z5zO9+97v841atWsVhhx1WI1k2R2kOAAAAAAAAsJupzv3I161bF9dff33+vuMREWedddZWj7n33nujS5cu+a9Ro0Ztce6BBx4YRx99dH48ZMiQmD179hbnjxgxosqu94svvjjq1au9altpDgAAAAAAAOQlSZK5r93RV7/61bjnnnu2Wk5HRMyaNSu+853vxMsvv5x/rmXLlvHP//zPNZrnyiuvzD9euXJlXH755TFv3rxN5o0ZMyZuvPHGKlkuvfTSGs2yseJaXR0AAAAAAACALRoyZEj8+te/3uT5hQsXVhmfeuqpm8xp167dZo+NiFi2bFn84he/iPvvvz+6desW3bt3j44dO0bTpk0jImLBggUxbty4eP3112Pt2rX54xo2bBi/+MUvYo899tiZt7WJww47LC677LJ44IEHIiJi8uTJcfrpp8fZZ58dBx10UKxevTrGjBkTL7/8cqxbty4iIoqKiuL222+PJk2a1GiWjSnNAQAAAAAAAFKyZMmSmDFjxjbnbW5OZWXlNo/L5XIxceLEmDhx4jbn7r333vHzn/88evfuvc25O+Lf//3fY/HixfHkk09GRMSKFSviiSee2OzcBg0axI9//OM47rjjaiXLhlyeHQAAAAAAAGA387WvfS169eoV9evX3+bcjh07xrXXXhu///3va60wj/js0v8//vGP47777ouDDjpos3Pq1asXffv2jaeffjrOO++8WstSJVcul8sV5EzAVjXuNSDtCABANS36231pRwAAAIDdXiPXTS64fb73bNoRCm7m/eekHaHWrFmzJqZNmxYzZsyIefPmxYoVKyJJkigtLY3WrVtHz549o127dqlkKysri7Kyspg3b17Ur18/2rZtG7169Yq2bdsWNIe/ZgAAAAAAAIC8JEnSjkANatCgQXTt2jW6du2adpRNdOnSJbp06ZJ2DJdnBwAAAAAAACC7lOYAAAAAAAAAZJbSHAAAAAAAAIDMUpoDAAAAAAAAkFnFaQcAAAAAAAAA6pAk7QBQWHaaAwAAAAAAAJBZSnMAAAAAAAAAMktpDgAAAAAAAEBmKc0BAAAAAAAAyKzitAMAAAAAAAAAdUeSJGlHgIKy0xwAAAAAAACAzFKaAwAAAAAAAJBZSnMAAAAAAAAAMktpDgAAAAAAAEBmFacdAAAAAAAAAKg7kiRJOwIUlJ3mAAAAAAAAAGSW0hwAAAAAAACAzFKaAwAAAAAAAJBZ7mkOAAAAAAAA5LmnOVljpzkAAAAAAAAAmaU0BwAAAAAAACCzlOYAAAAAAAAAZJbSHAAAAAAAAIDMKk47AAAAAAAAAFB3JEmSdgQoKDvNAQAAAAAAAMgspTkAAAAAAAAAmaU0BwAAAAAAACCzlOYAAAAAAAAAZFZx2gEAAAAAAACAOiRJOwAUlp3mAAAAAAAAAGSW0hwAAAAAAACAzFKaAwAAAAAAAJBZSnMAAAAAAAAAMqs47QAAAAAAAABA3ZEkSdoRoKDsNAcAAAAAAAAgs5TmAAAAAAAAAGSW0hwAAAAAAACAzFKaAwAAAAAAAJBZxWkHAAAAAAAAAOqOJEnSjgAFZac5AAAAAAAAAJmlNAcAAAAAAAAgs5TmAAAAAAAAAGSWe5oDAAAAAAAAeW5pTtbYaQ4AAAAAAABAZinNAQAAAAAAAMgspTkAAAAAAAAAmaU0BwAAAAAAACCzitMOAAAAAAAAANQdSZKkHQEKyk5zAAAAAAAAADJLaQ4AAAAAAABAZinNAQAAAAAAAMgspTkAAAAAAAAAmVWcdgAAAAAAAACg7kiStBNAYdlpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOK0w4AAAAAAAAA1B1JkqQdAQrKTnMAAAAAAAAAMktpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZVZx2AAAAAAAAAKDuSJK0E0Bh2WkOAAAAAAAAQGYpzQEAAAAAAADILKU5AAAAAAAAAJnlnuYAAAAAAABAXr16bmpOtthpDgAAAAAAAEBmKc0BAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOK0w4AAAAAAAAA1B1JknYCKCw7zQEAAAAAAADILKU5AAAAAAAAAJmlNAcAAAAAAAAgs5TmAAAAAAAAAGRWcdoBAAAAAAAAgLojSZK0I0BB2WkOAAAAAAAAQGYpzQEAAAAAAADILKU5AAAAAAAAAJmlNAcAAAAAAAAgs4rTDgAAAAAAAADUHUmSdgIoLDvNAQAAAAAAAMgspTkAAAAAAAAAmaU0BwAAAAAAACCzlOYAAAAAAAAAZFZx2gEAAAAAAACAuiNJkrQjQEHZaQ4AAAAAAABAZinNAQAAAAAAAMgspTkAAAAAAAAAmaU0BwAAAAAAACCzitMOAAAAAAAAANQdSZKkHQEKyk5zAAAAAAAAADJLaQ4AAAAAAABAZinNAQAAAAAAAMgs9zQHAAAAAAAA8tzSnKyx0xwAAAAAAACAzFKaAwAAAAAAAJBZSnMAAAAAAAAAMktpDgAAAAAAAEBmFacdAAAAAAAAAKg7kiRJOwIUlJ3mAAAAAAAAAGSW0hwAAAAAAACAzFKaAwAAAAAAAJBZSnMAAAAAAAAAMqs47QAAAAAAAABA3ZEkaSeAwrLTHAAAAAAAAIDMUpoDAAAAAAAAkFlKcwAAAAAAAAAyS2kOAAAAAAAAQGYVpx0AAAAAAAAAqDuSJEk7AhSUneYAAAAAAAAAZJbSHAAAAAAAAIDMUpoDAAAAAAAAkFlKcwAAAAAAAAAyqzjtAAAAAAAAAEDdkSRpJ4DCstMcAAAAAAAAgMxSmgMAAAAAAACQWUpzAAAAAAAAADLLPc0BAAAAAACAvMRNzckYO80BAAAAAAAAyCylOQAAAAAAAACZpTQHAAAAAAAAILOU5gAAAAAAAABkVnHaAQAAAAAAAIC6I0nSTgCFZac5AAAAAAAAAJmlNAcAAAAAAAAgs5TmAAAAAAAAAGSW0hwAAAAAAACAzCpOOwAAAAAAAABQdyRJknYEKCg7zQEAAAAAAADILKU5AAAAAAAAAJnl8uwAAAAAAAAAu7FcLhczZsyIKVOmxCeffBIrVqyIkpKSaNWqVXTv3j3222+/tCOmSmkOAAAAAAAAkKI1a9ZEWVlZTJgwIcaPHx/jx4+PadOmRWVlZX5OWVlZtdZcvXp1/OUvf4kXX3wx3nzzzViwYMEW53bo0CG+8Y1vxMUXXxz169ff4fexNSeddFLMmjWr2sc99NBDcfzxx9dCos8pzQEAAAAAAIC8JEk7QbZccMEFMXny5KioqKjRdU855ZSYN2/eds39+OOP49Zbb41hw4bFPffcEx06dKjRLHWd0hzqiBd+c0vaEQAAAGC399GClWlHAACqqUu7krQjQK0aP358ray7atWqKuN99903jjzyyNh///2jRYsWsXLlypgwYUK88MIL+bmTJk2Kb37zm/Hkk09GmzZtaiVXRESrVq2iSZMm2zW3pKT2/w6oM6V5RUVFvPfee/HBBx/E0qVLY/ny5bFu3bpqrTFgwIBaSgcAAAAAAABQu0pLS6Nbt27Ro0ePGDt2bIwbN26n1mvcuHGce+658ZWvfCW6du262TkDBw6Mq666KkaNGhUREbNmzYqf/vSn8V//9V87de6tufrqq+O8886rtfWrK/XS/N13341f/epX8dJLL+30JQeU5gAAAAAAAMCu5JJLLonu3btHjx49olOnTpH84/r4gwYN2qnS/KKLLor+/ftH69attzqvdevW8eCDD8aFF14Y77//fkREPP/883HVVVdl5jLtqZXmuVwu7rrrrvjlL38ZuVwucrncZuclG9w0YXNzkiSJXC5XZR4AAAAAAADAruDGG2+slXWvuuqq7Z7buHHj+N73vhc/+MEP8s/99a9/jYsvvrg2otU5qZXmt99+e/zqV7/abOG9taJ849e2VLYDAAAAAAAA1WezajYdc8wxVcYff/xxSkkKL5XSfNSoUfHII49EkiSRJEnUr18/Lr744jj55JNj3bp10b9//4j47A/kyy+/HCtWrIgFCxbE22+/HX/84x/jgw8+iCRJomXLlnHTTTfFIYccksbbAAAAAAAAANgtNGnSpMp45cqVKSUpvFRK8wcffDAiPtsp3rhx43jkkUfisMMOi4jPbiy/ob333jsiIg466KA49thj43vf+148++yz8ZOf/CQWLVoU1157bdx3333Rt2/fgr4HAAAAAAAAgN3FzJkzq4z33HPPlJIUXsFL8+XLl8dbb72Vv6zDv/7rv+YL8+11zjnnRKdOneLSSy+NlStXxhVXXBG///3v8wU7AAAAAAAAANvvpZdeqjI+9NBDa+1cf/jDH+Kpp56KDz/8MJYtWxZNmjSJFi1aRM+ePaNv375xxhlnRIMGDWrt/BurV7Az/cO4ceNi3bp1kcvlon79+vG1r31th9bp2bNnXHHFFRHx2aUB7rvvvpqMCQAAAAAAAJmUJNn7yrry8vL4v//7v/y4RYsW0adPn1o73xtvvBFjx46NTz/9NCoqKmLx4sUxffr0GDZsWFxzzTVx8sknx+9///taO//GCr7T/JNPPomIz+5X3qVLlygtLd3q/IqKiqhfv/5mX7vooovi7rvvjlWrVsULL7wQN910UzRs2LDGMwMAAAAAAAC7r9mzZ8fs2bN3ao327dtH+/btayhRYd155535Hjci4rvf/W6t7/Ru3LhxNGvWLCorK2Px4sVRUVGRf23evHkxcODAGD9+fNxwww21miMihdJ88eLF+cd77bXXJq9vXJCvXr16i6V5w4YNo2fPnjFq1KhYuXJljBkzxr3NAQAAAAAAgGp5+umnd/rK1gMGDIjvf//7NZSocF5++eUYMmRIftylS5f4xje+UePnKSoqihNPPDFOO+20OPLII2OfffbJv7ZmzZp4++2347HHHosRI0bknx8yZEi0bt06vvvd79Z4ng0VvDTfUKNGjTZ5rkmTJlXGCxcu3Opu9A1vQD937tyaCwcAAAAAAACwG5s8eXIMHDgwcrlcRHy2aXnw4MG1ssv8N7/5TbRs2XKzrzVo0CCOOuqoOOqoo2L48OExcODAWLt2bURE3HPPPXHGGWdEhw4dajzTegW/p3nTpk3zj5cvX77J602aNKmys/zjjz/e6npr1qzJP16wYEENJAQAAAAAAADYvc2cOTO+853vxIoVKyIiol69enHbbbfFgQceWCvn21JhvrF+/frFwIED8+OKior43//931rJtF7Bd5pv+BsA8+fP3+ycTp06RVlZWUREjBs3Lr7whS9scb2JEyfmH29u5zoAAAAAAACw/ZIkSTtCwZ1//vnRp0+fnVpjV7qf+fz58+Pb3/52zJs3L//cj370o+jXr1+KqT73jW98Ix599NH8feZfeeWVWj1fwUvzAw44ICIicrlcTJ06NXK53CZ/8Hr06BFlZWWRy+Vi2LBhcfnll0dx8aZRR44cmf8fKmLX+kYEAAAAAAAA6ob27dtnpmtcvHhxfPvb346PPvoo/9xVV10VF110UYqpqiouLo4TTjghnnjiiYiImD17dsydOzfatm1bK+cr+OXZ27Ztm99tXl5eHu++++4mc04//fSI+Oy3WGbNmhWDBg2K8vLyKnPGjBkT119/fb5wLyoqiiOPPLKW0wMAAAAAAADsmpYvXx7//M//HFOmTMk/d9lll8V3v/vdFFNtXseOHauMP/3001o7V8F3mkdE9O3bN5588smI+Gy3+KGHHlrl9WOPPTYOPPDAmDp1akREPPfcc/HXv/41evfuHaWlpfHhhx/GxIkT8zekT5IkvvSlL0WzZs0K+0YAAAAAAAAAdgGrVq2Kf/mXf4nx48fnn7vkkkviBz/4QYqptqxx48ZVxhtvsq5JBd9pHhHxpS99KSI+u0T7008/HRUVFVVD1asXN998c9SvXz//3NKlS+OVV16J5557Ll+Yr99l3rp167jmmmsK9wYAAAAAAAAAdhFr1qyJAQMGxJgxY/LPnXfeeXHDDTekmGrrFixYUGXcokWLWjtXKjvNjzjiiPjP//zPWLduXUR8Voi3atWqypxevXrFfffdF9dcc00sXrx4s+vkcrno2LFj/Pd///cmxwMAAAAAAADV9499q+wm1q5dGz/4wQ/itddeyz93xhlnxE9+8pP8JuW6aOzYsfnH9evXr7X7mUekVJonSRLnn3/+Nucdf/zxMWLEiHj88cfjr3/9a3z00UexbNmyaNq0aRx00EFx2mmnxfnnnx8NGjQoQGoAAAAAAACAXUcul4vrrrsuXnrppfxzJ554Ytxxxx1RVFSUYrKt++CDD+LNN9/Mjw877LBNLtdek1IpzaujWbNm8b3vfS++973vpR0FAAAAAAAAYJfx4x//OH7/+9/nx3369Im77767ym2yd9SgQYPimWeeyY9ffvnl2GeffTY7t7y8PBo1arRd665evTquvfbaqKyszD939tln71zYbUjlnuYAAAAAAAAA1J6f//zn8X//93/5ce/eveP++++Phg0bFjzLKaecEo888kgsXLhwq/Pef//9uOiii+Ldd9/NP9e5c+c499xzazVfwXeaT5o0KYYNG5Yff/vb367V688DAAAAAAAA1FVDhgyJX//615s8v3HBfOqpp24yp127dps99pNPPomHHnqoynMzZ86s1o7tLa29I+bPnx+33XZb3HHHHXHooYdGt27dokOHDlFaWhqVlZUxb968GD16dPztb3+LXC6XP65FixZx//33R3Fx7dbaBS/NR48eHY8++mgkSRJt2rSJQYMGFToCAAAAAAAAsAVJkqQdIVOWLFkSM2bM2Oa8zc3Z8BLm23p+3rx51cq1pbV3RmVlZYwdOzbGjh27zbkHH3xw3HnnnbHffvvVeI6NFbw0X7NmTf7xQQcd5A8dAAAAAAAAwG7sW9/6VowaNSrKysq2WcYffPDBcfHFF8c555wTDRo0KEi+JLfh/vYCeOaZZ+K6666LJEmiX79+MXjw4EKeHuqsV6csSjsCAFBNR3ZqkXYEAKCaPlqwMu0IAEA1dWlXknaEzDlu8GtpRyi4V6/6QtoRMqG8vDymTJkSM2fOjPnz58fKlSujqKgo9thjj2jbtm0ceuih0apVq4LnKvhO83bt2uUfL1qkJAQAAAAAAADIgkaNGkXPnj2jZ8+eaUepol6hT3j44YdH06ZNI5fLxbvvvhtr164tdAQAAAAAAAAAiIgUSvMGDRpEv379IiJixYoVMXTo0EJHAAAAAAAAALYgSZLMfZFtBS/NIyKuuuqqaN++feRyubjjjjvivffeSyMGAAAAAAAAABmXSmm+xx57xP333x977bVXLFu2LC6++OJ49NFHo7y8PI04AAAAAAAAAGRUksvlcoU+6bPPPhsREZ9++mncd999sXLlykiSJEpKSuKYY46Jrl27RosWLaJJkybVWvecc86p+bBQIK9OWZR2BACgmo7s1CLtCABANX20YGXaEQCAaurSriTtCJlz/J2vpx2h4P56Zd+0I5Ci4jROOmjQoCr3BkiSJHK5XKxYsSJGjhwZI0eO3KF1leYAAAAAAAAAVEcqpfl6uVwuX55vWKJv+Pq2rC/cN3c8AAAAAAAAUD1qN7ImtdJ8fSG+s1eHT+Hq8gAAAAAAAADsJlIpzYcMGZLGaQEAAAAAAACgilRK86OOOiqN0wIAAAAAAABAFane0xwAAAAAAACoWxI3NSdj6qUdAAAAAAAAAADSojQHAAAAAAAAILOU5gAAAAAAAABkltIcAAAAAAAAgMwqrukFn3322U2eO+ecc7Y5pyZsfB4AAAAAAACgepIk7QRQWDVemg8aNCiSjf4kbVxmb25OTVCaAwAAAAAAAFAdNV6abyiXy221HM/lcjt9jiRJtnkeAAAAAAAAANicWinNt6cMr4nCvCbXAQAAAAAAACB7arw0HzJkSI3MAQAAAAAAAIDaVuOl+VFHHVUjcwAAAAAAAIDCc1tksqZe2gEAAAAAAAAAIC1KcwAAAAAAAAAyS2kOAAAAAAAAQGYpzQEAAAAAAADIrOK0A6w3Z86cePXVV2Ps2LExc+bMWLJkSaxcuTIiIl566aVN5q9bty7Wrl0bERH16tWL4uI681YAAAAAAABgl5UkaSeAwkq9af7oo4/irrvuipdeeikqKyvzz+dyuYiISLbwp3L48OExcODAiIjYY4894tVXX42GDRvWfmAAAAAAAAAAdhupXp7997//fZx77rkxYsSI/K7xXC4XuVxui2X5emeccUa0bds2crlcLFu2LEaMGFGIyAAAAAAAAADsRlIrzZ977rm49tpr85dgj/isMG/fvn107do1v9N8S4qKiuLMM8/Mjzd3CXcAAAAAAAAA2JpUSvNZs2bFddddFxGfXX69Xr168e1vfzv+/Oc/x8iRI+Pee+/drnVOPfXUiPisbB81atQ2i3YAAAAAAAAA2FAq9zS/6667Ys2aNRER0aBBg3jwwQejT58++de3dWn29bp37x4NGjSINWvWxNKlS+PDDz+M/fffv1YyAwAAAAAAQBbU286uDnYXBd9pvnr16njxxRcjSZJIkiSuvPLKKoV5dRQVFcUBBxyQH0+bNq2mYgIAAAAAAACQAQUvzceMGROrV6+OXC4XJSUlcfHFF+/Uem3atMk/njdv3s7GAwAAAAAAACBDCl6az549OyI+uwT7oYceGvXr19+p9UpLS/OPly9fvlNrAQAAAAAAAJAtBb+n+aJFi/KPW7VqtdPrrV27Nv+4Xr2C/w4AAAAAAAAA7Fbc0pysKXjLXFJSkn+8cuXKnV5v4cKF+cfNmzff6fUAAAAAAAAAyI6Cl+YtW7bMP/7www93aq1169bFpEmT8uPWrVvv1HoAAAAAAAAAZEvBS/OuXbtGREQul4sPPvggZs2atcNrvf7667FixYqI+OzS7L17966RjAAAAAAAAABkQ8FL8/333z/22Wef/PiBBx7YoXXWrVsXv/jFLyIiIkmSOOSQQ2KPPfaokYwAAAAAAAAAZEPBS/OIiAsvvDAiPttt/rvf/S6GDh1a7TVuu+22ePvtt/PjSy65pKbiAQAAAAAAQGYlSZK5L7ItldL80ksvjdatW0eSJJHL5eKGG26IW265JT799NNtHjtt2rS47LLL4te//nX+m7hz585x5plnFiA5AAAAAAAAALuT4jRO2rBhw7j77rvjW9/6VqxZsyZyuVw88cQT8Zvf/CYOP/zwaN++fZX5gwcPjkWLFsU777wTU6dOjYjPdqlHRDRp0iTuvvtuvwECAAAAAAAAQLWlUppHRPTu3TvuuuuuuPrqq2PVqlUREbF27doYPXp0lXm5XC5++ctf5h9HRL4gLy0tjbvvvjs6d+5cwOQAAAAAAAAA7C5SuTz7eieddFIMHTo0evbsmS/E19vcPQTWP87lctGtW7f47W9/G3379i1oZgAAAAAAAAB2H6ntNF9vv/32i9/85jfx1ltvxZNPPhmjR4/e4r3NGzduHEcddVR89atfjZNOOqnASQEAAAAAAGD3V89dkcmY1Evz9Y455pg45phjIiLiww8/jDlz5sSSJUti7dq10axZs2jVqlUceOCBUVxcZyIDAAAAAAAAsIurkw30fvvtF/vtt1/aMQAAAAAAAADYzaV6T3MAAAAAAAAASJPSHAAAAAAAAIDMqpOXZwcAAAAAAADSkSRJ2hGgoOw0BwAAAAAAACCzanynef/+/Wt6ye2SJEk8+uijqZwbAAAAAAAAgF1TjZfmo0ePLvglG3K5nMtEAAAAAAAAAFBtqd7TPJfLVRlvb/G98XEAAAAAAAAAsCNqvDRv3759teYvWrQoysvLI6JqGd6oUaMoLS2NiIjly5fn50R8Xq43btw4mjdvvpOJAQAAAAAAgPVc4JmsqfHSfOTIkds998EHH4x77703crlcFBcXx2mnnRb9+vWLHj16RJs2barMnTdvXowfPz6GDx8eI0aMiLVr10ZFRUV85Stficsuu6ym3wYAAAAAAAAAGZDkUrrW+S233BJPPPFERER069Ytbr/99ujcufN2HTtt2rQYOHBgTJo0KZIkia9+9atx00031WJaqH2vTlmUdgQAoJqO7NQi7QgAQDV9tGBl2hEAgGrq0q4k7QiZ86UHR6cdoeCe+5ej0o5AiuqlcdLhw4fH448/HrlcLrp27RpDhgzZ7sI8IqJz587x2GOPRdeuXSOXy8VvfvObeO6552oxMQAAAAAAAAC7o1RK81/+8pcR8dm9yW+55ZZo0qRJtdcoKSmJm2++OT9+6KGHaiwfAAAAAAAAZFWSwf+QbQUvzadMmZK/rHrnzp3jkEMO2eG1evToEQcccEDkcrkoKyuLsrKyGkwKAAAAAAAAwO6u4KX51KlT8487deq00+ttuMaGawMAAAAAAADAthS8NJ8zZ06trT137txaWxsAAAAAAACA3U/BS/Pi4uL84+nTp+/0ehuuUVRUtNPrAQAAAAAAAJAdxdueUrPatWsXERG5XC6mTp0akydPjoMPPniH1nrvvffi/fff32RtAAAAAAAAYMfUS9JOAIVV8J3mRx11VBQXF0eSJJHL5eLGG2+M8vLyaq+zatWquPHGG/PjoqKiOProo2syKgAAAAAAAAC7uYKX5s2bN4+TTjopcrlcJEkSEydOjEsvvTRmzJix3Wt89NFHcemll8bEiRMjSZJIkiROPvnkaN68ee0FBwAAAAAAAGC3U/DLs0dEXH/99fH666/HypUrIyLi7bffjjPPPDP69esXp59+evTo0SNatWpV5ZiFCxfG+PHj4/nnn4/nn38+Kioq8rvVS0tL47rrrkvjrQAAAAAAAACwC0ulNG/Xrl3cc8898a//+q+xevXqSJIk1qxZE8OGDYthw4ZFRESjRo2itLQ0IiKWL19e5RLu63ep53K5aNSoUdxzzz3uZw4AAAAAAABAtRX88uzr9e3bNx5++OHYe++98yV4xGeFeC6Xi1WrVsX8+fNj/vz5sWrVqvzzEZEvzDt06BAPP/xwHHvssWm9DQAAAAAAANitrL89cpa+yLbUSvOIiN69e8cf//jHGDBgQOy55575Uny9zX2T5nK52HPPPWPAgAHxhz/8IXr37l3IyAAAAAAAAADsRlK5PPuGGjVqFAMGDIjLL7883nrrrRg3blxMmjQpFi5cGEuXLo2IiKZNm0arVq2iW7du0atXrzjmmGOiqKgo5eQAAAAAAAAA7OpSL83XKyoqir59+0bfvn3TjgIAAAAAAABARqR6eXYAAAAAAAAASFOd2WkOAAAAAAAApC9J0k4AhWWnOQAAAAAAAACZpTQHAAAAAAAAILPq1OXZc7lczJkzJ5YsWRLLly+PXC5XreOPPPLIWkoGAAAAAAAAwO4o9dK8vLw8nn322Rg+fHhMmDAhVq1atUPrJEkSkyZNquF0AAAAAAAAAOzOUi3NX3311Rg0aFB8+umnERHV3lkOAAAAAAAA1Kx6SZJ2BCio1Erz5557LgYOHBjr1q3b5LVkgz+IGxfpW3sNAAAAAAAAAKojldL8o48+ihtuuCHWrVsXSZJELpeLbt26xcknnxwNGjSIwYMHR8RnBfmtt94aK1asiPnz58c777wTY8aMibVr10aSJNGyZcu4/PLLo7S0NI23AQAAAAAAAMAuLpXS/MEHH4zy8vL8eNCgQXHppZdGRMSsWbPypXlExLnnnlvl2Llz58Z//dd/xTPPPBOLFi2Kxx57LB5++OHYe++9C5IdAAAAAAAAgN1HvUKfsKKiIoYPHx5JkkSSJHHhhRfmC/Pt0bZt27j11lvjP/7jPyKXy8WMGTPiO9/5Tqxatar2QgMAAAAAAACwWyp4aT5+/PgoLy+PXC4XSZLEv/zLv+zQOhdddFF89atfjVwuF9OnT4//+Z//qeGkAAAAAAAAkD1Jkr0vsq3gpfmHH34YEZ/dr3y//fbb5mXVKysrt/jaFVdcEfXqffYWhg4dWmMZAQAAAAAAAMiGgpfmS5YsyT/ef//9N3m9qKioynjNmjVbXKtVq1bRvXv3yOVyMW/evHj77bdrLCcAAAAAAAAAu7+Cl+YbluBNmjTZ5PWSkpIq40WLFm11vfbt2+cff/zxxzuZDgAAAAAAAIAsKS70CTcsysvLyzd5vbS0NJIkiVwuFxERn3zySZVifGPrL88eETF//vwaTAoAAAAAAADZk7jJNxlT8J3m7dq1yz/e3C7yevXqRYcOHfLjCRMmbHW96dOn11w4AAAAAAAAADKl4KV5p06dIiIil8vF+++/v9k5Bx98cP7x888/v8W13n///Xjvvffyv+2y55571mBSAAAAAAAAAHZ3qZTmzZs3j4iIJUuWxIwZMzaZc/LJJ0fEZ8X6O++8E48//vgmc5YsWRLXXnttfl5ERO/evWspNQAAAAAAAAC7o4KX5hERxxxzTP7xn//8501eP/XUU6NFixb5e5v/5Cc/iX/6p3+KRx55JJ566qm4/fbbo1+/fvld5kmSxBFHHBH77LNPId8GAAAAAAAAALu44jROetppp8Wf/vSnyOVyMXTo0PjmN79Z5fWSkpIYOHBgXH/99fni/I033og33ngjPyeXy+Vfa9CgQX7XOQAAAAAAALDj/nFnZMiMVErzk046Kc4+++xYt25dRETMmTMn2rVrV2XOeeedFzNnzoz7778/f8/yDa0vzBs2bBg/+9nPonv37gXJDgAAAAAAAMDuI5XSfH3RvS1XXHFFHHPMMXH//ffHmDFjYu3atfnXGjduHCeccEIMGDAgOnfuXJtxAQAAAAAAANhNpVKaV8dRRx0VRx11VKxcuTJmz54dy5Yti6ZNm0aHDh2iQYMGaccDAAAAAAAAYBdW50vz9UpKSuKAAw5IOwYAAAAAAAAAu5FdpjQHAAAAAAAAal+9JEk7AhRUvbQDAAAAAAAAAEBalOYAAAAAAAAAZJbSHAAAAAAAAIDMqvF7mvfv37+ml9wuSZLEo48+msq5AQAAAAAAANg11XhpPnr06EiSpKaX3apcLlfwcwIAAAAAAMDuSOtG1tR4aV4duVyuynh7i++NjwMAAAAAAACAHVHjpXn79u2rNX/RokVRXl4eEVXL8EaNGkVpaWlERCxfvjw/J+Lzcr1x48bRvHnznUwMAAAAAAAAQFbVeGk+cuTI7Z774IMPxr333hu5XC6Ki4vjtNNOi379+kWPHj2iTZs2VebOmzcvxo8fH8OHD48RI0bE2rVro6KiIr7yla/EZZddVtNvAwAAAAAAAIAMSHIpXev8lltuiSeeeCIiIrp16xa33357dO7cebuOnTZtWgwcODAmTZoUSZLEV7/61bjppptqMS3UvlenLEo7AgBQTUd2apF2BACgmj5asDLtCABANXVpV5J2hMz52qPj0o5QcE9+s1faEUhRvTROOnz48Hj88ccjl8tF165dY8iQIdtdmEdEdO7cOR577LHo2rVr5HK5+M1vfhPPPfdcLSYGAAAAAACAbEiSJHNfZFsqpfkvf/nLiPjsD9wtt9wSTZo0qfYaJSUlcfPNN+fHDz30UI3lAwAAAAAAACAbCl6aT5kyJX9Z9c6dO8chhxyyw2v16NEjDjjggMjlclFWVhZlZWU1mBQAAAAAAACA3V3BS/OpU6fmH3fq1Gmn19twjQ3XBgAAAAAAAIBtKS70CefMmVNra8+dO7fW1gYAAAAAAIAsqOcW32RMwXeaFxd/3tNPnz59p9fbcI2ioqKdXg8AAAAAAACA7Ch4ad6uXbuIiMjlcjF16tSYPHnyDq/13nvvxfvvv7/J2gAAAAAAAACwPQpemh911FFRXFwcSZJELpeLG2+8McrLy6u9zqpVq+LGG2/Mj4uKiuLoo4+uyagAAAAAAAAA7OYKXpo3b948TjrppMjlcpEkSUycODEuvfTSmDFjxnav8dFHH8Wll14aEydOjCRJIkmSOPnkk6N58+a1FxwAAAAAAACA3U7xtqfUvOuvvz5ef/31WLlyZUREvP3223HmmWdGv3794vTTT48ePXpEq1atqhyzcOHCGD9+fDz//PPx/PPPR0VFRX63emlpaVx33XVpvBUAAAAAAADYrSRJknYEKKhUSvN27drFPffcE//6r/8aq1evjiRJYs2aNTFs2LAYNmxYREQ0atQoSktLIyJi+fLlVS7hvn6Xei6Xi0aNGsU999zjfuYAAAAAAAAAVFvBL8++Xt++fePhhx+OvffeO1+CR3xWiOdyuVi1alXMnz8/5s+fH6tWrco/HxH5wrxDhw7x8MMPx7HHHpvW2wAAAAAAAABgF5ZaaR4R0bt37/jjH/8YAwYMiD333DNfiq+3/n7lG8rlcrHnnnvGgAED4g9/+EP07t27kJEBAAAAAAAA2I2kcnn2DTVq1CgGDBgQl19+ebz11lsxbty4mDRpUixcuDCWLl0aERFNmzaNVq1aRbdu3aJXr15xzDHHRFFRUcrJAQAAAAAAANjVpV6ar1dUVBR9+/aNvn37ph0FAAAAAAAAMmujC0HDbq/gpfmkSZNi2LBh+fG3v/3taNu2baFjAAAAAAAAAEDhS/PRo0fHo48+GkmSRJs2bWLQoEGFjgAAAAAAAAAAERFRr9AnXLNmTf7xQQcdFInrOwAAAAAAAACQkoKX5q1bt84/btq0aaFPDwAAAAAAAAB5Bb88e7t27fKPFy1aVOjTAwAAAAAAAFvhStFkTcF3mh9++OHRtGnTyOVy8e6778batWsLHQEAAAAAAAAAIiKF0rxBgwbRr1+/iIhYsWJFDB06tNARAAAAAAAAACAiUijNIyKuuuqqaN++feRyubjjjjvivffeSyMGAAAAAAAAABmXSmm+xx57xP333x977bVXLFu2LC6++OJ49NFHo7y8PI04AAAAAAAAAGRUksvlcoU+6bPPPhsREZ9++mncd999sXLlykiSJEpKSuKYY46Jrl27RosWLaJJkybVWvecc86p+bBQIK9OWZR2BACgmo7s1CLtCABANX20YGXaEQCAaurSriTtCJlz6f+9m3aEgvvVRT3TjkCKitM46aBBgyJJkvw4SZLI5XKxYsWKGDlyZIwcOXKH1lWaAwAAAAAAAFAdqZTm6+VyuXx5vmGJvuHr27K+cN/c8QAAAAAAAAB8bsqUKVFWVhZz586NBg0aRNu2baNXr17Rpk2bgmd5991344MPPoh58+ZFkyZNom3btnHkkUdGs2bNCpojtdJ8fSG+s1eHT+Hq8gAAAAAAAAA1Zs2aNVFWVhYTJkyI8ePHx/jx42PatGlRWVmZn1NWVrZT53jppZfi3nvvjcmTJ2/yWlFRUfTp0ycGDRoUBx544E6dZ3s89dRT8dBDD8VHH320yWv169ePk08+Oa677rpo165drWeJSKk0HzJkSBqnBQAAAAAAALbBFZ4L64ILLojJkydHRUVFrZ3j5ptvjscff3yLr1dWVsZrr70W559/ftx88821dlvsNWvWxJVXXhkvvvjiFudUVFTEn/70p3jzzTfjrrvuir59+9ZKlg2lUpofddRRaZwWAAAAAAAAoE4ZP358ra5/7733VinMS0pK4qyzzoouXbrE6tWrY8yYMTFy5MhYt25drF69Om644YZo27Zt9OnTp8az/OhHP6pSmLdo0SLOPvvs6NSpUyxZsiTeeOONePPNNyMiYsmSJfH9738/nnzyyTjooINqPMuGkpzrm0Od8OqURWlHAACq6chOLdKOAABU00cLVqYdAQCopi7tStKOkDnferJ2S9y66JGv9Ujt3F26dMk/Li0tjW7dukWPHj1i7NixMW7cuPxrO3J59nfeeSe+8pWvVDnXQw89FG3btq0yb8yYMXH55ZfH0qVLIyKiVatW8eKLL0aTJk2qfc4tGT58ePzgBz/Ij4855pj4xS9+EaWlpVXm/elPf4qBAwfGmjVrIiLioIMOimHDhkW9evVqLMvGam9lAAAAAAAAALbqkksuiZ/97GcxfPjwGDNmTPz617+Oa665Jvbbb7+dXvuuu+7KPy4pKYkHHnhgk8I8IuKII46In/zkJ/nxwoULa/SW25WVlXHPPffkx+3atdtsYR4Rcfrpp1cp16dMmRJ//OMfayzL5ijNAQAAAAAAAFJy4403xjnnnBOdO3eu0fvJT506NX+p84iI/v37R/v27bc4/7TTTovevXvnx4899lisW7euRrK89tprMX369Px4wIABmy3M1/vmN79ZJWtNFvibozQHAAAAAAAA8pIMfu2OXnrppSrjCy+8cJvHXHDBBfnHCxYsiHfeeafGs5SUlMSXvvSlrc4vKiqKc889Nz+eMGFCzJ07t0aybE6dKc3ffvvtuOuuu+KSSy6Jk046KQ4//PDo2rVrdOvWbbPzP/3005g+fXpMnz49Zs+eXeC0AAAAAAAAAHXXK6+8kn/csWPH2GeffbZ5TN++fbe4Rk1lOeyww6KkpGSbxxx77LH5x7lcLv7617/WSJbNKa61lbfT3//+97jttttiwoQJ+edyudw2j3v33Xfj8ssvj4iIRo0axauvvrrVLfwAAAAAAAAAWTFlypT840MPPXS7jmnXrl20a9cu5syZs8kaO2rJkiVVdolvb5YePXpEcXFxrF27tsaybEmqO80feOCB6N+/f0yYMCFflK//721dr/+EE06Ijh07Ri6Xi/Ly8lq/+TsAAAAAAADArmDu3LmxfPny/Lhjx47bfey+++6bfzxt2rSdzrLxGtubpWHDhtG2bdv8+IMPPtjpLFuS2k7zRx55JP7rv/4rIj4vyBs1ahTdu3ePJk2axF/+8pdtrnHmmWfGfffdFxERI0eOjK997Wu1FRcAAAAAAADYTc2ePXunbwndvn37aN++fQ0l2jkzZ86sMt5rr722+9h27drlH8+aNSv1LOszfPzxxzudZUtSKc3LysrijjvuyJfljRs3jquuuiouvPDCaNCgQcyaNWu7SvNTTz017rvvvsjlcvG3v/0t1q5dG8XFqV9xHgAA+P/s3XeclNX5N+B7tlCWlV4EBBQRsATFxgs2BI3GLsbYYs1PYwySWMGaWGJHYyyxRY0tRkU0RhMVeyHYUASVJipFQDosu7AL8/5BmLD0sjOzy1xXPvvJc5455zzfCZrRveecAwAAANRYeevYEXpzNGjQoNRi3Y3Vt2/fOPfcc6so0aZZcZV5RESDBg3We+yKfcvLy2PRokVRu3btrGSpX79+6rqkpGSjM6xLVirMt912WyxdujQilr3Rxx57LDp27LjB83Ts2DHq1q0bpaWlUVZWFhMmTIjtttuuquMCAAAAAAAA1BgLFy6s1K5Vq9Z6j125QF5SUrJJRfNNyVKnTp01zlOVMn6m+YIFC+Ldd9+NRCIRiUQiLr300o0qmEcs29Z9xSJ5OvexBwAAAAAAAKgJFi1aVKldWFi43mNXLmqvPNemZtmQovmKfcvKyjYpx9pkfKX5Rx99FBUVFRER0bBhwzjyyCM3ab4mTZqkrmfMmLFJcwEAAAAAAAC555hjjonu3btv0hzV5TzziFVXi5eXl6/32MWLF691rk3NsvL865tlxVXnVS3jRfOpU6dGxLJV4l26dEmda76xiouLU9fp3MceAAAAAAAA2Dy1atWqWhW9N1VRUVGl9oYUqldeGV6vXr2sZVlxdfnK81SljBfN586dm7rekEPe12TFP7SCgqwc0Q4AAAAAAACbjU1c80o1sOLC44jKNdp1mTdvXuq6sLBwk1eab0qW+fPnp643tXi/Nhk/03yLLbZIXS9YsGCT5/vhhx9S1w0bNtzk+QAAAAAAAABqsq222qpS+/vvv1/vsSv2bd26dbXJ0qZNm03OsiYZL5qveAb5uHHjNmmu8vLy+PLLL1Ptli1bbtJ8AAAAAAAAADVdixYtKq3w/u6779Z77Ip927dvv8lZVp5jfbMsXrw4pk2blmpvs802m5xlTTJeNP/Rj34UERHJZDImTZoUY8eO3ei5hgwZktrHvqCgILp27VolGQEAAAAAAABqso4dO6auP/300/UaM3Xq1Jg6depq59hYDRs2jBYtWmxwlhEjRkRFRUWq3alTp03OsiYZL5q3atUqOnTokGrffvvtGzXPokWL4q677oqIiEQiEbvuumvUqVOnSjICAAAAAAAA1GT77rtv6vrbb7+NSZMmrXPMe++9V6m93377VXmWTz/9NBYuXLjOMe+//37qOpFIVJqjqmW8aB4RcdJJJ6WuX3vttbjzzjs3aHx5eXkMGDCg0vbup59+epXlAwAAAAAAgFyVSCRy7mdzdMABB1RqP/300+sc88wzz6SumzRpErvsskuVZ1m4cGG8+OKLa+2/ZMmSGDx4cKq94447VlqtXtWyUjT/2c9+ltpzPplMxl133RVnn312pfPJVyeZTMbbb78dxx13XPz73/9O/UXctWvX6NmzZwaSAwAAAAAAAFR/2223XXTr1i3VfuSRR2LKlClr7P/yyy/HJ598kmqfdNJJkZe35nLygAEDolOnTqmfta1k33vvvWPrrbdOte+8885YsGDBGvv/9a9/rZT15JNPXmPfqpCVonl+fn7cddddUb9+/UgkEpFMJuOtt96KPn36xAEHHBBXXHFFpf7nn39+nH766dGtW7f45S9/mSquJ5PJaNKkSdx2223ZeBsAAAAAAAAA1db555+ful64cGH86le/iunTp6/S76OPPorLL7881W7cuHGcdtppVZajoKAg+vXrl2pPnTo1+vbtu9rC+csvv1yp/tuhQ4c44ogjqizLavOldfa1aN++fdx///3Rt2/f1B9MMpmMSZMmxeTJk1P9kslk/Otf/0pdR0Sq0N6yZcu4++6707oUHwAAAAAAACBdHnnkkXj00UdXuT9z5sxK7QMPPHCVPltuueVqxy63yy67xNlnnx333HNPRER89dVXcfDBB8eRRx4ZHTt2jEWLFsVHH30Ur732WixdujQili2Avummm6JevXqb8rZWceihh8abb74Z//jHPyIiYujQoXHggQfGUUcdFdtss03Mmzcv3nvvvUpnmRcVFcXAgQPXuuK9KmStaB4R0aVLl/jHP/4RV199dfz73/9OFcUjYrVnBywvlkcs+4viqquuisaNG2csLwAAAJuvioqK+OzT4TFl8uT44YfpUVxcHM1bbBk777JLNGrk3z0BoLqYM3tWTPr26/hh2tSYN3dOLFpUFoWFtaJecXG02qpttO+4fRQVVe0v+QEgnebOnRvffffdOvutrs+SJUvWOe63v/1tzJkzJ5588smIiCgpKYknnnhitX1r1aoVV111Veyzzz7rnHdj/OEPf4gFCxbE66+/HhERs2bNigcffHC1fevXrx8DBw6Mzp07pyXLirJaNI+IaNiwYdx6661x3nnnxZNPPhnDhg2LL7/8crV/wFtvvXX06NEjfvazn2XkfxwAAAA2f6WlpXHfPXfH84OfjZkzZ6zyekFBYey9zz7Rt99vY7uOnbKQEAByW0VFefzj6Sfii8+Hx5gvR8acWTPX2j8vLy923bNHHP7TE6PrHt0zlBJg87Kata3UYIlEIq666qrYe++9409/+lOMGTNmlT55eXnRvXv3GDBgQHTs2DFtWWrVqhV//vOf4+9//3vcf//9MXHixFX6FBYWRq9evWLAgAHRqlWrtGVZUSK54vLuaqKsrCx++OGHmDt3blRUVESDBg2iSZMmUb9+/WxHq7aGDRsWp5xySqo9evToLKZhY7wzZna2IwAb4cHbro73X39po8a2ats+rr5r9d/mA2qGPdo3ynYEYBONGzc2LjyvX0z4+ut19q1du3Zc2P+S+NlxJ2QgGZAu385YmO0IwAZaMH9+nHjYvhs1dp9eB8W5F/8u6tStW8WpgEzqtGVRtiPknF8+MyrbETLu3p/umO0IGTN69OgYPXp0TJ8+PQoLC6NFixbRtWvXrByJPWLEiPj6669j+vTpUVRUFFtuuWXsvvvu0bBhw4zmyPpK89WpU6dOtGnTJtq0aZPtKNRgS5YsiQkTJsSYMWNi+vTpUVpaGsXFxdG0adPYeeedM/bNFAAAoHr64Yfp8auzfhHTp02rdH+HHXeMrbZqE3PmzIlRIz+PkpKSiIhYtGhR/OHq30dxveI45LDDs5AYAFiuQaPG0XqrdlG/YaOoU6dulJUujO+nTIqJ334dS1fYxfSd11+O2bNmxFU33x2FtWplMTEAVB+dOnWKTp2qx05qXbp0iS5dumQ7RvUsmldHzz77bFxyySUbPd7K78xYsGBBDBkyJF577bX4z3/+E/PmzVtj306dOsVpp50WRx99dCTsMwIAADklmUzGBb/tV6lgvl3HjnHdDTdHx07/Ow5s3rx5cdcdt8eTTzyWuvf7Ky+Ljp07R4cO22U0MwDksvoNGsYe3feNXbv1iB26dI0mTZuvtt/smTPi+acfj+eeejRVPB/56cfx9GN/iRPP+FUmIwMANUhWiubjxo2LDh06ZOPRbMYWLFgQPXr0iEWLFq1X/9GjR8cll1wS//jHP+K2226LRo1srwpsuhseeHa9+xYUFKYxCQCwNq+9+kp89unwVLv1VlvFgw8/FvUbNKjUr379+nHJZVdEXl4innjs0YhYtuL8rjtuj9tuvzOjmQEgV9UrLo6/Dh4S+fn56+zbqEnTOO3s38TW224Xt157Wer+c089GsecdHrUrl0nnVEBNht5FhuSY7JSND/ssMPiRz/6URx11FFx2GGHRYOVfilREzRv3jzq1Kk+/4DVrVu3nF/NvnTp0lUK5h06dIg999wz2rRpEw0aNIh58+bF8OHD4/XXX4/y8vKIiBg6dGj84he/iMceeyyKipyLAmyapi0c/QAANcE9f65c8L708itXKZivqN9vL4g3X389pkyZHBERrw95Nb768svovP32ac0JAEQkEon1KpivqOeBh8SrLz4Xnw//MCIiykpLY8QnH8Ye3fdJR0QAoIbL2vbsI0eOjJEjR8aNN94YPXv2jKOPPjr23XffDf6Hn2y55ZZbolu3btmOwWo0bNgwjj322Dj22GOjXbt2q7x++umnxzfffBP9+vVLfdFg1KhRcdddd8VFF12U6bgAAECGjR0zOsaOGZNqt2+/bey9z35rHVO3bt346c+Ojz/9cWDq3r9efEHRHACqsV337J4qmkdETJsyKYtpAIDqLC+bD08mk7F48eJ49dVX45xzzol99903brzxxvjqq6+yGYsaKj8/P84+++wYMmRIXHjhhastmC+39dZbx0MPPRRNmzZN3XvssceitLQ0E1EBAIAseuvNNyq1Dzns8PUad+hK/d588/UqywQAVL16xfUrtUtLF2YpCQBQ3WVlpfnhhx8eQ4YMqVSgTCaTMXPmzHj44Yfj4Ycfjs6dO8fRRx8dhx12WDRu3DgbMdOupKQkRo8eHRMmTIjZs2fHkiVLon79+tGqVavYbbfdori4ONsRN0pFRUWMHTs2xo8fHzNmzIjS0tLYYostokmTJrHrrrtGixYt0vLcevXqxXnnnbfe/Zs0aRKnnXZa3HLLLRERUVZWFsOGDYuePXumJR8AAFA9DH3/vUrtXXfbfb3GbdmyZbRq1Tq1Rfs3EybE1O+/jy1btqzyjADAppvxw9RK7cZNmmUpCQBQ3WWlaH7zzTdHSUlJ/Pvf/47nn38+Pvxw2RY5iUQiIpYV0L/88sv46quv4qabbop99903jj766Nh///2joCBrO8pXiR9++CH++c9/xssvvxyff/55VFRUrLZffn5+9OrVK/r16xcdO3Zc57zDhg2LU045JdVe3fnmN9xwQzz00EOp9h133BE//vGP1zrv0qVL49RTT40PPvggIiLq1KkTgwYNig4dOlTqV1ZWFq+88kq89NJL8cEHH0RJScka59xpp52ib9++sf/++6/zfaXbylvsT5w4MUtJAACATBk/flzqOi8vL3bYcaf1HvujnXdOFc0jIsaPG6toDgDVUEVFebz3xquV7u3QpWuW0gDUPP8t2UHOyNr27PXq1YtjjjkmHnnkkXjttdfi3HPPjbZt20YymYyI/xXQKyoq4o033oh+/frF3nvvHddee22MGjUqW7E32YMPPhg33HBDDB8+fI0F84iIJUuWxKuvvho//elP46WXXqqSZ59//vnRuXPnVPuKK66IadOmrXXM/fffnyqYR0RcfPHFqxTMIyKGDh0aF110UbzxxhtrLZhHLDvP/uyzz44bbrgh9eedLfXq1avUtj07AABs3ubNnRuzZ81KtZs0aRJ169Zd7/GtW29Vqf3NNxOqLBsAUDWWVFTEPbfdEJMnfpu6t0f3faNl6zZZTAUAVGfVYtl2q1at4te//nX8+te/juHDh8fgwYPj3//+d8ybNy/VJ5lMxpw5c+Lxxx+Pxx9/PDp06BB9+vSJww8/vNK51DXJVlttFbvttltst9120bBhw1i6dGlMmTIl3nvvvfj8888jImLRokVx8cUXR9u2bWOnndZ/9cPq1KpVKwYOHBh9+vSJRYsWxZw5c6J///7x0EMPpb6ksKLPP/887rjjjlS7Z8+ecdJJJ63zOQ0bNozddtstdthhh2jSpEkUFhbGzJkzY/jw4fH222/HkiVLIiLioYceilatWlVaIZ9pkyZNqtRu0qRJlpIAm4sn7h0Y47/6PGZOnxqlCxdE3aLi2KJBw9i6w/bRqctusftevaJO3aJsxwSAnDVx4neV2i223LBV4i1abFmp/d13362hJwCQSWWlpTF92pQY9dkn8dLgp+LbCf/bWaZR46Zx9nkDspgOAKjuqkXRfEVdu3aNrl27xuWXXx5DhgyJ559/Pt57772oqKiotH372LFj46abboqBAwfGXnvtFUcffXQcfPDBWU6/bnl5eXHYYYfFqaeeGl26dFltn/POOy/eeuutuOiii2Lu3LlRXl4eV111VTz99NOb/PwOHTrExRdfHNdcc01ELFsh/tBDD8UZZ5xRqV9paWlceOGFUV5eHhHLisnXXXfdWufu2rVrnHnmmbHvvvtGYWHhavtMmDAhfvOb36S2jx84cGAcfvjh0ahRo019axvltddeq9TeZZddspID2Hy8/s/K/1+9YN6cWDBvTnw/8ZsY+sa/4pkH74iD+pwUB/X5eeTlZW3DFwDIWQsWLKjUbtS48QaNb9S48r+7LFgwf5MzAQAb7pSjD4g5s2aus982HTrFxb+/MZq1cJwKALBm1fa39bVq1YpDDjkk7r333njrrbeif//+0bFjx0rbtyeTyaioqIi33norzj///CwnXj/9+vWLgQMHrrFgvtx+++0Xt99+e6o9YsSIGDlyZJVk+PnPfx777rtvqn3rrbfGV199VanPddddF998802l9tpWYffo0SOefPLJ6N279xoL5hER22yzTTz44IPR+L+/mCorK4vBgwdv5DvZNNOnT48XXngh1e7YsWNsu+22WckC5I4F8+fGoL/eHbf97jdRsmDeugcAAFVq4cLKx0nVrlV7g8bXrl1npfkWbnImAKDqbdd5x7jwyuvj1vsej9Zt2mU7DgBQzVW7lear06RJkzj99NPj9NNPj6+++ioGDx4cL774YsyYMSNVPM/02djru6V4586d4/nnn0+1a9de/1/IdO/ePbp16xbDhg2LiIh33313k7doX+7666+PI444ImbOnBnl5eVxwQUXxKBBg6JOnToxZMiQeOqpp1J9TzrppOjZs+da59uQ99W0adM46aSTUlu/v/vuu6usdM+Eq6++utIvuPr27ZvxDMDmo1WbbaLLnntFu207R/OWW0WdonqxeFFZzPxhaowe8XG899pLsXCFIvmXn34Yf77+kjjv6tsjP79GfBwDwGahdGFppXat2rU2aPzK/+6z8nwAQPUwbvQX8eLgv0et2rXj/+29f7bjANQ4qzvWFzZnNe639J07d47zzz8/tt9++7jxxhtjzpw52Y6UVt27d08VzUeNGlVl8zZt2jSuu+66+OUvfxkREePGjYubbropzj777Lj88stT/ZZv517VunfvniqaV+X7Wl+PPvpovPrqq6n23nvvHQcddFDGcwA13067dY9eh/8stu7QebWvt9lmu9hlz33iyBPPjMfvHRhDX38p9dpXIz6Ofz75UBx50pmZigsArGRDfxG0cv9kZPYL3ADAMgPvfSyWLlkaERHJ5NIoWbAgpk6ZGCM++TDefPWlKF1YEl9+/ml8+fmnsU+vg+K3l1wdhbU27MtyAEDuqFFF848++iiee+65+Pe//x0lJSXrHpBGzZs3jzp16qyzX8uWm3ZWTtOmTVPX06ZN26S5VtazZ8848cQT44knnoiIiMcffzyGDRsWs2fPjoiIwsLCGDhw4Hq9zw214vuaM2dOLFq0aINWq2+K9957L2644YZUu3HjxpXaABtiz30PXK9+dYrqxS/OuzJq1aodb/37f8dSvPr836L34T+L4voN0hURAFhB3aK6ldqLyhZt0PiysrJK7aKiok3OBABsuGbNt1zl3rYdO8dePQ+Mk35xTvzpht/FB++/HRER77z+cixZUhEDrr4l0zEBgBqi2hfNJ06cGM8//3w899xzMXny5IiIVc41j6hchM2EW265Jbp167bR40tLS+O1116Ld955J0aPHh1Tp06NkpKSWLx48RrHzJ8/f6Oftyb9+/ePYcOGxfjx4yNi2Yrz5c4///zo3Hn1KyfXZOnSpTFs2LAYMmRIfPHFFzFx4sRYsGBBlJaufcvC+fPnZ6RoPnLkyDj33HOjoqIiIpZtrXjHHXdEs2bN0v5sgIiIE846P0Z+MjRmTp8aERFlpQvjg3dejV6H/jTLyQAgN9StW7nIvWjxhhXNF6/UX9EcAKqf+g0axiXXDIzfX/zr+OzjDyIi4v23Xou3X/t37Nv74CynAwCqo2pZNC8pKYl//etf8dxzz8XHH38cEZUL5csVFhbG/vvvH3369Im99947K1k3xnPPPRc33nhjzJo1a4PGLVq0Yb/MWR916tSJgQMHxrHHHhvl5eWp+927d4/TTz99g+YaMWJEXHHFFfHVV19tcI50vLeVjR8/Ps4888zULgUFBQVx++23x+677572ZwMsV1BYGL0OOzaefvCO1L0vP/1Q0RwAMqS4uLhSe85/d9paX7NX+ve44uItNjkTAFD18gsK4qx+/ePXpx6Tuvf8U48pmgMAq1VtiubJZDLee++9GDx4cLz++uupLe+SyWQkEonUqvJkMhldunSJo446Kg477LCoX79+lpNvmPvvvz9uuWX12wA1bNgw6tSpE7VWOFunpKQkZs6cmdZM+fn5kZeXV+lejx49Nuhsv2HDhsVZZ521ylaFERH16tWLevXqRe3atVNzLlmyJLVzQMT/vhSRLpMmTYrTTz899UWFvLy8uPHGG2P//fdP63MBVmeHXfas1J707fgsJQGA3NOmTdtK7alTv9+g8VOnTl1pvjabnAkASI82W7ePdtt0iG8nLNtdc9zoL2LB/HlRvEXN+p0yQDbkrbsLbFayXjQfP358DB48OP7xj3/EDz/8EBGrripPJpPRvHnzOPLII+Ooo46KbbfdNmt5N8VXX30Vt912W6rdtGnTOOWUU2KfffaJDh06VCqWLzdo0KC49NJL05Zp8eLFceGFF66y0vvOO++M/fffP7bbbrt1zlFWVhYDBgxIFcwLCwvj+OOPjwMPPDB23HHHVVZyRCzbdv+AAw6omjexDtOmTYvTTjut0pnwv//97+Owww7LyPMBVtakectK7QXz5mQnCADkoAYNG0ajxo1TK8ZnzpgRpaWlUbdu3XWMXGby5EmV2tts077KMwIAVaflVm1TRfNkMhnTvp+iaA4ArCIrRfM5c+bEiy++GIMHD45Ro0ZFxOq3X69du3b07t07jj766OjRo8cqq6FrmieeeCKWLFkSERHNmjWLQYMGRYsWLdY6Jh3nmK9o4MCBMXr06FS7qKgoFi5cGIsWLYoLLrggnnnmmdUW81c0ZMiQmDJlSkQsW8F9//33R/fu3dc6Jt3va7lZs2bFaaedFhMnTkzd69+/fxx33HEZeT7A6tSqVbtSuzwDR1QAAP+z7bYd4qNZy843Xbp0aXwxamTstvse6zX28xGfVWq337ZDlecDAKpOQUHlX4GXly/OUhIAoDrLStF87733jiVLllQqlK+4/XrXrl2jT58+8ZOf/GS1q5Rrqv/85z+p61NOOWWdBfOIZduKp8v7778ff/3rX1PtY489Nvbee+/4zW9+ExERo0ePjltvvTUGDBiw1nlWfF977bXXOgvmEel9X8vNmzcvzjjjjPj6669T984999w444wz0v5sgLVZeWV5vfoNshMEAHLU/+veIz768INU+5OPP1qvovnU77+PKSscM7X1NttEy1at0pIRAKgaM2dMr9Ru2KhxlpIAANVZVpZuV1RURETl7ddbtmwZZ599drz88svxt7/9LY499tjNqmAeETF9+v/+Aa1z587rNWbYsGFpyTJnzpzo379/6osL7dq1i0svvTQOPvjgOProo1P9Hn744Xj//ffXOld1el/LlZSUxJlnnhlffvll6t4ZZ5wRffv2TetzAdbHhLFfVmo3bNw0S0kAIDf13L9XpfZL/3xhvca9uFK/nj17raEnAFAdLFxYEmO/GpVq16pVO5o0bZ7FRABAdZW1M82TyWTUrVs3fvzjH8dRRx21XquTa7rlBeqIZWeJr8sHH3wQY8aMSUuWK664IlXsLigoiJtvvjmKiooiIuLyyy+PDz/8MCZNmhTJZDIGDBgQ//jHP6Jhw4arnWvF97Xy2eirM3/+/Hj++ec3/U2swaJFi+Kcc86JTz/9NHXv+OOPj/79+6ftmQAb4sN3hlRqd9xxl+wEAYActV3HTtFhu44xbuyyf9/6+uvx8e47b8Xe++y3xjFlZWXxzFNPVrr3k0MPT2tOAGDTDP7bX6OivDzV7rLbnlG4jqMoAVhmxeOUIRdkZaX5HnvsEdddd128++67ceONN+ZEwTwiYsstt0xdv/nmm2vtu2DBgvjd736XlhzPPPNMvPLKK6n2OeecEzvvvHOqXVxcHDfffHPk5+dHRMS0adPiyiuvXON8LVu2TF2/8847sXTp0rU+/6qrrkrbmeYVFRXxm9/8ptKW8UceeWT8/ve/T8vzADbU12NGxYfvVi6ad9ljryylAYDc9atzKu9Cdf0frol5c+eusf+fbhsYU6b8b2v2/XsfEJ233z5t+QCA/xn890eidOHCDRrz7uuvxNOPP1jp3sGHH1OVsQCAzUhWiuaPPvpo9OnTJ+rVq5eNx2fNXnv9ryjy7LPPxksvvbTafhMnTozTTjstvv7668jLq9o/ou+++y7+8Ic/pNpdu3aNs88+e5V+u+66a6X7L7/8cgwaNGi1c/bo0SN1PWHChLj++utjyZIlq/RbsGBBXHLJJfHCCy9U+fuKWLbivX///vHGG2+k7h100EFx/fXX+0YUkBZvv/xclC0sWe/+U76bEHf/YUAkV/hyUftOO8X2O6/7DFUAoGr1PvDHsfMuXVPtSRMnxhmn/TzGjhldqd/8+fPj+j9cE48/9kjqXu3ataNvv99mKioA5LynHrk/zjz+0Lj/jpvjq1EjYsl/j/9cnfFjvoxbr708brqqfyxd4XeUu3ffJ/bca827ygAAuS1r27PnotNOOy2eeuqpKC8vjyVLlsR5550XTz31VOy9997RuHHjmDdvXnzyySfxxhtvxOLFi6OoqChOPPHEeOCBB6rk+RUVFXHhhRfGwv9+K7NevXqVVpSv7Jxzzol33303Pvvss4iIuPbaa2OPPfaItm3bVup3wAEHxNZbbx3ffPNNREQ88sgj8f7778dBBx0UrVu3jrKyshg9enS88sorMXv27IiI6Nu3b/zpT3+qkve13Mcffxz//Oc/K937/PPP4+CDD17vObp06RIDBw6s0lzA5uvFpx6OQX+9O7rtd1Dsue+BsU3HHSI/f9WP1pIF8+Ktfw2OF5/+aywq/d834wsKa8XxZ52XycgAwH8lEom45bbb48Tjfho//PfoqrFjxsSxfY6MHXbYMVq3aRNz58yJkZ+PiJKSyl+S+93V10aHDttlIzYA5Kx5c+fEC888ES8880TUqlU72m7TPho2bhr1ireIivLyWDB/bnwzfmzMnTN7lbEdt98pLrzy+iykBgBqCkXzDGrbtm1cffXVcdlll6W2MB86dGgMHTp0lb5FRUUxcODAmDNnTpU9/+67704VwCMirrzyymjTps0a+y8/6/yoo46KhQsXxsKFC+Oiiy6KJ554olKhvaCgIG6//fY4+eSTY968eRERMW7cuBg3btwqcyYSifjVr34VRx55ZJUXzVe3un3KlCkbNMeKW+gDrI+S+fPi9X8+Ha//8+korFU7WrdtH/UbNY669Ypj8aKymDl9akyaMC6WLq38/1F5efnxi/OujPYdd8xScgCgefMW8ef7/hIXntcvvpkwISKW7WA1atTIGDVq5Cr9a9euHRdePCAOPeyITEcFAFawePGiGDf6y3X2SyQScfARP43Tzv5t1C0qykAygM1Hng18yTFZ2Z49l/Xp0yfuu+++aN++/Wpfz8/Pj3322SeeffbZ6NWrV5U9d/jw4XHPPfek2gcffHAcddRR6xzXrl27uOyyy1LtTz/9NO66665V+nXu3DmeeeaZSlvQr67PvffeG7/5zW82LDxADVG+eFF8M+7LGPHhezHszZdj+NC34rvxo1cpmDdu2iIuuu6u2GOfA7KUFABYbrvtOsaTTw+O039xZjRu0mS1fQoKCqPn/r3i8Sefjp8df2KGEwIAA66+JQ4/5oRou82263XsY/0GDeOQo34Wf3zgb/Gr8y9VMAcA1imRTCaT2Q6Ri5LJZIwcOTJGjRoVc+bMieLi4mjevHl07do1mjVrlu14m2TixInx8ccfx/Tp06OwsDCaNWsWnTt3jg4dOmQ7WrX2zphVt44Cqrd3XvlHfPbBuzHuyxGxYN6ctfZNJBKx1dYdYr+fHB3d9z8katepk5mQQFrt0b5RtiMAVaiioiI+Hf5JTJ40KWbMmBHFxfWiRYsto8suXaNx48bZjgdUkW9nLFx3J6DaWliyIL6dMC6mfT8l5s6eFYsWlUV+fn4U1SuOBg0bxTYdOkXL1mveXROomTpt6csvmfbb57/KdoSM++ORnbMdgSxSNIdqQtEcarZZP0yLqZO/jVkzpkfJvLlRXr4oCgtrR1HxFtGoSbPYptOOUa+4frZjAlVM0RwAah5FcwCoeRTNM0/RnFzjTHMAqAKNm7WIxs1aZDsGAAAAAACwgRTNAQAAAAAAgJS8RLYTQGblZTsAAAAAAAAAAGSLojkAAAAAAAAAOUvRHAAAAAAAAICcpWgOAAAAAAAAQM4qyHYAAAAAAAAAoPpIJBLZjgAZZaU5AAAAAAAAADmrRq80nzZtWpx44okRsewbL0OGDMlyIgAAAAAAAABqkhpdNK+oqIjJkydHhG0iAAAAAAAAANhwtmcHAAAAAAAAIGfV6JXmAAAAAAAAQNXKs8EzOcZKcwAAAAAAAABylqI5AAAAAAAAADlL0RwAAAAAAACAnKVoDgAAAAAAAEDOKsh2AAAAAAAAAKD6SCSynQAyy0pzAAAAAAAAAHKWojkAAAAAAAAAOUvRHAAAAAAAAICc5UxzAAAAAAAAICXPoebkGCvNAQAAAAAAAMhZaVlpfsopp6Rj2lUsXrw4I88BAAAAAAAAYPOUlqL5Bx98EIkMbduQSCQimUxm5FkAAAAAAAAAbF5szw4AAAAAAABAzkrLSvOIsPobAAAAAAAAaiCrbsk1aSmaP/LII+mYFgAAAAAAAACqVFqK5nvuuWc6pgUAAAAAAACAKmV3BQAAAAAAAABylqI5AAAAAAAAADkrLduzAwAAAAAAADVTIpHtBJBZm8VK8zlz5sQf//jHbMcAAAAAAAAAoIap0UXzWbNmxc033xy9evWKe++9N9txAAAAAAAAAKhhauT27NOnT48HHnggnn766SgrK4tkMhkJ+0QAAAAAAAAAsIFqVNF8ypQpcd9998Wzzz4b5eXliuUAAAAAAAAAbJKMFM2nT58er776anzwwQcxderUmDt3btSuXTtat24de+yxRxx++OHRtGnTNY7//vvv4+67747BgwfHkiVLIplMRkREIpFIXe+3336ZeCsAAAAAAACwWcuzaJUck9aieTKZjNtuuy0eeeSRWLRoUaX7ERFjxoyJN954I/70pz9Fv3794vTTT680vry8PO655574y1/+EosWLUqtLF9eLE8kEvGTn/wkzjrrrOjcuXM63woAAAAAAAAAm6G0Fc2XLl0av/71r+PNN9+stDJ8xf+OWFZALy0tjZtuuinmzJkT5513XkRETJo0Kfr27RujR49epVheWFgYRx11VPzf//1ftGvXLl1vAQAAAAAAAIDNXNqK5g888EC88cYbqWJ3xP9WmK9oxdfuu+++6NmzZzRr1ixOOOGEmDFjRqpgnkwmo27duvGzn/0szjjjjGjRokW6ogMAAAAAAACQI9JSNF+4cGHce++9lQriTZs2jSOPPDJ+9KMfRYMGDWLBggXx5ZdfxvPPPx+TJ09O9b333ntj4cKF8cMPP6Tu1a1bN37+85/HGWecEQ0bNkxHZAAAAAAAAAByUFqK5v/617+ipKQkVfTu2bNn3HrrrVFUVFSp34EHHhjnnHNO/O53v4tBgwZFIpGIt99+O7UiPZlMxv777x+///3vrSwHAAAAAACADFjhpGXICXnpmPSjjz6KiGVF7y233DJuu+22VQrmyxUUFMQ111wTO+20UySTydRPIpGI008/Pf785z8rmAMAAAAAAACQFmkpmn/xxRcRsey88uOOOy7q1q279hB5eXHyySdXute2bdvo379/OuIBAAAAAAAAQESkqWg+c+bM1PVuu+22XmP22GOP1HUikViliA4AAAAAAAAAVS0tRfN58+alrps1a7ZeY5o2bVqpvd1221VpJgAAAAAAAABYWUE6Jl28eHHqulatWus1Znm/5eeZt2zZMh3RAAAAAAAAgLXIS2Q7AWRWWlaaV4WCgrTU8wEAAAAAAAAgpdoWzQEAAAAAAAAg3RTNAQAAAAAAAMhZad8Dfdq0aRkb16pVq416FgAAAAAAALBMXsKh5uSWtBXNE4lEJJPJOPHEEzd47MaMSyQS8cUXX2zwswAAAAAAAADIXWldab68cL4h/ZfbkHEAAAAAAAAAsDHSvj17YiO3b9iQcQrsAAAAAAAAAGyMtBTNnS0OAAAAAAAAQE2QlqL566+/no5pAQAAAAAAgDTbyI2kocbKy3YAAAAAAAAAAMgWRXMAAAAAAAAAclZatmd/7rnnUtcHHXRQ1K1bNx2PAQAAAAAAAIBNkpai+YABAyLx38MO9txzT0VzAAAAAAAAAKqltBTNIyKSyWSqcA4AAAAAAADUDHlKfOQYZ5oDAAAAAAAAkLMUzQEAAAAAAADIWYrmAAAAAAAAAOQsRXMAAAAAAAAAclZBtgMAAAAAAAAA1UciEtmOABllpTkAAAAAAAAAOUvRHAAAAAAAAICclfbt2adNm5buR6S0atUqY88CAAAAAAAAoOZLW9E8kUhEMpmME088MV2PWOV5X3zxRUaeBQAAAAAAAMDmIe0rzZPJZLofAQAAAAAAAFSRvES2E0Bmpb1onkik/+8qhXkAAAAAAAAANkZai+aJRCKaN28e+fn56XwMAAAAAAAAAGyUtBXNk8lkJBKJ+Nvf/hatWrVK12MAAAAAAAAAYKOlfXt2AAAAAAAAoOZwpjm5Ji/bAQAAAAAAAAAgWxTNAQAAAAAAAMhZiuYAAAAAAAAA5CxFcwAAAAAAAAByVkG2AwAAAAAAAADVRyKRyHYEyCgrzQEAAAAAAADIWWkrmvsGCgAAAAAAAADVXdqK5slkMl1TAwAAAAAAAECVSMuZ5o888kjqumnTpul4BAAAAAAAAABssrQUzffcc890TAsAAAAAAACkWZ5TmMkxadueHQAAAAAAAACqO0VzAAAAAAAAAHKWojkAAAAAAAAAOUvRHAAAAAAAAICcVZDtAAAAAAAAAED1kUhkOwFklpXmAAAAAAAAAOQsRXMAAAAAAAAAcpaiOQAAAAAAAAA5S9EcAAAAAAAAgJxVkO0AAAAAAAAAQPWRl0hkOwJklJXmAAAAAAAAAOQsRXMAAAAAAAAAcpaiOQAAAAAAAAA5y5nmAAAAAAAAQEqeI83JMdWmaF5eXh5ffvllfP311zFv3rxYsGBBLF26dIPm6Nu3b5rSAQAAAAAAALA5ynrRfMSIEfHwww/HkCFDory8fJPmUjQHAAAAAAAAYENkrWieTCbjtttuiwceeCCSyWQkk8nV9kskEpXGrO71ZDJZqR8AAAAAAAAArI+sFc1vuummePjhh1db8F5boXzl19ZUbAcAAAAAAACAdclK0XzYsGHx0EMPRSKRiEQiEYWFhXHSSSdF7969Y+nSpXHKKadExLIC+WuvvRYlJSUxY8aM+PTTT+Of//xnfP3115FIJKJx48bx+9//PnbcccdsvA0AAAAAAADY7NjgmVyTlaL5vffeGxHLVorXrVs3Hnroodhll10iImLy5MmV+rZu3ToiIjp27Bg9evSIc845J5577rm49tprY/bs2dG/f/+48847Y6+99sroewAAAAAAAACg5svL9AMXLFgQ//nPf1KrzH/961+nCubr66ijjooHH3ww6tatG6WlpdGvX79Viu0AAAAAAAAAsC4ZX2k+fPjwWLp0aURE1KpVK44//viNmqdLly7Rr1+/uOGGG2LhwoVx5513xvXXX1+VUQEAAAAAAADSplOnTps8x2uvvRZbbbXVJs8zadKk6N2790aNHTFiRNSuXXuTM2RLxleaf//99xGx7LzyTp06RXFx8Vr7l5eXr/G1E044IerWrRvJZDJeeeWVWLRoUZVmBQAAAAAAAKiu8vLyol69etmOUeNlfKX5nDlzUtctW7Zc5fXCwsJK7UWLFq1yb7natWtHly5dYtiwYbFw4cL46KOPnG0OAAAAAAAAmyAvEtmOkDPatm27Qf0XLVoU06ZNS7W7d+8ejRo1qupYERHRunXryM/PX6++iUTN/msm40XzFdWpU2eVeyt/E2LmzJlrXY3etGnT1PWKf4EAAAAAAAAAVGevvvrqBvV/6KGH4oYbbki1+/TpU9WRUh555JEq2fa9Jsj49uz169dPXS9YsGCV1+vVq1dpZfnEiRPXOt/ixYtT1zNmzKiChAAAAAAAAADVz7PPPpu6rl+/fhx44IFZTLP5yHjRvE2bNqnrH374YbV92rdvn7oePnz4WucbNWpU6np1K9cBAAAAAAAAarqRI0fGmDFjUu1DDjkkateuncVEm4+MF807dOgQERHJZDLGjRsXyWRylT4/+tGPUn2ef/75qKioWO1cr7/+ekyZMiXVbtWqVRoSAwAAAAAAAGTXiqvMIyKOOeaYLCXZ/GS8aN6iRYvUavOysrIYMWLEKn0OPvjgiFh2YPzkyZNjwIABUVZWVqnPRx99FJdeemnqUPn8/PzYY4890pweAAAAAAAANm+JRO79VHeLFy+OF198MdXu0KFDdOnSJYuJNi8F2XjoXnvtFU8++WRELFstvvPOO1d6vUePHrHddtvFuHHjIiLixRdfjLfffjt23XXXKC4ujm+++SZGjRqVWqWeSCTi0EMPjQYNGmT2jQAAAAAAAACk2WuvvRZz5sxJtfv06ZO9MJuhrBTNDz300HjyyScjmUzGoEGDom/fvlFYWJh6PS8vL66++uo49dRTo7y8PCIi5s2bF2+99VaqTzKZjEQiEclkMpo1axYXX3xxxt8HAAAAAAAAUPNNmTKl0rHQG6NVq1ZpO056xa3ZCwoK4sgjj0zLc1Z06623xrhx42LKlClRVlYWDRo0iObNm8duu+0WvXr1ih49eqQ9Q6Ykkqs7VDzNkslkPPvss7F06dKIiOjVq1c0adJklX5vv/12XHzxxalvTSRW2Btheex27drFn//852jfvn36g0MavTNmdrYjAAAbaI/2jbIdAQDYQN/OWJjtCADABuq0ZVG2I+Scu9//JtsRMm7Jxy/EnXfeuUlz9O3bN84999wqSvQ/06dPj549e8aSJUsiImL//fePe+65p8qfM2nSpOjdu/d6999hhx3immuuiZ122qnKs2RaVlaaJxKJ9TqYft99942XX345Hn/88Xj77bfj22+/jfnz50f9+vWjY8eOcdBBB8UxxxwTtWrVykBqAAAAAAAAgMx67rnnUgXziFivOmtVqV+/fmyxxRZRUlISc+fOjRXXY3/xxRdxwgknxA033BCHHnpoxjKlQ1aK5huiQYMGcc4558Q555yT7SgAAAAAAACw2ctLrLvP5mbJurtkzeDBg1PXjRo1ip49e6btWfXq1YtDDjkkevfuHTvvvHM0btw49dq8efPivffeiwceeCBGjhwZERGLFy+O/v37R4sWLWL33XdPW650y8r27MCqbM8OADWP7dkBoOaxPTsA1Dy2Z8+8e4Z+k+0IGXdEu1rV8kzzTz/9NI477rhU+9RTT41LL720Sp+x3OLFi2Px4sVRXFy81n5LliyJm266KR5++OHUvfbt28c///nPyM/PT0u2dKv2K80BAAAAAAAA0ikdBe+q8Oyzz1Zq9+nTJ23PqlWr1nodi52fnx+XXHJJTJo0KYYMGRIREV9//XW8/PLLccghh6QtXzrlZTtAVZk1a1a2IwAAAAAAAABUibKysnjppZdS7R122CE6d+6cxUSVXXjhhZXab775ZnaCVIGsFM2vueaaKC8vr7L5hg4dGkcddVSVzQcAAAAAAACQTa+++mrMnz8/1U7nKvONsc0220SHDh1S7c8++yyLaTZNVormjz/+eBx33HHx3XffbdI8yWQybr/99vi///u/+OGHH6ooHQAAAAAAAOSuvEQi536qo8GDB6euCwsL47DDDstimtVr165d6nrmzJlZTLJpsrY9+5dffhlHH310vPDCCxs1ftq0aXHyySfHPffcE0uWLKnidAAAAAAAAADZ8f3338fQoUNT7V69ekWjRo2ymGj16tatm7ouKyvLYpJNk9UzzUtKSuLiiy+OSy+9dIP+R3z99dfjiCOOiI8//jh1Ly9vszmeHQAAAAAAAMhhgwcPjqVLl6baxxxzTBbTrNmMGTNS19WxqL++slJpPvTQQyOZTEYikYhkMhmDBw+OY445JsaMGbPWceXl5XHttdfGr3/965g7d25ELNuivVmzZvHggw9mIjoAAAAAAABAWj333HOp62bNmsXee++dvTBrUF5eHiNGjEi1W7duncU0myYrRfOBAwfGNddcE7Vr147Ef88IGD9+fPzsZz+Lv//976sd8+2338Zxxx0Xjz/+eKWC+7777hvPP/98dOvWLZNvAQAAAAAAADZLiUTu/VQnH330UXz77bep9lFHHRX5+flZTLR6zz33XCxcuDDV7tGjRxbTbJqs7Wl+7LHHxtNPPx3bbrttqgheVlYWv//97+O3v/1tLFiwINX3+eefjz59+sSXX36Zupefnx8XX3xx3HfffdG4ceNsvAUAAAAAAACAKvXss89Wah999NEbPVevXr2iU6dO0alTp+jVq9ca+y1atCiSyeR6z/vtt9/GLbfckmrn5+fHYYcdttE5sy2rB4Fvt912MWjQoPjpT39aafX4yy+/HEcffXQMGzYsLrnkkhgwYECUlJRExLLt2Lfaaqt44okn4owzzshmfAAAAAAAAIAqs3DhwvjXv/6Vanft2jW23XbbtD/3008/jaOPPjpeeumlKCsrW2vf119/PU444YSYM2dO6t4xxxwT7du3T3PK9CnIdoDatWvHtddeG927d48rr7wySkpKIplMxsSJE+O0006LiEh9qyGZTMZPfvKTuOaaa6K4uDiLqQEAAAAAAACq1ssvv1xpy/M+ffpk7NlffvllnHfeeVFUVBS77bZbbL/99tG8efOoV69elJaWxsSJE+Pdd9+NsWPHVhq38847x2WXXZaxnOmQ9aL5coceemjstNNOcf7558eoUaNSq86Xq1u3blx66aVx7LHHZjElAAAAAAAAQHqsuDV7nTp14pBDDsl4hoULF8Y777wT77zzzjr7Ll/wXKdOnQwkS59qUzSPiGjatGm0bt06Ro0aFRGRKpwnEono2rVrVv6iAAAAAAAAgFySl0hkO0JOmjhxYnz44Yep9oEHHpix3bfbtm0bffr0iQ8//DAmTpy41r75+fnRo0ePOOWUU2LffffNSL50SyQ35ET3NBo1alScd955lf4QlhfMl2vbtm3ceuutseOOO2YjIqTVO2NmZzsCALCB9mjfKNsRAIAN9O2MhevuBABUK522LMp2hJzzlw++y3aEjPvFnm2zHaHamDNnTowZMyamTJkSs2bNirKysqhdu3bUr18/2rZtGz/60Y+iqGjz+vuyWqw0/+tf/xoDBw6MxYsXp1aXFxcXx4knnhiPPfZYlJaWRkTEt99+G8cff3xceOGFceqpp2Y5NQAAAAAAAMDmpWHDhrHnnntmO0ZG5WXz4fPmzYtzzjknbrjhhkoF85122ikGDx4c559/fjz77LPRuXPn1Krz8vLyuOGGG+JXv/pVzJkzJ5vxAQAAAAAAAKjhslY0Hz58eBx11FHxxhtvpAriyWQyTjnllPjb3/4Wbdq0iYiIrbfeOv7+97/Hz3/+80r93nzzzTj66KPj448/ztZbAAAAAAAAAKCGy0rR/L777ouTTz45pkyZkrpXv379uOuuu+LSSy+NwsLCSv1r1aoVl19+edx5551Rv3791Dnn33//fZx66qnx5z//OaP5AQAAAAAAYHOVSOTeD7ktK0XzW2+9NZYsWZJaNd61a9d47rnnonfv3msdd8ABB8TgwYNj5513Tq06r6ioiD/96U9x2mmnZSY8AAAAAAAAAJuNrJ5pHhFx5plnxmOPPRYtW7Zcr/6tWrWKxx9/PM4666yIiFThfdiwYemMCQAAAAAAAMBmKGtF80aNGsX9998fF1xwQeTn52/Q2Pz8/Dj//PPjgQceiCZNmqQpIQAAAAAAAACbu6wUzbt16xbPP/987L333ps0z1577RXPP/98dO/evYqSAQAAAAAAAJBLCrLx0IcffjgSiUSVzNWkSZN48MEH47777quS+QAAAAAAACCXZf18Z8iwrPw1X1UF8xXn++Uvf1mlcwIAAAAAAACw+fNFEQAAAAAAAABylqI5AAAAAAAAADlL0RwAAAAAAACAnFVQ1RN++OGHq9zbY4891tmnKqz8HAAAAAAAAGDDJBKJbEeAjKryovnJJ59c6W+kRCIRX3zxxVr7VIXVPQcAAAAAAAAA1qbKi+bLJZPJKukDAAAAAAAAAOmSljPNFcwBAAAAAAAAqAmqfKX59ddfXyV9AAAAAAAAgMxzojm5psqL5kcffXSV9AEAAAAAAACAdEvL9uwAAAAAAAAAUBMomgMAAAAAAACQsxTNAQAAAAAAAMhZVX6mOQAAAAAAAFBz5SUS2Y4AGWWlOQAAAAAAAAA5q1qtNE8mkzF16tSYO3duLFiwIJLJ5AaN32OPPdKUDAAAAAAAAIDNUdaL5mVlZfHcc8/FSy+9FCNHjozS0tKNmieRSMQXX3xRxekAAAAAAAAA2JxltWj+zjvvxIABA2LWrFkRERu8shwAAAAAAAAANkXWiuYvvvhiXHTRRbF06dJVXkskEqnrlQvpa3sNAAAAAAAA2DSJdXeBzUpWiubffvttXHbZZbF06dJIJBKRTCZjhx12iN69e0etWrVi4MCBEbGsQH799ddHSUlJ/PDDD/HZZ5/FRx99FBUVFZFIJKJx48bxq1/9KoqLi7PxNgAAAAAAAACo4bJSNL/33nujrKws1R4wYECcdtppERExefLkVNE8IuLoo4+uNHbatGnxxz/+MQYPHhyzZ8+Oxx57LB588MFo3bp1RrIDAAAAAAAAsPnIy/QDy8vL46WXXopEIhGJRCKOPfbYVMF8fbRo0SKuv/76+N3vfhfJZDK+++67OPPMM6O0tDR9oQEAAAAAAADYLGW8aP75559HWVlZJJPJSCQS8ctf/nKj5jnhhBPiuOOOi2QyGRMmTIj77ruvipMCAAAAAAAAsLnLeNH8m2++iYhl55VvvfXW69xWfcmSJWt8rV+/fpGXt+wtPPvss1WWEQAAAAAAAHJVIpF7P+S2jBfN586dm7reZpttVnk9Pz+/Unvx4sVrnKtJkyax0047RTKZjOnTp8enn35aZTkBAAAAAAAA2PxlvGi+YhG8Xr16q7xeVFRUqT179uy1zteqVavU9cSJEzcxHQAAAAAAAAC5JONF8xUL5WVlZau8XlxcHIkV9kD4/vvv1zrf8u3ZIyJ++OGHKkgIAAAAAAAAQK7IeNF8yy23TF2vbhV5Xl5etGnTJtUeOXLkWuebMGFC1YUDAAAAAAAAIKdkvGjevn37iIhIJpMxduzY1fbp3Llz6vpf//rXGucaO3ZsfPnll6mV6U2bNq3CpAAAAAAAAJB7EolEzv2Q27JSNG/YsGFERMydOze+++67Vfr07t07IpYV1j/77LN4/PHHV+kzd+7c6N+/f6pfRMSuu+6aptQAAAAAAAAAbI4yXjSPiPh//+//pa7feOONVV4/8MADo1GjRpFIJCKZTMa1114bv/jFL+Khhx6Kp59+Om666aY45JBDUqvME4lE7L777rHVVltl8m0AAAAAAAAAUMMVZOOhBx10UPz73/+OZDIZzz77bJx66qmVXi8qKoqLLrooLr300lTh/P3334/3338/1SeZTKZeq1WrVmrVOQAAAAAAAACsr6wUzXv16hVHHnlkLF26NCIipk6dGltuuWWlPn369IlJkybF3XffvdpzBJYXzGvXrh033nhj7LTTThnJDgAAAAAAAJuzrGxVDVmUSC4/ELya+uCDD+Luu++Ojz76KCoqKlL369atGz179oy+ffvGtttum8WEUDXeGTM72xEAgA20R/tG2Y4AAGygb2cszHYEAGADddqyKNsRcs7fh0/OdoSMO65r62xHIIuystJ8Q+y5556x5557xsKFC2PKlCkxf/78qF+/frRp0yZq1aqV7XgAAAAAAAAA1GBpKZpfcsklqev+/ftHw4YNN3nOoqKi6NChwybPAwAAAAAAAADLpaVoPnjw4NQ55Oeee+46i+bPPfdc6vqggw6KunXrpiMWAAAAAAAAAFSStu3Zk8lkqnC+LgMGDEj13XPPPRXNAQAAAAAAIEvWt8YHm4u8bAdYLplMZjsCAAAAAAAAADmm2hTNAQAAAAAAACDTFM0BAAAAAAAAyFmK5gAAAAAAAADkrIJsBwAAAAAAAACqj0S2A0CGWWkOAAAAAAAAQM5SNAcAAAAAAAAgZymaAwAAAAAAAJCzFM0BAAAAAAAAyFkF6X5AIpFIa38AAAAAAACg6qjXkWvSVjRf/jfTCSecEPn5+es9bkP7r/i8IUOGbPA4AAAAAAAAAHJXWleaJ5PJmDp1atr6r8g3XgAAAAAAAADYUGktmmeqkJ1MJjPyHEinPdo3ynYEAAAA2Oz9Z9LMbEcAADZQpy2Lsh0B2MylrWiukA0AAAAAAABAdZeWovlrr72WjmkBAAAAAACANMvLdgDIsLQUzVu3bp2OaQEAAAAAAACgSvmiCAAAAAAAAAA5S9EcAAAAAAAAgJylaA4AAAAAAABAzkrLmeYAAAAAAABAzZRIJLIdATLKSnMAAAAAAAAAcpaiOQAAAAAAAAA5S9EcAAAAAAAAgJzlTHMAAAAAAAAgxYnm5BorzQEAAAAAAADIWYrmAAAAAAAAAOQsRXMAAAAAAAAAcpaiOQAAAAAAAAA5qyDbAQAAAAAAAIDqI5HIdgLILCvNAQAAAAAAAMhZiuYAAAAAAAAA5CxFcwAAAAAAAABylqI5AAAAAAAAADmrINsBAAAAAAAAgOojLxLZjgAZZaU5AAAAAAAAADlL0RwAAAAAAACAnKVoDgAAAAAAAEDOUjQHAAAAAAAAIGcVZDsAAAAAAAAAUH0kEtlOAJllpTkAAAAAAAAAOUvRHAAAAAAAAICcpWgOAAAAAAAAQM5SNAcAAAAAAAAgZxVkOwAAAAAAAABQfSQike0IkFFWmgMAAAAAAACQsxTNAQAAAAAAAMhZiuYAAAAAAAAA5CxnmgMAAAAAAAApCUeak2OsNAcAAAAAAAAgZymaAwAAAAAAAJCzFM0BAAAAAAAAyFmK5gAAAAAAAADkrIJsBwAAAAAAAACqj7xIZDsCZJSV5gAAAAAAAADkLEVzAAAAAAAAAHKWojkAAAAAAAAAOUvRHAAAAAAAAICcVZDtAAAAAAAAAED1kUhkOwFklpXmAAAAAAAAAOQsRXMAAAAAAAAAcpaiOQAAAAAAAAA5S9EcAAAAAAAAgJxVkO0AAAAAAAAAQPWRSGQ7AWSWleYAAAAAAAAA5CxFcwAAAAAAAABylqI5AAAAAAAAADlL0RwAAAAAAACAnFWQ7QAAAAAAAABA9ZGIRLYjQEZZaQ4AAAAAAABAzlI0BwAAAAAAACBnKZoDAAAAAAAAkLOcaQ4AAAAAAACk5DnSnBxjpTkAAAAAAAAAOUvRHAAAAAAAAICcpWgOAAAAAAAAQM5SNAcAAAAAAAAgZxVkOwAAAAAAAABQfSQike0IkFFWmgMAAAAAAACQsxTNAQAAAAAAAMhZiuYAAAAAAAAA5CxFcwAAAAAAAAByVkG2AwAAAAAAAADVRyKR7QSQWVaaAwAAAAAAAJCzFM0BAAAAAAAAyFmK5gAAAAAAAADkLGeaAwAAAAAAALCKpUuXxieffBLfffddzJgxI+rXrx8tW7aMPfbYI4qKirIdr8oomgMAAAAAAAApiUhkO0LO6dSp00aNe+mll2Lbbbet4jQRS5Ysib/85S/x6KOPxvTp01d5vaioKA499NC46KKLokGDBlX+/EyzPTsAAAAAAAAAERExb968+PnPfx4DBw5cbcE8ImLhwoXx9NNPxxFHHBFffPFFhhNWPSvNAQAAAAAAAKqJ5s2bR506ddarb61atar02RUVFfGb3/wmPvnkk9S9Vq1axRFHHBGtW7eOWbNmxZAhQ+Lzzz+PiIipU6fG2WefHU8//XS0aNGiSrNkkqI5AAAAAAAAQDVxyy23RLdu3bLy7Iceeijef//9VPuwww6L66+/vlJx/uyzz45HHnkkrrvuukgmkzFt2rS44oor4r777stG5Cphe3YAAAAAAACAHLdgwYJ44IEHUu0ddtghbrzxxtWuZj/llFPipJNOSrXfeuut+PjjjzOSMx0UzQEAAAAAAICUvETu/RDx/PPPx5w5c1Ltiy66KAoK1rxx+W9/+9uoW7duqv3II4+kM15aKZoDAAAAAAAA5LjXXnstdd26devo3r37WvtvscUWcdBBB6Xa77zzTixevDht+dJJ0RwAAAAAAAAgh5WVlcUHH3yQavfo0SMSiXUvwe/Ro0fquqSkpMZu0a5oDgAAAAAAAJDDvv766ygvL0+1d9555/Ua17Vr10rt0aNHV2muTFnzJvQAAAAAAAAAZNRf//rXuOmmm2LSpElRUlISxcXF0axZs9hll11i3333jd69e0deXtWujR4/fnyldrt27dZrXOvWrSM/Pz+WLFkSEcuK7zWRojkAAAAAAACQkoh1b8tN+qx4tnhExOzZs2P27NkxZsyYeOqpp2LrrbeOK664Ivbee+8qe+akSZMqtVu2bLle4/Lz86NZs2YxderUiIiYOHFilWXKJEVzAAAAAAAAIKdNmTIlpkyZsklztGrVKlq1alUleerVqxcNGjSIRYsWxZw5c1IruSMivvnmmzjzzDPjoosuijPOOKNKnrdgwYJK7QYNGqz32Pr166eK5iUlJVWSJ9MUzQEAAAAAAICcNmjQoLjzzjs3aY6+ffvGueeeu1Fja9WqFT/+8Y+jd+/esdtuu0WLFi1Sry1cuDA+/PDDePjhh+P999+PiIilS5fGjTfeGC1atIhDDz10k3Ivf8aKateuvd5j69Sps8Z5agpFcwAAAAAAAIAseuutt6Jx48arfa2oqCj222+/2G+//eLhhx+O66+/PvXa1VdfHfvtt18UFxdv0vMXLVpUqV1YWLjeY2vVqpW6Lisr26Qc2VK1J8QDAAAAAAAANVoikXs/2bamgvnKTjvttDjllFNS7Tlz5sTf/va3TX7+yivLy8vL13vs4sWLU9crrjqvSaw0BwAAAAAAAHLaMcccE927d9+kOarqPPN16du3bzzzzDOprdDffPPNOPPMMzdpzqKiokrtRYsWrfcW7SuuLl95nppC0RwAAAAAAADIaa1atcpY0XtTNWjQIPbYY4946623IiLis88+2+Q5V97efe7cuVG/fv31Gjt//vzUdb169TY5SzbYnh0AAAAAAACgBmnXrl3qury8PObNm7dJ82211VaV2t9///16jVuyZElMnz491W7Tps0m5cgWRXMAAAAAAACAGqRu3bqV2itukb4x2rdvX6n93Xffrde4yZMnx5IlS9Y4T02haA4AAAAAAACkJHLwp6aZMWNGpXbDhg03ab727dtHYWFhqv3pp5+u17jhw4dXanfs2HGTcmSLojkAAAAAAABADfLJJ5+krps3bx61atXapPnq1q0be+yxR6o9dOjQSCaT6xz3/vvvp66Liopi991336Qc2aJoDgAAAAAAAFBDDB06NCZMmJBq9+jRo0rmPeCAA1LXkyZNiqFDh661//z58+Pll19OtffZZ59NLt5ni6I5AAAAAAAAQBaUl5dHRUXFevefNWtWXH755ZXuHXnkkWvsf/LJJ0enTp1SP2tzxBFHRIMGDVLtW265Za3Z/vjHP0ZpaWmqfcopp6wrfrWlaA4AAAAAAACQBdOmTYuf/OQn8fTTT8f8+fPX2vfjjz+O4447LiZNmpS6t9dee1XZSvMtttgi/u///i/VHjVqVAwYMCDKy8tX6fvoo4/G448/nmrvs88+NXZr9oiIgmwHAAAAAAAAAKqPvEQi2xFyynfffReXX355XH311bHrrrvG9ttvHy1btozi4uJYvHhxfP/99zF06NAYMWJEpXFt27aNW265pUqznH766fHuu+/GsGHDIiLihRdeiE8++SQOP/zw2GqrrWLWrFkxZMiQSlmaNWsW1157bZXmyDRFcwAAAAAAAIAsW7x4cfznP/+J//znP+vs261bt7j55pujcePGVZqhsLAw7rjjjvjlL38Zw4cPj4iIyZMnxz333LPa/s2bN48///nPseWWW1ZpjkyzPTsAAAAAAABAFjRs2DBOPPHE2HbbbSOxjhX+iUQidt1117jtttvi4YcfjhYtWqQlU4MGDeLxxx+P8847L5o1a7baPkVFRfHTn/40Xnjhhdhpp53SkiOTEslkMpntEEBEWUW2EwAAAMDm7++fTsx2BABgA526e5tsR8g5Q8fNyXaEjOveoWG2I8SCBQtizJgxMWnSpJg5c2aUlpZGYWFh1K9fP1q1ahU777xz1K9fP6OZlixZEp988kl8++23MXPmzKhfv360bNky9txzzygqKspolnRSNIdqQtEcAAAA0k/RHABqHkXzzFM0J9c40xwAAAAAAABIWfsm4bD5caY5AAAAAAAAADlL0RwAAAAAAACAnKVoDgAAAAAAAEDOUjQHAAAAAAAAIGcVZDsAAAAAAAAAUI0ksh0AMstKcwAAAAAAAABylqI5AAAAAAAAADlL0RwAAAAAAACAnOVMcwAAAAAAACAl4VBzcoyV5gAAAAAAAADkLEVzAAAAAAAAAHKWojkAAAAAAAAAOUvRHAAAAAAAAICcVZDtAAAAAAAAAED1kUhkOwFklpXmAAAAAAAAAOQsRXMAAAAAAAAAcpaiOQAAAAAAAAA5S9EcAAAAAAAAgJxVkO0AAAAAAAAAQPWRyHYAyDArzQEAAAAAAADIWYrmAAAAAAAAAOQsRXMAAAAAAAAAcpaiOQAAAAAAAAA5qyDbAQAAAAAAAIBqJJHtAJBZVpoDAAAAAAAAkLMUzQEAAAAAAADIWYrmAAAAAAAAAOQsRXMAAAAAAAAAclZBtgMAAAAAAAAA1UciEtmOABllpTkAAAAAAAAAOUvRHAAAAAAAAICcpWgOAAAAAAAAQM5ypjkAAAAAAACQknCkOTnGSnMAAAAAAAAAcpaiOQAAAAAAAAA5S9EcAAAAAAAAgJylaA4AAAAAAABAzirIdgAAAAAAAACg+khkOwBkmJXmAAAAAAAAAOQsRXMAAAAAAAAAcpaiOQAAAAAAAAA5S9EcAAAAAAAAgJxVkO0AAAAAAAAAQDWSyHYAyCwrzQEAAAAAAADIWYrmAAAAAAAAAOQsRXMAAAAAAAAAcpaiOQAAAAAAAAA5qyDbAQAAAAAAAIDqIxGJbEeAjLLSHAAAAAAAAICcpWgOAAAAAAAAQM5SNAcAAAAAAAAgZymaAwAAAAAAAJCzCrIdAAAAAAAAAKg+EolsJ4DMstIcAAAAAAAAgJylaA4AAAAAAABAzlI0BwAAAAAAACBnKZoDAAAAAAAAkLMKsh0AAAAAAAAAqD4S2Q4AGWalOQAAAAAAAAA5S9EcAAAAAAAAgJylaA4AAAAAAABAznKmOQAAAAAAAPA/DjUnx1hpDgAAAAAAAEDOUjQHAAAAAAAAIGcpmgMAAAAAAACQsxTNAQAAAAAAAMhZBdkOAAAAAAAAAFQfiUhkOwJklJXmAAAAAAAAAOQsRXMAAAAAAAAAcpaiOQAAAAAAAAA5S9EcAAAAAAAAgJxVkO0AAAAAAAAAQPWRSGQ7AWSWleYAAAAAAAAA5CxFcwAAAAAAAABylqI5AAAAAAAAADlL0RwAAAAAAACAnFWQ7QAAAAAAAABA9ZHIdgDIMCvNAQAAAAAAAMhZiuYAAAAAAAAA5CxFcwAAAAAAAABylqI5AAAAAAAAADmrINsBAGBzVFFREZ99OjymTJ4cP/wwPYqLi6N5iy1j5112iUaNGmc7HgCwGj6/AQAA/iuR7QCQWYrmAFCFSktL47577o7nBz8bM2fOWOX1goLC2HuffaJvv9/Gdh07ZSEhALAyn98AAACQ2xLJZDKZ7RBARFlFthMAm2rcuLFx4Xn9YsLXX6+zb+3atePC/pfEz447IQPJAIA18fkNuefvn07MdgRgAz127fnx3ZcjqmSuSx8fUiXzAJl16u5tsh0h54ycvCDbETJup9bF2Y5AFllpvpkYNmxYnHLKKan26NGjs5gGIPf88MP0+NVZv4jp06ZVur/DjjvGVlu1iTlz5sSokZ9HSUlJREQsWrQo/nD176O4XnEcctjhWUgMAPj8BoDcUlBYK9sRAIBqStGczVZJSUmMGzcuJk+eHNOnT4/S0tLIz8+PBg0aRLt27WKnnXaK4mLfGgI2XTKZjAt+26/SL9y369gxrrvh5ujYqXPq3rx58+KuO26PJ594LHXv91deFh07d44OHbbLaGYAyHU+vwEg93Tcfa9sRwCoMRIONSfHKJqvp2effTYuueSSjR5v5XdmfPvtt3HvvffGxx9/HN9++22s7fSBgoKC2G+//eKss86KXXbZJXMhgc3Oa6++Ep99OjzVbr3VVvHgw49F/QYNKvWrX79+XHLZFZGXl4gnHns0IpatWLvrjtvjttvvzGhmAMh1Pr8BoOY4qu/lUVG+eMMGJZPx8O/OjYXz5qRu/WifA6s2GACw2cjLdgCoSmPHjo1BgwbFN998s9aCeURERUVFvPbaa3H88cfHzTffnKGEwObonj9X/oX5pZdfucov3FfU77cXRKtWrVPt14e8Gl99+WXa8gEAq/L5DQA1R3HDxtGw2ZYb9DPnh6mVCubFjZrENj/aLXtvAgCo1qw030jNmzePOnXqZDtGSrdu3axmX0mzZs1i5513jvbt28eWW24ZRUVFUVpaGt9991289957MWbMmIhYti3jAw88EBERF110UTYjAzXQ2DGjY+x///8kIqJ9+21j7332W+uYunXrxk9/dnz86Y8DU/f+9eIL0Xn77dOWEwD4H5/fALD5+/ydVyq1d9rrgMjLy89SGgCgulM030i33HJLdOvWLdsxWEnz5s3jggsuiN69e8e222671r4vvfRSXHrppVFaWhoREQ8++GAcdthhsb1fegEb4K0336jUPuSww9dr3KGHHV7pl+5vvvl6nHfhxVWaDQBYPZ/fALB5W1xWGl998E6lez/a58dZSgMA1AS2Z2ez0qVLlzjrrLPWWTCPiDjkkEPimmuuSbWXLl0agwYNSmc8YDM09P33KrV33W339Rq3ZcuWlbZ4/WbChJj6/fdVmg0AWD2f3wCwefvqg3eifFFZqt2yfcdotlW7LCYCqHkSidz7IbdZaZ5FJSUlMXr06JgwYULMnj07lixZEvXr149WrVrFbrvtFsXFxdmOuFEqKipi7NixMX78+JgxY0aUlpbGFltsEU2aNIldd901WrRoke2IKYceemj84Q9/iNmzZ0dExMiRI7OcCKhpxo8fl7rOy8uLHXbcab3H/mjnnWPKlMn/m2vc2NiyZcsqzQcArMrnNwBs3lbemt0qcwBgXRTNM+yHH36If/7zn/Hyyy/H559/HhUVFavtl5+fH7169Yp+/fpFx44d1znvsGHD4pRTTkm1V3e++Q033BAPPfRQqn3HHXfEj3+89n9gXLp0aZx66qnxwQcfREREnTp1YtCgQdGhQ4dK/crKyuKVV16Jl156KT744IMoKSlZ45w77bRT9O3bN/bff/91vq90y8vLi3bt2qWK5sv/G2B9zJs7N2bPmpVqN2nSJOrWrbve41u33qpS+5tvJsRe++xbZfkAgFX5/AaAzdvcGdPi2y8/S7XzCwpjxx69spgIAKgJbM+eYQ8++GDccMMNMXz48DUWzCMilixZEq+++mr89Kc/jZdeeqlKnn3++edH586dU+0rrrgipk2bttYx999/f6pgHhFx8cUXr1Iwj4gYOnRoXHTRRfHGG2+stWAesWw199lnnx033HBDJJPJDXwXVW/FvA0bNsxeEKDGmTjxu0rtFltu2CqzFi22rNT+7rvv1tATAKgqPr8BYPM28t0hESv8zrFD125Rt7h+FhMBADWBleZZtNVWW8Vuu+0W2223XTRs2DCWLl0aU6ZMiffeey8+//zziIhYtGhRXHzxxdG2bdvYaaf13zJwdWrVqhUDBw6MPn36xKJFi2LOnDnRv3//eOihhyKxmsMaPv/887jjjjtS7Z49e8ZJJ520zuc0bNgwdtttt9hhhx2iSZMmUVhYGDNnzozhw4fH22+/HUuWLImIiIceeihatWpVaYV8pk2ePDnGjx+fau+6665ZywLUPAsWLKjUbtS48QaNb9S40Urzzd/kTADA2vn8BoDN2+fvvlqpbWt2AGB9KJpnWF5eXhx22GFx6qmnRpcuXVbb57zzzou33norLrroopg7d26Ul5fHVVddFU8//fQmP79Dhw5x8cUXxzXXXBMRy1aIP/TQQ3HGGWdU6ldaWhoXXnhhlJeXR8SyLQuvu+66tc7dtWvXOPPMM2PfffeNwsLC1faZMGFC/OY3v0ltHz9w4MA4/PDDo1GjRqvtn05lZWVxySWXxNKlSyMionbt2nHiiSdmPAdQcy1cWHlnjdq1am/Q+Nq166w038JNzgQArJ3PbwDYfE0a+0XM+n5Sql1Uv2Fsu/OeWUwEUHOtutQSNm+2Z8+wfv36xcCBA9dYMF9uv/32i9tvvz3VHjFiRIwcObJKMvz85z+Pfff935l7t956a3z11VeV+lx33XXxzTffVGo3adJkjXP26NEjnnzyyejdu/caC+YREdtss008+OCD0fi/qznKyspi8ODBG/lONlxZWVmMHz8+Hn/88Tj88MNj2LBhERGRSCTiqquuijZt2mQsC1DzlS4srdSuVbvWBo2vXbvyL+lXng8AqHo+vwFg8/X5269Uau/Yo1fkF1g3BgCsm39i2Ejru6V4586d4/nnn0+1V/4Fy9p07949unXrlirsvvvuu5u8Rfty119/fRxxxBExc+bMKC8vjwsuuCAGDRoUderUiSFDhsRTTz2V6nvSSSdFz5491zrfhryvpk2bxkknnZTa+v3dd99dZaV7VbnjjjvizjvvXGufrbfeOi6//PLYZ5990pIByB2rO+piQ/onI7mGngBAuvj8BoDNQ0X54vjyP29WutfF1uwAwHqy0rya6969e+p61KhRVTZv06ZNK223Pm7cuLjpppti+vTpcfnll6fuL9/Ovaql631tqF69esVDDz2kYA5slLpFdSu1F5Ut2qDxZWVlldpFRUWbnAkAWDuf3wCweRr7ydAoW7gg1W7etn202LpDFhMBADWJleYbqXnz5lGnTp119mvZsuUmPadp06ap62nTpm3SXCvr2bNnnHjiifHEE09ERMTjjz8ew4YNi9mzZ0dERGFhYQwcOHC93ueGWvF9zZkzJxYtWrRBq9XXV4MGDaJt27YREZFMJmPBggUxZ86cSCaXrQZ5/fXX45133okTTzwxLrjggrRkADZfdetW/iX5osUb9kv3xSv190t3AEg/n98AsHlaeWv2LvtaZQ4ArD9F8410yy23RLdu3TZ6fGlpabz22mvxzjvvxOjRo2Pq1KlRUlISixcvXuOY+fPnb/Tz1qR///4xbNiwGD9+fEQsW3G+3Pnnnx+dO3feoPmWLl0aw4YNiyFDhsQXX3wREydOjAULFkRp6drP+Zs/f35aCtannHLKKlvpz58/P95///34y1/+Ep999lmUl5fHX//61/jqq6/igQceiFq1NuxMQyB3FRcXV2rP+e+XjtbX7FmzVppvi03OBACsnc9vANj8LJg7O77+/KNUOy8/P3bs0TuLiQA2Axt2khXUeIrmWfDcc8/FjTfeGLNW+mXLuixatGErINZHnTp1YuDAgXHsscdGeXl56n737t3j9NNP36C5RowYEVdccUV89dVXG5wjHe9tTbbYYos46KCD4sADD4zrrrsuHn300YiIGDZsWPzpT3+KCy+8MGNZgJqtTZu2ldpTp36/QeOnTp260nxtNjkTALB2Pr8BYPMz6r3XYumSJal2+y57RL0GjbKYCACoaRTNM+z++++PW265ZbWvNWzYMOrUqVNppXNJSUnMnDkzrZny8/MjL6/y8fY9evSIRGL9v0Y0bNiwOOuss1Y53y8iol69elGvXr2oXbt2as4lS5bE5MmTU32Wb5eeSXl5eXHZZZfFiBEj4rPPPouIiMceeyzOOuusqF+/fsbzADVPg4YNo1HjxqkVZzNnzIjS0tKoW7fuOkYuM3nypErtbbZpX+UZAYDKfH4DwObn83cqb83+o31szQ4AbBhF8wz66quv4rbbbku1mzZtGqecckrss88+0aFDh9VuCz5o0KC49NJL05Zp8eLFceGFF66y0vvOO++M/fffP7bbbrt1zlFWVhYDBgxIFcwLCwvj+OOPjwMPPDB23HHHVbY/jIiYOHFiHHDAAVXzJjZBIpGIE088MVU0Ly0tjQ8++KBaZANqhm237RAfzfogIpYdUfHFqJGx2+57rNfYz0d8VqndftsOVZ4PAFiVz28A2HxM+3Z8TP/u61S7bvEW0XG37llMBADURHnr7kJVeeKJJ2LJf7cJatasWTz77LPxy1/+MnbYYYc1nqOdjnPMVzRw4MAYPXp0ql1UVBQRy7ZLv+CCC9Z6xvpyQ4YMiSlTpkTEstXb999/f1x++eXRrVu31RbMI9L/vjbEyue2f/fdd1lKAtRE/697j0rtTz7+aA09K5v6/fcxZYUdN7beZpto2apVlWYDAFbP5zcAbD5WXmW+/f/bP/ILCrOUBgCoqRTNM+g///lP6vqUU06JFi1arHPMpEmT1tlnY73//vvx17/+NdU+9thj4/rrr0+1R48eHbfeeus651nxfe21117Rvfu6v8mZzve1oQoLK/9D9JIVzj8CWJee+/eq1H7pny+s17gXV+rXs2evNfQEAKqaz28A2DwsXbIkRr73WqV7Xfa1NTtAVUjk4H/IbYrmGTR9+vTU9cqrm9dk2LBhackyZ86c6N+/f+os8Xbt2sWll14aBx98cBx99NGpfg8//HC8//77a52rOr2vjbFyAb9p06ZZSgLURNt17BQdtuuYan/99fh495231jqmrKwsnnnqyUr3fnLo4WnJBwCsyuc3AGwexn/2YSycNyfVbtKqbbTadv1+PwkAsCJF8wxaXqCOiPXa9vyDDz6IMWPGpCXLFVdckSp2FxQUxM0335zamv3yyy+PrbbaKiKWZR4wYEDMmTNnjXOt+L5WPht9debPnx/PP//8JqSvWq+++mql9g477JClJEBN9atz+lZqX/+Ha2Le3Llr7P+n2wbGlCn/29p1/94HROftt09bPgBgVT6/AaDmW3lrdqvMAYCNpWieQVtuuWXq+s0331xr3wULFsTvfve7tOR45pln4pVX/vcPlOecc07svPPOqXZxcXHcfPPNkZ+fHxER06ZNiyuvvHKN87Vs2TJ1/c4778TSpUvX+vyrrroqLWeal5eXR3l5+QaN+fjjj2Pw4MGp9tZbbx2dOnWq6mjAZq73gT+OnXfpmmpPmjgxzjjt5zF2zOhK/ebPnx/X/+GaePyxR1L3ateuHX37/TZTUQGA//L5DQA1W2nJ/Bg7fGiqnUjkxU57HZDFRABATaZonkF77bVX6vrZZ5+Nl156abX9Jk6cGKeddlp8/fXXkZdXtX9E3333XfzhD39Itbt27Rpnn332Kv123XXXSvdffvnlGDRo0Grn7NGjR+p6woQJcf3116/2XPAFCxbEJZdcEi+88EKVv6+IZcX9gw46KB5//PGYPXv2WvtWVFTEU089FWeeeWZUVFSk7l9wwQVVngvY/CUSibjlttujWfPmqXtjx4yJY/scGSf+7Ji46ILfxlm/OC0O6r1fPPnEY5XG/u7qa6NDh+0yHRkAcp7PbwCo2b4c+mYsWWEBzdY7dY0tGjt2EaCqJBK590NuK8h2gFxy2mmnxVNPPRXl5eWxZMmSOO+88+Kpp56KvffeOxo3bhzz5s2LTz75JN54441YvHhxFBUVxYknnhgPPPBAlTy/oqIiLrzwwli4cGFERNSrV6/SivKVnXPOOfHuu+/GZ599FhER1157beyxxx7Rtm3bSv0OOOCA2HrrreObb76JiIhHHnkk3n///TjooIOidevWUVZWFqNHj45XXnklVczu27dv/OlPf6qS97WiyZMnx9VXXx3XXXdddOnSJXbcccdo3bp1bLHFFpFMJmPu3LkxduzYeOedd2LmzJmVxp588snx4x/bwgnYOM2bt4g/3/eXuPC8fvHNhAkRsez4ilGjRsaoUSNX6V+7du248OIBcehhR2Q6KgDwXz6/AaDmWnVr9oOylAQA2BwommdQ27Zt4+qrr47LLrsstYX50KFDY+jQoav0LSoqioEDB671LPENdffdd6cK4BERV155ZbRp02aN/ZefdX7UUUfFwoULY+HChXHRRRfFE088UanQXlBQELfffnucfPLJMW/evIiIGDduXIwbN26VOROJRPzqV7+KI488Mi1F8+UqKirik08+iU8++WSdfWvXrh19+/aNs846K215gNyw3XYd48mnB8e9f74rnn/u2Zi10pdzIiIKCgpj7332ib79fhvbdXQcBABkm89vAKh5Zn4/KSaP+zLVrl23KDruvtdaRgAArJ2ieYb16dMnmjVrFtddd118/fXXq7yen58fPXr0iMsuuyy22WabePbZZ6vkucOHD4977rkn1T744IPjqKOOWue4du3axWWXXRaXXXZZRER8+umncdddd0W/fv0q9evcuXM888wzcdVVV8V777232rk6d+4c559/fuy3334xadKkjX8za9CsWbO49NJL4+23347hw4dHSUnJWvs3btw4DjvssPj5z38e7dq1q/I8QG6qW7du/Pb8C6Nvv9/Gp8M/icmTJsWMGTOiuLhetGixZXTZpWs0btw42zEBgBX4/AaAmmXlVebbd9svCmvVzlIaAGBzkEgmk8lsh8hFyWQyRo4cGaNGjYo5c+ZEcXFxNG/ePLp27RrNmjXLdrxNMnHixPj4449j+vTpUVhYGM2aNYvOnTtHhw4dMpZh6dKl8fXXX8c333wT33//fZSUlEQikYji4uJo3LhxbL/99tGuXbtIVKNDKsoq1t0HAAAA2DR//3RitiMAABvo1N3XvGsu6TF66sJsR8i4TlsWZTsCWaRoDtWEojkAAACkn6I5ANQ8iuaZNyYHi+YdFc1zWl62AwAAAAAAAABAtiiaAwAAAAAAAJCzFM0BAAAAAAAAyFmK5gAAAAAAAADkrIJsBwAAAAAAAACqkUS2A0BmWWkOAAAAAAAAQM5SNAcAAAAAAAAgZymaAwAAAAAAAJCzFM0BAAAAAAAAyFkF2Q4AAAAAAAAAVB+JSGQ7AmSUleYAAAAAAAAA5CxFcwAAAAAAAABylqI5AAAAAAAAADlL0RwAAAAAAACAnFWQ7QAAAAAAAABA9ZFIZDsBZJaV5gAAAAAAAADkLCvNAQAAAAAAALJs8eLFMX78+Bg7dmzMnDkzFi1aFFtssUW0aNEidtlll2jatGm2I262FM0BAAAAAAAAsmDWrFnx73//O95444346KOPYuHChWvsu+uuu8YvfvGLOOCAA6o8x6RJk6J3794bNXbEiBFRu3btKk6UWYrmAAAAAAAAABk2fvz4OOKII6KiomK9+n/yySfxySefxKGHHhrXXXdd1KlTJ80Jc4eiOQAAAAAAAJCSyHaAHLF48eJKBfO8vLzYfvvtY/fdd49WrVrFFltsETNnzowPPvgg3n333UgmkxER8eKLL8aCBQviz3/+c+Tn56clW+vWrdd77kSi5v8Vo2gOAAAAAAAAkCUtWrSI448/Po455pho0aLFKq+fddZZMWLEiPjNb34TU6ZMiYiIt956K/7+97/HiSeemJZMjzzySGy11VZpmbs6yst2AAAAAAAAAIBcU1RUFP37949XX301zjnnnNUWzJfr0qVL/OUvf6l0dvj999+fiZg5QdEcAAAAAAAAIMPatWsXZ5xxRqVC+Nq0b98++vTpk2pPmTIlxo4dm654OUXRHAAAAAAAAPifRA7+1BDdunWr1J44cWKWkmxeFM0BAAAAAAAAaoB69epVapeWlmYpyeZF0RwAAAAAAACgBpg0aVKldpMmTbKUZPNSkO0AAAAAAAAAAKzba6+9lrouLCyMHXfcMS3PufXWW2PcuHExZcqUKCsriwYNGkTz5s1jt912i169ekWPHj3S8txsUTQHAAAAAAAAqOa++uqreP/991PtvffeO7bYYou0POvFF1+s1J4xY0bMmDEjvvjii3j00Udjhx12iGuuuSZ22mmntDw/0xTNAQAAAAAAgJREJLIdIeOmTJkSU6ZM2aQ5WrVqFa1ataqiRJVVVFTE5ZdfHkuXLk3d+/Wvf52WZy1Xv3792GKLLaKkpCTmzp0byWQy9doXX3wRJ5xwQtxwww1x6KGHpjVHJiiaAwAAAAAAADlt0KBBceedd27SHH379o1zzz23ihJVdsstt8Tnn3+eah933HHxox/9qEqfUa9evTjkkEOid+/esfPOO0fjxo1Tr82bNy/ee++9eOCBB2LkyJEREbF48eLo379/tGjRInbfffcqzZJpiuYAAAAAAAAA1dSgQYPioYceSrW32WabuOSSS6r0Gc2bN4+33347iouLV/t6/fr14yc/+Un8+Mc/jptuuikefvjhiIgoLy+PK664Iv75z39Gfn5+lWbKpLxsBwAAAAAAAABgVW+99VZceeWVqXbDhg3j/7d332F2VWX/uD9nZjJJJpUS0knoECUUQXoNCgQQBUGBl6qCr9iQLmKjI1aqgF9qBF8xoFKVItJ7F0kgBFIIECAJ6VPO74/85pAhbUImM5mc+74uLs7ae+29nz1hWFnnWeXiiy9O586dW/Q51dXVi0yYz6+ysjKnnnpqdtttt9KxMWPG5K677mrReFqbmeYAAAAAAABAWdt///2zzTbbLNM9Wno/8yeffDLf/e53U1dXl2Te8ulXXHFF1llnnRZ9zidxwgkn5O677y6V//Wvf2X48OFtGNGykTQHAAAAAAAASgqFto6g9fXr16/Fk97L4sUXX8wxxxyT2bNnJ0k6duyYSy+9NEOHDm3jyOZZa621su666+bVV19Nkjz33HNtHNGysTw7AAAAAAAAwApi1KhR+drXvpbp06cnSTp06JDf/e532Wqrrdo4sqYGDRpU+vzee++1YSTLTtIcAAAAAAAAYAUwduzYHHXUUZkyZUqSeXuIn3/++dl5553bNK6FmX9f9cYZ8e2VpDkAAAAAAABAG5s4cWKOPPLIvPvuu0mSQqGQM844Y4XdK3zy5Mmlz6usskobRrLsJM0BAAAAAAAA2tC7776bI444IhMnTiwdO+2007L//vu3YVSLVltbm+eff75U7t+/fxtGs+yq2joAAAAAAAAAYMVRaOsAysyUKVNy1FFH5Y033igdO/7443PooYe2YVSLd8stt2TmzJml8rbbbtuG0Sw7SXMAAAAAAACANjB9+vR8/etfz6hRo0rHvvnNb+boo49e5nvvuuuumTBhQpJ5M8HvvffehdabM2dOqqurUyg0b7jEG2+8kQsuuKBUrqyszN57773M8bYly7MDAAAAAAAAtLI5c+bkf//3f/PCCy+Ujh122GE57rjjWjWOZ599Nl/60pdy++23Z/bs2Yute++99+aggw7KlClTSsf233//rL322ss5yuXLTHMAAAAAAACAVnbHHXfk8ccfb3Lsvvvuy7/+9a9m3+Pzn/98TjzxxGWO5eWXX85xxx2XmpqafOYzn8lGG22UNdZYI126dMmsWbMybty4PPjggxk9enST6zbZZJOcdtppy/z8tiZpDgAAAAAAANDKGhoaFjg2bty4pbrHe++911LhJElmzpyZBx54IA888MAS6+65554544wz0qlTpxaNoS1ImgMAAAAAAAAfad7W1qwk1lxzzey333554oknlpi0r6yszLbbbpvDDjssO+64YytFuPwVisVisa2DAJLZdW0dAQAAAKz8/vTs0s3cAQDa3uFbDGzrEMrO2PcWv6/1ymjwau1/tnRLmDJlSkaNGpWJEyfm/fffz+zZs9OxY8d07949a665ZjbeeOPU1NS0dZgtzkxzAAAAAAAAANKzZ8989rOfbeswWl1FWwcAAAAAAAAAAG3FTHMAAAAAAACgpGBTc8qMmeYAAAAAAAAAlC1JcwAAAAAAAADKlqQ5AAAAAAAAAGVL0hwAAAAAAACAslXV1gEAAAAAAAAAK45Coa0jgNZlpjkAAAAAAAAAZUvSHAAAAAAAAICyJWkOAAAAAAAAQNmSNAcAAAAAAACgbFW1dQAAAAAAAADAiqPQ1gFAKzPTHAAAAAAAAICyJWkOAAAAAAAAQNmSNAcAAAAAAACgbEmaAwAAAAAAAFC2qto6AAAAAAAAAGDFUSi0dQTQusw0BwAAAAAAAKBsSZoDAAAAAAAAULYkzQEAAAAAAAAoW5LmAAAAAAAAAJStqrYOAAAAAAAAAFiRFNo6AGhVZpoDAAAAAAAAULYkzQEAAAAAAAAoW5LmAAAAAAAAAJQte5oDAAAAAAAAJQVbmlNmzDQHAAAAAAAAoGxJmgMAAAAAAABQtiTNAQAAAAAAAChbkuYAAAAAAAAAlK2qtg4AAAAAAAAAWHEU2joAaGVmmgMAAAAAAABQtiTNAQAAAAAAAChbkuYAAAAAAAAAlC1JcwAAAAAAAADKVlVbBwAAAAAAAACsOAqFto4AWpeZ5gAAAAAAAACULUlzAAAAAAAAAMqWpDkAAAAAAAAAZUvSHAAAAAAAAICyVdXWAQAAAAAAAAArjkIKbR0CtCozzQEAAAAAAAAoW5LmAAAAAAAAAJQtSXMAAAAAAAAAypakOQAAAAAAAABlq6qtAwAAAAAAAABWIIW2DgBal5nmAAAAAAAAAJQtSXMAAAAAAAAAypakOQAAAAAAAABlS9IcAAAAAAAAgLJV1dYBAAAAAAAAACuOQlsHAK3MTHMAAAAAAAAAypakOQAAAAAAAABlS9IcAAAAAAAAgLJlT3MAAAAAAACgpGBTc8qMmeYAAAAAAAAAlC1JcwAAAAAAAADKlqQ5AAAAAAAAAGVL0hwAAAAAAACAslXV1gEAAAAAAAAAK45CCm0dArQqM80BAAAAAAAAKFuS5gAAAAAAAACULUlzAAAAAAAAAMqWpDkAAAAAAAAAZauqrQMAAAAAAAAAViCFtg4AWpeZ5gAAAAAAAACULUlzAAAAAAAAAMqWpDkAAAAAAAAAZUvSHAAAAAAAAICyVdXWAQAAAAAAAAArjkJbBwCtzExzAAAAAAAAAMqWpDkAAAAAAAAAZUvSHAAAAAAAAICyJWkOAAAAAAAAQNmqausAAAAAAAAAgBVHodDWEUDrMtMcAAAAAAAAgLIlaQ4AAAAAAABA2ZI0BwAAAAAAAKBs2dMcAAAAAAAAKCnEpuaUFzPNAQAAAAAAAChbkuYAAAAAAAAAlC1JcwAAAAAAAADKlqQ5AAAAAAAAAGWrqq0DAAAAAAAAAFYchUJbRwCty0xzAAAAAAAAAMqWpDkAAAAAAAAAZUvSHAAAAAAAAICyJWkOAAAAAAAAQNmSNAcAAAAAAACgbEmaAwAAAAAAAFC2JM0BAAAAAAAAKFuS5gAAAAAAAACULUlzAAAAAAAAAMpWVVsHAAAAAAAAAKw4CoW2jgBal5nmAAAAAAAAAJQtSXMAAAAAAAAAypakOQAAAAAAAABlS9IcAAAAAAAAgLJV1dYBAAAAAAAAACuOQgptHQK0KjPNAQAAAAAAAChbkuYAAAAAAAAAlC1JcwAAAAAAAADKlj3NAQAAAAAAgJKCLc0pM2aaAwAAAAAAAFC2JM0BAAAAAAAAKFuS5gAAAAAAAACULUlzAAAAAAAAAMpWVVsHAAAAAAAAAKw4Cm0dALQyM80BAAAAAAAAKFuS5gAAAAAAAACULUlzAAAAAAAAAMqWpDkAAAAAAAAAZauqrQMAAAAAAAAAViCFtg4AWpeZ5gAAAAAAAACULUlzAAAAAAAAAMqWpDkAAAAAAAAAZUvSHAAAAAAAAICyVdXWAQAAAAAAAAArjkIKbR0CtCozzQEAAAAAAAAoW5LmAAAAAAAAAJQtSXMAAAAAAAAAypakOQAAAAAAAABlq6qtAwAAAAAAAABWHIVCW0cArctMcwAAAAAAAADKlqQ5AAAAAAAAAGVL0hwAAAAAAACAsiVpDgAAAAAAAEDZqmrrAAAAAAAAAIAVR6GtA4BWZqY5AAAAAAAAAGVL0hwAAAAAAACAsiVpDgAAAAAAAEDZsqc5AAAAAAAA8BGbmlNmJM0BAAAAAAAAVhANDQ15+umn8+abb2by5Mnp3r17+vbtmy233DI1NTWtFsfcuXPz5JNPZsKECXn//fez6qqrpn///tliiy1SXV3danG0BklzAAAAAAAAgDZWX1+fP/zhD7nuuuvyzjvvLHC+pqYme+21V0488cT06NFjucUxe/bs/O53v8tf/vKXTJkyZYHzPXv2zP7775/vfve76dSp03KLozUVisVisa2DAJLZdW0dAQAAAKz8/vTsuLYOAQBYSodvMbCtQyg7M2vLL31Y06Ft16SfNm1ajjnmmDz99NNLrNunT59ceumlGTJkSIvHMWHChBx99NF59dVXl1h33XXXzeWXX57+/fu3eBytTdIcVhCS5gAAALD8SZoDQPsjad76JM1bV11dXb7xjW/k4YcfLh3r169fvvCFL6R///55//33c/fdd+eFF14one/du3f+/Oc/p3fv3i0Wx/Tp03PQQQdl1KhRpWPrrLNOhg8fnt69e2fSpEm5/fbbM2bMmNL59ddfPzfccEO6du3aYnG0BUlzWEFImgMAAMDyJ2kOAO2PpHnrm1Xb1hG0vs4d2u7ZV1xxRS644IJSee+9984555yzwL7h1157bc4+++w0pnd32mmnXH755S0Wx09/+tPccMMNpfLXvva1nHjiiSkUPhpQUCwWc/755+f//b//Vzp28MEH5yc/+UmLxdEWKto6AAAAAAAAAIByNH369Fx55ZWl8pAhQ3LeeectkDBPksMOOyyHHHJIqXz//ffnqaeeapE4xo0bl5tuuqlU3mWXXXLSSSc1SZgnSaFQyMknn5xddtmldOzPf/5zxo1r34NTJc0BAAAAAAAA2sBf//rXTJkypVQ+8cQTU1VVtcj63//+99O5c+dS+dprr22ROG644YbU1s5bYqBQKOSUU05ZbP35z9fW1jaZod4eSZoDAAAAAAAAtIF77rmn9Ll///7ZZpttFlu/W7du2X333UvlBx54IHPnzm3ROLbccssMHjx4sfUHDx6cLbfccqHXt0eS5gAAAAAAAACtbPbs2Xn88cdL5W233XaB5dAXZtttty19njFjxjIv0f7GG29k7NixC71/c+MYO3Zs3nzzzWWKoy1JmgMAAAAAAAAlhUL5/dMWxowZU1oSPUk22WSTZl232WabNSm/8soryxTHqFGjmpQ33XTTTxTHx+/TnkiaAwAAAAAAALSy1157rUl50KBBzbquf//+qaysLJXHjBnTonGsueaazbpu4MCBi71PeyJpDgAAAAAAANDKxo8f36Tct2/fZl1XWVmZXr16lcrjxo1rsTgqKirSu3fvZl3Xu3fvVFR8lG5e1jjaUlVbBwAAAAAAAADQliZOnJiJEycu0z369euXfv36Nbv+9OnTm5R79OjR7Gu7d++eSZMmJZm3r/mymD+OLl26pKqqeSnkDh06pHPnzqXnL2scbUnSHAAAAAAAAChrf/nLX3LRRRct0z2+/e1v5zvf+U6z68+cObNJuWPHjs2+tlOnTou8z9Ka//qliaExjsZk+bLG0ZYkzWEF0clvIwAAACx3h28xcMmVAADKnJxF65gzZ06TcocOHZp9bXV1denz7NmzWyyOpYmhpeNoS/Y0BwAAAAAAAGhlH5/VXVtb2+xr586dW/o8/6zzZY1jaWJo6TjaknEiAAAAAAAAQFnbf//9s8022yzTPZZmP/MkqampaVKeM2dOs5dHn39W98fvs7Tmv/7js99bM462JGkOAAAAAAAAlLV+/fotddJ7WXXt2rVJeerUqenevXuzrv3www9Ln7t06dJiccycOTN1dXWpqlpyGrmuri6zZs1qsTjakuXZAQAAAAAAAFrZgAEDmpTfeuutZl1XX1+fd955p1QeOHBgi8VRX1+ft99+u1nXTZo0KQ0NDS0WR1uSNAcAAAAAAABoZWuvvXaT8ptvvtms6yZMmJD6+vpF3qe14hg3btxi79OeSJoDAAAAAAAAtLK11147HTp0KJWfffbZZl33zDPPNCmvv/76yxTHBhts0KTcVnG0JUlzAAAAAAAAgFbWuXPnbLnllqXyI488kmKxuMTrHn744dLnmpqabLHFFssUx6BBgzJo0KCF3r+5cQwePLjJPdobSXMAAAAAAACANrDbbruVPo8fPz6PPPLIYut/+OGHueuuu0rlHXbYIdXV1cscx7Bhw0qfn3jiiYwdO3ax9ceOHZsnnniiVN51112XOYa2JGkOAAAAAAAA0Aa+8IUvpEePHqXyBRdckLq6ukXW/81vfpNZs2aVyocddtgi6+66667ZYIMNssEGGywxqX3QQQeVloovFos577zzFlv/3HPPLX3u0KFDDj744MXWX9FJmgMAAAAAAAC0gW7duuXrX/96qfzSSy/llFNOSW1t7QJ1r7vuuowYMaJU3mGHHZZ5afZGa665Zvbbb79S+d57780vfvGLBZaLLxaLOf/883PfffeVju2///4ZOHBgi8TRVgrF5iyMDwAAAAAAAECLq62tzde+9rU89thjpWP9+/fPPvvskwEDBuT999/P3Xffneeff750vlevXrnpppvSp0+fRd531113zYQJE0r3u/feexcbx/Tp0/OVr3wlr776aunYuuuumz333DO9e/fO22+/ndtuuy1jxowpnV9vvfVy4403pmvXrkv93isSSXMAAAAAAACANjR16tQcc8wxeeaZZ5ZYd4011sill16aT3/604utt7RJ82Tevurf+MY3miTGF2XttdfOFVdckQEDBiyx7orO8uwAAAAAAAAAbahHjx4ZMWJEjjvuuPTq1WuhdWpqavLlL385f//735eYMP+kBgwYkJtvvjlHHXVUk73WPx7rUUcdlZtvvnmlSJgnZpoDAAAAAAAArDDq6+vz9NNP54033sh7772X7t27p2/fvvnsZz+bmpqaVotj7ty5eeKJJzJhwoR88MEHWWWVVdK/f/9sueWWqa6ubrU4WoOkOQAAAAAAAABly/LsAAAAAAAAAJQtSXMAAAAAAAAAypakOQAAAAAAAABlS9IcAAAAAAAAgLIlaQ4AAAAAAABA2ZI0BwAAAAAAAKBsSZoDAAAAAAAAULYkzQEAAAAAAAAoW5LmAAAAAAAAAJQtSXMAAAAAAAAAypakOQAAAAAAAABlS9IcAAAAAAAAgLIlaQ4AAAAAAABA2ZI0BwAAAAAAAKBsSZoDAAAAAAAAULYkzQEAAGgXisVik38DACu+YrG4QBs+/zEAgBWBpDkAZaVYLKaurq6twwAAmmn+L9QLhUKTf3/8PACwYvh4+10oFDJz5swUCoXMnTu3dAwAYEVRKPqGAYAyUVdXl6qqqiTJ7NmzU1FRkerq6jaOCgBYmGKxWPoyvaGhIdOnT8/06dNz7733lr54/9SnPpWBAwdm4MCBC1wDALS+j7ffEyZMyKRJk3LnnXfm9ddfT7FYTENDQ7bYYotsvvnm2W677do4YgCAeSTNAVjpNTQ0pKLio8VVRowYkTPOOCPf/e53861vfasNIwMAlmTMmDF5+umn88gjj+Sf//xn5s6dWzpXVVWVnj17Zv/998+hhx6a1VdfvQ0jBQAavfbaa3nkkUfy0EMP5eGHH86cOXNSUVGRhoaGUp1CoZDvf//72WeffdKvX78F+u4AAK1J0hyAsvHYY4/lZz/7WcaMGZMkWWONNXLDDTekf//+bRwZANCocYbazJkz8+ijj+bvf/97Hn300XzwwQdN6lVWViZJ6uvrkyRbbbVVzjjjjKy55pqtHjMAME9j+33rrbfm4YcfzpQpU5LMS5DP/zV0VVVV6urq0qNHj3z+85/PGWec0UYRAwDMI2kOwEpv5syZufnmm3PxxRfn/fffT1VVVSorKzNnzpz8z//8T370ox+1dYgAQJquDvPXv/41V155ZUaPHp0k6dmzZwYPHpyqqqr06NEjr7zySsaPH1+q39DQkAMPPDBf//rXJc4BoBXV19eXBrP9+c9/znXXXZdRo0YlSVZZZZVsttlm6dWrVzbffPO89dZbee6553LfffeVru/YsWPOOuus7L333rZaAQDajKQ5ACulxk57XV1dbr755lx11VWlGeYfH+F+4403ZtNNN22jSAGA+TU0NOR3v/tdLrvssiTzZqJtv/32GT58eDbaaKOst956pbq///3vc/vtt+eVV15JkvTo0SPHHntsDjnkkNKX9wDA8ldbW5vzzjsv119/fZJ57feOO+6Y4cOHZ+ONN86gQYOa1D/vvPNyzTXXlJZr33bbbXPZZZelurq61WMHAEgSm8QAsFJq/KL8uuuuy7nnnltKmPfv3z877rhjevToUap76aWXpq6urk3iBAA+Mn369PzmN7/JlVdemSSpqanJl770pXzrW9/K3nvvXUqY19bWJkmOOOKInHDCCenQoUOSZOrUqXn00Ufz3nvvtc0LAEAZGjVqVI455phSwrxPnz455JBD8p3vfCfDhw8vJczr6upKSfLvfOc72XLLLUv3eO+99zJx4sTWDx4A4P8naQ7ASmn27Nn50Y9+lPPOOy8zZsxIknTu3DmHHXZYjj322Gy//fZJ5s06v//++/OPf/yjLcMFAJLcfffdueWWW0qD2Xbaaad8+9vfztChQ0vLsCcpJck7duyYHXbYIQcddFDp3AMPPFBq+wGA5auhoSEvvfRSHn744dKxL3zhCzn66KOz0UYbNWm/q6qqUlFRkYaGhtTU1GTfffctnRs9enQ6d+7cqrEDAMxP0hyAlVKnTp2a7IO2+uqr5/zzz8/hhx+eoUOHZuedd87AgQNLy7RfeumlmTp1aluFCwBlr66uLr/85S/zzjvvpFOnTjnwwAPz61//Or17917itdttt126deuWioqK1NbWNvniHgBYfioqKjJ48OD07ds3VVVVOe+88/KDH/wgq6222iKvaeyrb7LJJqVEed++fVslXgCARZE0B2ClU19fnyT5xje+kdVWWy1bb711Lr744nzuc58rJcm322677LjjjikUCikUChk9enRuvPHGtgwbAMpWQ0NDqqqqctJJJyVJunXrli9+8YtJPmrXF6dr164pFoulL+G7dOmSJKV2HwBYfjbYYIN8+9vfznHHHVeaPb649ruxvR41alRpy5XPfOYzzRooBwCwvFS1dQAA0NIqKyvT0NCQNddcM6eddlq6dOmSjTfeOMlHnfNVV101w4YNy3PPPZcXX3wxSXLllVdm9913z+DBg9sqdAAoS41Lt+6zzz755z//mR122CGbb755knnt+pJsvPHG6dSpU6ZPn54k+eCDD5KkyaozAMDyUVNTk912263J8uqLar8bB7m9/fbb+eMf/1jakuXAAw8s1WloaGiyrDsAQGvwtw8AVkqNX5IPHz48O+20U5MOd+Oss8985jPZeeedSx37Dz/8MFdeeWXrBwsAlNrn0047LcOGDUuxWGz2TPE333wztbW1pS/o11lnnSb3BACWrx49eqS6unqRbW+xWEx9fX2pr37HHXfk5ZdfTocOHbLvvvumU6dOueGGG/Loo49mwoQJpesaGhpaJX4AADPNAVgpfXxm2fxLthYKhRSLxXTs2DG77rprnn322Tz44INJkptuuin77LNPttpqq1aPGQDKWWM7/UmWZq2rq0ttbW3pHjU1NU3uCQC0joW1vfX19amsrExlZWU++OCDnHPOOfnb3/5WOv/QQw/lr3/9a6ncr1+/7Lrrrjn22GOzyiqrtErcAABmmgNQFj7ecW8sDxkyJLvuumtWX3310rlLLrkkc+fObdX4AIBPbsyYMZk5c2YaGhpSU1OTtdZaq61DAgD+f40rwfzhD3/ITjvt1CRhniSTJ09uUm/ixIm5/vrrc/LJJ+fVV19t3WABgLJlpjkAZatx9vmOO+6YZ555Jn//+99TKBTy2GOP5dZbb81+++3X1iECAM0wfvz4JPOWcN18882z6qqrtnFEAECjt99+OyeddFIee+yxJsd32mmn7LnnnqmtrU2SPPHEE/nnP/+ZWbNmpVAo5N///nf69u2bo48+Ov3792+L0AGAMiJpDkDZapxtPmDAgOy222558cUX8/rrrydJLr300uy0005ZbbXV2jJEAKAZXnzxxdLnT3/605ZlB4AVSGVlZQYMGJAnnngiFRUV2X777XP00Udn8803b1LvgAMOyO23354//OEPeemll5Ik99xzTzbZZBOD2gGA5c7y7ACUtWKxmCTZeuuts+OOO5aWgxs3blyuv/76tgwNAGiGGTNm5PHHH09V1bwx4UOGDEnyURsPALSt1VdfPXvttVf23HPPnHXWWbnssstKCfOGhoYkKW2R9vnPfz7f/e53S9dOnjw5TzzxRD788MPWDxwAKCuS5gCUtcaZaD169MiwYcOy8cYbl85dddVVGTVqVFuFBgA0w6uvvpopU6akoaEhXbt2zYYbbpgkZpsDwAqgcRDbVlttlfPOOy/77rtvkqS+vj5JUlEx7+vp6urqJElVVVW23377fPGLXyzd4957782cOXNaMWoAoBxJmgPA/2+zzTbLrrvumq5duyZJZs+encsvv3yBesVisdTBBwDaRuOX8KNHj04yb6baBhtskF69ei2yfuNsNgCgdTQOYqusrExVVVWpLW5c5W1hKioqstVWW6W6ujpVVVWZOnVqnnrqqVaJFwAoX5LmAJB5X6R36NAhO++8c7bccsvS8VtvvTX3339/qU5dXV0KhUIqKyvz9ttvZ9q0aaVzAEDrafwS/qGHHiod22CDDdK5c+cF6tbX16dQKKSioiIffPBBZs2a1WpxAgAfaZxZvijFYjGFQiFdunTJ3LlzS33tVVZZpTXCAwDKmKQ5AOSjL97XX3/9DBs2LH369Cmdu/TSS/Phhx+mUCikqqoq9fX1ufbaa7PHHnvk9NNPb6uQAaDszZo1K08++WRpttrQoUOTfLQ/auPKMJWVlWloaMjVV1+dQw89NNdee23bBAwALFZj37x79+6lclVV1RKT7QAAy8rfNgDg/9c4gn377bfPtttum2ReB/3ZZ5/N3XffnSS5++67c9BBB+X888/PnDlzctddd+XRRx+1byoAtLJisZixY8fmww8/TENDQ7p3754NNtigdK5YLJaS6ffcc08OOuig/OIXv8hrr72WESNG5L///W9bhg8AfEzjVirFYjF//vOfkyR1dXX51Kc+lU9/+tNtHB0AsLKrausAAKBRQ0PDQkePNy7Ptrw1PqNPnz7Zdddd88ILL5T2Sb3gggty55135rHHHsucOXNKCfb1119/kXunAkA5aIv2u/Her7zySmbPnp0k6du3b9Zcc80myfL//ve/ufTSS3P//fc3ab8HDx6cHj16LJfYAKA9aOv+98IUCoUUCoU8/vjjeeKJJ0rHt9tuu3Tq1GmRMQMAtARJcwDazPyd8cbO7+TJk/Pqq69mlVVWSXV1ddZaa61W7bA3xrHDDjvklVdeyeuvv566urq89957eeihh1JXV5ckWWONNXLKKadk+PDhrRYbAKwIVoT2u/He//73v0vH1l9//XTp0iVJ8sEHH+SKK67IyJEjM3Xq1FKyXPsNQLlaEdrvJcU1d+7c3HvvvTn33HPzzjvvpLKyMjvvvHO+8Y1vJFnyfugAAMtC0hyANtPYMX7ttdfy7LPP5tFHH81dd92VDh06ZMaMGenVq1d23HHHDB8+PNttt91yj6e+vr40M61jx46ZMWNGqqqqUigUUldXV0qYH3vssfnOd76z3OMBgBXRitB+F4vFzJ49O//5z39Kx3bfffckyYgRI3LttdfmzTffLNVNtN8AlLcVof2eX2PivjGuCRMm5MEHH8zNN9+ct99+O0lSU1OT/fffP507d27TGfAAQHkoFBu/QQCAVvb+++/n3//+d/7xj3/kiSeeyIcfflg6V1FRkYaGhiRJVVVVTj755HzhC19Ijx49lsuSbPN3wB944IFcfvnleeaZZ1IsFlNfX58k2XPPPXPKKaekd+/eLfpsAGhPVpT2+7XXXsvBBx+cqVOnZpVVVsmBBx6Y5557Lk8++WQaGhpKcQwfPjwnn3yy9huAsrYitN8LS3yPGzcuL7zwQh588MHcfffdmTZtWpJkyy23zOmnn57111+/RZ4NALAkkuYAtKrG2dxTp07NiBEj8pe//CUTJkxIkvTs2TMdOnRITU1Npk2blg8//LA0u7tXr175whe+kBNPPHG5xfbaa6/lsssuyz333JNZs2aVZqYNGTIkP/zhD7PFFlsst2cDwIpsRWy/b7311pxwwgkpFAopFovp2bNnpk2bVvrSf8iQITnttNPymc98psWfDQDtwYrYfr/++utJ5iXx77zzzrz++ut59dVXM2nSpCTJ6quvnt133z0HHXRQ1l133RZ/PgDAokiaA9DqZsyYkZ/+9Kf5+9//niTp3Llzdtlll2y99dbZcMMNM3To0EyaNCkvvvhifv/73+eFF14oXXvZZZdl5513bvHZam+//XZOP/30Jnuj9ujRIyeeeGK+/OUvt9hzAKC9WtHa79NPPz1//vOf06FDhxSLxdIX/dpvAPjIitR+v//++/nKV76SWbNmZfLkyU3OderUKVtssUV23333DB8+PF26dFnm5wEALA1JcwBa1ZgxY3LWWWfloYceSpJssMEG2XfffbPrrrtm0KBBCyzV9sILL+Siiy7K/fffnyQZMGBAbrnllnTt2rVF45o9e3b+7//+L2effXaS5Gtf+1q+973vpbq6ukWfAwDt0YrUfjd+cf/b3/42l156aaqqqkoJ86OOOirf//73td8AkBWr/W507bXX5uyzzy6tFJMkw4YNy0477ZSddtrJdioAQJuRNAegVV100UW55JJL0tDQkFVWWSXHHXdc9t5779TU1CT5aI+zurq6VFZWplAoZNy4cdlrr71SX1+f+vr6HHPMMTnuuONaPLZRo0blnnvuyfDhwzNo0KAWvz8AtFcrYvs9evToHHPMMZk4cWKGDRuWk08+OWuuuWaL3R8A2rsVsf2ePn16fvjDH2bGjBlZa621csABB2TQoEHp2LHjAkl8AIDWVNXWAQCwcikWi2loaEhlZeUC52bNmpUPP/wwDQ0N6du3b84444xsv/32Teo0dtirquY1UWPGjMm5556buXPnlo5dddVV2XPPPbPhhhu2aOzrr79+1l9//Ra9JwC0B+2x/R40aFB+8IMfpHv37tlxxx1b5J4A0J60x/a7a9euOfPMM1NbW5vVVlutRe4JANASWm4zWADKXl1dXQqFQiorK0vLpM6vc+fO2XfffTNkyJAMHz681GFvXPSkvr4+SVJVVZU5c+bknHPOyfDhw/Pvf/87hUIh9fX1qayszNy5c3PZZZfFYikAsOzaa/tdXV2dvffeW8IcgLLUXtvvJOnevbuEOQCwwpE0B6DFNI5EHzFiRIYPH5633nprgTqDBw/OKaecku9+97sLnGscHX/TTTdl++23zzXXXJNk3uj3Xr16ZdiwYaWO/Z133pl//etfy+lNAKB8aL8BoP3RfgMAtCx7mgPQYl555ZWcdNJJeeWVV7LhhhvmxhtvTKdOnRZZv6GhIRUVH43fGjVqVH75y1/m/vvvLx2rqanJ7rvvnm9+85sZNGhQDj300DzxxBNJkk9/+tO55ppr0qVLl+X3UgCwktN+A0D7o/0GAGhZZpoD0GIeeeSRvPLKK0nmLQW3uA57klRUVJRGrj/zzDM566yz8vDDD5fODx06NBdddFHOOeecDBo0KPX19fnCF76QZN7o9xdffDEjR45cTm8DAOVB+w0A7Y/2GwCgZUmaA5S5llhwpPEe06dPLx0bOHBgkix0b7X5VVZWZvbs2bn66qvz2GOPpba2NhUVFfnBD36Q//u//8u2226bJKX91NZaa62sueaapRHyv//97zNx4sRlfgcAaE+03wDQ/mi/AQBWXJLmAGXq8ccfb7F7FQqFJMmUKVNKxzp06JDko33WFufiiy/OXXfdlSRZZ511cskll+Too49OktJI+Mb91tZbb71MnTo19fX16dChQyZPnpyrr766pV4FAFZo2m8AaH+03wAAKz5Jc4Ay89xzz+WrX/1qDjvssDz44IMpFAqLHY1eLBbT0NDQrHuPHTu21IFfe+21k2SJ177//vu5/fbbS9d9/vOfz7bbbptisZhisVjqrCdJbW1tampq0q9fv1JsSXLdddfl+eefb1aMANAeab8BoP3RfgMAtB+S5gBlZMqUKTnnnHPy7LPPJkl+/etfJ1n0aPS6uroUCoVUVFRk7ty5pQ74xzv5jaPRGxoaUiwWU1FRkY4dOyZJaRm3RZk0aVLefffdVFZWpn///jn88MNTXV2dQqFQ6sg36tChQyZNmpRJkyalc+fO6dq1a5J5nfcLL7xwiUvRAUB7pP0GgPZH+w0A0L5ImgOUke7du+drX/taqbP70ksvZcSIEYus39iZv+iiizJ8+PCcc845eeutt5p08htHo0+fPj3jx49PMq/z3qdPn2bFNGvWrMydOzd1dXWZPn16pk2bVrrv/M9o9NBDD+WDDz7Ipz71qZx44oml4w888EDGjBnTrGcCQHui/QaA9kf7DQDQvkiaA5SRioqKbLnlltl+++2TJMOGDctuu+22yPpPPvlkdtlll1x00UUZP358rrvuuhxwwAE5/vjjS3uyNY5Gnz17dml0enV1dWkJtyXp1q1bBg8enGTeSPb579s4sr7xGf/9739L+6etscYa2WeffbLFFltkxx13zL333pv1119/6X4gANAOaL8BoP3RfgMAtC8LXw8IgJVWz549881vfjOHH354NttssyTzRqYvbBm3uXPnZocddshjjz2WN954I8m8PdBuu+223HXXXdl9990zbNiwDB8+PNXV1Rk3blwqKipSW1vb7Hh69OiR/v37Z+zYsZk8eXIeeOCBDB06NOuvv34pptmzZ+eFF17IiBEjMm7cuHTs2DF77bVXqqurc+mll6Zbt24t8JMBgBWX9hsA2h/tNwBA+1Eozr/mDgBlpaGhIbW1taX9z5KPlmKbfz+z6dOn59prr83999+f5557Lsm8UfPFYjHFYjGf/exns/766+fWW2/NlClT0q9fv9x0001ZddVVmxXH1VdfncsuuyxTpkxJdXV1Ntxww3zzm9/MkCFD8t///jdjxozJ3XffnaeffjpJss022+TXv/51evbs2UI/CQBoP7TfAND+aL8BAFZskuYAJEnuvvvuhS4VV19fn8rKyiTzOu933HFHRowYkTFjxmTu3LkL1K+oqEjfvn1zzTXXZMCAAU2u/7jGEfZTpkzJaaedlgceeKB0z5qamhQKhVRUVGTWrFmpq6tLknz+85/PT37yk6y22mot9eoA0G5pvwGg/dF+AwCseCTNAcrcv//975xzzjl5/fXXc9FFF2W33XZLXV1dqqqa7uAxf+d76tSpeeGFF3LVVVfliSeeKHW0q6qqUldXl169euUrX/lKDjzwwKyxxhqlexSLxSYj6JOPOu7PPPNMrr/++tx2222l+1RUVJT2VRs4cGA+//nP59BDD02fPn2W548EAFZ42m8AaH+03wAAKy5Jc4AyNmXKlBx77LF56qmnkiSDBw/OnXfemWThHexGjeeKxWIefvjh3HvvvRkxYkRpZHp9fX2SZI011sh2222XAw88sLR/W7L4Pdx+/etf58EHH8y4ceMyd+7crL766tlll12y8847Z7vttkt1dXVL/xgAoF3RfgNA+6P9BgBYsUmaA5SxYrGYf//73/nBD36QGTNmJElOOumkHHXUUYtd1m1hjjzyyDzyyCOlznySVFZWpr6+Pp07d87ee++d3XbbLTvttNNCr5+/Iz9jxoxMnz4948aNy5AhQ9KhQ4d06NBhGd8WAFYO2m8AaH+03wAAKzZJc4AyN23atPzyl7/Mn/70pyRJdXV1HnjggfTo0WORI9I/bsaMGdlvv/3y5ptvplgsZrvttsvMmTPzzDPPLFB3u+22y0EHHZTNN988q666aqmDv6hR9QDAgrTfAND+aL8BAFZcS/6bGAArte7du2f//fdP3759k8xbou0Xv/hFs68vFouprKxMZWVlisVievbsmSOOOCK/+93vcsopp2TQoEGlEfOFQiEPPfRQfvCDH+SII47IHXfckRkzZpQ67MZxAUDzaL8BoP3RfgMArLjMNAdYySztsm5JMnv27FxzzTX59a9/XTo2cuTIDBkyJHV1damqqlrs9a+//nr222+/zJkzJw0NDbn11luz7rrrJknef//9PP3007nqqqvy/PPPp7a2trRsXJL06NEjJ5xwQg444IClfFMAWHlovwGg/dF+AwCsPMw0B1hBNXdM08frNY44HzVqVN57771MmzZtifft1KlT9thjjwwdOrR07KyzzkqSJXbYi8ViGhoaUllZmUKhkDXWWCOrrrpqqVPes2fP7Lbbbrnyyivzi1/8InvssUfpXKFQyKGHHqrDDsBKQ/sNAO2P9hsAgMX/TQyAVtfQ0JAkTfYyW9zeZo1Lq02aNCn/+c9/8vTTT+fWW29NsVjMtGnTMmjQoOywww4ZPnx4Ntpoo0XuXda/f/8cfPDBef7555MkTz31VG6//fYMHz58saPdC4VCpk6dmunTp5fuPf9o+8a4O3funD322CN77LFHHnnkkbz00kvZd99906tXr6X9EQHACkf7DQDtj/YbAIBGlmcHWEHMP2I8SZ555pk888wzOeqooxbbaZ8xY0Yee+yx3H333Xn00UczceLEhdbr1q1bzjjjjOyyyy7p2LFjisXiAh34yZMn5+c//3n+8Y9/JEl69+6d+++/vxTfojr8N998c04//fTU1dVls802yw033LDQmBf3HgDQHmm/AaD90X4DAPBx/uYEsAKoq6tLoVBIZWVlPvjgg/zwhz/MQQcdlPPPPz+jRo1KRUVFaQR8ktLyanPmzMnf/va3XHjhhRk5cmQmTpyYjh07pkuXLunRo0dqampK13z44Yc555xzcuONN5Y64B8fN7Xaaqvlq1/9arp27Zokefvtt3PRRRclSZPnN2o8VldXl7q6ulKHvL6+fqEdfB12AFYm2m8AaH+03wAALIy/PQG0ocbOd+PSa1deeWV22GGHjBw5snTs97//fZKmHd7G0fAXX3xxzjrrrLz88stJkq233jrHHntsLrjggtx111255pprcu6552b11VdPZWVl3n777fzxj3/M3/72tyQL7q9WKBQydOjQ7LfffqVjF198cd55551UVlaW4m3UGNMbb7yRZF4nvm/fvqX91QBgZaT9BoD2R/sNAMDi2NMcoA00jhBv7Hzfc889OeecczJ+/Pgk8zrPXbp0yT777JOvf/3rC1w/adKk/OIXv8htt92WJBkwYED23nvvfO5zn8t6662X6urqJEnPnj2z8cYbZ5VVVsnVV1+dRx55JOPHj88f/vCHbLvttunVq9cCS7Z17do1X/rSl3L//ffnjTfeSLFYzHnnnZdf/vKXC4xUb9w7bf7OfL9+/ZIsfjk5AGiPtN8A0P5ovwEAaA4zzQFaUbFYLC2jVlFRkVdffTVHHXVUjj322IwfPz4VFRWprq7OTjvtlCuuuCI/+tGP0qdPnwWWZrvnnnvyr3/9K8m8vdIOPPDAHHroofnUpz5V6rAXi8XU19enWCxmp512yje/+c2sscYaqa+vz6hRo3LZZZclWfiSbeuss04OOuigJPO+QLjtttvy1FNPpVAopK6urlSv8UuH0aNHlzroHTp0KF0HACsD7TcAtD/abwAAloakOUAradw3raqqKjNnzsyZZ56ZvffeOw8//HAKhUIqKiqywQYb5Nxzz81ll12WoUOHJskCI9GnT5+e559/PjNmzEhVVVVOOumkHH300VlttdWaPK9xFHqhUEhtbW3+9re/5Z133kmhUEihUMjIkSPz3HPPlerOr7q6Orvttlu22GKL0hJyZ511VpKPlrJL5n0x0NDQkIaGhhSLxXTt2jVbbLFFy//wAKCNaL8BoP3RfgMAsLQkzQFaSWNnd8SIEdl+++1z/fXXJ5k3InyNNdbI9773vdx4440ZPnx4ko860h8fid61a9fsscceGTJkSA455JAccMABST5acu7j+7SNGDEiW221Vf7yl7+U7lEsFjNr1qxcdNFFST4asT6/vn375uCDDy6NWP/Pf/5TukfjaPdCoZCpU6dm7NixOfDAA/PAAw9ku+22W6afEwCsSLTfAND+aL8BAFhahWLjEEYAlqtnnnkmxx9/fCZOnJhkXme8pqYme+65Z44++ugMHDgwyUcj1BemcZ+yWbNm5dZbb83OO++cXr16lc7PPyr+kUceydlnn53Ro0cnmdfBrqmpyXrrrZcXXngh9fX1qaioyPnnn5+99957oc99//33c8455+Tvf/97kqRHjx558MEH06FDh9Kzamtr8+GHH2bVVVdt2R8YAKwAtN8A0P5ovwEAWFpmmgO0gtmzZ+f+++/PxIkTU1FRkQ4dOqRPnz751a9+lTPOOCMDBw4sLbO2qA57Mq/jXSwW07lz5xxwwAHp1atX5h/7VFFRkcmTJ+fHP/5xjjzyyNJeZx06dMg222yTK664Ir/61a+y/fbbJ5nXyf/973+fOXPmpLKycoG921ZdddUceOCB6dmzZ5Jk6tSp+cUvfpEkped26NBBhx2AlZL2GwDaH+03AACfkU8tcAAAJhBJREFUhKQ5QCvo1KlTdt9992y33XZpaGhIbW1tZsyYkdVXXz3FYjHFYjEVFRULLAXXqHE5tiSl5drmLzd2tv/73//mJz/5SW6++ebS+X79+uUnP/lJ/t//+3/ZfPPNs/rqq2fTTTdN586dkySjR4/OH/7wh0XGPmTIkHzlK18pla+//vp8+OGHi/1yAQBWBtpvAGh/tN8AAHwSkuYArWSdddbJHnvsUeosT506NVdccUXef//9BTrijerr61MsFkv7o9155515/fXXS+caNXb2//SnP+XBBx9MbW1tkuTAAw/MLbfcki9/+ctJktra2lRXV2eTTTZJZWVlqeM9YsSIjBs3LhUVFU3umyRdunTJnnvumX79+mXffffNww8/nG7durXUjwUAVmjabwBof7TfAAAsLUlzgFZSXV2drbfeOsOGDSsdu+OOO/Loo48u0FEuFoulPc4KhUKefvrp7L///vn+97+fiy++OElKHe7GZdouv/zy3HDDDZkzZ0769OmTs88+Oz//+c/TrVu3Uue/Q4cOSZKtt946PXv2LD3jvffeyyWXXNLkvvNbd911c9NNN+W8884rLRUHAOVA+w0A7Y/2GwCApSVpDtCKBg4cmD333DN9+/YtHRsxYkQmTpxYKtfV1aVQKKSysjLvvvtujj/++Bx88MF56aWXUigU8sgjj+T5558v1S8UCpk5c2buvffe0rGdd945n/vc55KktE9b42j6+vr6TJs2LV26dCmdLxQKuf322/PYY4+V6syvqqrKvmkAlC3tNwC0P9pvAACWhqQ5QCtpHJG+2WabZY899igdf/rpp/OPf/wjM2bMSJLSUnAXX3xxdtxxx9x2220pFAqpqKjIwIEDc+yxx2bo0KFN7v3qq6/mP//5T6qqqtKjR49873vfKy3h9vF92iorK9O5c+fSsnR9+/ZNsVhMXV3dAqPoAaDcab8BoP3RfgMAsLQkzQFaSeNI81VXXTXDhg3LkCFDSuduuOGGvP/++0nmLRm300475cILL0yxWEyhUEiPHj1y+OGH58Ybb8zBBx+8wL2rq6szd+7c1NXVpUOHDnnnnXeSfPRFQaPG8j333JN33303q622Wg477LB07tw59fX1efzxx/Poo48ul/cHgPZI+w0A7Y/2GwCApVXV1gEAlKONNtooe+21V15++eUUi8WMHz8+v/nNbzJhwoQ8++yzSeZ18jt27Jgdd9wx//u//5uNNtooybyl2yoqKkpfAiTJjBkz0q9fv0ycODH19fWZPHly1l9//RQKhTQ0NJRGuxcKhUycODHXX399kmSbbbbJNttsk/vuuy+TJ0/OGWeckc0337x1fxgA0E5ovwGg/dF+AwDQHJLmAG2gS5cu2WGHHfLoo4/mgQceSJLcdtttSVLqkA8ZMiTHHHNMdttttyTzRqkXi8WFLt32qU99KjU1NUmSDz74ILfeemsGDx6c/v37lzrs9fX1GT16dK677ro899xzSZIdd9wxG2ywQc4666wMGDBgub83ALRn2m8AaH+03wAANIekOUAbWXvttbPXXnvl2WefzYcffpjKyso0NDSkV69eOfLII/M///M/pf3V6uvrU1lZ2WR0e6P6+vp06tQphxxySH72s58lSf7+97+ntrY2Bx98cDbaaKO8+uqrGT16dO65557cf//9qa+vz5AhQ7LddtsliQ47ADST9hsA2h/tNwAAS1IofnzDHQBazcSJE3PRRRdl5MiRqaioSENDQ0455ZQcccQRSZK6urpSx31RGvddS5IDDjggL7zwQulc9+7dU1NTk4qKikyfPj3Tpk1Lkmy22WY588wzs8466yyfFwOAlZj2GwDaH+03AACLU9HWAQCUs379+mX33XfPwIED09DQkCS544478tprr6VYLC6xw57M2yetrq4uSXL66adnk002KR2fMWNGJk2alIkTJ2batGlZZZVVcsABB+SnP/2pDjsAfELabwBof7TfAAAsjpnmAG2kcYT6Bx98kKuvvjq///3vS+e+973v5cgjj0ynTp2W+r5vvPFGrr322vzzn//MO++8kyTp1KlTdthhh2y//fYZPnx4unXr1mLvAQDlRPsNAO2P9hsAgCWRNAdYATz77LM555xz8txzzyVJevfunQsvvDBDhw79RPcrFot56623Mnny5EycODGf+tSnssoqq6Rr164tGTYAlDXtNwC0P9pvAAAWZsnrDgGw3G244YbZe++989JLL6Wuri5vv/12brrppgwePDjdu3df6vsVCoX069cv/fr1+8QdfwBg8bTfAND+aL8BAFgYe5oDrAA6deqUbbfdNjvttFPp2C233JInn3wyFgQBgBWT9hsA2h/tNwAACyNpDrCCWGuttbLXXntllVVWSZLMnTs3N9xwQ2lfNABgxaP9BoD2R/sNAMDHSZoDrCAqKirymc98Jp///OdLxx544IHcd999qa2tbcPIAIBF0X4DQPuj/QYA4OMkzQFWIL17987uu++etdZaq3Tsj3/8Y9588802jAoAWBztNwC0P9pvAADmJ2kOsIJo3Dvt05/+dPbaa6/S8VGjRuXWW2/NrFmz2io0AGARtN8A0P5ovwEA+DhJc4AVRKFQSJJ07949O++8c7bccsvSuT/96U959tln2ygyAGBRtN8A0P5ovwEA+DhJc4AV0Prrr5999tknNTU1SZL3338/Y8aMKY2GBwBWPNpvAGh/tN8AACRJVVsHAMCCqqurs+WWW2bTTTfNW2+9lZ///OdNRr4DACse7TcAtD/abwAAkqRQNGwSYIU1YcKE9O/fv63DAACWgvYbANof7TcAQHmTNAcAAAAAAACgbNnTHAAAAAAAAICyJWkOAAAAAAAAQNmSNAcAAAAAAACgbEmaAwAAAAAAAFC2JM0BAAAAAAAAKFuS5gAAAAAAAACULUlzAAAAAAAAAMqWpDkAAAAAAAAAZUvSHAAAAAAAAICyJWkOAAAAAAAAQNmSNAcAAAAAAACgbEmaAwAAAAAAAFC2JM0BAAAAAAAAKFuS5gAAAAAAAACULUlzAAAAAAAAAMqWpDkAAAAAAAAAZUvSHAAAAAAAAICyJWkOAACwGCNHjswGG2xQ+uexxx5r65CAZhg/fnyT390LL7ywReoCAACw8qlq6wAAAIDyMn78+AwbNmyZ7vGlL30p5557bgtFxNJ47LHHcthhhy3XZ5xzzjnZb7/9SuVdd901EyZMWOw11dXV6d69e1ZbbbUMGTIkW2yxRfbcc8906dJlqZ798ff77Gc/m+uuu27pXgAAAABoV8w0BwAAoN2bO3duJk+enFdeeSU333xzTjvttOywww65/PLLU19f39bhsZKZf1b6Kaec0tbhAAAAsIwkzQEAAFgpzZgxI7/85S9z7LHHSpwDAAAAi2R5dgAAoE317t07f/zjH5fqmpqamuUUDUuy6aab5p577mlW3YMPPjhvv/12qTxixIj06dNnidetssoqiz2/sPvMnTs37777bp566qn86U9/yqRJk0rn7rvvvvz617/OCSec0Ky4AQAAgPIiaQ4AALSpqqqqDBgwoK3DWKT99tuvyf7a5a5jx47N/vOqqmra5ezTp0+L/Fkv6j5rr712ttpqqxx++OH5wQ9+kH/961+lc9dee20OPfTQ9O7de5mfz8pnwIABeeWVV9o6DAAAANqI5dkBAABYqXTp0iW/+tWvsvrqq5eOzZkzJ//4xz/aMCoAAABgRSVpDgAAwEqnS5cu2XfffZsce+KJJ9ooGgAAAGBFZnl2AABgpVEsFjNmzJiMGTMmkyZNyowZM1JdXZ0ePXpk8ODB2XjjjVNdXd3WYbaYt99+O6NHj864cePy4YcfJkl69OiRvn37ZrPNNku3bt3aOMK2tfHGGzcpv/XWW20UyfLx9ttv5/nnn8+kSZMyZ86crLHGGtlkk00yaNCgFn3O888/nzfffDPvvPNO6urqst5662WXXXZZ7DVz587Ns88+mwkTJuS9995LRUVFVl111Wy44YbZcMMNlzmmsWPH5vnnn88777yTjh07pk+fPhk6dGi7XH5/5syZGT16dF5//fV88MEHmT17drp165ZVV101n/70p7Pmmmu2dYgAAAArPUlzAACgXZs9e3buvffe3HXXXXn00UczZcqURdbt1KlThg8fnmOOOSaDBw9u1v1HjhyZU089tVS+9tprs9VWWzWp09DQkCOOOCKPPfZY6dhxxx2Xb37zm816xvHHH59bb721VD744IPzk5/8ZIF6DQ0NefLJJ3PbbbfloYceyrhx4xZ5z4qKimy99dY55phjsvXWWzcrjpVNjx49mpSnTZvWRpF8MhdeeGEuuuiiUvmee+7JgAED8uKLL+Z3v/tdHnzwwdTX1y9w3SabbJJTTjklm2++ebOes8EGG5Q+f+lLX8q5556bhoaGXHXVVfnjH/+Y8ePHN6m/4YYbLjJpPmbMmFx88cW59957M3PmzIXW6d27d4488sgccsghSz2I5amnnsq5556b559/foFzlZWV2X777fPd7343n/70p5fqvuPHj8+wYcNK5W9/+9v5zne+06TOKaeckptvvnmBa2+++eaFHm+0sL3SJ0yYkNtuuy333XdfXnjhhdTW1i7y+v79++ewww7LV7/61XTq1Kk5rwMAAMBSsjw7AADQrv34xz/OcccdlzvvvHOxCfNkXoJ95MiR2XfffZskqZdVRUVFLrjggqy66qqlYxdeeGGeeuqpJV775z//uUksG264YZMk/fxGjhyZQw89NDfeeONiE+bJvAT7ww8/nMMPPzznnnvuQpOrK7vp06c3Ka8Mqwz87W9/y1e/+tXcf//9i/wzfe6553LIIYfk97///Sd6xtSpU3P44Yfn/PPPXyBhvijFYjG//e1vs88+++TWW29dZMI8mTdD/txzz81+++23VLP/L7vsshxyyCELTZgnSX19fe6///589atfzd/+9rdm37e11dfXZ9iwYfnlL3+Zp59+erEJ82Regv2cc87JV77ylUyYMKGVogQAACgvZpoDAADtWkNDQ5Nyz549s+6662aVVVZJp06dMmPGjLz++usZO3ZsisViknnJ8xNOOCHdunXLTjvt1CJxrLHGGjn//PPzjW98I8ViMXV1dTn++ONzyy23pGfPngu9ZvTo0TnzzDNL5ZqamvzmN79ZZHK3Mf5GnTp1yrrrrptevXqla9eumTNnTiZOnJhXXnmlSSLuqquuSlVVVU444YRlf9F25OWXX25S7t+/fxtF0jKeeOKJ/OhHP0pdXV2SeTO2N9poo9TU1GTixIl5/vnnS78PDQ0N+dWvfpWOHTvmiCOOaPYzisViTjzxxDz++ONJkqqqqmy88cbp06dP5syZkzfeeGOh15x88sn561//2uR4p06dMmTIkKyxxhpJkjfffDMvv/xy6b/j0aNH56tf/Wpuuumm9OrVa7FxXX311fn1r3/d5FhlZWWGDh2avn37ZsaMGfnPf/6Td999N7W1tTn11FNz1llnNfu9W1OxWGzyu1woFDJgwIAMGjQo3bt3T6FQyAcffJCXX345H3zwQanef//73xx11FEZOXJkunTp0hahAwAArLQkzQEAgHZv/fXXz3777Zdddtllkcuujxs3Lr///e/z5z//Ocm8xNUpp5ySe+65JzU1NS0Sxw477JCvf/3rueKKK5LM20P7lFNOyWWXXbZA3dmzZ+e4447L7NmzS8d+8pOfZK211lrsM1ZfffXst99+2XXXXTN06NBUVlYuUGfatGm58cYbc8kll2TWrFlJkiuvvDKf+9znsskmmyzLK7YbtbW1CyRxt9xyyzaKpmWcffbZqaury2qrrZaf/OQn+dznPpeKio8WkHv77bdz5pln5h//+Efp2AUXXJBtt90266+/frOe8Y9//CMzZ85MoVDI4Ycfnv/93/9dYNDHx2efX3HFFU1+1j169Mhxxx2X/fbbLx07dmxSd9y4cTn77LNz7733JkkmTZqUU045JVdeeWUKhcJCY3rllVdywQUXNDm2995755RTTmmSbG9oaMidd96ZM844I++//37OPvvsZr1zc5100kn59re/nSRNlnLffffdc9JJJy3VvaqqqjJs2LDsscce2WGHHdKtW7cF6jQ0NOShhx7K+eefn1GjRiWZt5f7BRdcsNDtGwAAAPjkJM0BAIA2NWHChCZ7Ki/JOeeck/32269U/sEPfpB+/fot8bqBAwfmzDPPzDrrrJNzzz03SfL+++/nlltuycEHH7z0gS/C97///Tz55JN55plnkiT33Xdfrr766gVm+5555pkZPXp0qfylL30pX/ziFxd775133jn77rvvEpcZ7969e44++uhsueWWOeywwzJ37twUi8VcddVV+c1vfvNJXqtdqa+vz09/+tMmS1l36tQp++yzTxtGteymTZuWnj175rrrrss666yzwPnevXvnwgsvzKmnnpqRI0cmmTd44Iwzzsh1113XrGc0Lqv+05/+NF/96lcXWmfAgAGlz6NHj85vf/vbUrlPnz4ZMWJEkzrzGzhwYC655JL88Ic/LMX44IMP5v7778/OO++80GvOPPPMJisnHHLIIfnxj3+8QL2KiooMHz486623Xg455JBMnTp18S+7lFZdddUmWzA0qqmpWeT7LkxlZWX++c9/LvH/WxUVFdlhhx3ymc98JkceeWSeffbZJPO2afje9763yBUsAAAAWHr2NAcAANq15iTM53fkkUfmU5/6VKl8xx13tGg8VVVV+dWvfpUePXqUjl1wwQV54YUXSuXbbrutNOM9SdZaa62FJgE/rlevXku1L/dmm22WQw45pFS+++67M3fu3GZf357MnTs3EyZMyF//+tcceOCBuemmm5qc/853vlNaJrw9O/nkkxeaMJ/fj3/84ya/F48//nheffXVZj9jl112WWTC/OOuvPLK0nLxhUIhv/3tb5eYQC4UCvnpT3+aPn36lI5de+21C607evTo0lLxSTJ48OCccsopi73/euutlxNPPLFZ8beFQqGwVP/fqqmpyc9+9rNSefbs2aWZ+gAAALQMSXMAAKDs7LrrrqXPL774Yurr61v0/v369WuyNHRtbW2OO+64TJ8+PW+88UZOP/300rmOHTvmN7/5TYstEf9x8y8jXVtbu8A+3+3RsGHDssEGGzT5Z+ONN86uu+6ak046KS+++GKT+t/4xjfy9a9/vY2ibTn9+vXLl770pSXW69y5c4488sgmx/7+9783+zlHHXVUs+pNmzYtt912W6m88847Z9NNN23WtR07dsyBBx5YKj/22GOlrQTm9/G4v/71rzdr4Mj++++f3r17NyuW9mDDDTdsMhjhueeea8NoAAAAVj6WZwcAANpU796988c//rHZ9VdZZZVm1auvr8/06dMzc+bMBZLi8yfdZs6cmUmTJqV///7NjqE5dttttxx22GGlGbTjxo3LD3/4w4wfPz4zZswo1TvllFOy4YYbLtOzisViZsyYkRkzZjRZxrrx3PzGjBlTFvuaFwqF7LTTTvnGN76RLbbYoq3DaRG77777Ivf9/rjhw4fnrLPOKpUbtwtYkm7dujV77/enn366yX9vu+++e7OuazT/n0tdXV2ee+65bL311k3qzB93RUVFs59RUVGRPfbYI9dcc81SxdTW5syZk+nTp2f27NkL/O727NmztJ/8mDFj2iI8AACAlZakOQAA0KaqqqqWaj/gRZkxY0b++c9/5p577sl///vfjBs3boGk06JMmzatxZPmSXLiiSfm6aefLs18vuuuu5qc33333T/Rfur19fV5+OGHc+edd+aFF17ImDFjFkiWL0pL7/O8oioWi5k5c+ZKNdt44403bnbd1VdfPX379s1bb72VJHnppZeadd2GG27Y7MT8008/3aQ8f1K3ORoaGpqU59+DvtF//vOf0udBgwale/fuzb7/0vy82srYsWNz66235rHHHsuoUaMyZcqUZl03bdq05RsYAABAmZE0BwAA2r2RI0fm/PPPzwcffPCJrp8+fXoLRzRPdXV1fvOb3+SLX/ziAs/o379/zjzzzKW+5zPPPJMf//jHGTVq1CeKaXm9a2saMWJEk/2w6+rq8tZbb2X06NG5/vrr88YbbySZt5f3QQcdlBtuuCEDBw5sq3BbzNK+w5prrllKmk+fPj1z585d4tLmq666arPvP2nSpCblb37zm0sV38d9fEBH46zrRmuuueZS3W/QoEHLFM/yNG3atJx33nn5y1/+0uzBPfNbGX6PAQAAViT2NAcAANq13/3udzn11FM/ccI8WXDGa0saOHDgQmeTn3XWWUs1azZJ/v3vf+ewww77xAnzZMHl2tujPn36ZMCAAaV/Bg8enG222SaHHXZY7rzzzib7eb/77rs59thjM3fu3DaMuGV07dp1qep369atSbk5s5Nramqaff+WXrVg5syZTcofj3dp339p67eWqVOn5vDDD89NN930iX8fV4bfYwAAgBWJmeYAAEC79fjjj+fiiy9ucmzTTTfNnnvumU9/+tPp06dPVllllVRXV6dDhw6lOiNHjsypp57aKjGOHTs2119//QLHb7nllmyzzTbNvs+UKVNy4oknNkn+9u/fP/vuu28222yzDBw4MKuvvno6duzYZDbx+PHjM2zYsGV7iXakoqIiJ598csaOHZv77rsvSfLKK6/k0ksvzfe+9702jm7lUldX16L3K5dE8Lnnnttk2fmOHTtmzz33zLbbbpv1118/a6yxRmpqatKxY8dUVHw01+HQQw/N448/3hYhAwAArPQkzQEAgHbrkksuaVL+0Y9+lEMPPXSJ182YMWN5hdTE3Llzc9xxxy0wgzb5KGn+xS9+sVn3+uMf/9hkv+O99tor55577hKX226td12RFAqF/OxnP8tjjz1W+tn/4Q9/yJe//OXlsnd9a1naJbk//PDDJuWlXdlgSXr06NGkfPvtt2edddZpsft/PN6lff8VcQnzt956KzfffHOpvMYaa+Saa67J2muvvcRry/F3GQAAoLVYnh0AAGiXZsyYkSeffLJU3nbbbZuVME+SyZMnL6+wmjj//PObzCjdZptt0qlTp1L5Zz/7WV5//fVm3ev+++8vfe7WrVvOPPPMJSbMk9Z71xVN79698z//8z+l8pw5cxYYZNHejBs3bqnqv/nmm6XPXbt2bdZ/L0vj4/ufL8sWCQvTsWPHJkusz/8+zdG4t/2K5P77728yo/7EE09sVsI8mbfVAAAAAMuHpDkAANAuTZw4MbW1taXy9ttv3+xrn3322eUQUVN33313rrvuulJ54MCBueiii3LaaaeVjs2cOTPHHXdcs/bbnj8B+JnPfKbZe0+3xruuqI466qgmP6dbbrkl48ePb8OIls0LL7zQ7Lrvvvtu3nrrrVL5U5/6VIvHs+mmmzYpP/fccy3+jCFDhpQ+v/HGG83al73R0vy8WsvHE/nN/f/WW2+9lXfeeWd5hAQAAEAkzQEAgHbq40tPzz8jdXEmTZrUZIb68jBx4sT88Ic/LJU7dOiQX/3qV+natWsOPPDA7LnnnqVzL7/8cs4777wl3nP+paab+67FYjG33nrrUkS+cllllVVywAEHlMp1dXW5/PLL2zCiZXPXXXc1e9/vO+64o0l5s802a/F4tt566xQKhUU+syXMH3dDQ0PuuuuuZl3X0NCQO++8s8XjaTT/rP35B+8syceXjG/u7/Lf//73Zj8DAACApSdpDgAAtEsf3+947Nixzbrut7/9berq6pZDRPPU1dXlBz/4QaZOnVo6dvzxx2fo0KGl8hlnnJEBAwaUytdff33uvvvuxd63W7dupc/NXdL9r3/9a8aMGdPc0FdKX/va19KhQ4dSeeTIkXn77bfbMKJPbuLEiU32w16U2bNn56qrrmpybJ999mnxeFZfffXstttupfILL7zQ4onzj8d95ZVXNmtlhr/85S/L9c95/t/HpVk2ff7rkub9f+v999/P1Vdf3exnAAAAsPQkzQEAgHZpzTXXTOfOnUvlW265ZYl7Kt9www0ZOXLkco3rd7/7XZ555plSeeedd84RRxzRpE63bt3y61//ukky94c//GGT5bQ/bv311y99fumll/L4448vNo7nn38+Z5xxxlJGv/Lp3bt3vvjFL5bKtbW1ueKKK9ouoGV03nnnLXEgxM9+9rNMnDixVP7sZz+bddddd7nEc+yxx6ai4qOvFn74wx8u8b/Nj3vnnXdy//33L/Tceuutl89+9rOl8tixY3Puuecu9n6vvvpqfvGLXyxVDEtrrbXWKn1+4YUXMmPGjGZdN//vcZIFBjd83KxZs3LcccflvffeW/ogAQAAaDZJcwAAoF2qrq7OzjvvXCq///77OeqoozJq1KgF6k6ePDk/+clP8tOf/jTJvGW7l4eHHnqoyfLfvXv3zjnnnNNkCetGQ4cOzXHHHVcqT506Nccff3zq6+sXeu/dd9+9Sfk73/lO7rnnngXqzZ49O1dffXUOP/zwTJ8+fbm9a3vy9a9/vUli989//nMmT57crGvnzJmT8ePHL/U/kyZNavH36N69e6ZMmZJDDz00d911VxoaGpqcf/vtt/Pd7363ycCQDh065PTTT2/xWBpttNFG+f73v18qz5w5M0cccUTOPPPMvPnmm4u8btq0abn99tvz/e9/P7vuumtuueWWRdb90Y9+1GSAyYgRI3L88ccvMMO7oaEhd9xxRw499NBMnTp1gdUoWtIWW2xR+jxz5swcc8wx+ec//5nXXnttgf8W5rfjjjs2GewzcuTInHPOOQss254kTz75ZA466KA8+uijKRQK6dmz53J7HwAAgHJX1dYBAAAAfFLf/va3c++992bOnDlJkv/85z/ZZ599stFGG2WttdZKQ0NDJk6cmBdffLGUYBw0aFAOOeSQnH322S0ay+TJk3PSSSeV9pyurKzML3/5y6y66qqLvOaoo47Ko48+mn//+99Jkqeeeiq/+93vmiTTG335y1/ONddcU1rOecqUKfnWt76V/v37Z8iQIenYsWPefffdPP/885k1a1aSpFOnTvnpT3+a733vey36ru3N4MGDs8cee+T2229PMm9gwR/+8IecfPLJS7z2ueeey7Bhw5b6mf3798+999671NctzimnnJLTTz89kydPzne/+9307t07Q4YMSU1NTSZOnJjnnntugUT6CSecsMDs5pZ2zDHHZMKECfnTn/6UJKmvr891112X6667LgMGDMjaa6+d7t27p66uLh9++GHGjh2bCRMmNPv+G2ywQU444YScc845pWO33npr7rjjjmyyySbp27dvZs6cmRdffLGUSK+qqsqpp56aU089tWVf9v93wAEH5Kqrrir9v+eJJ57IE088sdC6r7zySunzqquumiOPPDKXXHJJ6djVV1+d//u//8umm26a1VZbLdOnT88rr7zSZLWAI488Mi+++OJSz+IHAACgeSTNAQCAdmvdddfNeeedlxNPPDG1tbWl4y+//HJefvnlBeoPHjw4V1555SKTW59UQ0NDTjzxxCazl7/1rW9lyy23XOx1hUIh5513Xr7whS+Ukn2XX355tt5662yzzTZN6lZXV+eSSy7J4Ycf3mSG7YQJExaagKypqclvf/vbrL322svyaiuNY445ppQ0T5Ibb7wx3/jGNxY7qGFFs9VWW+Wss87Kaaedlvr6+rz99tuL3Le7UCjkuOOOW2BrgOXl5z//eTbYYIOcf/75mT17dun4wmZbL8ySZoUfccQRmTVrVn7729+WBqbU19fn6aefXqBuVVVVzjrrrCazwVvagAEDcu655+bUU09t8r7N8e1vfzuvvfZa7rrrrtKxmTNn5uGHH15o/a985Ss58cQTc/jhhy9TzAAAACya5dkBAIB2bc8998wf//jHxSbI1lhjjXzzm9/MyJEjM3DgwBaP4fLLL2+S8PrsZz+bb33rW826dtVVV80FF1xQWj68MQG/sD2M11lnndx88835whe+kKqqhY+BrqmpyRe/+MX87W9/y4477vgJ3mbltOGGG2annXYqlWfOnJlrrrmmDSP6ZL70pS/lxhtvzPbbb99kyfn5DR06NCNGjMgxxxzTqrEdcsghueeee3LUUUeld+/eS6w/ePDg/M///E9uvPHG/OxnP1ti/f/93//N9ddfn6FDhy70fEVFRbbffvvccMMNTfaxX16GDx+e22+/Pd/+9rfz2c9+Nr169UqnTp2WeF1lZWV++9vf5rTTTkuvXr0WWW+zzTbLhRdemJ///OeL/LMGAACgZRSKjUO0AQAA2rlx48blqaeeKs347tWrVwYOHJhNN910pUs6ffDBB3nyySczYcKEzJkzJ6uttlp69+6dLbbYosmeybRfF154YS666KJS+Z577smAAQNK5UmTJuW5557LpEmTMnfu3PTq1SubbrppBg8e3AbRLui1117LK6+8kg8++CDTpk1LdXV1unfvnoEDB2bdddfN6quv/onvPXbs2Dz77LN5991307Fjx/Tu3TtDhw5N3759W/ANlr/a2to8//zzeeWVVzJt2rR07do1vXr1ypAhQ5bLAB8AAAAWTtIcAAAAVkBLSpoDAAAALWPlmmoBAAAAAAAAAEtB0hwAAAAAAACAsiVpDgAAAAAAAEDZkjQHAAAAAAAAoGxJmgMAAAAAAABQtiTNAQAAAAAAAChbkuYAAAAAAAAAlK1CsVgstnUQAAAAAAAAANAWzDQHAAAAAAAAoGxJmgMAAAAAAABQtiTNAQAAAAAAAChbkuYAAAAAAAAAlC1JcwAAAAAAAADKlqQ5AAAAAAAAAGVL0hwAAAAAAACAsiVpDgAAAAAAAEDZkjQHAAAAAAAAoGxJmgMAAAAAAABQtiTNAQAAAAAAAChbkuYAAAAAAAAAlC1JcwAAAAAAAADKlqQ5AAAAAAAAAGVL0hwAAAAAAACAsiVpDgAAAAAAAEDZkjQHAAAAAAAAoGxJmgMAAAAAAABQtiTNAQAAAAAAAChb/x/zFJodP7sJsgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "image/png": {
              "width": 998,
              "height": 723
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "oENoyHsUPjWv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9fe8148f259402bbd2a99588349a5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebd223b7949e434ea6b502c16b71591f",
              "IPY_MODEL_b8ba366fc20746139d5a54dd2719451e",
              "IPY_MODEL_a9fc59958dde42938619e7c3be1805c0"
            ],
            "layout": "IPY_MODEL_22e5d9571b4b4e9ba6d4a1c98b9363b0"
          }
        },
        "ebd223b7949e434ea6b502c16b71591f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4706c893530474d8cd90ac910a5049c",
            "placeholder": "​",
            "style": "IPY_MODEL_bd4a10107b6e49759b77fac41f959033",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b8ba366fc20746139d5a54dd2719451e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36adadb46a3f44e6953cd54f17ab1329",
            "max": 92,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d1f6dced6164b5fa7287f51e512a365",
            "value": 92
          }
        },
        "a9fc59958dde42938619e7c3be1805c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_323239dc52f04623933bf122ff417a6f",
            "placeholder": "​",
            "style": "IPY_MODEL_585c3749e6c944c4a28c5479d906b783",
            "value": " 92.0/92.0 [00:00&lt;00:00, 3.03kB/s]"
          }
        },
        "22e5d9571b4b4e9ba6d4a1c98b9363b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4706c893530474d8cd90ac910a5049c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd4a10107b6e49759b77fac41f959033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36adadb46a3f44e6953cd54f17ab1329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1f6dced6164b5fa7287f51e512a365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "323239dc52f04623933bf122ff417a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "585c3749e6c944c4a28c5479d906b783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ae608470ddb4e82aac02858cb76ae84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ec311b4c6aa487988cfc582f07e6407",
              "IPY_MODEL_2164a4b273f04de3a37233c57fdd468e",
              "IPY_MODEL_4f1b9fb05ce746c1b030e02d8157a007"
            ],
            "layout": "IPY_MODEL_4ca18ef9b7404d3dafb0caca78677372"
          }
        },
        "0ec311b4c6aa487988cfc582f07e6407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2e5c02a90fd4a88b02ade11bd665f5b",
            "placeholder": "​",
            "style": "IPY_MODEL_811ef1ba41774f948aeeb15541abbb54",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "2164a4b273f04de3a37233c57fdd468e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0989e34443f44f838a74478ac119970e",
            "max": 849961,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85d67dce20f646379dc0ac93c32fefb9",
            "value": 849961
          }
        },
        "4f1b9fb05ce746c1b030e02d8157a007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7871440760243848152b1f4c30de774",
            "placeholder": "​",
            "style": "IPY_MODEL_280b211638304b0ba4820eb53dd3d187",
            "value": " 850k/850k [00:00&lt;00:00, 929kB/s]"
          }
        },
        "4ca18ef9b7404d3dafb0caca78677372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e5c02a90fd4a88b02ade11bd665f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811ef1ba41774f948aeeb15541abbb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0989e34443f44f838a74478ac119970e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d67dce20f646379dc0ac93c32fefb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7871440760243848152b1f4c30de774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "280b211638304b0ba4820eb53dd3d187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d062330255c04d0dac70c3a3c8f3c3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_706134e14cfa45bda0104c2f7cabe195",
              "IPY_MODEL_ec4b2c80cf0c47a39dcfdc4870542538",
              "IPY_MODEL_38fa00238ac54008b2a1ee3b057851b1"
            ],
            "layout": "IPY_MODEL_d75155c2df8d4e07bdd5e00d78e38ad3"
          }
        },
        "706134e14cfa45bda0104c2f7cabe195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e4021b0eb9406195fdefb47844325d",
            "placeholder": "​",
            "style": "IPY_MODEL_c82edf79fab84d2e8ff6c573ee5d8506",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "ec4b2c80cf0c47a39dcfdc4870542538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ff5ca33fca4502852598b3a382b675",
            "max": 508261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b523cf4cc687469581bf710a1ef60a2e",
            "value": 508261
          }
        },
        "38fa00238ac54008b2a1ee3b057851b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9194f36b8c1c4286bad12938ce59ac9f",
            "placeholder": "​",
            "style": "IPY_MODEL_9e24090a737143bca46d48062a1ede85",
            "value": " 508k/508k [00:00&lt;00:00, 17.8MB/s]"
          }
        },
        "d75155c2df8d4e07bdd5e00d78e38ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e4021b0eb9406195fdefb47844325d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82edf79fab84d2e8ff6c573ee5d8506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1ff5ca33fca4502852598b3a382b675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b523cf4cc687469581bf710a1ef60a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9194f36b8c1c4286bad12938ce59ac9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e24090a737143bca46d48062a1ede85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bf0beb7ea1e46c59194e961a9f49223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb894d9e3f2d43ceb20086ccba31b8e4",
              "IPY_MODEL_b5d9f390618c421d91cb1edc0bef9e95",
              "IPY_MODEL_c1f8071f17504aa28af0b7106f68bf34"
            ],
            "layout": "IPY_MODEL_6665965b39a741039bf879e9d8918428"
          }
        },
        "fb894d9e3f2d43ceb20086ccba31b8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cdccc5ff6644c27adfb4883063e5d64",
            "placeholder": "​",
            "style": "IPY_MODEL_d27efcad87cf48309862c1240b8853ff",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "b5d9f390618c421d91cb1edc0bef9e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeefd5ba4d6443ff8f5a950725af34f0",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9f0e5e33cea4a66b89d92d55dff6a80",
            "value": 120
          }
        },
        "c1f8071f17504aa28af0b7106f68bf34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1ac4c5bc67044da8491400fdfab0d76",
            "placeholder": "​",
            "style": "IPY_MODEL_7c652b6d2c944658a8ec2ef5afa3dd8d",
            "value": " 120/120 [00:00&lt;00:00, 7.97kB/s]"
          }
        },
        "6665965b39a741039bf879e9d8918428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cdccc5ff6644c27adfb4883063e5d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d27efcad87cf48309862c1240b8853ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeefd5ba4d6443ff8f5a950725af34f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9f0e5e33cea4a66b89d92d55dff6a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1ac4c5bc67044da8491400fdfab0d76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c652b6d2c944658a8ec2ef5afa3dd8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e099347a64c74516ba59fae9d0911318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17c19613e9b741c5b91da0c4e8b5a068",
              "IPY_MODEL_85a5165745ec447d9b73912554708b68",
              "IPY_MODEL_841091dde446449e9f08ffef4ec02a2c"
            ],
            "layout": "IPY_MODEL_2a6818f7f59b41c58fe454c605ebe2ae"
          }
        },
        "17c19613e9b741c5b91da0c4e8b5a068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72a0a3a523241a192059b3ae09308c5",
            "placeholder": "​",
            "style": "IPY_MODEL_e05b3acbd93c44c7ac5ac9e26798e58f",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "85a5165745ec447d9b73912554708b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf9a64724c3a455882e93b82bc46b37a",
            "max": 666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa7ebfb973c94641a4ebb8fc0df06510",
            "value": 666
          }
        },
        "841091dde446449e9f08ffef4ec02a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_288043a07574419c91cbcf00cab39456",
            "placeholder": "​",
            "style": "IPY_MODEL_f826c65178254fcc935e9bf690c35a88",
            "value": " 666/666 [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "2a6818f7f59b41c58fe454c605ebe2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72a0a3a523241a192059b3ae09308c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05b3acbd93c44c7ac5ac9e26798e58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf9a64724c3a455882e93b82bc46b37a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa7ebfb973c94641a4ebb8fc0df06510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "288043a07574419c91cbcf00cab39456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f826c65178254fcc935e9bf690c35a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17e03d4c43a945bd9a3f7b22b25085f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc23432eef1a44099a2159fd4ece22c2",
              "IPY_MODEL_646fc774ac1645bba77cbcc2d8b2891a",
              "IPY_MODEL_cba1ac6fcdb24e41896180baedd7c84b"
            ],
            "layout": "IPY_MODEL_10073cbcd4ac4ddba126c48286437b4d"
          }
        },
        "bc23432eef1a44099a2159fd4ece22c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc3aa8a52dd423aadce9e4eb414b640",
            "placeholder": "​",
            "style": "IPY_MODEL_77c95762d5c34efd981f8bb374e6943d",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "646fc774ac1645bba77cbcc2d8b2891a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_981eedf881414f239344439936b37aa1",
            "max": 510378682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee2140388df2472fb29fb87019e27d90",
            "value": 510378682
          }
        },
        "cba1ac6fcdb24e41896180baedd7c84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80b9e8f6b66a464ea55a85d43567a768",
            "placeholder": "​",
            "style": "IPY_MODEL_f8e1bad65527469382e0e73d67d28d0b",
            "value": " 510M/510M [00:01&lt;00:00, 306MB/s]"
          }
        },
        "10073cbcd4ac4ddba126c48286437b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc3aa8a52dd423aadce9e4eb414b640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c95762d5c34efd981f8bb374e6943d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "981eedf881414f239344439936b37aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee2140388df2472fb29fb87019e27d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80b9e8f6b66a464ea55a85d43567a768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e1bad65527469382e0e73d67d28d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}