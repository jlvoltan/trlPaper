{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural + 512 tokens [kfold][P4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 4**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 512 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "1a38aba3-35d1-4065-ad24-d1843572cb8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=4  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lFCPPlujqL5L",
        "outputId": "f467b34f-d891-4414-b556-d6b241a07c13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_4.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9cZxPMZOfICS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f991aefd-fef4-4c7d-c862-10fdd443cb24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h5RDBcpVf0TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66bef06-09f2-43cf-b4a7-a67649e87b48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "463adc85-6bd5-44f5-d786-6c62f082fefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 02:09:05 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "3bfd34be-fff8-4540-a729-73d82a98b5f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "d7ee527c-9841-455f-d484-85afb0ade6c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WPj7c-IBgWRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "b940dc4e431e48119f320de36b758fdd",
            "d2fc87ea31764ba2880dace55c47e8ed",
            "caa2380db9014dddb37ec96f780a5f1f",
            "1121d3534067446f8d044dd727a1f5c3",
            "deb9589c3a4543f2b30bb8f7924ff7ad",
            "1e052766693c4b58a3f1d300712afe72",
            "df2d4e0ea8df40a394c3a6b144ff6984",
            "83cce591e4f14258abc3cc19eedd65c5",
            "6eed425fe98142d4b3612af18cbe322a",
            "364e14124794417c861142131df5e0ad",
            "34249fa658cc4f729d41172d2aba282c",
            "a79be80d076b4f9ba4378da4df7aa45a",
            "5be0179a2a924fba9ec9b475ad463208",
            "b0768ad058a7410eb49e13ec280b1a28",
            "03b2c99635a0435498b1da35f3d0d7b0",
            "856b47eb7f1443729c0e2c909e477791",
            "33382c9de19f47eca0feb6567e8f5a0d",
            "d46a48a0963c440394b2429e44e8b7b0",
            "51d8d5c43a7049ae90d777450a2499bb",
            "1d2fb7c9c6eb4e72b6b4880beb490998",
            "6529d6df57044bb0815cb5029138b2db",
            "47f8cc0aed09443195dfcd041cb2236b",
            "e57d95e0624341859582dd8974da749d",
            "34896824bd66456faddff9013fde0ed9",
            "4d2ebf7025804e64963410f32f1b1a75",
            "626fe494664346478825306331a5dc8e",
            "3d173ac5213f47dd8748c2e2191871e6",
            "fbab8d085db0485ea1ff3a9b303d4b20",
            "7611df624d264f0ba5cf784abad7391c",
            "080671c2e89f4d82bbe21958b403e29d",
            "088f50bd522642bb8d9c4e31011a04d8",
            "3a35714abf634fe7a0350e023dcc2ed9",
            "8a6ab8f7f6b44c2993ac61148e50ad27",
            "464ba841815346c0b2bf96e24524fced",
            "f6115dce306b4d11babc18049091618a",
            "4fd4c9fd70584034b56486e1fa373e1b",
            "e340078e9bd44f45be2ebc0242f6bf42",
            "400d9fdc112a4de280e35bcd9d5457fb",
            "34352a0e5c974116a6002ef3defde228",
            "ce5056f782354ec0970b45dc6a3ae35a",
            "c6706cf212d4481eba9b7d05eced3c2c",
            "3486a5bfc8854b738d7e1f3dd98fd4bc",
            "6f107f95c2384dffa006062deca7edae",
            "194de5357ce04d1baf5b69699f08fdf4"
          ]
        },
        "outputId": "ec5a678d-6e43-4a78-dfe1-e9e9e8b7e998"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b940dc4e431e48119f320de36b758fdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a79be80d076b4f9ba4378da4df7aa45a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e57d95e0624341859582dd8974da749d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "464ba841815346c0b2bf96e24524fced"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qSErznNMh4P5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "422df16e8b46441587150ab0bf4f7dea",
            "bc52dffe6a5d47f8849e398545dfabad",
            "6df5aa9d6428435997fdd296aefd7cb5",
            "c6a5a53a6b6a40049c02701dbfe9d956",
            "b50a46e7d47d430cba6fe4415e7be8c2",
            "27f06f06e52142d49b377ac5713a046f",
            "530325af5c6f4bba9ba1ea5ab21c8bb8",
            "3ea875bdf82a40e8b6f94d30dee1b366",
            "fbc44b71dcf548a9a12d2eb60a6d0b64",
            "21c3e77cd63a46f89c97fa3ae7f97e34",
            "160df92cc3144054a371b648f5f7f3bc"
          ]
        },
        "outputId": "68943ab5-5c84-4fef-9db5-5441dbd00ea6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "422df16e8b46441587150ab0bf4f7dea"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "6dc16bca-17b0-4d78-dcb0-9a1712ba71ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "175e033a-eeef-4557-9374-7ae8d59a9029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "a6cd1125-e6ed-4c41-fb86-9f722769099f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40650e3d-4ef9-4f5b-9cde-bf71f890807b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40650e3d-4ef9-4f5b-9cde-bf71f890807b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-40650e3d-4ef9-4f5b-9cde-bf71f890807b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-40650e3d-4ef9-4f5b-9cde-bf71f890807b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f96b6e34-e6e9-468e-90a0-036cb5a8baf4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f96b6e34-e6e9-468e-90a0-036cb5a8baf4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f96b6e34-e6e9-468e-90a0-036cb5a8baf4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "58f66586-7dfa-4d41-bfa7-85ebc15131b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "d354d316-a4e4-4691-ec78-6bf4673084f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((108, 2), (27, 2), (33, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "b0313b67-ddb4-4849-ab91-347a6e6ac37f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "3920486b-6e42-4089-9b07-ae956e1b2790"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "566a7733-10ab-425c-b483-f93767e37ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "b127c186-33fa-4303-80e0-e8b72f67f71f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "e913ac31-f60a-43d3-b83a-984d902daa82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "94be98ee-d215-4f92-d039-90b47c948fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "c00d03fd-9068-4443-9393-0f680a89f89a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0271944531372614 accuracy 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9185500293970108 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9925655722618103 accuracy 0.5648148148148148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.830709271132946 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9489634888512748 accuracy 0.5925925925925926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9341453686356544 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0269655202116286 accuracy 0.5555555555555556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9093088954687119 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0134189512048448 accuracy 0.5277777777777778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9286852031946182 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9822347419602531 accuracy 0.5555555555555556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9205604791641235 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8850866556167603 accuracy 0.537037037037037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7649691998958588 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7644577026367188 accuracy 0.7222222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1712986528873444 accuracy 0.4074074074074074\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7351202432598386 accuracy 0.6944444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7322817519307137 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7652325970785958 accuracy 0.7037037037037037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7301109954714775 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6974016513143267 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6309697106480598 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8426762776715415 accuracy 0.6944444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.0352237969636917 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.1597083849566323 accuracy 0.5277777777777778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.87357197701931 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.782630171094622 accuracy 0.6944444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6394127011299133 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.643038951924869 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6500129774212837 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7091651665312904 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7356022298336029 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6540641635656357 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7389203831553459 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6910292676516941 accuracy 0.7222222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6327517405152321 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6858792113406318 accuracy 0.7222222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6587988957762718 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8089391972337451 accuracy 0.6944444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6460292413830757 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6814935398953301 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6488818749785423 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6707255691289902 accuracy 0.7222222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6601862162351608 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.644934892654419 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6646696738898754 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6318713596888951 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6573379263281822 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6085936107805797 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6565746665000916 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.605595520564488 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6597582325339317 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6013505011796951 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6592001989483833 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6251954223428454 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6584052816033363 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.638681926897594 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6576098278164864 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6127505621739796 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6546264663338661 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6140068790742329 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.654619537293911 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5864557900599071 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.65891283005476 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5842382184096745 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6775805130600929 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5308638364076614 accuracy 0.7962962962962963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.795792430639267 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5579556961144719 accuracy 0.8055555555555555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9309977740049362 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5262252645833152 accuracy 0.8055555555555555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7342118322849274 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.433794661292008 accuracy 0.8703703703703703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.233299344778061 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3549464914415564 accuracy 0.8888888888888888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9910217523574829 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3685228063591889 accuracy 0.8796296296296295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6037914454936981 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3392164946666786 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2314315140247345 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3587615588413818 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.3333792686462402 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.361624637751707 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7071260809898376 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.35770440314497265 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6847072541713715 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.35378360455589636 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5787135362625122 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3592692871711084 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.688627928495407 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3248034891273294 accuracy 0.9074074074074073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.711804986000061 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3402699027210474 accuracy 0.9074074074074073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7130466401576996 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.34088750795594286 accuracy 0.9074074074074073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7384929656982422 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.31843429431319237 accuracy 0.9074074074074073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7558743953704834 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3290207194430487 accuracy 0.9074074074074073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7605215013027191 accuracy 0.5555555555555556\n",
            "\n",
            "CPU times: user 8min 56s, sys: 31.3 s, total: 9min 27s\n",
            "Wall time: 10min 16s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "019bf567-7c5f-407a-d41c-7d938c093edc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "c25576f6-361d-4e47-8b9c-436075ef58a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7272727272727273"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "f67e284d-d19e-4b82-cf98-f2a19730ea69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "6d62d2e0-1fe4-49ca-bc38-2914fc95e935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.80      0.84      0.82        19\n",
            "     Faixa 2       0.43      0.38      0.40         8\n",
            "     Faixa 3       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.73        33\n",
            "   macro avg       0.69      0.68      0.68        33\n",
            "weighted avg       0.72      0.73      0.72        33\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "HQ54xluu8RL3",
        "outputId": "84d42a7c-0c84-4974-cc8f-82dd56b8dc46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB6oAAAW0CAYAAAB/qY1NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAB7CAAAewgFu0HU+AAEAAElEQVR4nOzdeZxXdb0/8PcZBhhgRPZlBBVZRBQNXJGbmmYWWe6Z1zTz/io1tNxJsXIpLTVTyZvp1cQlLSXN7bpb7ka4sMggiCIggsg+MzDL9/cHl6+M7MzMOQPzfN7HPO75nPmcz3l972Pwiq/5nJPkcrlcAAAAAAAAAEBKCrIOAAAAAAAAAEDToqgGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWFWQcAAAAAAAAAID0rVqyIcePGxUcffRTz5s2LiIj27dtHr169YsCAAdG6desGz6CoBgAAAAAAAMjQihUrorS0NCZMmBDjx4+P8ePHx7Rp06K6ujo/p7S0tM73mTVrVowaNSqeeuqpWLJkyVrnFBYWxqBBg+KCCy6I3Xffvc73XBdFNQAAAAAAAEBGjj322Jg8eXJUVlY26H3uvvvuuOaaa6KsrGy986qqquJf//pXlJaWKqoBAAAAAAAAtkbjx49v8HvcfPPN8dvf/jY/bt68eey9996x1157RefOnSOXy8W8efPinXfeiVdffTWWLl3a4JkU1QAAAAAAAACNQHFxcQwYMCAGDhwY48aNizfeeKPOaz744IO1Sur9998/LrvssujZs+da569YsSKeeeaZ6NixY53vvT5JLpfLNegdAAAAAAAAAFirK664InbbbbcYOHBg7LTTTpEkSUREjBgxIv72t7/l523OO6o/+eSTGDZsWCxatCgiIr785S/H9ddfH4WF2e9nzj4BAAAAAAAAQBM1cuTIBlv7d7/7Xb6k7tChQ1x55ZWNoqSOiCjIOgAAAAAAAAAA9Wvp0qXxyCOP5MennnpqtG3bNsNEtSmqAQAAAAAAALYyjz76aJSXl0dERJIkcfjhh2ecqDZFNQAAAAAAAMBW5tVXX80f9+jRI7p3755hmjU1jgeQAwAAAAAAAFBv3n777fxxv379IiIil8vFc889F2PGjIlJkybF3Llzo7i4OLp37x777bdfHHnkkbHzzjunkk9RDQAAAAAAADRps2fPjtmzZ9dpjZKSkigpKamnRHWzdOnSmDlzZn7ctWvX+OSTT+LCCy+MF198sdbcBQsWxIIFC2LSpEnxpz/9KY4++uj4+c9/Hi1atGjQjIpqAAAAAAAAoEl74IEHYtSoUXVaY/jw4XHmmWfWU6K6WbBgQa1xLpeL733vezFlypT8ubZt20br1q1j/vz5UVlZGRERNTU1cf/998f7778ft99+e4OW1YpqaCRaDRqedQQAYBO9/vBVWUcAADZR327FWUcAADZRkTYrdU2xs/jNqek87jotS5YsqTW+//7782X01772tRg+fHj06dMnIiIqKiriySefjKuvvjrmzp0bERFjx46NX//613HJJZc0WMaCBlsZAAAAAAAAgNSVlZXVGq8qqU899dT43e9+ly+pIyKKiorim9/8Ztx7773RuXPn/Pl77rknPvjggwbL6HdQAAAAAAAAgCbtmGOOiSFDhtRpjcbyfuqIiJYtW65xrnfv3nHuueeu85rtttsuLr744vjJT34SESsfA37vvffGhRde2CAZFdUAAAAAAABAk1ZSUtKoiua6at269Rrnjj/++CgsXH89/JWvfCW6dOmSfwT4q6++2iD5Ijz6GwAAAAAAAGCrUlxcvMa5vffee4PXNWvWLAYPHpwfl5aWRk1NTb1mW8WOagAAAAAAAOAzib2uW7rOnTtHUVFRVFRU5M917959o65dfV51dXUsXrw42rVrV98R7agGAAAAAAAA2JoUFBREr169ap1r0aLFRl37+fdbr1ixot5yrU5RDQAAAAAAALCV6d+/f63x4sWLN+q6RYsW1Ro3xG7qCEU1AAAAAAAAwFbnwAMPrDWePHnyRl1XWlqaP+7cufNG78TeVIpqAAAAAAAA4DNJ0vS+tkIHHHBArcd4P/nkkxu8Zs6cOfHWW2/lx/vuu2+DZItQVAMAAAAAAABsddq0aRPHHXdcfvzwww9vcFf1ddddF9XV1fnxN7/5zQbLp6gGAAAAAAAA2AqdccYZ0bp164iIqKysjNNOOy2mTJmyxrzq6uq47rrr4sEHH8yf22OPPdZ4fHh9KmywlQEAAAAAAABYr9GjR8edd965xvn58+fXGh966KFrzOnWrdtar12lY8eO8etf/zp+/OMfR01NTXz00Udx1FFHxaGHHhqDBw+OVq1axezZs+N///d/47333stft+2228a1115bh0+1YYpqAAAAAAAAgIwsWrQoZsyYscF5a5uz+mO61+UrX/lKXHrppXH55ZfHihUroqqqKh5//PF4/PHH1zq/e/fu8Yc//CF69uy54fB14NHfAAAAAAAAwGeSgqb3tZX71re+FWPGjIkDDjggmjVrttY5bdq0iVNPPTX+9re/Rf/+/Rs8U5LL5XINfhdgg1oNGp51BABgE73+8FVZRwAANlHfbsVZRwAANlGR5wOnrtVeZ2cdIXXlY6/LOkJq5s+fH//+97/j448/jrKysmjXrl306tUrBg0aFM2bN08thz/aAAAAAAAAAE1Ex44d4ytf+UrWMTz6GwAAAAAAAIB0KaoBAAAAAAAASJVHfwMAAAAAAACfSZKsE9AE2FENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkqjDrAAAAAAAAAEAjktjrSsPzUwYAAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKSqMOsAAAAAAAAAQCOSJFknoAmwoxoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVHlHNQAAAAAAAPCZxF5XGp6fMgAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWFWQcAAAAAAAAAGpEkyToBTYAd1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoKsw4AAAAAAAAANCKJva40PD9lAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqgqzDgAAAAAAAAA0IkmSdQKaADuqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVBVmHQAAAAAAAABoRBJ7XWl4fsoAAAAAAAAASJWiGgAAAAAAAIBUKaoBAAAAAAAASJWiGgAAAAAAAIBUFWYdAAAAAAAAAGhEkiTrBDQBdlQDAAAAAAAAkCpFNQAAAAAAAACpUlQDAAAAAAAAkCrvqAYAAAAAAAA+k9jrSsPzUwYAAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKSqMOsAAAAAAAAAQCOS2OtKw/NTBgAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApKow6wAAAAAAAABAI1KQZJ2AJsCOagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWFWQcAAAAAAAAAGpHEXlcanp8yAAAAAAAAAFKlqAYAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVYVZBwAAAAAAAAAakSTJOgFNgB3VAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKTKO6oBAAAAAACAzyT2utLw/JQBAAAAAAAAkCpFNQAAAAAAAACpUlQDAAAAAAAAkCpFNQAAAAAAAACpKsw6AAAAAAAAANCIJEnWCWgC7KgGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSVZh1AAAAAAAAAKARSex1peH5KQMAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVYpqAAAAAAAAAFJVmHUAAAAAAAAAoBFJkqwT0ATYUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKSqMOsAAAAAAAAAQCOS2OtKw/NTBgAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqvKMaAAAAAAAA+EySZJ2AJsCOagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWFWQcAAAAAAAAAGpHEXlcanp8yAAAAAAAAAFKlqAYAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVYVZBwAAAAAAAAAakSTJOgFNgB3VAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqgqzDgAAAAAAAAA0Iom9rjQ8P2UAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqCrMOAAAAAAAAADQiib2uNDw/ZQAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoKsw4AAAAAAAAANCJJknUCmgA7qgEAAAAAAABIlaIaAAAAAAAAgFQpqgEAAAAAAABIlXdUAwAAAAAAAJ9J7HWl4fkpAwAAAAAAACBVimoAAAAAAAAAUuXR3wAAAAAAAAAZWrFiRZSWlsaECRNi/PjxMX78+Jg2bVpUV1fn55SWltb7fadOnRpHHnlkVFZW5s/ts88+ceedd9b7vT5PUQ0AAAAAAACQkWOPPTYmT55cqyxOQy6Xi0suuST1+66iqAYAAAAAAAA+kyRZJ2hSxo8fn8l977vvvhg3blwm945QVAMAAAAAAAA0CsXFxTFgwIAYOHBgjBs3Lt54440Guc+8efPi2muvjYiI9u3bRy6Xi4ULFzbIvdZFUQ0AAAAAAACQkZNOOil22223GDhwYOy0006R/N+O9hEjRjRYUX3FFVfE4sWLIyLiggsuiFGjRimqAQAAAAAAAJqKkSNHpnq/559/Pv73f/83IiL23nvvOProo2PUqFGpZoiIKEj9jgAAAAAAAACkrqysLC677LKIiGjevHn8/Oc/zyyLHdUAAAAAAADAZxJ7XbdWN9xwQ8yaNSsiIk455ZTo27dvZln8lAEAAAAAAABs5SZNmhSjR4+OiIjtttsufvSjH2WaR1ENAAAAAAAAsBWrrq6OkSNHRnV1dUSsfC92q1atMs3k0d8AAAAAAABAkzZ79uyYPXt2ndYoKSmJkpKSekpUv+68886YOHFiREQccsghcfDBB2ecSFENAAAAAAAANHEPPPBAjBo1qk5rDB8+PM4888x6SlR/Zs+eHddff31ERLRu3TpGjhyZcaKVFNUAAAAAAADAZ5Ik6wTUo8suuyzKysoiIuKMM85oNLu+vaMaAAAAAAAAYCv0+OOPx3PPPRcREf369YtTTjkl20CrsaMaAAAAAAAAaNKOOeaYGDJkSJ3WaCw7lVdZsmRJ/PKXv4yIiCRJ4uc//3k0b94841SfUVQDAAAAAAAATVpJSUmjK5rr6pprrol58+ZFRMRRRx0Ve+21V8aJavPobwAAAAAAAICtyLhx4+K+++6LiIh27drF+eefn3GiNdlRDQAAAAAAAOQlSZJ1BOrosssui1wuFxER5513XnTo0CHjRGtSVAMAAAAAAABsRWbOnJk/vvnmm+OPf/zjeud//PHH+eO33norDj300Pz4pJNOipNPPrneMyqqAQAAAAAAALZSH3744SbNX758ecyYMSM/XrRoUX1HigjvqAYAAAAAAAAgZXZUAwAAAAAAAHneUb3lGzt27CbNP/jgg2PWrFkREbHPPvvEnXfe2RCxarGjGgAAAAAAAIBUKaoBAAAAAAAASJVHfwMAAAAAAABkZPTo0Wt91Pb8+fNrjQ899NA15nTr1i2Vx3Q3BEU1AAAAAAAAQEYWLVoUM2bM2OC8tc2prq5uiEipUFQDAAAAAAAAn0myDkBToKgGAAAAAAAAyMiZZ54ZZ555ZqYZnn322dTvWZD6HQEAAAAAAABo0hTVAAAAAAAAAKRKUQ0AAAAAAABAqryjGgAAAAAAAMhLkiTrCDQBdlQDAAAAAAAAkCpFNQAAAAAAAACpUlQDAAAAAAAAkCpFNQAAAAAAAACpKsw6AAAAAAAAANB4JEmSdQSaADuqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVBVmHQAAAAAAAABoPJIkyToCTYAd1QAAAAAAAACkyo5qAGhEBvTuHrv32y66d942WrQojGVly2P23EUxefqceOe9OZHL5bKOCABblUULPo2ZM6bHJ3PnxOJFC2PF8ooobN482rTZJrr32D526ts/WrVuk3VMAGAdqqqq4q0334jZs2bFvHlzo7i4OLp07RZ7fOEL0b59h6zjAQDroagGgLVIkiT69+oae+22Y+y56/ax1647xG59S6Jli+b5Od//2Z1x18Ov1flexa1bxvATvxSnHrV/9Oy+7r9EL15aHs+/PiWuuf3J+NeED+p8XwBoiqqqKuPRB/4c70x4M6a+MyEWLpi/3vkFBQXxhb2HxLCjT4gv7DUkpZQAwIaUl5fHH/9wUzz0tzExf/4na3y/sLB5/McXvxjDz/pJ9O23cwYJAYANUVQDwGqO+vIX4rTjD4xBu/SMbdoUNfj9Dtmvf9xy2UnRvfO2G5zbtrhVfPPgPeJfE95XVAPAZlpeURF3/vH6jZ5fU1MT4157Kca99lIM/dJhcfq5l0RRq1YNmBAA2JCpU9+N884+K6a/994651RVVcbzzz0br7z8Upx34U/jW8efkGJCgC2fd1STBkX1VuK1116Lk08+OT8uLS3NMA3Almv/L/SOA/bqm8q9Tj5iv/j9yBOisLBZrfOl0+fE+7Pnx4JFZVHcpih26tEp+u3QZY15AED92LZdh+jeY/to2659FBW1ioryspgze2bM/GB61NRU5+e99NwTseDTT+KSq0ZF8xYtMkwMAE3XvHlz4/Qf/FfM/fjjWucH7Lpr9OjRMxYuXBgTJ4yPZcuWRUTE8uXL45eX/SKK2xTHsMO/kUFiAGBdFNUAsBEWLimLZWXLY7uu7etlva/+x65x0yX/Gc2aFURERHV1TfzPmJfid6Ofiekz13xk2TZtiuKwoQPiO9/cN2pqvKcaAOqi7bbtYs/9vhhf2Hv/2GXgoOjQqfNa5y349JN45P574uG/3pUvrCe99e8Yc89tcfwpp6UZGQCIiFwuF+f+5KxaJXXffv3iV1ddHf127p8/t3jx4vj9jdfHvffclT/3i59dHP36948+fdL55XQAYMMU1RtpzJgx8dOf/nSzr7fDOV3V1dUxderUGD9+fP5rypQpUVlZmZ/zzDPPRI8ePTJMCTRWZeUr4u0pM+PfEz+IsRNnxL8nfhDvfjA3Lv7hsBh52rA6r99um1bx3z8/MV9SVyyvjG+d88d46uV31nnNkmUVcf+T4+L+J8flrwMANl3rNsVxy1+fjGbNNvykkvYdOsVJPzgrdtipT9xw5SX58w//9a448oRTomXLhn9NCADwmWeeejLeevON/Hi7Hj3itj/dFW23rf06rbZt28ZPL74kCgqSuOeuOyNi5c7q3994fVx3/ahUMwMA66aoZqszfPjwePHFF6O8vDzrKMAW6Nf/80SMuO5vUV1d02D3uOLHR0a3Tm3z49MvvXu9JfXnNWQ2ANjaJUmyUSX16g748rB49vGHYsKbYyMioqKiPCa88a/Yc78vNkREAGAd/vDftUvmi0b+bI2SenVn/eTceP7ZZ2P27FkREfHs00/F5Hfeif677NKgOQGAjaOo3kxdunSJoqLG89vz++67r13b/2fSpElKamCzfbJgaYOu36NruzjlyCH58fOvl8a9j49t0HsCAHW3x15D8kV1RMTHH83KMA0AND3vTimNd6dMyY932ql3/McXD1zvNa1atYpjv/XtuOF31+bPPf7ow4pqgI2RZB2ApkBRvZmuueaa2HfffbOOwQYUFRXFLrvsErvttlt8+OGH8fzzz2cdCWjiTjpiv1qP7r7pz//IMA0AsLGKt2lba1xRXpZREgBomv7x/HO1xsMO/8ZGXff1w79Rq6h+/vln4+zzLqjXbADA5lFUs9U54ogjoqSkJAYOHBh9+vSJwsKVP+Y33nijohrI3Enf2C9/vHhpeTzx0qQM0wAAG+uTeXNqjdt36JRREgBoml55+aVa48F77rVR13Xr3j1KSrbLP/77/enTY85HH0W37t3rPSMAsGkU1RlatmxZlJaWxvTp02PBggVRXV0dbdu2jZKSkthzzz2juLg464ibpaqqKt59992YNm1afPLJJ1FeXh7bbLNNdOzYMQYPHhxdu3Zt0Pv/+Mc/btD1ATbXdl3aRa8en/1H7bdKZ8aKyqoMEwEAG6OqqjJeef7pWud22X1QRmkAoGmaNm1q/rigoCAG7LrbRl87cI898kV1RMS0qe8qqgGgEVBUp2zevHnxyCOPxBNPPBHjx4+Pqqq1FxTNmjWLgw8+OM4666zo16/fBtd97bXX4uSTT86P1/a+6quuuipuv/32/PjGG2+Mr3zlK+tdt6amJr773e/G66+/HhErH6X9wAMPRJ8+fWrNq6ioiCeffDIee+yxeP3112PZsmXrXHO33XaL4cOHx5e+9KUNfi6ArcngAdvXGk+c+lH+eI+de8R3jxwSX9yzb/Ts1j4KCwti3qdLYuLUj+Kpl9+Jex59PZYsq0g7MgA0edXVVXHrDb+O2TM/yJ/bc78vRreSnhmmAoCmZfGiRbHg00/z444dO0arVq02+vrttutRa/z++9Nj6BcPqLd8AMDmUVSn7Lbbbovbbrttg/Oqq6vjqaeein/+859x1VVXxbBhw+p873POOSdeeeWVmDx5ckREXHLJJbHHHnusd4fzLbfcki+pIyIuuOCCNUrqiIhXXnklzj///I3KMWHChDjttNPie9/7Xlx44YWRJMkmfhKALdMe/Wv/xXjW3IVR1LJ5XHn2UXHa8Wv+BbnNdi1jx+06xdcPHBgjTxsWPx/1cNw25qU15gEA9auivDzmffxRTBo/Lp546C8xY/q0/PfadegY/++sCzNMBwBNz4cfzqg17tpt03ZDd+3ardZ4xowZ65gJwCq6G9KgqM5Qjx49Ys8994y+fftGu3btoqamJmbPnh0vvfRSjB8/PiIili9fHhdccEFsv/32sdtuG/84m7Vp0aJFXHvttXH00UfH8uXLY+HChXHhhRfG7bffvtZ/4IwfPz5uvPHG/Piggw6KE088cYP3adeuXey5554xYMCA6NixYzRv3jzmz58fb7zxRvzzn/+M6urqiIi4/fbbo6SkpNZOcICtWdeObWuNly+vjAeu/2EcvG//DV7bqX1x/P6SE2LnXl3jwmvHNFREAGiS/t+xX4mFC+ZvcN6OfXaOc0ZeGZ27elQoAKRp6dKltcbtO3TYpOvbd2j/ufWW1DkTAFB3iuqUFRQUxOGHHx7f/e53Y/fdd1/rnLPPPjv+8Y9/xPnnnx+LFi2KysrKuPTSS+Ovf/1rne/fp0+fuOCCC+Lyyy+PiJU7oW+//fY49dRTa80rLy+P8847LyorKyNi5eN0fvWrX6137UGDBsX3v//9OOCAA6J58+ZrnTN9+vT48Y9/nH80+bXXXhvf+MY3on379mudD7A1abdN7ceSnfWdg6NHt5X//CsrXxG33P9CPP7CxJg9d2G0bVMUQ76wU5x2/IHRe/vOta5594O5cev9L6aaHQCasj477xqHH3tiDDnwy9GsWbOs4wBAk1NWVvs1gy1btNyk61u2LPrcemV1zgQA1F1B1gGamrPOOiuuvfbadZbUqxx44IFx/fXX58dvv/12TJgwoV4yfOc734kDDvjsEbO//e1v848DX+VXv/pVvP/++7XGHTt2XOea+++/f9x7771xyCGHrLOkjojo1atX3HbbbdHh/37rsaKiIv72t79t5icB2LK0La5dVK8qqT/86NPY99tXxYjf/i3+8a8p8e4Hc+Pfk2bEqHuejz2P+2X8/dm3al3363OOjq4dt0ktNwA0ddOmTIr/fei++PerL2QdBQCapPKy8lrjFi1bbNL1LVvWLrY/vx4AkA07qjfTxj6uun///vHQQw/lx5//l6L1GTJkSOy7777x2muvRUTEiy++WOfHf69y5ZVXxje/+c2YP39+VFZWxrnnnhsPPPBAFBUVxdNPPx1/+ctf8nNPPPHEOOigg9a73qZ8rk6dOsWJJ56Yf6z4iy++uMaOboCtUUHBmq9ZqKqqjm+d88eYOmPuWq9ZvqIqThpxe7x274jov9PKd2q1btUiTv/2QfGL3z/coHkBoKm46qbRUVNTExERuZqaWLZsaXw8e2ZMePNf8c+nH4/ysmUxecJbMXnCuTH0S4fF8At+Ec1bbNp/IAcA6s+mvjf18/NzkavPOADAZrKjupEbMmRI/njixIn1tm6nTp1qPcp76tSp8Zvf/Cbmzp0bI0eOzJ9f9ajw+tZQnwugMSsrX7HGub8+8e94c/LM9V63orIqLr3pkVrnjjtscL1mA4CmrFOXbtGlW0l06VYSXUt6xE59+8eQA78c3//xT+Omu/4eew357IlULz33RFz/q5HrWQ0AqG+tWtd+QtnyiuWbdH1FRUWtcevWreucCWBrlyRJk/sifYrqzdSlS5fYfvvtN/jVvXv3Ot2nU6dO+eOPP/64rrFrOeigg+I///M/8+O77747vve978WCBQsiIqJ58+Zx7bXXRlFR0bqW2Gyrf66FCxfG8uWb9i+XAFuipWVr/rPur0+M26hrH/nH27Wu36ln5+jWqW29ZQMA1m6bbdvF+ZdeHQMH75M/9+oLz8SLzz6RYSoAaFpatapdLC9fsWn/LXHF5+YrqgGgcfDo7810zTXXxL777rvZ15eXl8czzzwTL7zwQpSWlsacOXNi2bJlsWLFmrvtVlmyZMlm329dLrzwwnjttddi2rRpEbFyZ/Uq55xzTvTv33+T1qupqYnXXnstnn766Zg0aVJ8+OGHsXTp0igvX/97X5YsWbJJjw8H2BItXrrmPwv/PfGDjbq2qqom3i6dGfsP6p0/13eHrjHnk8X1lg8AWLtmzQrjv4ZfED859dj8uUfuvzv+4+DDMkwFAE1HcXFxrfHC/9tos7EWfPrp59bbps6ZAIC6U1Rn4MEHH4xf//rX8enn/gVpQxpi13FRUVFce+21cdxxx0VlZWX+/JAhQ+J73/veJq319ttvxyWXXBKTJ0/e5Bx2VANNwdQZ82qNq6trYu6nG/9LSB/Pr11Kd9jWb4ADQFp67NArtu/VO2ZMX/lLvtOmTIqlSxZH8TaecAIADa1nz+1rjefM+WiTrp8zZ87n1utZ50wAQN0pqlN2yy23xDXXXLPW77Vr1y6KioqiRYsW+XPLli2L+fPnN2imZs2aRUFB7afA77///pv0PP7XXnstfvCDH6zxvpeIiDZt2kSbNm2iZcuW+TWrq6tj1qxZ+Tm5XG4z0wNsOSZPr/0X48qq6k26fvmKqlrjli38v3EASFO37bbPF9W5XC7mzpmtqAaAFGzbrl2079AhvzN6/iefRHl5ebRq1WoDV640a9bMWuNevXaq94wAwKbzX7hTNHny5Ljuuuvy406dOsXJJ58cX/ziF6NPnz61CupVHnjggbjooosaLNOKFSvivPPOW2NH86hRo+JLX/pS9O3bd4NrVFRUxIgRI/IldfPmzePb3/52HHroobHrrruu8WieiIgPP/wwvvzlL9fPhwDYQkyaVvs3votaNo8WzQtjRWXVOq6obdttav8F/NNFZfWWDQDYsMLC2n+FrlrtqVQAQMPq3btPjP309YhY+frBSRMnxJ577b1R145/+61a451696n3fABbm03ZzAibq2DDU6gv99xzT1RXr9w917lz5xgzZkz88Ic/jAEDBqy1pI5omPdSr+7aa6+N0tLS/Lh165WPkV2+fHmce+65631n9ipPP/10zJ49OyIiCgoK4pZbbomRI0fGvvvuu9aSOqLhPxdAY/TRvEUx4d3Ztc7179V1o6/v36vbGusBAOn59JO5tcbbtmufURIAaHr2G7J/rfG4f4/dqOvmfPRRzF7tyY479uoV3UtK6jUbALB5FNUpevXVV/PHJ598cnTtuuFyYubMmRucs7lefvnluOOOO/Lj4447Lq688sr8uLS0NH77299ucJ3VP9fQoUNjyJAhG7ymIT8XQGP29+dq/xb3wfv236jrevXoFL16dMqPFywuW2OHNgDQcMrLlsXU0kn5cYsWLaNDpy4ZJgKApuWgLx1ca/zYIw9v1HWPfm7eQQcdvI6ZAEDaFNUpmjv3s9++799/44qJ1157rUGyLFy4MC688ML8u6F32GGHuOiii+KrX/1qHHXUUfl5f/rTn+Lll19e71qN6XMBNHb3PT42qqtr8uP/OnZoNC9stsHrfnTCgbXGT7/yTv6f4QBAw3vovtG1HvW926C9o/k6nowFANS/vv12jj59++XH7703LV584R/rvaaioiLu/8u9tc597evfaJB8AMCmU1SnaPVCYWMeqf3666/HlClTGiTLJZdcki+YCwsL4+qrr84/9nvkyJHRo0ePiFiZecSIEbFw4cJ1rrX65/r8u67XZsmSJfHQQw/VIT3AlmvK+x/Hnx/7V37cZ/sucflZ31zvNQfs1Td++K0Dap373ehnGiQfAGzt/v6XO6O8vGyTrnn5+SdjzD231zr3lcOPqc9YAMBGOP2M4bXGV/7y8li8aN2vxbrhumtj9uzPHvv9pUO+HP132aXB8gEAm0ZRnaJu3T57t+jzzz+/3rlLly6Nn//85w2S4/77748nn3wyPz7jjDNijz32yI+Li4vj6quvjmbNVu7w+/jjj+NnP/vZOtfr3r17/viFF16Impqadc6NiLj00ku9oxpo1Lbv3mGtX+22aVVrXqd2xWud17XjNutd/7KbHomFSz77D+Q/PumQ+P0lJ0SHbdvUmldQkMQpRw2JB64/LQpX23V99yOvxbhJM+rhkwJA03P/XbfGj078Rtz++2tiyqTxUV1dtc657015J2648pL47eU/jZqa6vz5wfv+R+y1/wHrvA4AaBiHHPqV2OMLg/LjmR9+GKee8p14d0pprXlLliyJK395edx91+j8uZYtW8bws36SVlSALV6SJE3ui/QVZh2gKRk6dGi8//77ERExZsyY2H///WPYsGFrzPvwww/j7LPPjvfeey8KCgo2WPxuihkzZsQvf/nL/HjQoEFx2mmnrTFv8ODBcdppp8Xvf//7iIh44okn4oEHHohjjllz18D+++8f9913X0RETJ8+Pa688soYMWJEvuheZenSpfHLX/4yHn744Xr/XAD1qfSxyzZq3pXnHBVXnnPUGuf/OfbdOOz716/zug/nLIgTz78tHrzx9GjefOU/K089emicePg+8fr492P23EVR3Lpl7LP7jtG5fe3S+63SmXHmL+9d27IAwEZavGhhPDrmz/HomD9HixYto8eOO0W79h2jTfE2UVVVGUuXLI4P3ns3Fi9csMa1ffrvGmeP/FUGqQGAJEnimuuuj/88/tiY939Pi3x3ypQ47ugjYsCAXWO7nj1j0cKFMWH827Fs2bJa1/78siuiT5++WcQGANZBUZ2iU045Jf7yl79EZWVlVFdXx9lnnx1/+ctf4j/+4z+iQ4cOsXjx4hg3blw899xzsWLFimjdunX853/+Z9x66631cv+qqqo477zzoqxs5S6+Nm3a1No5/XlnnHFGvPjii/HWW29FRMQVV1wRe++9d2y//fa15n35y1+OHXfcMV/Cjx49Ol5++eU47LDDYrvttouKioooLS2NJ598MhYsWPkfeoYPHx433HBDvXyuz3vyySfj6quvXuP8os89Bujkk09e62d/6qmnGiQXwOqefW1ynHjB/8R///zE6Nhu5U7qli2axxf3XPdfmp96+Z048YL/ifKKynXOAQA2zYoVy+O9Ke9scF6SJPGVbxwT3/nBj6NVq9YpJAMA1qZLl67x33/8nzjv7LPi/enTI2LlqwknTpwQEydOWGN+y5Yt47wLRsTXD1//a7cAgPQpqlO0/fbbx2WXXRYXX3xxfjfxK6+8Eq+88soac1u3bh3XXnvtet8NvaluuummfOkcEfGzn/0sevbsuc75q95dfeSRR0ZZWVmUlZXF+eefH/fcc0+tgrewsDCuv/76OOmkk2Lx4sURETF16tSYOnXqGmsmSRKnn356HHHEEQ1WVC9dujRmzNjwI3FnzZq1wTkADenh59+OsRM/iJ+d8fU46pBBse3nHi2+yttTZsbV//Nk3P/kuJQTAsDW57xfXB1jX/5HjH/jXzFrxvQNPump7bbtYsiBh8ahhx8dO/bul1JKAGB9+vbtF/f+9W9x83//Ph56cEx8On/+GnMKC5vHf3zxizH8rJ9E3347Z5ASANgQRXXKjj766OjcuXP86le/ivfee2+N7zdr1iz233//uPjii6NXr14xZsyYernvG2+8EX/4wx/y469+9atx5JFHbvC6HXbYIS6++OK4+OKLIyLizTffjN///vdx1lln1ZrXv3//uP/+++PSSy+Nl156aa1r9e/fP84555w48MADY+bMmZv/YQAaWKtBw1O710fzFsXpl94TP7nyL7H/oN7Rs1v76NKxbZSVL4+585fEa29Pjw/nrPnYUQBg8+w+eJ/YffA+ERFRtmxpzHh/Wsz9aFYsWrggViyviIKCZtG6uDi23bZ97NinX3QrWfcv9wIA2WnVqlX85JzzYvhZP4k33xgXs2bOjE8++SSKi9tE167dYvcvDIoOHTpkHRNgy+WVzaQgyeVyuaxDNEW5XC4mTJgQEydOjIULF0ZxcXF06dIlBg0aFJ07d846Xp18+OGH8e9//zvmzp0bzZs3j86dO0f//v2jT58+WUdr1NIsxgCA+vH6w1dlHQEA2ER9uxVnHQEA2ERFtl2mruN3/5x1hNTNv+OErCM0Of5oZyRJkhg4cGAMHDgw6yj1rmfPnut9pDgAAAAAAADQtBVkHQAAAAAAAACApkVRDQAAAAAAAECqPPobAAAAAAAAyEuSJOsINAF2VAMAAAAAAACQKkU1AAAAAAAAAKlSVAMAAAAAAACQKkU1AAAAAAAAAKkqzDoAAAAAAAAA0HgkSZJ1BJoAO6oBAAAAAAAASJWiGgAAAAAAAIBUKaoBAAAAAAAASJWiGgAAAAAAAIBUFWYdAAAAAAAAAGg8kiTJOgJNgB3VAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqgqzDgAAAAAAAAA0IknWAWgK7KgGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFXeUQ0AAAAAAADkJYmXVNPw7KgGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFWKagAAAAAAAABSVZh1AAAAAAAAAKDxSJIk6wg0AXZUAwAAAAAAAJAqRTUAAAAAAAAAqVJUAwAAAAAAAJAqRTUAAAAAAAAAqSrMOgAAAAAAAADQeCRJknUEmgA7qgEAAAAAAABIlaIaAAAAAAAAgFQpqgEAAAAAAABIlaIaAAAAAAAAgFQVZh0AAAAAAAAAaDySJMk6Ak2AHdUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqCrMOAAAAAAAAADQiSdYBaArsqAYAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVd5RDQAAAAAAAOQliZdU0/DsqAYAAAAAAAAgVYpqAAAAAAAAAFKlqAYAAAAAAAAgVYpqAAAAAAAAAFJVmHUAAAAAAAAAoPFIkiTrCDQBdlQDAAAAAAAAkCpFNQAAAAAAAACpUlQDAAAAAAAAkCpFNQAAAAAAAACpKsw6AAAAAAAAANB4JEmSdQSaADuqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVBVmHQAAAAAAAABoRJKsA9AU2FENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkqjDrAAAAAAAAAEDjkSRJ1hFoAuyoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUlWYdQAAAAAAAACg8UiSJOsINAF2VAMAAAAAAACQKkU1AAAAAAAAAKlSVAMAAAAAAACQKu+oBgAAAAAAAPK8o5o02FENAAAAAAAAQKrsqAYAAAAAAADYiuVyuZgxY0ZMmTIlPvroo1i2bFm0bt06OnbsGLvttlvsuOOOqWdSVAMAAAAAAABkaMWKFVFaWhoTJkyI8ePHx/jx42PatGlRXV2dn1NaWrpJay5fvjyef/75eOqpp+KVV16JTz75ZJ1ze/bsGd/5znfixBNPjObNm2/259gUimoAAAAAAACAjBx77LExefLkqKysrNd1v/zlL8fcuXM3au6HH34YV155ZTz00ENxww03RM+ePes1y9ooqgEAAAAAAIC8JEmyjtCkjB8/vkHWLS8vrzXefvvtY++9945evXpF+/bto6ysLCZMmBBPPvlkfu6kSZPiu9/9btx7773RpUuXBsm1iqIaAAAAAAAAoBEoLi6OAQMGxMCBA2PcuHHxxhtv1Gm9Vq1axVFHHRXf+ta3YpdddlnrnPPPPz/OPffceO211yIiYtasWfGrX/0qfve739Xp3huiqAYAAAAAAADIyEknnRS77bZbDBw4MHbaaaf8jvYRI0bUqag+4YQT4uSTT47OnTuvd17nzp3j5ptvjuOOOy7efffdiIh4/PHH49xzz23QR4AXNNjKAAAAAAAAAKzXyJEj48gjj4zevXvX62PXzz333A2W1Ku0atUqzjjjjFrn/vnPf9ZblrVRVAMAAAAAAAA0cfvtt1+t8Ycfftig9/PobwAAAAAAAOAz9beply1ImzZtao3Lysoa9H52VAMAAAAAAAA0cTNnzqw17tSpU4PeT1ENAAAAAAAA0MQ9/fTTtcZ77LFHg97Po78BAAAAAACAJm327Nkxe/bsOq1RUlISJSUl9ZQoXRUVFfHnP/85P27fvn0MGTKkQe+pqAYAAAAAAACatAceeCBGjRpVpzWGDx8eZ555Zj0lStdvf/vb+Oijj/LjH/zgB9GiRYsGvaeiGgAAAAAAAMhLkiTrCKTomWeeidGjR+fHO++8c3znO99p8Pt6RzUAAAAAAABAEzR58uQ4//zzI5fLRUREy5Yt49prr23w3dQRdlQDAAAAAAAATdwxxxxT53cyb2nvp545c2Z8//vfj2XLlkVEREFBQVx11VXRt2/fVO6vqAYAAAAAAACatJKSki2uaK6LefPmxamnnhpz587Nn/vZz34Ww4YNSy2DR38DAAAAAAAANBELFy6MU089NT744IP8uXPPPTdOOOGEVHPYUQ0AAAAAAADkJUmSdQQayNKlS+P//b//F1OmTMmfO+200+IHP/hB6lnsqAYAAAAAAADYypWXl8cPf/jDGD9+fP7cSSedFGeffXYmeRTVAAAAAAAAAFuxFStWxPDhw2Ps2LH5c0cffXRcfPHFmWVSVAMAAAAAAABspaqqquLss8+OF198MX/ua1/7WlxxxRWZPubdO6oBAAAAAACAPK+o3nrkcrn46U9/Gk8//XT+3Je+9KW4+uqro1mzZhkms6MaAAAAAAAAYKt06aWXxt///vf8eMiQIXH99ddH8+bNM0y1kqIaAAAAAAAAYCtzzTXXxJ///Of8ePDgwXHTTTdFy5YtM0z1GY/+BgAAAAAAAMjI6NGj484771zj/Pz582uNDz300DXmdOvWba3XfvTRR3HLLbfUOjdz5sw44ogjNjrXutauL4pqAAAAAAAAgIwsWrQoZsyYscF5a5tTXV291rlrOz937txNyrWuteuLohoAAAAAAADIS5Ik6wg0AYpqAAAAAAAAgIyceeaZceaZZ9brmj169IjS0tJ6XbO+FWQdAAAAAAAAAICmRVENAAAAAAAAQKoU1QAAAAAAAACkyjuqAQAAAAAAgLwkyToBTYEd1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoKsw4AAAAAAAAANB5JkmQdgSbAjmoAAAAAAAAAUqWoBgAAAAAAACBVimoAAAAAAAAAUqWoBgAAAAAAACBVhVkHAAAAAAAAABqPJMk6AU2BHdUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApMo7qgEAAAAAAIC8ggIvqabh2VENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkqjDrAAAAAAAAAEDjkSRZJ6ApsKMaAAAAAAAAgFQpqgEAAAAAAABIlaIaAAAAAAAAgFQpqgEAAAAAAABIVWHWAQAAAAAAAIDGI0mSrCPQBNhRDQAAAAAAAECqFNUAAAAAAAAApEpRDQAAAAAAAECqFNUAAAAAAAAApKow6wAAAAAAAABA45EkWSegKbCjGgAAAAAAAIBUKaoBAAAAAAAASJWiGgAAAAAAAIBUKaoBAAAAAAAASFVh1gEAAAAAAACAxiNJkqwj0ATYUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKSqMOsAAAAAAAAAQOORJEnWEWgC7KgGAAAAAAAAIFWKagAAAAAAAABSpagGAAAAAAAAIFXeUQ0AAAAAAADkeUU1abCjGgAAAAAAAIBUKaoBAAAAAAAASJWiGgAAAAAAAIBUKaoBAAAAAAAASFVh1gEAAAAAAACAxiNJkqwj0ATYUQ0AAAAAAABAqhTVAAAAAAAAAKRKUQ0AAAAAAABAqhTVAAAAAAAAAKSqMOsAAAAAAAAAQOORJFknoCmwoxoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEhVYdYBAAAAAAAAgMYjSZKsI9AE2FENAAAAAAAAQKoU1QAAAAAAAACkSlENAAAAAAAAQKoU1QAAAAAAAACkqjDrAAAAAAAAAEDjkSRZJ6ApsKMaAAAAAAAAgFQpqgEAAAAAAABIlaIaAAAAAAAAgFR5RzUAAAAAAACQl3hJNSmwoxoAAAAAAACAVCmqAQAAAAAAAEiVohoAAAAAAACAVCmqAQAAAAAAAEhVYdYBAAAAAAAAgMYjSbJOQFNgRzUAAAAAAAAAqVJUAwAAAAAAAJAqRTUAAAAAAAAAqVJUAwAAAAAAAJCqwqwDAAAAAAAAAI1HkiRZR6AJsKMaAAAAAAAAgFQpqgEAAAAAAABIlaIaAAAAAAAAgFQpqgEAAAAAAABIVWHWAQAAAAAAAIDGI0myTkBToKiGRuLZv16RdQQAAADY6i2pqMo6AgCwiYqK1VmwNWo0f7IrKyvjnXfeiffeey8WL14cS5cujZqamk1aY/jw4Q2UDgAAAAAAAID6knlR/fbbb8ef/vSnePrpp6OysrJOaymqAQAAAAAAABq/zIrqXC4X1113Xdx6662Ry+Uil8utdV6y2kPw1zYnSZLI5XK15gEAAAAAAADQeGVWVP/mN7+JP/3pT2stmddXTn/+e+squAEAAAAAAIBNZ4MoacikqH7ttdfi9ttvjyRJIkmSaN68eZx44olxyCGHRE1NTZx88skRsfIPwTPPPBPLli2LTz75JN5888145JFH4r333oskSaJDhw7xi1/8InbdddcsPgYAAAAAAAAAmyGTovrmm2+OiJU7olu1ahW33357fOELX4iIiFmzZtWau91220VERL9+/WL//fePM844Ix588MG44oorYsGCBXHhhRfGqFGjYujQoal+BgAAAAAAAAA2T0HaN1y6dGm8+uqr+d3UP/rRj/Il9cY68sgj47bbbotWrVpFeXl5nHXWWWsU3AAAAAAAAAA0TqkX1W+88UbU1NRELpeL5s2bx7e//e3NWmf33XePs846KyIiysrKYtSoUfUZEwAAAAAAAJqkJGl6X6Qv9aL6o48+ioiV75/eeeedo7i4eL3zKysr1/m9E044IVq1ahW5XC6efPLJWL58eb1mBQAAAAAAAKD+pV5UL1y4MH/cvXv3Nb7fvHnzWuP1lc8tW7aM3XffPSJW7qoeO3Zs/YQEAAAAAAAAoMGkXlSvrqioaI1zbdq0qTWeP3/+etfo1KlT/vjjjz+un2AAAAAAAAAANJjUi+q2bdvmj5cuXbrG99u0aVNrV/WHH3643vVWrFiRP/7kk0/qISEAAAAAAAAADSn1orpnz57543nz5q11zk477ZQ/fuONN9a73sSJE/PHa9uhDQAAAAAAAGy8JEma3BfpS72o7tOnT0RE5HK5mDp1auRyuTXmDBw4MD/noYceiqqqqrWu9eyzz8bs2bPz45KSkgZIDAAAAAAAAEB9Sr2o7tq1a35XdUVFRbz99ttrzPnqV78aESt/W2PWrFkxYsSIqKioqDVn7NixcdFFF+V/w6FZs2ax9957N3B6AAAAAAAAAOqqMIubDh06NO69996IWLkreo899qj1/f333z/69u0bU6dOjYiIRx99NP75z3/G4MGDo7i4ON5///2YOHFifjd2kiTx9a9/Pbbddtt0PwgAAAAAAAAAmyz1HdUREV//+tcjYuWjvR944IGorKysHaqgIC677LJo3rx5/tzixYvjH//4Rzz66KP5knrVburOnTvHBRdckN4HAAAAAAAAAGCzZbKjeq+99opf/vKXUVNTExErS+iOHTvWmjNo0KAYNWpUXHDBBbFw4cK1rpPL5WKHHXaI//7v/17jegAAAAAAAGDT/d9eUWhQmRTVSZLEMcccs8F5BxxwQDzxxBNx9913xz//+c/44IMPYsmSJdG2bdvo169fHHbYYXHMMcdEixYtUkgNAAAAAAAAQH3IpKjeFNtuu22cccYZccYZZ2QdBQAAAAAAAIB6kMk7qgEAAAAAAABoulLfUT1p0qR46KGH8uNTTz01unbtmnYMAAAAAAAAADKSelH9+uuvxx133BFJkkSXLl1ixIgRaUcAAAAAAAAA1iFJkqwj0ASk/ujvFStW5I/79evnBx0AAAAAAACgiUm9qO7cuXP+uG3btmnfHgAAAAAAAICMpV5Ud+vWLX+8YMGCtG8PAAAAAAAAQMZSL6r33HPPaNu2beRyuXj77bejqqoq7QgAAAAAAAAAZCj1orpFixYxbNiwiIhYtmxZjBkzJu0IAAAAAAAAwDokSdLkvkhf6kV1RMS5554bJSUlkcvl4uqrr4533nknixgAAAAAAAAAZCCTonqbbbaJm266Kbp37x5LliyJE088Me64446oqKjIIg4AAAAAAAAAKUpyuVwu7Zs++OCDERHx6aefxqhRo6KsrCySJInWrVvHfvvtF7vssku0b98+2rRps0nrHnnkkfUfFlLyytSFWUcAADZRcVFh1hEAgE3UrV1R1hEAgE3Uudjfv9N2wG9fyjpC6v55ztCsIzQ5mRTV/fv3X+NZ76ti1OUZ8B4hzpZMUQ0AWx5FNQBseRTVALDlUVSnT1FNGjL9k53L5fLF9NoK6o3p0JMkqbUOAAAAAAAAsPnUbqQhs6J6VQld1w3dGWwIBwAAAAAAAKAOMimqR48encVtAQAAAAAAAGgEMimq99lnnyxuCwAAAAAAAEAj4O3zAAAAAAAAQF7iJdWkQFENAAAAAAAA0ERMmTIlSktL4+OPP44WLVpE165dY9CgQdGlS5dUcyiqAQAAAAAAADK0YsWKKC0tjQkTJsT48eNj/PjxMW3atKiurs7PKS0trdM9nn766bjxxhtj8uTJa3yvWbNmMWTIkBgxYkT07du3TvfZWIpqAAAAAAAAgIwce+yxMXny5KisrGywe1x22WVx9913r/P71dXV8eKLL8YxxxwTl112WRx55JENlmUVRTUAAAAAAABARsaPH9+g69944421SurWrVvHN7/5zdh5551j+fLlMXbs2Hj22WejpqYmli9fHhdffHF07do1hgwZ0qC56r2ofvDBB9c49/nGfW1z6kMazT4AAAAAAABszZIk6wRNV3FxcQwYMCAGDhwY48aNizfeeKNO67311lsxatSo/HjnnXeOW265Jbp27Zo/973vfS/Gjh0bp59+eixevDiqqqri3HPPjaeeeiratGlTp/uvT70X1SNGjIjkcz+9ny+Q1zanPiiqAQAAAAAAgC3JSSedFLvttlsMHDgwdtppp3yPOmLEiDoX1dddd13+uHXr1vGHP/yhVkm9yl577RVXXHFFnHXWWRERMX/+/Bg9enScfvrpdbr/+hQ02MoRkcvlNvj9un5tzH0AAAAAAAAAGqORI0fGkUceGb17967Xzb5Tp06NV155JT8++eSTo6SkZJ3zDzvssBg8eHB+fNddd0VNTU295fm8BimqVy+R1zenvu4FAAAAAAAAwGeefvrpWuPjjjtug9cce+yx+eNPPvkk3nrrrXrPtUq9P/p79OjR9TIHAAAAAAAAgM3zj3/8I3+8ww47RI8ePTZ4zdChQ9dYY9CgQfWeLaIBiup99tmnXuYAAAAAAAAA6avPx0+TnSlTpuSP99hjj426plu3btGtW7eYM2fOGmvUtwZ9RzUAAAAAAAAA6fr4449j6dKl+fEOO+yw0dduv/32+eNp06bVa67VKaoBAAAAAAAAtiIzZ86sNe7evftGX9utW7f88axZs+ot0+fV+6O/AQAAAAAAALYks2fPjtmzZ9dpjZKSkigpKamnRHWz+m7qiIhtt912o69dfW5lZWUsX748WrZsWW/ZVlFUAwAAAAAAAE3aAw88EKNGjarTGsOHD48zzzyznhLVTVlZWa1xixYtNvraz5fSy5Yt27qL6jlz5sQLL7wQ48aNi5kzZ8aiRYvy/wd8+umn15hfU1MTVVVVERFRUFAQhYWN5qMAAAAAAADAFitJsk5AXS1fvrzWuHnz5ht97edL7c+vVV8yb3c/+OCDuO666+Lpp5+O6urq/PlcLhcREck6/iQ89thjcf7550dExDbbbBMvvPBCgzT5AAAAAAAAAFuSz/emlZWVG33tihUr1rtWfcm0qP773/8ev/jFL6K8vDxyuVwkSVKroF51vDZf+9rX4pprrok5c+bEkiVL4oknnohvfvObaUUHAAAAAAAAthLHHHNMDBkypE5rNJb3U0dEtG7dutb48+Xz+nx+B3WbNm3qJdPnZVZUP/roo3HhhRfmC+qIlbuoS0pKYtttt4133nlnvdc3a9YsDj/88Lj11lsjYuXjwRXVAAAAAAAAwKYqKSlpVEVzXRUXF9caL1q0aKOvXbx4cf64efPmDbajuqBBVt2AWbNmxU9/+tOIWLlzuqCgIE499dR47rnn4tlnn40bb7xxo9Y59NBDI2Jlwf3aa6+tdwc2AAAAAAAAQFPQo0ePWuOPPvpoo69dfe52221Xb5k+L5Md1dddd11+e3mLFi3i5ptvrrWVfl3vpf683XbbLVq0aBErVqyIxYsXx/vvvx+9evVqkMwAAAAAAADQFBRsZFdH49W1a9coLi6OpUuXRkTEjBkzNvra1efutNNO9Z5tldR3VC9fvjyeeuqpSJIkkiSJc845Z7Of996sWbPo06dPfjxt2rT6igkAAAAAAACwxerXr1/++M0339yoa+bMmRNz5sxZ6xr1LfWieuzYsbF8+fLI5XLRunXrOPHEE+u0XpcuXfLHc+fOrWs8AAAAAAAAgC3eAQcckD/+4IMPYubMmRu85qWXXqo1PvDAA+s91yqpF9WzZ8+OiJWP995jjz2iefPmdVpv9ReBr9q6DgAAAAAAANCUffnLX641/utf/7rBa+6///78cceOHeMLX/hCfcfKS72oXrBgQf64Y8eOdV6vqqoqf1xQkPrHAQAAAAAAgK1KkjS9r61R3759Y999982PR48end9UvDZPPPFEjBs3Lj8+8cQTG7R/Tb3Zbd26df64rKyszuvNnz8/f9yuXbs6rwcAAAAAAACwNTjnnHPyx2VlZXH66aev9XXKY8eOjZEjR+bHHTp0iFNOOaVBsxU26Opr0aFDh/zx+++/X6e1ampqYtKkSflx586d67QeAAAAAAAAQJpGjx4dd9555xrnV9+wGxFx6KGHrjGnW7dua712lS984Qtx2mmnxR/+8IeIiJg8eXJ89atfjSOOOCL69esXy5cvj7Fjx8YzzzwTNTU1ERHRrFmz+M1vfhNt2rSpy8faoNSL6l122SUiInK5XLz33nsxa9as2G677TZrrZdeeimWLVsWESsf+z148OB6ywkAAAAAAADQ0BYtWhQzZszY4Ly1zamurt7gdT/5yU9i4cKFce+990ZExLJly+Kee+5Z69wWLVrEpZdeGl/84hc3uG5dpf7o7169ekWPHj3y41Xt/aaqqamJ3//+9xERkSRJ7LrrrrHNNtvUS0YAAAAAAACArUGSJHHppZfGqFGjol+/fmudU1BQEEOHDo0HHnggjj766FRypb6jOiLiuOOOi+uuuy5yuVzcf//9MWjQoE3+wFdddVW8+eab+fFJJ51UzykBAAAAAACg6UmSJOsITcqZZ54ZZ555ZoPf59BDD41DDz00SktLo7S0NObOnRvNmzePrl27xqBBg6Jr164NnmF1mRTVp5xyStx1113xySefRC6Xi4svvjgmTpwYP/rRj2q9w3ptpk2bFldffXX84x//yP8h6d27dxx++OFpRAcAAAAAAADYYu28886x8847Zx0jm6K6ZcuWcf3118f3vve9WLFiReRyubjnnnvivvvuiz333DNKSkpqzb/22mtjwYIF8dZbb8XUqVMjYuU7riMi2rRpE9dff73f7AAAAAAAAADYQmRSVEdEDB48OK677ro477zzory8PCIiqqqq4vXXX681L5fLxa233po/jvjscQPFxcVx/fXXR+/evVNMDgAAAAAAAEBdFGR584MPPjjGjBkTu+++e76EXiVJkvzX6uciVhbWAwYMiL/85S8xdOjQVDMDAAAAAAAAUDeZ7aheZccdd4z77rsvXn311bj33nvj9ddfj08//XStc1u1ahX77LNPHH/88XHwwQennBQAAAAAAAC2fgXeuEsKMi+qV9lvv/1iv/32i4iI999/P+bMmROLFi2Kqqqq2HbbbaNjx47Rt2/fKCxsNJEBAAAAAAAA2AyNsvXdcccdY8cdd8w6BgAAAAAAAAANINN3VAMAAAAAAADQ9CiqAQAAAAAAAEhVo3z0NwAAAAAAAJCNJEmyjkATYEc1AAAAAAAAAKmq9x3VJ598cn0vuVGSJIk77rgjk3sDAAAAAAAAsPHqvah+/fXXU38cQC6X8wgCAAAAAAAAgC1Epu+ozuVytcYbWzZ//joAAAAAAAAAthz1XlSXlJRs0vwFCxZERUVFRNQuoIuKiqK4uDgiIpYuXZqfE/FZod2qVato165dHRMDAAAAAAAAq3iQMWmo96L62Wef3ei5N998c9x4442Ry+WisLAwDjvssBg2bFgMHDgwunTpUmvu3LlzY/z48fHYY4/FE088EVVVVVFZWRnf+ta34rTTTqvvjwEAAAAAAABAA0lyGT1H+/LLL4977rknIiIGDBgQv/nNb6J3794bde20adPi/PPPj0mTJkWSJHH88cfHL37xiwZMCw3vlakLs44AAGyi4qJM36QDAGyGbu2Kso4AAGyizsX+/p22r9/8etYRUvfoD/fJOkKTU5DFTR977LG4++67I5fLxS677BKjR4/e6JI6IqJ3795x1113xS677BK5XC7uu+++ePTRRxswMQAAAAAAAAD1JZOi+tZbb42Ile+avvzyy6NNmzabvEbr1q3jsssuy49vueWWessHAAAAAAAATVXSBP+H9KVeVE+ZMiX/yO7evXvHrrvuutlrDRw4MPr06RO5XC5KS0ujtLS0HpMCAAAAAAAA0BBSL6qnTp2aP95pp53qvN7qa6y+NgAAAAAAAACNU+pF9Zw5cxps7Y8//rjB1gYAAAAAAACgfqReVBcWFuaPp0+fXuf1Vl+jWbNmdV4PAAAAAAAAgIZVuOEp9atbt24REZHL5WLq1KkxefLk6N+//2at9c4778S77767xtoAAAAAAADA5ilIsk5AU5D6jup99tknCgsLI0mSyOVyMXLkyKioqNjkdcrLy2PkyJH5cbNmzWLfffetz6gAAAAAAAAANIDUi+p27drFwQcfHLlcLpIkiYkTJ8Ypp5wSM2bM2Og1PvjggzjllFNi4sSJkSRJJEkShxxySLRr167hggMAAAAAAABQL1J/9HdExEUXXRQvvfRSlJWVRUTEm2++GYcffngMGzYsvvrVr8bAgQOjY8eOta6ZP39+jB8/Ph5//PF4/PHHo7KyMr8ru7i4OH76059m8VEAAAAAAAAA2ESZFNXdunWLG264IX70ox/F8uXLI0mSWLFiRTz00EPx0EMPRUREUVFRFBcXR0TE0qVLaz0efNVu7FwuF0VFRXHDDTd4PzUAAAAAAADAFiL1R3+vMnTo0Ljttttiu+22yxfPEStL6FwuF+Xl5TFv3ryYN29elJeX589HRL6k7tmzZ9x2222x//77Z/UxAAAAAAAAYKuy6tW7TemL9GVWVEdEDB48OB555JEYPnx4dOrUKV9Er7K2H4xcLhedOnWK4cOHx8MPPxyDBw9OMzIAAAAAAAAAdZTJo79XV1RUFMOHD4/TTz89Xn311XjjjTdi0qRJMX/+/Fi8eHFERLRt2zY6duwYAwYMiEGDBsV+++0XzZo1yzg5AAAAAAAAAJsj86J6lWbNmsXQoUNj6NChWUcBAAAAAAAAoAFl+uhvAAAAAAAAAJqeRrOjGgAAAAAAAMhekmSdgKbAjmoAAAAAAAAAUqWoBgAAAAAAACBVjerR37lcLubMmROLFi2KpUuXRi6X26Tr99577wZKBgAAAAAAAEB9ybyorqioiAcffDAee+yxmDBhQpSXl2/WOkmSxKRJk+o5HQAAAAAAAAD1LdOi+oUXXogRI0bEp59+GhGxyTuoAQAAAAAAgPpVkCRZR6AJyKyofvTRR+P888+PmpqaNb6XrPbD//nyen3fAwAAAAAAAKDxy6So/uCDD+Liiy+OmpqaSJIkcrlcDBgwIA455JBo0aJFXHvttRGxspS+8sorY9myZTFv3rx46623YuzYsVFVVRVJkkSHDh3i9NNPj+Li4iw+BgAAAAAAAACbIZOi+uabb46Kior8eMSIEXHKKadERMSsWbPyRXVExFFHHVXr2o8//jh+97vfxd/+9rdYsGBB3HXXXXHbbbfFdtttl0p2AAAAAAAAAOqmIO0bVlZWxmOPPRZJkkSSJHHcccflS+qN0bVr17jyyivj5z//eeRyuZgxY0Z8//vfj/Ly8oYLDQAAAAAAAEC9Sb2oHj9+fFRUVEQul4skSeKHP/zhZq1zwgknxPHHHx+5XC6mT58ef/zjH+s5KQAAAAAAADQ9SdL0vkhf6kX1+++/HxEr3z+94447bvCR3dXV1ev83llnnRUFBSs/wpgxY+otIwAAAAAAAAANJ/WietGiRfnjXr16rfH9Zs2a1RqvWLFinWt17Ngxdtttt8jlcjF37tx488036y0nAAAAAAAAAA0j9aJ69eK5TZs2a3y/devWtcYLFixY73olJSX54w8//LCO6QAAAAAAAABoaIVp33D1crqiomKN7xcXF0eSJJHL5SIi4qOPPqpVRn/eqkd/R0TMmzevHpMCAAAAAABA05N4aTMpSH1Hdbdu3fLHa9stXVBQED179syPJ0yYsN71pk+fXn/hAAAAAAAAAGhwqRfVO+20U0RE5HK5ePfdd9c6p3///vnjxx9/fJ1rvfvuu/HOO+/kf6ujU6dO9ZgUAAAAAAAAgIaQSVHdrl27iIhYtGhRzJgxY405hxxySESsLLPfeuutuPvuu9eYs2jRorjwwgvz8yIiBg8e3ECpAQAAAAAAAKgvqRfVERH77bdf/vi5555b4/uHHnpotG/fPv+u6iuuuCL+67/+K26//fb461//Gr/5zW9i2LBh+d3USZLEXnvtFT169EjzYwAAAAAAAACwGQqzuOlhhx0W//u//xu5XC7GjBkT3/3ud2t9v3Xr1nH++efHRRddlC+rX3755Xj55Zfzc3K5XP57LVq0yO+uBgAAAAAAADbf/711FxpUJkX1wQcfHEcccUTU1NRERMScOXOiW7duteYcffTRMXPmzLjpppvy76Be3aqSumXLlvHrX/86dtttt1SyAwAAAAAAAFA3SW7VC54bqddffz1uuummGDt2bFRVVeXPt2rVKg466KAYPnx49O7dO8OEUD9embow6wgAwCYqLsrk9z4BgDro1q4o6wgAwCbqXOzv32k77k/jso6Qur+eMjjrCE1Oo/+Tvc8++8Q+++wTZWVlMXv27FiyZEm0bds2evbsGS1atMg6HgAAAAAAAACbqNEX1au0bt06+vTpk3UMAAAAAAAAAOpoiymqAQAAAAAAgIZXkCRZR6AJKMg6AAAAAAAAAABNi6IaAAAAAAAAgFQpqgEAAAAAAABIVb2/o/rkk0+u7yU3SpIkcccdd2RybwAAAAAAAAA2Xr0X1a+//nokKb9gPZfLpX5PAAAAAAAA2Bpp3UhDvRfVmyKXy9Uab2zZ/PnrAAAAAAAAANhy1HtRXVJSsknzFyxYEBUVFRFRu4AuKiqK4uLiiIhYunRpfk7EZ4V2q1atol27dnVMDAAAAAAAAECa6r2ofvbZZzd67s033xw33nhj5HK5KCwsjMMOOyyGDRsWAwcOjC5dutSaO3fu3Bg/fnw89thj8cQTT0RVVVVUVlbGt771rTjttNPq+2MAAAAAAAAA0ECSXEbP0b788svjnnvuiYiIAQMGxG9+85vo3bv3Rl07bdq0OP/882PSpEmRJEkcf/zx8Ytf/KIB00LDe2XqwqwjAACbqLgo0zfpAACboVu7oqwjAACbqHOxv3+n7dt3vJF1hNTd+91BWUdocgqyuOljjz0Wd999d+Ryudhll11i9OjRG11SR0T07t077rrrrthll10il8vFfffdF48++mgDJgYAAAAAAICmIUmSJvdF+jIpqm+99daIWPlDfvnll0ebNm02eY3WrVvHZZddlh/fcsst9ZYPAAAAAAAAgIaTelE9ZcqU/CO7e/fuHbvuuutmrzVw4MDo06dP5HK5KC0tjdLS0npMCgAAAAAAAEBDSL2onjp1av54p512qvN6q6+x+toAAAAAAAAANE6pv31+zpw5Dbb2xx9/3GBrAwAAAAAAQFNQ4JXNpCD1HdWFhZ9149OnT6/zequv0axZszqvBwAAAAAAAEDDSr2o7tatW0RE5HK5mDp1akyePHmz13rnnXfi3XffXWNtAAAAAAAAABqv1IvqffbZJwoLCyNJksjlcjFy5MioqKjY5HXKy8tj5MiR+XGzZs1i3333rc+oAAAAAAAAADSA1Ivqdu3axcEHHxy5XC6SJImJEyfGKaecEjNmzNjoNT744IM45ZRTYuLEiZEkSSRJEocccki0a9eu4YIDAAAAAAAAUC8KNzyl/l100UXx0ksvRVlZWUREvPnmm3H44YfHsGHD4qtf/WoMHDgwOnbsWOua+fPnx/jx4+Pxxx+Pxx9/PCorK/O7souLi+OnP/1pFh8FAAAAAAAAtipJkmQdgSYgk6K6W7duccMNN8SPfvSjWL58eSRJEitWrIiHHnooHnrooYiIKCoqiuLi4oiIWLp0aa3Hg6/ajZ3L5aKoqChuuOEG76cGAAAAAAAA2EKk/ujvVYYOHRq33XZbbLfddvniOWJlCZ3L5aK8vDzmzZsX8+bNi/Ly8vz5iMiX1D179ozbbrst9t9//6w+BgAAAAAAAACbKLOiOiJi8ODB8cgjj8Tw4cOjU6dO+SJ6lVXvn15dLpeLTp06xfDhw+Phhx+OwYMHpxkZAAAAAAAAgDrK5NHfqysqKorhw4fH6aefHq+++mq88cYbMWnSpJg/f34sXrw4IiLatm0bHTt2jAEDBsSgQYNiv/32i2bNmmWcHAAAAAAAAIDNkXlRvUqzZs1i6NChMXTo0KyjAAAAAAAAQJP1uQceQ4NIvaieNGlSPPTQQ/nxqaeeGl27dk07BgAAAAAAAAAZSb2ofv311+OOO+6IJEmiS5cuMWLEiLQjAAAAAAAAAJChgrRvuGLFivxxv379IvHsAAAAAAAAAIAmJfWiunPnzvnjtm3bpn17AAAAAAAAADKW+qO/u3Xrlj9esGBB2rcHAAAAAAAA1sMTkUlD6juq99xzz2jbtm3kcrl4++23o6qqKu0IAAAAAAAAAGQo9aK6RYsWMWzYsIiIWLZsWYwZMybtCAAAAAAAAABkKPWiOiLi3HPPjZKSksjlcnH11VfHO++8k0UMAAAAAAAAADKQSVG9zTbbxE033RTdu3ePJUuWxIknnhh33HFHVFRUZBEHAAAAAAAAgBQluVwul/ZNH3zwwYiI+PTTT2PUqFFRVlYWSZJE69atY7/99otddtkl2rdvH23atNmkdY888sj6DwspeWXqwqwjAACbqLioMOsIAMAm6tauKOsIAMAm6lzs799pO+XPb2cdIXV/OmH3rCM0OZkU1f37948kSWqdWxXj8+c3hUeIsyVTVAPAlkdRDQBbHkU1AGx5FNXpU1SThkz/ZOdyuXwxvbaCemM69CRJaq0DAAAAAAAAQOOWWVG9qoSu64buDDaEAwAAAAAAAFAHmRTVo0ePzuK2AAAAAAAAwAZ4kjFpyKSo3meffbK4LQAAAAAAAACNQEHWAQAAAAAAAABoWhTVAAAAAAAAAKRKUQ0AAAAAAABAqjJ5RzUAAAAAAADQOCVZB6BJaDRF9ZtvvhnPPfdcjBs3LmbNmhWLFi2KsrKySJIkJk2atMb8Tz/9NBYtWhQRES1btoySkpK0IwMAAAAAAACwGTIvqv/973/HVVddFRMmTMify+VyG7zu7bffjtNPPz0iIoqKiuKFF16I4uLiBssJAAAAAAAAQP3I9B3Vf/jDH+Lkk0+OCRMm5MvpVf87Sdb/UIGDDjoodthhh8jlclFRURGPPPJIg+cFAAAAAAAAoO4yK6pvv/32+N3vfhfV1dX5c0VFRbH33nvHQQcdtFG7qg8//PD88bPPPtsgOQEAAAAAAACoX5k8+ru0tDSuvvrq/K7pVq1axbnnnhvHHXdctGjRImbNmhXPP//8Btc59NBDY9SoUZHL5eJf//pXVFVVRWFh5k8zBwAAAAAAgC1WwQaefAz1IZNW97rrrouampqIiGjbtm3cdddd0a9fv01ep1+/ftGqVasoLy+PioqKmD59evTt27e+4wIAAAAAAABQj1J/9PfSpUvjxRdfjCRJIkmSuOiiizarpI5Y+R7r1Yvp9957r75iAgAAAAAAANBAUi+qx44dG1VVVZHL5WLbbbeNI444ok7rdezYMX/8ySef1DUeAADA/2fvvsOsqu71gX/PMENvUkRQwYKKXazBXqOxRNHYFdtPogYxVuzGaNQY0VgTyxVj1BgVFGtUFLvCtQMiAqJSpMpQZ2CGOb8/uJww0pk5ew/M53OfeXLWnrX3ec+NSOCdtRYAAAAAeZZ4UT1x4sSIWLgaervttsudU726GjdunHs9Z86cKj0LAAAAAAAAgPxL/IzqGTNm5F43a9asys+bN29e7nVhYSpHbgMAAAAAAMBao4rrTGGlJL6iukmTJrnXs2fPrvLzpkyZknvdvHnzKj8PAAAAAAAAgPxKvKhe/EzpUaNGVelZZWVlMXz48Ny4bdu2VXoeAAAAAAAAAPmXeFG97bbbRkRENpuNcePGxciRI1f7WQMGDIjS0tKIWLjtd+fOnaslIwAAAAAAAAD5k3hR3a5du+jYsWNufOedd67Wc+bNmxf33ntvRERkMpnYcccdo379+tWSEQAAAAAAAID8Sbyojog4+eSTc6/feOONuOeee1bp/rKysrj88ssrbR1+xhlnVFs+AAAAAAAAqK0ymUyt+yJ5qRTVxx13XGy88cYRsXAL8HvvvTfOOeecSudNL002m4133nknjj/++PjPf/6T+wenc+fOse+++yaQHAAAAAAAAICqKkzjTevUqRP33ntvnHjiiTFz5szIZrPx9ttvx9tvvx3rr79+tG/fvtL8iy66KKZPnx7Dhg2LWbNm5a5ns9lo1apV3HHHHUl/BAAAAAAAAABWUyorqiMiNtlkk3jwwQejdevWuWvZbDbGjRsXH374YaVrr7zySnz00Ue5UnvR9bZt28aDDz4Ybdq0STw/AAAAAAAAAKsnlRXVi2y33Xbx/PPPxx//+Mf4z3/+kyuhI2Kpe8FnMpncnIMOOiiuv/76aNGiRWJ5AQAAWLvMmP5TjPthTEydPDFmziiO+fNKo7CoKBo1ahJtN2gfm2zWKRo0bJR2TAAAAFjrpFpUR0Q0b948br/99rjwwgvjySefjEGDBsXw4cNjwYIFS8zdaKONYvfdd4/jjjsuOnXqlEJaAAAA1mTl5WXxUt9/xfChn8eo4UOjePq05c4vKCiIHXbpEocefWLssHOXhFICAACkaynrSaHaZbKLL2OuIUpLS2PKlCkxY8aMKC8vj2bNmkXLli2jadOmaUeDvPlwVHHaEYA8GvnVl3HTZd3j57/tPvLSoJQSAdWhcf3Uf+4TWEVzZs+K047cd7Xu3WO/g+Pci6+J+g0aVG8oIFHrNa+fdgSgiioqKuK7Md/G8GFDYviwIfH1V0Nj9MhvoqysLDfnyutujEN/3TXFlEB1at3Yn7+T9ttnhqUdIXH3/2brtCPUOjXyV3b9+vVjww03jA033DDtKGuMQYMGRbdu3XLjESNGpJgGgMWVl5fHI/fcvERJDQDUDM2at4i2G7SPps3Xifr1G0RpydyYOGFcjPt+TFRU/He3r/cHvhrTf5oa19xyTxTVrZtiYgConQYOeDX6PvWvGDF8WJTMnZt2HACgimpkUQ3VYcGCBTFmzJj45ptvYvLkyVFSUhKNGzeOVq1axfbbbx/t2rVLOyJQS7z8zD9j/Pffph0DAPg/TZs1j51+sVfssMvuseW2naNFq9ZLnTf9p6nx4jNPxAtPP5YrrL/64pPo98TDcfzp5yQZGQCIiC8//zQ+/+R/044BAFSTVIrqUaNGRceOHdN469XWr1+/uOKKK1b7fiuckzF79uwYMGBAvPHGG/HRRx/FzJkzlzl3iy22iNNPPz26du0aGYctAHkyacLYeOHffSIioqCgThQWFcb8efNSTgUAtVfDRo3jwadfizp16qxw7jotWsWp3XtGh006xl03X5O7/sLTj8VRJ54e9erZPhgAaoLGjZtEg4YNY8rkSWlHAVhrFOhNSEAqRfXhhx8e2267bRx11FFx+OGHR7NmzdKIwVpm9uzZsfvuu8e8lSyARowYEVdccUU8//zzcccdd8Q666yT54RAbfSPe/4cZfMX/nvpgMOPiU8/ejemTf4x5VQAUHtlMpmVKqkXt/eBh8abr/SPoZ9/HBERpaUlMfSz/42dfrFXPiICAMtRr1792GyLTtFpq21iy623iS232iY27LBRPPzAfdHngfvSjgcA1WLSpEkxZMiQ+PHHH2P27NlRr169WGeddaJTp06x2WabRWHh2rFpdmqfYujQoTF06ND485//HPvuu2907do19t5771X+C4O0rLvuulG/fs356fnddtut1q/arqioWKKk7tixY+y6666x4YYbRrNmzWLmzJnx2WefxZtvvhllZWUREfHhhx/GWWedFY899lg0bNgwjejAWur9N16Or75YuCVZ8xat4uhTfxuffvRuyqkAgNWx/c5dckV1RMSkH8enmAYAaqduZ/02fvf7S9eav5wHgJ979dVX4+GHH47PP/98mXNatGgRv/nNb+K3v/1tNG7cOLlweZDq7+jZbDbmz58fr7/+erz++uvRokWL+PWvfx1HHnlkdOrUKc1oK3TbbbfFbrvtlnYMlqJ58+Zx7LHHxrHHHhsdOnRY4vtnnHFGfPfdd9GzZ89cuT9s2LC4995749JLL006LrCWmj1zRjz50J258Yln/z4aNFyz/0cDANRmjZs0rTQuLZmbUhIAqL3WWadF2hEAIC/Kysrisssui5dffnmFc3/66ad44IEH4vnnn4/777+/xneqy1OQxpseccQRS6xGzmazMW3atHjkkUeia9eu0bVr13j00Ufjp59+SiMia6A6derEOeecEwMGDIhLLrlkqSX1IhtttFH06dMnWrVqlbv22GOPRUlJSRJRgVrgXw/dGbNmFkdExNadd43d9j4o3UAAQJVMnTKx0nidFq2WMRMAAABWzbXXXluppC4oKIh99tknLrnkkrjpppvi2muvjeOPP77SccoTJ06M008/PSZPnpxG5GqRyorqv/zlLzFnzpz4z3/+E/3794///d+F26Jm/u9g9mw2G8OHD4+vv/46br311th7772ja9eusd9++61V27rMmTMnRowYEWPGjInp06fHggULomnTptGuXbvYaaed1tjl+uXl5TFy5MgYPXp0TJ06NUpKSqJJkybRsmXL2HHHHaNNmzZ5ed9GjRrFhRdeuNLzW7ZsGaeffnrcdtttERFRWloagwYNin333Tcv+YDa46svPo7333gpIiIKi+rGqefarQEA1mTl5WXx4VsDKl3bcrvOKaUBAADIv/+r7EjAp59+Gv369cuNW7RoEffff39st912S8y95JJL4pJLLom33347IiKmT58ed9xxR9x8882J5a1OqbW+jRo1imOOOSaOOeaYmDBhQjz77LPx/PPPx/fffx8R/y2ty8vLY+DAgTFw4MBo1qxZHH744dG1a9fYeuut04peJVOmTIkXX3wxXn311RgyZEiUl5cvdV6dOnVi//33j549e8bmm2++wucOGjQounXrlhsv7bzqW265Jfr06ZMb33333fHLX/5yuc+tqKiI0047LQYPHhwREfXr14++fftGx44dK80rLS2N1157LV5++eUYPHhwzJkzZ5nP3GabbaJHjx6x3377rfBz5dvPt28fO3ZsSkmAtcX8+fPiH/fckhsfdmy3WG/99ikmAgCqYsGC8njorj/HhHHf567t9Iu9Yr12G6aYCgAAgLVF//79K41vvvnmpZbUERFNmzaNO++8Mw455JCYOHHhzl//+c9/4vrrr4+6devmPWt1S2Xr759r165d/O53v4tXX301/vWvf8Vxxx0XTZo0iWw2m5uTzWajuLg4Hn/88fjNb34TRxxxRPTp0yemTp2aYvJV9/DDD8ctt9wSn3322TJL6oiIBQsWxOuvvx6/+c1vVmo/+pVx0UUXVdqn/pprrolJkyYt954HH3wwV1JHRFx22WVLlNQRER9++GFceumlMXDgwOWW1BERQ4cOjXPOOSduueWWSv8dp6FRo0aVxrb+BqrqhX/3iUkTFv7QS5t2G8Rhx3ZbwR0AQE1TWlISY7/7Nl594Zm49LcnxYCXns19r3mLlvH/evZKMR0AAABrk6+++ir3unXr1ivc+bdBgwZx2GGH5cZz585dYxdi1rh9tDt37hydO3eOq6++OgYMGBD9+/eP999/P8rLyyttDT5y5Mi49dZbo3fv3rHHHntE165d45BDDkk5/arZYIMNYqeddorNNtssmjdvHhUVFTFhwoR4//33Y8iQIRERMW/evLjsssuiffv2sc0221Tp/erWrRu9e/eOo48+OubNmxfFxcXRq1ev6NOnT+7/t4sbMmRI3H333bnxvvvuGyeffPIK36d58+ax0047xVZbbRUtW7aMoqKimDZtWnz22WfxzjvvxIIFCyIiok+fPtGuXbtKK8GTNm7cuErjli1bppQEWBuM/+HbeOWZx3LjU8+9NOrWrZdiIgBgZfy/3/wyiqdPW+G8jTpuERddfXO0btM2gVQAAADUBjNmzMi93mCDDVbqnvbtK+/iufgz1iQ1rqhepG7dunHooYfGoYceGtOmTYvnn38+nnvuudyW1plMJrLZbJSXl8fbb78d77777hpRVBcUFMThhx8ep5122jKX7V944YXx9ttvx6WXXhozZsyIsrKyuP766+Ppp5+u8vt37NgxLrvssrjhhhsiYuFK6D59+sSZZ55ZaV5JSUlccsklUVZWFhELC9ybbrppuc/u3LlznH322bH33ntHUVHRUueMGTMmLrjggtx/j717944jjjgi1llnnap+tNXyxhtvVBrvsMMOqeQA1nzZbDb+cc8tUV6+8N+bu+51YGyz4y9STgUAVIeOW2wdh//m5Oiyz4FRp06dtOMAAACwFmnatGnu9dy5c1fqnp/vENyiRYtqzZSUGrH194q0bNkyzjjjjOjfv38899xzcdppp+VWvi6+ynpN0LNnz+jdu/cyS+pF9tlnn7jzzjtz4y+//DKGDh1aLRlOOeWU2HvvvXPj22+/Pb7++utKc2666ab47rvvKo2Xt9p49913jyeffDIOOOCAZZbUEREbb7xxPPzww7lfMKWlpfHss88uc34+TZ48OV544YXcePPNN49NN900lSzAmu/t/zwX3wz7IiIi6jdoGCee/ft0AwEA1Wb0N1/Ff/r/Oz756N20owAAACQik8nUuq+0LL6IcvTo0fHTTz+t8J5BgwblXrdu3To6dOiQj2h5V2NXVC9Lp06d4qKLLoott9wy/vznP0dxcXEqOVZ2u+pOnTpVOgS9Xr2V3wK2S5cusdtuu+X+YXvvvfeqvP33IjfffHP8+te/jmnTpkVZWVlcfPHF0bdv36hfv34MGDAgnnrqqdzck08+eYX74a/K52rVqlWcfPLJuW3F33vvvSVWdCfhj3/8Y6WfTOnRo0fiGYC1w4zp0+KpPvfmxkef+ttYp2XrFBMBAKvilvsejYqKioiIyFZUxJw5s2PShHEx9PP/jXcGvBIlc+fE10O/iK+HXhx77Hdw9LjsD1FUt27KqQEAAFgbHH/88fHEE0/EggULory8PG655Za49dZblzn/3Xffjbfeeis3PuOMM1It2qtijVhRvcjHH38cV199deyxxx5xxRVXpFZSJ6lLly6518OGDau257Zq1arSVt6jRo2KW2+9NSZPnhxXX3117vqircKrW74+18r65z//Ga+//npuvOeee8bBBx+ceA5g7fD4A7fH3DmzIiKi/Sabx4GHH5tyIgBgVbRad71Yd712se567aJNuw1ik806RZd9DoyzL7gi7nvs+di5y393pHp/4Ktx501XL+dpAAAAsPI222yz6NmzZ27cv3//OOecc2LIkCGVdpSePHly3HvvvXHeeeflru+9995x+umnJx252tT4FdVjx47Nbfk9fvz4iPjvNt+LzqmOWFi8JmndddeN+vXrr3Be27Ztq/Q+i3+uSZMmVelZP7fvvvvGSSedFE888URERDz++OMxaNCgmD59ekREFBUVRe/evVfqc66qxT9XcXFxzJs3b5VWZVfF+++/H7fccktu3KJFi0pjgFXx5ccfxOB3BkTEwt+XTvtdryhwdiUArDWaNGsel17/l7jx8vNjyKeDIyLio3ffiPfefDX23N8PuwIAAKwtJkyYEBMmTKjSM9q1axft2rVb5fvOOeecaNy4cfTu3Tvmzp0bAwcOjIEDB0bDhg1jnXXWiZKSkkpbgterVy+6desWPXv2jDpr8N9H18iies6cOfHKK6/Ec889F5988klEVC6nFykqKor99tsvjj766Nhzzz0TzXjbbbfFbrvtttr3l5SUxBtvvBHvvvtujBgxIiZOnBhz5syJ+fPnL/OeWbNmrfb7LUuvXr1i0KBBMXr06IhYuLJ6kYsuuig6deq0Ss+rqKiIQYMGxYABA+Krr76KsWPHxuzZs5c41P3nZs2alUhRPXTo0Dj//POjvLw8Ihb+Qr777rujdWtb9AKrbl5paTx633+3YNnnkKNi007Vc0QDAFBz1KlTGGf1uCx+f+ZvctdefOZxRTUAAMBapG/fvnHPPfdU6Rk9evSI888/f7XuPeWUU+JXv/pV3HDDDfHKK69ERMTcuXMrHWMbEbHxxhvHjTfeGDvvvHOVstYENaaozmaz8f7778ezzz4bb775ZpSWluauLzrEPJvNRjabje222y6OOuqoOPzww6Np06YpJ191zz33XPz5z39eqcPQFzdv3rxqz1K/fv3o3bt3HHvssVFWVpa73qVLlzjjjDNW6VlffvllXHPNNfH111+vco58fLafGz16dJx99tkxZ86ciIgoLCyMO++8c634hQyk49nHH4ipk36MiIgmzdaJY087L+VEAEC+bNBh42i/8abxw5iFP+Q7+puvYvasmdG4yZr3Z1IAAIAVWaPODl5LvPbaa9G7d+/47rvvljtvzJgxccopp8SBBx4Y11133Rq9GDP1onr06NHx7LPPxvPPPx9TpkyJiCVXT2ez2Vh33XXjyCOPjKOOOio23XTT1PJW1YMPPhi33XbbUr/XvHnzqF+/ftStWzd3bc6cOTFt2rS8ZqpTp04UFFT+V87uu+++SgevDxo0KLp37577AYPFNWrUKBo1ahT16tXLPXPBggW5rdwjotIe+/kwbty4OOOMM3I/HFBQUBB//vOfY7/99svr+wJrr3mlJfF6/ydz44N+fXzMnTs75s6dvdz7KhaUVxpPmVR5K5l1WrSOwqKi6gsKAFSb9dZvnyuqs9lsTJ44QVENAABAld1xxx3x97//PTfeYYcd4rTTTouddtopWrRoEaWlpTFixIh48cUX4+mnn47y8vJ4/fXX48svv4zHH388NtxwwxTTr75Uiuri4uJ46aWX4tlnn41hw4ZFxNK39q5Xr14ccMAB0bVr19h9992XKFPXNF9//XXccccduXGrVq2iW7dusddee0XHjh0rFdSL9O3bN6688sq8ZZo/f35ccsklS6xovueee2K//faLzTbbbIXPKC0tjcsvvzxXUhcVFcUJJ5wQBx10UGy99dbRuHHjJe4ZO3ZsHHjggdXzIVZg0qRJcfrpp1c64/sPf/hDHH744Ym8P7B2Ki8vjwULFuTG/f759+j3z78v546lu/TMrpXG19/1z+iw6eZVzgcAVL/Cwsp/hC5fbFcqAAAA1mzHHHNMdOnSpUrPWJ3zqfv371+ppD7llFPiqquuqtSLFhUVxc477xw777xzHHrooXH22WdHaWlpTJo0KX7/+9/HU089tUaeVZ1KUb3nnnvGggULKpXTi2/t3blz5zj66KPjV7/61VJLzjXVE088kSs1WrduHX379o02bdos9558nEu9uN69e8eIESNy44YNG8bcuXNj3rx5cfHFF8czzzyz1AJ9cQMGDMgdLl9QUBAPPvjgCn8h5/tzLfLTTz/F6aefHmPHjs1d69WrVxx//PGJvD8AALD2+Gnq5ErjZs3XSSkJAAAA1a1du3arVTRXRVlZWfTu3Ts33nrrrZcoqX9u1113jQsvvDBuvvnmiIgYOnRovPbaa/GrX/0q73mrWypLlMvLF257uvjW3m3bto1zzjknXn311fjXv/4Vxx577FpVUkdEfPTRR7nX3bp1W2FJHbFwy+p8+eCDD+If//hHbnzsscfm/qGOiBgxYkTcfvvtK3zO4p9rjz32WKmfNsnn51pk5syZceaZZ8a3336bu3b++efHmWeemff3BgAA1i4lc+fEqBFf5cZ169aLFq3WTTERAAAAa7pPPvmk0o7AJ5544krtMH3cccdF0WJHSA4YMCAv+fIttTOqs9lsNGjQIH75y1/GUUcdVeWl9GuCyZP/+9P3nTp1Wql7Bg0alJcsxcXF0atXr9yq9g4dOsSVV14ZDRs2jK5du8azzz4bERGPPPJI7L333rH77rsv81k16XMtMmfOnDj77LNj+PDhuWtnnnlm9OjRI6/vC9QejRo3iUdeWvV/l118xlExbfKPufHqPAMASF7/fz9aaavvbTrvEkUr2H0KAABgTbX4Ub3kz+K7HkdEbLPNNit1X8OGDWOTTTbJ3T9q1Khqz5aEVFZU77LLLnHTTTfFe++9F3/+859rRUkd8d9zuCMWng29IoMHD45vvvkmL1muueaaXMFcWFgYf/nLX6Jhw4YREXH11VfHBhtsEBELM19++eVRXFy8zGct/rl+ftb10syaNSv69+9fhfTLN2/evDjvvPPi888/z1074YQTolevXnl7TwAAYM3w/FP/jJKSuat0zwdvvRb9nuhT6dovDz+mOmMBAABQC5WUlFQaN2jQYKXvXdTrRUSUlpZWW6YkpVJU//Of/4yjjz46GjVqlMbbp2a99dbLvX7rrbeWO3f27Nlx3XXX5SXHM888E6+99lpufN5558X222+fGzdu3Dj+8pe/5A5dnzRpUlx77bXLfF7btm1zr999992oqKhY7vtff/31eTujury8PC644IJK25EfeeSR8Yc//CEv7wcAAKxZnnnsofjdyUdEn3tvi2++GhILFpQvc+633wyPu26+Jm6/4YqoqFiQu77jbnvGzrvvnURcAAAA1mJNmzatNJ46depK3ztlypTc6+bNm1dXpESltvV3bbTHHnvEd999FxER/fr1i9133z0OPfTQJeaNHTs2Lrzwwvj222+joKBghcXvqvjhhx/iT3/6U27cuXPnOOecc5aYt+OOO8Y555wT9957b0REvPrqq9G3b9845pglVw3svvvu8e9//zsiIsaMGRM333xzXH755bmie5HZs2fHn/70p3jhhReq/XNFLFzZ3atXrxg4cGDu2sEHHxw333yzLSoAAICcmTOK46V+/4qX+v0r6tatFxtstEk0X6dlNGrcJMrLy2L2rJnx/bcjY2bx9CXu7dhp67jw6ptSSA0ARET8OGH8Uq/PnjWz0ri4uHipc+vWrRstW7XOSzYAWFUdOnSoNP7ggw9i5513XuF933//fYwbN26Zz1lTKKoTdPrpp8dTTz0VZWVlsWDBgrjwwgvjqaeeij333DNatGgRM2fOjE8//TQGDhwY8+fPj4YNG8ZJJ50UDz30ULW8f3l5eVxyySUxd+7Cbe4aNWpUaeX0z5133nnx3nvvxRdffBERETfeeGPssssu0b59+0rzDjzwwNhoo41yJfyjjz4aH3zwQRx88MGx/vrrR2lpaYwYMSJee+21mD594V/09OjRI+66665q+VyLfPLJJ/Hiiy9WujZkyJA45JBDVvoZ2223XfTu3btacwEAADXX/Pnz4ttvhq9wXiaTiV8ecUyc0v2CaNCg4QrnAwD5cewRv1ypeffdeVvcd+dtS1zfYadd4p4HHqnmVABrnwLr/xKx0047Rf369XNbdz/++ONxwgknxLrrrrvc+37eZe2xxx55y5hPiuoEtW/fPv74xz/GVVddlVtN/OGHH8aHH364xNyGDRtG7969l3s29Kq67777cqVzRMS1114bG2644TLnLzq7+qijjoq5c+fG3Llz49JLL40nnniiUrldWFgYd955Z5x66qkxc+bCn1wcNWrUUg9uz2Qyce6558aRRx5Z7UX1ggULlrg2YcKEVXrG4tuzAwAAa59L/vCX+PiDt2PIZ/8b438Ys8Kdnpo2ax5d9jkoDjr86Nho080TSgkAAEBtUL9+/Tj++OPjH//4R0Qs3BHkrLPOirvuuis23njjJeaXlpbGTTfdFK+++mruWtu2beNXv/pVYpmrk6I6YUcffXS0bt06brrppvj222+X+H6dOnVi9913j6uuuio23njj6NevX7W872effRZ///vfc+NDDjkkjjrqqBXe16FDh7jqqqviqquuioiIzz//PO69997o2bNnpXmdOnWKZ555Jq6//vp4//33l/qsTp06xUUXXRT77LNPpe0IAAAAkrLdjrvGdjvuGhERc+fMjh++Gx2TfxwfM4qnx/x5pVFQUCcaNm4czZqtExt13DzWa7fsH+4FAACAqjrvvPPi7bffzu1c/M0338Thhx8ee++9d+y0007RokWLKCkpiW+++SZee+21+Omnn3L31qlTJ66//vqoW7duSumrJpPNZrNph6iNstlsDB06NIYNGxbFxcXRuHHjWHfddaNz587RuvWafUbK2LFj45NPPonJkydHUVFRtG7dOjp16hQdO3ZMO1qN9uGo4rQjAACrqHF9P/cJAGua9ZrXTzsCALCKWjf25++k/b7/12lHSNxfj+yU2nuPHTs2fve738WIESNW+p6GDRvGDTfcEIcffngek+WXohpqCEU1AKx5FNUAsOZRVAPAmkdRnTxFdfLmz58fjz/+eDzxxBPxww8/LHNew4YN4/DDD4/u3bsv94jfNYFf2QAAAAAAAEBOQSbtBLVP3bp144wzzogzzjgjfvjhhxg6dGhMnTo15syZE3Xr1o1mzZrFZpttFltuueUau9X3zymqAQAAAAAAAGqI9u3bR/v27dOOkXcFaQcAAAAAAAAAoHZRVAMAAAAAAACQKEU1AAAAAAAAAIlyRjUAAAAAAACQk8lk0o5ALWBFNQAAAAAAAACJWqNXVE+aNClOOumkiFj4kx0DBgxIOREAAAAAAAAAK7JGF9Xl5eUxfvz4iLAFAQAAAAAAAMCawtbfAAAAAAAAACRqjV5RDQAAAAAAAFSvAhsZkwArqgEAAAAAAABIlKIaAAAAAAAAgEQpqgEAAAAAAABIlKIaAAAAAAAAgEQVph0AAAAAAAAAqDkymbQTUBtYUQ0AAAAAAABAohTVAAAAAAAAACRKUQ0AAAAAAABAopxRDQAAAAAAAOQUOKSaBFhRDQAAAAAAAECi8rKiulu3bvl47BLmz5+fyPsAAAAAAAAAUH3yUlQPHjw4MgltCZDJZCKbzSbyXgAAAAAAAABUna2/AQAAAAAAAEhUXlZUR4RVzgAAAAAAALAGstKVJOSlqH700Ufz8VgAAAAAAAAA1gJ5Kap33XXXfDwWAAAAAAAAgLWAlfsAAAAAAAAAJEpRDQAAAAAAAECi8rL1NwAAAAAAALBmymTSTkBtsFasqC4uLo6//vWvaccAAAAAAAAAYCWs0UX1Tz/9FH/5y19i//33j/vvvz/tOAAAAAAAAACshDVy6+/JkyfHQw89FE8//XSUlpZGNpuNjD0IAAAAAAAAANYIa1RRPWHChHjggQeiX79+UVZWpqAGAAAAAAAAWAMlUlRPnjw5Xn/99Rg8eHBMnDgxZsyYEfXq1Yv1118/dtlllzjiiCOiVatWy7z/xx9/jPvuuy+effbZWLBgQWSz2YiIyGQyudf77LNPEh8FAAAAAAAA1moFFoqSgLwW1dlsNu6444549NFHY968eZWuR0R88803MXDgwLjrrruiZ8+eccYZZ1S6v6ysLP7+97/H//zP/8S8efNyK6gXFdSZTCZ+9atfRffu3aNTp075/CgAAAAAAAAAVJO8FdUVFRXxu9/9Lt56661KK6AX/8+IhaV1SUlJ3HrrrVFcXBwXXnhhRESMGzcuevToESNGjFiioC4qKoqjjjoq/t//+3/RoUOHfH0EAAAAAAAAAPIgb0X1Qw89FAMHDswVzBH/XUm9uMW/98ADD8S+++4brVu3jhNPPDGmTp2aK6mz2Ww0aNAgjjvuuDjzzDOjTZs2+YoOAAAAAAAAQB7lpaieO3du3H///ZVK6FatWsWRRx4Z2267bTRr1ixmz54dw4cPj/79+8f48eNzc++///6YO3duTJkyJXetQYMGccopp8SZZ54ZzZs3z0dkAAAAAAAAABKSl6L6lVdeiTlz5uSK5n333Tduv/32aNiwYaV5Bx10UJx33nlx3XXXRd++fSOTycQ777yTW3mdzWZjv/32iz/84Q9WUAMAAAAAAEACFjvFF/KmIB8P/fjjjyNiYdG83nrrxR133LFESb1IYWFh3HDDDbHNNttENpvNfWUymTjjjDPib3/7m5IaAAAAAAAAYC2Sl6L6q6++ioiF508ff/zx0aBBg+WHKCiIU089tdK19u3bR69evfIRDwAAAAAAAIAU5aWonjZtWu71TjvttFL37LLLLrnXmUxmieIaAAAAAAAAgLVDXorqmTNn5l63bt16pe5p1apVpfFmm21WrZkAAAAAAAAAqBkK8/HQ+fPn517XrVt3pe5ZNG/R+dRt27bNRzQAAAAAAABgOQoyaSegNsjLiurqUFiYlw4dAAAAAAAAgJTV2KIaAAAAAAAAgLWTohoAAAAAAACAROV9f+1JkyYldl+7du1W670AAAAAAACAhQoyDqkm//JWVGcymchms3HSSSet8r2rc18mk4mvvvpqld8LAAAAAAAAgGTldUX1orJ6VeYvsir3AQAAAAAAALDmyPvW35nV3BpgVe5TagMAAAAAAACsOfJSVDsrGgAAAAAAAIBlyUtR/eabb+bjsQAAAAAAAECereaGybBKCtIOAAAAAAAAAEDtoqgGAAAAAAAAIFF52fr7ueeey70++OCDo0GDBvl4GwAAAAAAAADWQHkpqi+//PLI/N/m9bvuuquiGgAAAAAAAICcvBTVERHZbDZXVgMAAAAAAABrhgIVHwlwRjUAAAAAAAAAiVJUAwAAAAAAAJAoRTUAAAAAAAAAiVJUAwAAAAAAAJCowrQDAAAAAAAAADVHJjJpR6AWsKIaAAAAAAAAgEQpqgEAAAAAAABIVN63/p40aVK+3yKnXbt2ib0XAAAAAAAAAKsnb0V1JpOJbDYbJ510Ur7eYon3++qrrxJ5LwAAAAAAAABWX95XVGez2Xy/BQAAAAAAAFBNCjJpJ6A2yHtRncnk/59kZTgAAAAAAADAmiOvRXUmk4l111036tSpk8+3AQAAAAAAAGANkreiOpvNRiaTiX/961/Rrl27fL0NAAAAAAAAAGuYvG/9DQAAAAAAAKw5nFFNEgrSDgAAAAAAAABA7aKoBgAAAAAAACBRimoAAAAAAAAAEqWoBgAAAAAAACBRhWkHAAAAAAAAAGqOTCaTdgRqASuqAQAAAAAAAEhU3opqP2kBAAAAAAAAwNLkrajOZrP5ejQAAAAAAAAAa7C8nFH96KOP5l63atUqH28BAAAAAAAAwBoqL0X1rrvumo/HAgAAAAAAAHlW4IRfEpC3rb8BAAAAAAAAYGkU1QAAAAAAAAAkSlENAAAAAAAAQKIU1QAAAAAAAAAkqjDtAAAAAAAAAEDNkcmknYDawIpqAAAAAAAAABKlqAYAAAAAAAAgUYpqAAAAAAAAABKlqAYAAAAAAAAgUYVpBwAAAAAAAABqjoJMJu0I1AJWVAMAAAAAAACQKEU1AAAAAAAAAIlSVAMAAAAAAACQKGdUAwAAAAAAADkFjqgmATWmqC4rK4vhw4fHt99+GzNnzozZs2dHRUXFKj2jR48eeUoHAAAAAAAAQHVJvaj+8ssv45FHHokBAwZEWVlZlZ6lqAYAAAAAAACo+VIrqrPZbNxxxx3x0EMPRTabjWw2u9R5mUym0j1L+342m600DwAAAAAAAICaK7Wi+tZbb41HHnlkqSXz8srpn39vWQU3AAAAAAAAADVTKkX1oEGDok+fPpHJZCKTyURRUVGcfPLJccABB0RFRUV069YtIhaW0m+88UbMmTMnpk6dGp9//nm8+OKL8e2330Ymk4kWLVrEH/7wh9h6663T+BgAAAAAAACw1rGRMUlIpai+//77I2LhiugGDRpEnz59YocddoiIiPHjx1eau/7660dExOabbx677757nHfeefHcc8/FjTfeGNOnT49evXrFPffcE3vssUeinwEAAAAAAACA1VOQ9BvOnj07Pvroo9xq6t/97ne5knplHXXUUfHwww9HgwYNoqSkJHr27LlEwQ0AAAAAAABAzZR4Uf3ZZ59FRUVFZLPZKCoqihNOOGG1nrPddttFz549IyJi7ty5cc8991RnTAAAAAAAAADyJPGi+scff4yIhedPb7HFFtG4cePlzi8rK1vm90488cRo0KBBZLPZeO2112LevHnVmhUAAAAAAACA6pd4UV1cXJx73bZt2yW+X1RUVGm8vPK5Xr16sd1220XEwlXVH3/8cfWEBAAAAAAAgFqqIDK17ovkJV5UL65+/fpLXGvUqFGl8bRp05b7jFatWuVeT5o0qXqCAQAAAAAAAJA3iRfVTZs2zb2ePXv2Et9v1KhRpVXVY8eOXe7z5s+fn3s9derUakgIAAAAAAAAQD4lXlRvuOGGuddTpkxZ6pxNNtkk9/qzzz5b7vOGDRuWe720FdoAAAAAAAAA1CyJF9UdO3aMiIhsNhujRo2KbDa7xJxtt902N6d///5RXl6+1Ge9+eabMWHChNy4Xbt2eUgMAAAAAAAAQHVKvKhu06ZNblV1aWlpfPnll0vMOeSQQyIiIpPJxPjx4+Pyyy+P0tLSSnM+/vjjuPLKKyOTWXi4eZ06dWKXXXbJc3oAAAAAAABYu2Uyte+L5BWm8aZ77LFHPPnkkxGxcFX09ttvX+n7u+++e2y22WYxatSoiIh46aWX4p133okdd9wxGjduHN99910MGzYstxo7k8nEYYcdFs2aNUv2gwAAAAAAAACwyhJfUR0Rcdhhh0XEwq29+/btG2VlZZVDFRTEH//4xygqKspdmzlzZrz99tvx0ksv5UrqRaupW7duHZdddllyHwAAAAAAAACA1ZbKiuqdd945/vSnP0VFRUVELCyhW7ZsWWlO586d45577onLLrssiouLl/qcbDYbHTp0iL/97W9L3A8AAAAAAABAzZRKUZ3JZOKYY45Z4by99947Xn311Xj88cfjnXfeie+//z5mzZoVTZs2jc033zwOPvjgOOaYY6Ju3boJpAYAAAAAAACgOmSyiw56BlL14ajitCMAAKuocf1Ufu4TAKiC9ZrXTzsCALCKWjf25++k/f3D79KOkLhzumyUdoRaJ5UzqgEAAAAAAACovRTVAAAAAAAAACRqrSmqf/rpp7QjAAAAAAAAALASUimqb7jhhigrK6u253344Ydx1FFHVdvzAAAAAAAAAMifVE6ff/zxx+Ozzz6Lv/71r9G+ffvVfk42m4277rorHnjggaioqKjGhAAAAAAAAFA7FWQyaUegFkht6+/hw4dH165d44UXXlit+ydNmhSnnnpq/P3vf48FCxZUczoAAAAAAAAA8iXVM6rnzJkTl112WVx55ZVRWlq60ve9+eab8etf/zo++eST3LWCgrXmuG0AAAAAAACAtVoq7e5hhx0W2Ww2MplMZLPZePbZZ+OYY46Jb775Zrn3lZWVxY033hi/+93vYsaMGRGxcPvv1q1bx8MPP5xEdAAAAAAAAACqKJWiunfv3nHDDTdEvXr1IvN/e9yPHj06jjvuuPj3v/+91Hu+//77OP744+Pxxx+vVHLvvffe0b9//9htt92S/AgAAAAAAACwVspkat8Xyctks9lsWm8+cuTIuPDCC2PUqFG54jmTycTBBx8cN954YzRu3DgiIvr37x9//OMfY+7cuRGxcBV1YWFhXHTRRXHmmWemFR+q1YejitOOAACsosb1C9OOAACsovWa1087AgCwilo39ufvpD046Pu0IyTu7N06pB1hCTNmzIjPPvssJk+eHD/99FMUFRXFuuuuG5tuumlsscUWUadOnbQjVkmqv7I322yz6Nu3b9xwww3xzDPP5MrqV199NYYNGxY33nhjPPfcc/Hcc89VWkW9wQYbxO233x7bbbddmvEBAAAAAAAAqtXHH38cf//73+Ojjz6KsrKypc5p2LBh7LHHHnHjjTdG8+bNkw1YTVJdUb24l156Ka699tqYM2dO7tqibcEXj/irX/0qbrjhhtxqa1hbWFENAGseK6oBYM1jRTUArHmsqE6eFdXpmD9/ftx4443x1FNPxcpWuK+99lp06JB+9tVRY35lH3bYYbHNNtvERRddFMOGDcutnl6kQYMGceWVV8axxx6bYkoAAAAAAACA6jV//vzo2bNnDBw4MHetSZMmsffee0enTp2iZcuWUVpaGhMmTIgvv/wyPv300ygvL08xcdXVmKI6IqJVq1ax/vrrx7BhwyIiKp1b3blz5zj00ENTTggAAAAAAABrt4L/2/WY5Fx33XWVSupu3brFBRdcsMxdpmfMmBH9+vWLhg0bJhWx2hWkHWCRYcOGRdeuXeP111+vtOX3otcffvhhHH300bkSGwAAAAAAAGBN9/7770e/fv1y48suuyyuuuqq5R6F3KxZszjjjDOidevWSUTMixpRVP/jH/+IE088MX744YeIWFhQN2rUKLp37x4NGjTIzfv+++/jhBNOiH/84x9pRQUAAAAAAACoFtlsNv74xz/mxnvssUecddZZKSZKTqpF9cyZM+O8886LW265JebPn5/b6nubbbaJZ599Ni666KLo169fdOrUKbe6uqysLG655ZY499xzo7i4OM34AAAAAAAAAKvtww8/jO+++y43/v3vf59alqSlVlR/9tlncdRRR8XAgQNzJXQ2m41u3brFv/71r9hwww0jImKjjTaKf//733HKKadUmvfWW29F165d45NPPknrIwAAAAAAAACstr59++Zed+jQIbbbbrsU0yQrlaL6gQceiFNPPTUmTJiQu9a0adO4995748orr4yioqJK8+vWrRtXX3113HPPPdG0adPcudU//vhjnHbaafG3v/0t0fwAAAAAAACwtspkat9XWj766KPc65133jm9ICkoTONNb7/99shkMrnV0Z07d47bb7892rZtu9z7DjzwwNhqq63ioosuis8//zwymUyUl5fHXXfdFYMGDYpHHnkkmQ8AAAAAAAAAUAUTJkyIqVOn5sabb755RESUlJTE888/Hy+++GKMGTMmiouLo3nz5rHxxhvHHnvsEccee2y0bNkyrdjVJtUzqiMizj777HjsscdWWFIv0q5du3j88ceje/fuERG5snvQoEH5jAkAAAAAAABQbb7++utK4zZt2sSXX34ZRx55ZFx77bUxePDgmDJlSpSVlcWUKVNi8ODBcccdd8SBBx4Yjz76aEqpq08qK6ojItZZZ5249dZbY88991zle+vUqRMXXXRR7LbbbtGrV69KP2kAAAAAAAAAsComTJhQ6dji1dGuXbto167dSs+fPn16pfG4cePiqquuijlz5kTEwgW7LVq0iEwmE9OmTYtsNhsREXPnzo0//elPMXHixLjsssuqlDlNqRTVu+22W9x2223RunXrKj1njz32iP79+8cll1xSaf92AAAAAAAAgJXVt2/fuOeee6r0jB49esT555+/0vNnzZpVaXznnXdGWVlZFBUVRffu3ePEE0/M9anTpk2Lf//73/G3v/0t5s+fHxER//M//xPbb799HHzwwVXKnZZUiupHHnkkMtV0KnnLli3j4YcfjgceeKBangcAAAAAAAC1WepnB9cSc+fOrTQuKyuLTCYTd955ZxxwwAGVvteyZcs477zzYtttt43u3btHRUVFRETceuutceCBB0adOnUSy11dUvnnrLpK6sWf99vf/rZanwkAAAAAAACQL/Xq1Vvi2m9+85slSurF7bXXXnHCCSfkxuPGjYt33nknL/nyLbUzqgEAAAAAAABqgmOOOSa6dOlSpWesyvnUERENGzZc4topp5yywvtOOeWUeOKJJ3Ljjz76KPbbb79Veu+aQFENAAAAAAAA1Grt2rVb5aK5qho3blxp3KRJk9hiiy1WeN+mm24aLVq0iJ9++ikiIoYPH56XfPlmi3kAAAAAAACAhG2wwQaVxm3btl3pI5Tbtm2bez19+vRqzZWUal9R/b//+79LXNtll11WOKc6/Px9AAAAAAAAgFWzsmUpVdOxY8dK46KiopW+t27durnX8+fPr7ZMSar2ovrUU0+t9A9vJpOJr776arlzqsPS3gcAAAAAAACgJmrSpEmsv/76MX78+IiImDlz5krfu/jc5s2bV3e0RORt6+9sNpv7Wpk51fEFAAAAAAAAsKbYZ599cq/Hjx8fs2fPXuE9paWl8f333+fGP99CfE2Rl6J6ZUpjxTIAAAAAAABQm/3yl7/Mva6oqIjXX399hfe88cYbUV5enhvvuuuuecmWb9W+9ffNN99cLXMAAAAAAACA5DmhOjm/+MUvYosttogRI0ZERMS9994bBx98cDRs2HCp8+fNmxd33313btygQYM46KCDEsla3aq9qO7atWu1zAEAAAAAAABYm2Uymbj44ouje/fuERExduzYOO+88+KOO+6IddZZp9LcmTNnxkUXXRRjxozJXTv55JOjRYsWiWauLtVeVAMAAAAAAACwcvbZZ5/o1q1bPProoxER8eGHH8YhhxwShx56aGyxxRYRETFy5Mh46aWXYvr06bn7tt1227jgggtSyVwdFNUAAAAAAAAAKbriiiuipKQknn766YiIKC4ujieeeGKZ83fddde4++67o27duklFrHYFaQcAAAAAAAAAqM0KCgrixhtvjHvvvTe23HLLZc5r27ZtXHvttfHwww9H8+bNkwuYB1ZUAwAAAAAAADkFmUzaEWqtAw88MA488MAYPXp0DB8+PCZPnhwLFiyIli1bxlZbbRWdOnVKO2K1UVQDAAAAAAAA1CCbbrppbLrppmnHyKsaVVRns9mYOHFizJgxI2bPnh3ZbHaV7t9ll13ylAwAAAAAAACA6pJ6UV1aWhrPPfdcvPzyyzF06NAoKSlZredkMpn46quvqjkdAAAAAAAAANUt1aL63Xffjcsvvzx++umniIhVXkENAAAAAAAAwJontaL6pZdeiksvvTQqKiqW+F5msQPaf15eL+97AAAAAAAAQNVkVjwFqiyVovr777+Pq666KioqKiKTyUQ2m42tttoqDjjggKhbt2707t07IhaW0jfffHPMmTMnpkyZEl988UV8/PHHUV5eHplMJlq0aBHnnntuNG7cOI2PAQAAAAAAAMBqSKWovv/++6O0tDQ3vvzyy+P000+PiIjx48fniuqIiK5du1a6d9KkSfHXv/41nn322Zg+fXo89thj8fDDD8f666+fSHYAAAAAAAAAqqYg6TcsKyuLl19+OTKZTGQymTj22GNzJfXKaNOmTdx8881x3XXXRTabjR9++CHOPvvsKCkpyV9oAAAAAAAAAKpN4kX1kCFDorS0NLLZbGQymfjtb3+7Ws858cQT4/jjj49sNhtjxoyJBx54oJqTAgAAAAAAAJAPiRfV3333XUQsPH96o402WuGW3QsWLFjm93r27BkFBQs/Qr9+/aotIwAAAAAAANRWmUzt+yJ5iRfVM2bMyL3eeOONl/h+nTp1Ko3nz5+/zGe1bNkyttlmm8hmszF58uT4/PPPqy0nAAAAAAAAAPmReFG9ePHcqFGjJb7fsGHDSuPp06cv93nt2rXLvR47dmwV0wEAAAAAAACQb4kX1YuX06WlpUt8v3HjxpFZbH39jz/+uNznLdr6OyJiypQp1ZAQAAAAAAAAgHxKvKheb731cq+Xtlq6oKAgNtxww9x46NChy33emDFjqi8cAAAAAAAAAHmXeFG9ySabRERENpuNkSNHLnVOp06dcq9feeWVZT5r5MiRMXz48NwK7FatWlVjUgAAAAAAAKh9MplMrfsieakU1c2bN4+IiBkzZsQPP/ywxJwDDjggIhaW2V988UU8/vjjS8yZMWNG9OrVKzcvImLHHXfMU2oAAAAAAAAAqkviRXVExC9+8Yvc64EDBy7x/YMOOijWWWedyGQykc1m48Ybb4yzzjor+vTpE08//XTceuutceihh+ZWU2cymdh5551jgw02SPJjAAAAAAAAALAaCtN404MPPjj+85//RDabjX79+sVpp51W6fsNGzaMSy+9NK688spcWf3BBx/EBx98kJuTzWZz36tbt25udTUAAAAAAAAANVsqRfX+++8fRx55ZFRUVERExMSJE2O99darNOfoo4+OcePGxX333bfUfeEXldT16tWLP//5z7HNNtskkh0AAAAAAADWZqlsyUytk8kuOuC5hho8eHDcd9998fHHH0d5eXnueoMGDWLfffeNHj16xKabbppiQqgeH44qTjsCALCKGtdP5ec+AYAqWK95/bQjAACrqHVjf/5O2r8/G592hMQd33n9tCPUOjX+V/auu+4au+66a8ydOzcmTJgQs2bNiqZNm8aGG24YdevWTTseAAAAAAAAAKsoL0X1FVdckXvdq1evaN68eZWf2bBhw+jYsWOVnwMAAAAAAABAuvJSVD/77LO5c6XPP//8FRbVzz33XO71wQcfHA0aNMhHLAAAAAAAAABqgLxt/Z3NZnNl9Ypcfvnlubm77rqrohoAAAAAAABSsrIdH1RFQdoBFslms2lHAAAAAAAAACABNaaoBgAAAAAAAKB2UFQDAAAAAAAAkChFNQAAAAAAAACJKkw7AAAAAAAAAFBzZNIOQK1gRTUAAAAAAAAAiVJUAwAAAAAAAJAoRTUAAAAAAAAAiVJUAwAAAAAAAJCowny/QSazasetr+p8AAAAAAAAoPro60hC3orqRf8An3jiiVGnTp2Vvm9V5y/+fgMGDFjl+wAAAAAAAABIVl5XVGez2Zg4cWLe5i/OT3YAAAAAAAAArBnyWlQnVR5ns9lE3gfyqfNGzdOOAACsolml5WlHAABW0UdjpqUdAQBYRUds2ybtCEAe5K2oVh4DAAAAAAAAsDR5KarfeOONfDwWAAAAAAAAyLOCtANQK+SlqF5//fXz8VgAAAAAAAAA1gJ+IAIAAAAAAACARCmqAQAAAAAAAEiUohoAAAAAAACAROXljGoAAAAAAABgzZTJZNKOQC1gRTUAAAAAAAAAiVJUAwAAAAAAAJAoRTUAAAAAAAAAiXJGNQAAAAAAAJDjhGqSYEU1AAAAAAAAAIlSVAMAAAAAAACQKEU1AAAAAAAAAIlSVAMAAAAAAACQqMK0AwAAAAAAAAA1RyaTdgJqAyuqAQAAAAAAAEiUohoAAAAAAACARCmqAQAAAAAAAEiUohoAAAAAAACARBWmHQAAAAAAAACoOQoik3YEagErqgEAAAAAAABIlKIaAAAAAAAAgEQpqgEAAAAAAABIlKIaAAAAAAAAgEQVph0AAAAAAAAAqDkymbQTUBtYUQ0AAAAAAABAohTVAAAAAAAAACRKUQ0AAAAAAABAohTVAAAAAAAAACSqMO0AAAAAAAAAQM2RiUzaEagFrKgGAAAAAAAAIFGKagAAAAAAAAASpagGAAAAAAAAIFHOqAYAAAAAAAByMo6oJgFWVAMAAAAAAACQKEU1AAAAAAAAAIlSVAMAAAAAAACQKEU1AAAAAAAAAIkqTDsAAAAAAAAAUHMURCbtCNQCVlQDAAAAAAAAkChFNQAAAAAAAACJUlQDAAAAAAAAkChFNQAAAAAAAACJKkw7AAAAAAAAAFBzZDJpJ6A2sKIaAAAAAAAAgEQpqgEAAAAAAABIlKIaAAAAAAAAgEQpqgEAAAAAAABIVGHaAQAAAAAAAICaI5NJOwG1gRXVAAAAAAAAACRKUQ0AAAAAAABAohTVAAAAAAAAACRKUQ0AAAAAAABAogrTDgAAAAAAAADUHJnIpB2BWsCKagAAAAAAAAASpagGAAAAAAAAIFGKagAAAAAAAAAS5YxqAAAAAAAAIKfAEdUkwIpqAAAAAAAAABKlqAYAAAAAAAAgUYpqAAAAAAAAABKlqAYAAAAAAAAgUYVpBwAAAAAAAABqjkxk0o5ALWBFNQAAAAAAAACJUlQDAAAAAAAAkChFNQAAAAAAAACJUlQDAAAAAAAAkKjCtAMAAAAAAAAANUcmk3YCagMrqgEAAAAAAABIlKIaAAAAAAAAgEQpqgEAAAAAAABIlKIaAAAAAAAAgEQVph0AAAAAAAAAqDkykUk7ArWAFdUAAAAAAAAAJEpRDQAAAAAAAECiFNUAAAAAAAAAJEpRDQAAAAAAAECiCtMOAAAAAAAAANQcBZm0E1AbWFENAAAAAAAAQKIU1QAAAAAAAAAkSlENAAAAAAAAQKIU1QAAAAAAAAAkqjDtAAAAAAAAAEDNkYlM2hGoBayoBgAAAAAAACBRimoAAAAAAAAAEqWoBgAAAAAAACBRzqgGAAAAAAAAcjKOqCYBVlQDAAAAAAAAkChFNQAAAAAAAACJUlQDAAAAAAAA1GBPPfVUbLHFFpW+7r777rRjVYmiGgAAAAAAAKCGmjp1atx2221px6h2hWkHAAAAAAAAAGqOTNoBqOSmm26KGTNmpB2j2llRDQAAAAAAAFADvfPOO/HSSy9FRMQmm2yScprqpagGAAAAAAAAqGFKSkriD3/4Q0REFBUVxZVXXpluoGqmqAYAAAAAAACoYe66664YP358REScffbZsfHGG6ecqHopqgEAAAAAAABqkOHDh8ejjz4aERHt27ePc845J+VE1a8w7QAAAAAAAABAzVGQyaQdoVarqKiIa665JsrLyyMi4pprrol69eqlnKr6WVENAAAAAAAAUEM89thjMWTIkIiIOPjgg2PvvfdOOVF+KKoBAAAAAAAAaoCJEyfGX//614iIaNSoUVx11VXpBsojW38DAAAAAAAAtdqECRNiwoQJVXpGu3btol27dlV6xvXXXx9z5syJiIiePXtGmzZtqvS8mkxRDQAAAAAAANRqffv2jXvuuadKz+jRo0ecf/75q33/a6+9Fm+++WZERGy55ZZx6qmnVilPTaeoBgAAAAAAAHIyaQeohWbPnh033HBDRERkMpn4wx/+EHXq1Ek5VX45oxoAAAAAAAAgRb17947JkydHRMRxxx0XO+ywQ7qBEmBFNQAAAAAAAFCrHXPMMdGlS5cqPWN1z6f+/PPP48knn4yIiBYtWsTFF19cpRxrCkU1AAAAAAAAUKu1a9dutYvmqigvL49rrrkmKioqIiKiV69e0axZs8RzpMHW3wAAAAAAAAApePjhh+Obb76JiIhdd901jjrqqHQDJciKagAAAAAAAOC/MmkHqB2mTJkS9957b0REFBUVxXXXXZdyomQpqgEAAAAAAAASNnXq1CgtLY2IiEwmE+eee+5y5y9YsKDS+J///Gc8//zzufFtt90W22+/ffUHzRNFNQAAAAAAAECK5s+fHz/88MMq3TNjxoyYMWNGbryo9F5TOKMaAAAAAAAAgERZUQ0AAAAAAADkZBxSnYgtt9wyRowYsdLzx40bFwcccEBu3KNHjzj//PPzES0RVlQDAAAAAAAAkChFNQAAAAAAAACJUlQDAAAAAAAAkChFNQAAAAAAAACJKkw7AAAAAAAAAFBzZDJpJ6A2UFQDAAAAAAAA1HAbbLBBjBgxIu0Y1cbW3wAAAAAAAAAkSlENAAAAAAAAQKIU1QAAAAAAAAAkyhnVAAAAAAAAQE4m7QDUClZUAwAAAAAAAJAoRTUAAAAAAAAAiVJUAwAAAAAAAJAoRTUAAAAAAAAAiSpMOwAAAAAAAABQg2TSDkBtYEU1AAAAAAAAAIlSVAMAAAAAAACQKEU1AAAAAAAAAIlSVAMAAAAAAACQqMK0AwAAAAAAAAA1RyYyaUegFrCiGgAAAAAAAIBEKaoBAAAAAAAASJSiGgAAAAAAAIBEOaMaAAAAAAAAyMk4opoEWFENAAAAAAAAQKIU1QAAAAAAAAAkSlENAAAAAAAAQKIU1QAAAAAAAAAkqjDtAAAAAAAAAEDNkUk7ALWCFdUAAAAAAAAAJEpRDQAAAAAAAECiFNUAAAAAAAAAJEpRDQAAAAAAAECiCtMOAAAAAAAAANQgmbQDUBtYUQ0AAAAAAABAohTVAAAAAAAAACRKUQ0AAAAAAABAohTVAAAAAAAAACSqMO0AAAAAAAAAQM2RiUzaEagFrKgGAAAAAAAAIFGKagAAAAAAAAASpagGAAAAAAAAIFGKagAAAAAAAAASVZh2AAAAAAAAAKDmyGTSTkBtYEU1AAAAAAAAAIlSVAMAAAAAAACQKEU1AAAAAAAAAIlSVAMAAAAAAACQqMK0AwAAAAAAAAA1RybtANQKVlQDAAAAAAAAkChFNQAAAAAAAACJUlQDAAAAAAAAkChnVAMAAAAAAAD/5ZBqEmBFNQAAAAAAAACJUlQDAAAAAAAAkChFNQAAAAAAAACJUlQDAAAAAAAAkKjCtAMAAAAAAAAANUcmMmlHoBawohoAAAAAAACARCmqAQAAAAAAAEiUohoAAAAAAACARCmqAQAAAAAAAEhUYdoBAAAAAAAAgJojk0k7AbWBFdUAAAAAAAAAJEpRDQAAAAAAAECiFNUAAAAAAAAAJEpRDQAAAAAAAECiCtMOAAAAAAAAANQcmbQDUCtYUQ0AAAAAAABAohTVAAAAAAAAACRKUQ0AAAAAAABAohTVAAAAAAAAACSqMO0AAAAAAAAAQA2SSTsAtYGiGgDyoLy8PL74/LOYMH58TJkyORo3bhzrtlkvtt9hh1hnnRZpxwMAAAAAgFQpqgGgGpWUlMQDf78v+j/bL6ZNm7rE9wsLi2LPvfaKHj1/H5ttvkUKCQGAxVVUVMR3Y76N4cOGxPBhQ+Lrr4bG6JHfRFlZWW7OldfdGIf+umuKKQEAAGDto6heSwwaNCi6deuWG48YMSLFNAC106hRI+OSC3vGmG+/Xeac8vKyeGvgm/HhB+/HJb2uiOOOPzHBhADAIgMHvBp9n/pXjBg+LErmzk07DgCwAk/ec1N8/NZ/VuveNhtuHJfe8Y9qTgQAVJWimrXWnDlzYtSoUTF+/PiYPHlylJSURJ06daJZs2bRoUOH2GabbaJx48ZpxwTWElOmTI5zu58VkydNqnR9q623jg022DCKi4tj2NAhMWfOnIiImDdvXvzpj3+Ixo0ax6GHH5FCYgCo3b78/NP4/JP/TTsGAABAjZRxSDUJUFSvpH79+sUVV1yx2vdb4ZyM77//Pu6///745JNP4vvvv49sNrvMuYWFhbHPPvtE9+7dY4cddkguJLDWyWazcfHve1YqqTfbfPO46Za/xOZbdMpdmzlzZtx7953x5BOP5a794dqrYvNOnaJjx80SzQwALF3jxk2iQcOGMWXypBVPBgAAAFabopq1ysiRI6Nv374rNbe8vDzeeOONePPNN+Oss86KSy+9NM/pgLXVG6+/Fl98/lluvP4GG8TDjzwWTZs1qzSvadOmccVV10RBQSaeeOyfEbFwZfW9d98Zd9x5T6KZAYCIevXqx2ZbdIpOW20TW269TWy51TaxYYeN4uEH7os+D9yXdjwAYDmuvO/fKz23TmFRHpMAAKtLUb2a1l133ahfv37aMXJ22203q7Z/pnXr1rH99tvHJptsEuutt140bNgwSkpK4ocffoj3338/vvnmm4hYuBLyoYceiohQVgOr5e9/q1wyX3n1tUuU1Ivr+fuL460334wJE8ZHRMSbA16Pr4cPj05bbpnXnADAf3U767fxu99fGoWF/lgMAGuiFuu2TTsCAFBF/kS+mm677bbYbbfd0o7Bz6y77rpx8cUXxwEHHBCbbrrpcue+/PLLceWVV0ZJSUlERDz88MNx+OGHx5aKImAVjPxmRIz8vx98iYjYZJNNY8+99lnuPQ0aNIjfHHdC3PXX3rlrr7z0gqIaABK0zjot0o4AAAAAtVpB2gGgOm233XbRvXv3FZbUERGHHnpo3HDDDblxRUXFSm8bDrDI228NrDQ+9PAjVuq+w34276233qy2TAAAAAAAVZHJ1L4vkmdFdYrmzJkTI0aMiDFjxsT06dNjwYIF0bRp02jXrl3stNNO0bhx47Qjrpby8vIYOXJkjB49OqZOnRolJSXRpEmTaNmyZey4447Rpk2btCPmHHbYYfGnP/0ppk+fHhERQ4cOTTkRsKb58IP3K4133GnnlbpvvbZto1279XPbf383ZkxM/PHHWK+trcsAAAAAAFj7KaoTNmXKlHjxxRfj1VdfjSFDhkR5eflS59WpUyf233//6NmzZ2y++eYrfO6gQYOiW7duufHSzqu+5ZZbok+fPrnx3XffHb/85S+X+9yKioo47bTTYvDgwRERUb9+/ejbt2907Nix0rzS0tJ47bXX4uWXX47BgwfHnDlzlvnMbbbZJnr06BH77bffCj9XvhUUFESHDh1yRfWi/wRYWaNHj8q9LigoiK223mal7912++1zRXVExOhRIxXVAAAAAADUCrb+TtjDDz8ct9xyS3z22WfLLKkjIhYsWBCvv/56/OY3v4mXX365Wt77oosuik6dOuXG11xzTUyaNGm59zz44IO5kjoi4rLLLluipI6I+PDDD+PSSy+NgQMHLrekjli4avmcc86JW265JbLZ7Cp+iuq3eN7mzZunFwRY48ycMSOm//RTbtyyZcto0KDBSt+//vobVBp/992YassGAAAAAAA1mRXVKdpggw1ip512is022yyaN28eFRUVMWHChHj//fdjyJAhERExb968uOyyy6J9+/axzTYrv0pvaerWrRu9e/eOo48+OubNmxfFxcXRq1ev6NOnT2SWsvn+kCFD4u67786N99133zj55JNX+D7NmzePnXbaKbbaaqto2bJlFBUVxbRp0+Kzzz6Ld955JxYsWBAREX369Il27dpVWgmetPHjx8fo0aNz4x133DG1LMCaZ+zYHyqN26y3aquh27RZr9L4hx9+WMZMAAAAYHHP/c+d8d2IoTF96sQonTsn6jdsFI2aNo8NN+kUm27TObbvsm/Ua9Aw7ZgAwHIoqhNWUFAQhx9+eJx22mmx3XbbLXXOhRdeGG+//XZceumlMWPGjCgrK4vrr78+nn766Sq/f8eOHeOyyy6LG264ISIWroTu06dPnHnmmZXmlZSUxCWXXBJlZWURsXCV4E033bTcZ3fu3DnOPvvs2HvvvaOoqGipc8aMGRMXXHBBbmvy3r17xxFHHBHrrLNOVT/aKistLY0rrrgiKioqIiKiXr16cdJJJyWeA1hzzZ49u9J4nRYtVun+dVpU/nff7NmzqpwJAAAAaoP3XulbaTxn5oyYM3NGTB73fXzyzqvx4j//Fvv++oTY98gTo6DAxqIAq2rJ5Y1Q/fwOnbCePXtG7969l1lSL7LPPvvEnXfemRt/+eWXMXTo0GrJcMopp8Tee++dG99+++3x9ddfV5pz0003xXfffVdp3LJly2U+c/fdd48nn3wyDjjggGWW1BERG2+8cTz88MPR4v/KnNLS0nj22WdX85OsutLS0hg9enQ8/vjjccQRR8SgQYMiIiKTycT1118fG264YWJZgDXf3LmVjzqoV7feKt1fr179nz1vbpUzAQAAABFzZ82Ilx+/Px688ZKY6wfDAaBGsqJ6Na3sdtWdOnWK/v3758b16q18idGlS5fYbbfdcmXqe++9V+Xtvxe5+eab49e//nVMmzYtysrK4uKLL46+fftG/fr1Y8CAAfHUU0/l5p588smx7777Lvd5q/K5WrVqFSeffHJuW/H33ntviRXd1eXuu++Oe+65Z7lzNtpoo7j66qtjr732yksGYO1VMrek0rhuvbqrdP/P/9358+cBAAAAlbXZYKPYcqcuscGmW0Sr9daP+g0axfx5pTF96qQYPfSz+N+3XomSxYrpkV9+HP+47erofk3vqFPHX4cDQE1iRXUN16VLl9zrYcOGVdtzW7VqVWkr71GjRsWtt94akydPjquvvjp3fdFW4dUtX59rVe2///7Rp08fJTVQLTKZVdsQ5+fzs5GtzjgAAACw1thih93i939+MC7966Nx+Knnxg677x8bbLJFtGq7QbTbqGNsvfMe8evTe8RVf3s6dtrn4Er3jh76WQx45tGUkgMAy+JHyFbTuuuuG/Xr11/hvLZt21bpfVq1apV7PWnSpCo96+f23XffOOmkk+KJJ56IiIjHH388Bg0aFNOnT4+IiKKioujdu/dKfc5VtfjnKi4ujnnz5q3SquyV1axZs2jfvn1ERGSz2Zg9e3YUFxdHNruwDHrzzTfj3XffjZNOOikuvvjivGQA1l4NGjaoNJ5XOm+V7i8tLa00btiwYZUzAQAAwNqo854HrNS8+g0axonnXxVFdevFR68/n7v+zotPxZ6HHhONmjTLV0QAYBUpqlfTbbfdFrvttttq319SUhJvvPFGvPvuuzFixIiYOHFizJkzJ+bPn7/Me2bNqv6zVHr16hWDBg2K0aNHR8TCldWLXHTRRdGpU6dVel5FRUUMGjQoBgwYEF999VWMHTs2Zs+eHSUly9/OdtasWXkpibt167bENu2zZs2KDz74IP7nf/4nvvjiiygrK4t//OMf8fXXX8dDDz0Udeuu2ta9QO3VoEHlYnne/FUrquf/bL6iGgAAAKrHUWdeECM+HxzTp0yMiIh5JXPj8/feiD1+dXTKyQDWEKu2eSSsFlt/p+C5556L/fffPy6++OJ47rnnYvjw4TF9+vTlltQREfPmrVoBsjLq168fvXv3jqKiokrXu3TpEmecccYqPevLL7+Mrl27xumnnx6PPfZYfPrppzFlypQVltQR+flsy9KkSZM4+OCD48knn4xTTz01d33QoEFx1113JZYDWPM1bty40rj4/3akWFnTf/rpZ89rUuVMAAAAQERhUdESpfTIIZ+klAYAWBorqhP24IMPxm233bbU7zVv3jzq169faUXvnDlzYtq0aXnNVKdOnSgoqPwzC7vvvvsqnbU6aNCg6N69+xLb2EZENGrUKBo1ahT16tXLPXPBggUxfvz43JxFW3EnqaCgIK666qr48ssv44svvoiIiMceeyy6d+8eTZs2TTwPsObZcMP2lcYTJ/64SvdPnDjxZ8/bsMqZAAAAgIU2327nSuMff/g2pSQAwNIoqhP09ddfxx133JEbt2rVKrp16xZ77bVXdOzYcalbTvft2zeuvPLKvGWaP39+XHLJJUusaL7nnntiv/32i80222yFzygtLY3LL788V1IXFRXFCSecEAcddFBsvfXWS6w4jIgYO3ZsHHjggdXzIaogk8nESSedlCuqS0pKYvDgwTUiG1DzNWvePNZp0SK3Mnra1KlRUlISDRo0WMGdC40fP67SeOONN6n2jAAAAFBbrdN6vUrjOTNnpJQEAFgaRXWCnnjiiViwYEFERLRu3Tr69u0bbdq0We49+TiXenG9e/eOESNG5MYNGzaMuXPnxrx58+Liiy+OZ555ZoVnNg8YMCAmTJgQEQtXKT/44IPRpUuX5d6T78+1Kn5+DvcPP/yQUhJgTbTpph3j458GR0RERUVFfDVsaOy08y4rde+QL7+oNN5k047Vng8AAABqq6K69SqNy+Ynd/wgALBizqhO0EcffZR73a1btxWW1BER48aNW+Gc1fXBBx/EP/7xj9z42GOPjZtvvjk3HjFiRNx+++0rfM7in2uPPfZYYUkdkd/Ptap+fj73oh8mAFgZv+iye6Xxp598vFL3Tfzxx5iw2BEIG228cbRt165aswEAAEBtNmdW5RXUjZo47g9gZWVq4f+RPEV1giZPnpx7/fNVvMsyaNCgvGQpLi6OXr165c6G7tChQ1x55ZVxyCGHRNeuXXPzHnnkkfjggw+W+6ya9LlWx89L81atWqWUBFgT7bvf/pXGL7/4wkrd99LP5u277/7LmAkAAACsjrGjhlcaN13H3/sBQE2iqE7QolI4YuHZ0CsyePDg+Oabb/KS5ZprrskVzIWFhfGXv/wlGjZsGBERV199dWywwQYRsTDz5ZdfHsXFxct81uKf6+dnXS/NrFmzon///lVIX71ef/31SuOtttoqpSTAmmizzbeIjpttnht/++3oeO/dt5d7T2lpaTzz1JOVrv3qsCPykg8AAABqqy8+GFhpvMlW26eUBABYGkV1gtZbb73c67feemu5c2fPnh3XXXddXnI888wz8dprr+XG5513Xmy//X//R1rjxo3jL3/5S9SpUyciIiZNmhTXXnvtMp/Xtm3b3Ot33303Kioqlvv+119/fV7OqC4rK4uysrJVuueTTz6JZ599NjfeaKONYosttqjuaMBa7tzzelQa3/ynG2LmjBnLmB1x1x29Y8KE/277vd8BB0anLbfMWz4AAACobX4Y+VV8/sGbla5tueOKjywEAJKjqE7QHnvskXvdr1+/ePnll5c6b+zYsXH66afHt99+GwUF1ftf0Q8//BB/+tOfcuPOnTvHOeecs8S8HXfcsdL1V199Nfr27bvUZ+6++3/PZx0zZkzcfPPNSz3nefbs2XHFFVfECy+8UO2fK2JhoX7wwQfH448/HtOnT1/u3PLy8njqqafi7LPPjvLy8tz1iy++uNpzAWu/Aw76ZWy/Q+fceNzYsXHm6afEyG9GVJo3a9asuPlPN8Tjjz2au1avXr3o0fP3SUUFABbz44TxS/2aPWtmpXnFxcVLnTdt6pSUkgNA7fLR6y9EacnclZ4/cex38chfro7sYgtqOmy+dWy23U75iAewVspkat8XyctkF9+3mWXq169fXHHFFbnxo48+GrvtttsqPeOHH36IQw89tNKq3y5dusSee+4ZLVq0iJkzZ8ann34aAwcOjPnz50fDhg3jpJNOioceeigiItZff/148803l/rsQYMGRbdu3XLjESNGLDGnvLw8TjrppPjiiy8iIqJRo0bRv3//2HDDDZf6zJ/Pb9iwYfTv3z/at2+/xLzDDjssvvvuu9y1jh07xsEHHxzrr79+lJaWxogRI+K1117LFcg9e/aMu+66Kzf/jTfeyG03vrrGjRsXBxxwQEQs3M58u+22i6233jrWX3/9aNKkSWSz2ZgxY0aMHDky3n333Zg2bVql+0899dS4+uqrq5ShKkrLVzwHqLkmT54UJx3/m5jyf8cqRERkMpnYaqutY/0NN4wZxcUxdMiXMWfOnEr33fTnv8Rhh/866bhANZnlN3BYo+2509ZVun+HnXaJex54pHrCAIn5aMy0FU8CapQ/nXtczCuZGzvudVDssMf+seFmW0adOoVLzJs7e1Z8+Fr/eLPfP2NeaUnuemFR3Tjvj3dF+80c+QdrqiO2bZN2hFpnxMSV/wGhtcUW6zVMO0Kts+Tv5uRN+/bt449//GNcddVVue2xP/zww/jwww+XmNuwYcPo3bv3cs+GXlX33XdfrnSOiLj22muXWVJH/Pfs6qOOOirmzp0bc+fOjUsvvTSeeOKJ3Lbgi+bdeeedceqpp8bMmQtXHowaNSpGjRq1xDMzmUyce+65ceSRR1YqqqtbeXl5fPrpp/Hpp5+ucG69evWiR48e0b1797zlAdZ+667bJv72wP/EJRf2jO/GjImIiGw2G8OGDY1hw4YuMb9evXpxyWWXK6kBAABgJcydPTPee6VvvPdK3yisWzfW23CTaNK8RTRo2CjmzyuN6VMnxY/fjY6Kiso7PRYU1IkTzr9SSQ0ANZCtvxN29NFHxwMPPBCbbLLJUr9fp06d2GuvvaJfv36x//77V9v7fvbZZ/H3v/89Nz7kkEPiqKOOWuF9HTp0iKuuuio3/vzzz+Pee+9dYl6nTp3imWeeqbS9+dLm3H///XHBBResWviV1Lp167jyyitjzz33jEaNGq1wfosWLaJbt27xwgsvKKmBarHZZpvHk08/G2ecdXa0aNlyqXMKC4ti3/32j8effDqOO+GkhBMCAADAmq98/vwYN/rrGP7JB/Hpu6/H0MHvxvhvv1mipG7eat049/o7Y4fdq+/vWQGA6mPr75Rks9kYOnRoDBs2LIqLi6Nx48ax7rrrRufOnaN169Zpx6uSsWPHxieffBKTJ0+OoqKiaN26dXTq1Ck6duyYWIaKior49ttv47vvvosff/wx5syZE5lMJho3bhwtWrSILbfcMjp06BCZGnTogJ1DYe1SXl4en3/2aYwfNy6mTp0ajRs3ijZt1ovtdugcLVq0SDseUE1s/Q0Aax5bf8OaZ9AbL8ZXH38Q340YEnNmzlju3EwmE207bBq/OOjI2Hnfg6NuvfoJpQTyydbfybP1N0lQVEMN4e+5AWDNo6gGgDWPohrWbMVTJ8XkCWOjeOrkmDtrRpSXzY/CorrRoHGTaNaidbTfbKto2LhJ2jGBaqaoTt43tbCo3lxRnThnVAMAAAAAsEZo3qpNNG+lsAKAtYEzqgEAAAAAAABIlKIaAAAAAAAAgEQpqgEAAAAAAABIlDOqAQAAAAAAgP/KpB2A2sCKagAAAAAAAAASpagGAAAAAAAAIFGKagAAAAAAAAASpagGAAAAAAAAIFGFaQcAAAAAAAAAao5MZNKOQC1gRTUAAAAAAAAAiVJUAwAAAAAAAJAoRTUAAAAAAAAAiVJUAwAAAAAAAJCowrQDAAAAAAAAADVHJpN2AmoDK6oBAAAAAAAASJSiGgAAAAAAAIBEKaoBAAAAAAAASJSiGgAAAAAAAIBEFaYdAAAAAAAAAKg5MmkHoFawohoAAAAAAACARCmqAQAAAAAAAEiUohoAAAAAAACARDmjGgAAAAAAAPgvh1STACuqAQAAAAAAAEiUFdUAAAAAAAAAKZs/f36MHj06Ro4cGdOmTYt58+ZFkyZNok2bNrHDDjtEq1at0o5YrRTVAAAAAAAAACn46aef4j//+U8MHDgwPv7445g7d+4y5+64445x1llnxYEHHphgwvxRVAMAAAAAAAAkbPTo0fHrX/86ysvLV2r+p59+Gp9++mkcdthhcdNNN0X9+vXznDC/FNUAAAAAAABATiYyaUeoFebPn1+ppC4oKIgtt9wydt5552jXrl00adIkpk2bFoMHD4733nsvstlsRES89NJLMXv27Pjb3/4WderUSSt+lSmqAQAAAAAAAFLSpk2bOOGEE+KYY46JNm3aLPH97t27x5dffhkXXHBBTJgwISIi3n777fj3v/8dJ510UtJxq00mu6h6B1JVunK7OgAANcgsv4EDwBrnozHT0o4AAKyiI7Zdsrgjv76dUpp2hMRt0jr5bbS///77eOONN+Lkk0+OevXqrXD+t99+G0cddVTMmzcvIiLatWsXAwcOzHfMvClIOwAAAAAAAABAbdOhQ4c488wzV6qkjojYZJNN4uijj86NJ0yYECNHjsxXvLxTVAMAAAAAAACsAXbbbbdK47Fjx6aUpOqcUQ0AAAAAAADkZDJpJ2BZGjVqVGlcUlKSUpKqs6IaAAAAAAAAYA0wbty4SuOWLVumlKTqFNUAAAAAAAAAa4A33ngj97qoqCi23nrrFNNUja2/AQAAAAAAgFptwoQJMWHChCo9o127dtGuXbtqSrSkr7/+Oj744IPceM8994wmTZrk7f3yTVENAAAAAAAA1Gp9+/aNe+65p0rP6NGjR5x//vnVlKiy8vLyuPrqq6OioiJ37Xe/+11e3ispimoAAAAAAAAgJ5N2AJZw2223xZAhQ3Lj448/PrbddtsUE1WdM6oBAAAAAAAAaqi+fftGnz59cuONN944rrjiihQTVQ8rqgEAAAAAAIBa7ZhjjokuXbpU6Rn5OJ/67bffjmuvvTY3bt68edx7773RoEGDan+vpCmqAQAAAAAAgFqtXbt2eSmaq+Ljjz+Onj17Rnl5eURENGrUKB588MHYdNNNU05WPWz9DQAAAAAAAFCDDB06NH77299GaWlpRETUq1cv/va3v8V2222XcrLqY0U1AAAAAAAA8F+ZtAPUbt98802cddZZMXv27IiIKCoqirvuuit22223lJNVLyuqAQAAAAAAAGqA7777Ls4888woLi6OiIg6derErbfeGvvuu2+qufJBUQ0AAAAAAACQsgkTJsQZZ5wRU6ZMiYiITCYTN9xwQxx66KEpJ8sPRTUAAAAAAABAiqZMmRKnn356TJgwIXftqquuimOOOSbFVPnljGoAAAAAAAAgJ+OQ6kQVFxfHmWeeGd9//33u2sUXXxynnnpqiqnyz4pqAAAAAAAAgBTMnj07/t//+3/xzTff5K6dc8450b179xRTJUNRDQAAAAAAAJCwefPmxbnnnhtDhgzJXevWrVtceOGFKaZKjq2/AQAAAAAAABL2yiuvxODBgytdGzhwYLz11lsr/Yxf/vKXcemll1ZzsmQoqgEAAAAAAAASVlFRscS1sWPHrtIzpk2bVl1xEqeoBgAAAAAAAHIymbQTUBtkstlsNu0QQERpedoJAIBVNctv4ACwxvlozJq74gQAaqsjtm2TdoRa54ef5qUdIXHtW9RLO0KtU5B2AAAAAAAAAABqF0U1AAAAAAAAAIlSVAMAAAAAAACQqMK0AwAAAAAAAAA1RybtANQKVlQDAAAAAAAAkChFNQAAAAAAAACJUlQDAAAAAAAAkChFNQAAAAAAAACJKkw7AAAAAAAAAFBzZDJpJ6A2sKIaAAAAAAAAgEQpqgEAAAAAAABIlKIaAAAAAAAAgEQpqgEAAAAAAABIVGHaAQAAAAAAAICaJJN2AGoBK6oBAAAAAAAASJSiGgAAAAAAAIBEKaoBAAAAAAAASJQzqgEAAAAAAICcjCOqSYAV1QAAAAAAAAAkSlENAAAAAAAAQKIU1QAAAAAAAAAkSlENAAAAAAAAQKIK0w4AAAAAAAAA1ByZtANQK1hRDQAAAAAAAECiFNUAwP9v777jo6j2/4+/Z3dTCJDQQgghAhbAKBEUlA4CCkQQRcHCBYSr4hUbKogFGyBFrKCg4o8axasGVFBQwItIl44FkCIlhCKQkISULb8/8t0xSwgETWaz5PV8PHy4Z+bMzGcC8Xj2cwoAAAAAAAAAAJYiUQ0AAAAAAAAAAAAAsBSJagAAAAAAAAAAAACApRz+DgAAAAAAAAAAAABA6WEY/o4AZQEzqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACzl8HcAAAAAAAAAAAAAAEoPQ4a/Q0AZwIxqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCkS1QAAAAAAAAAAAAAASzn8HQAAAAAAAAAAAACAUsTwdwAoC5hRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCmHvwMAAAAAAAAAAAAAUHoY/g4AZQIzqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAICl2KMaAAAAAAAAAAAAgMlgk2pYgBnVAAAAAAAAAAAAAABLkagGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAlnL4OwAAAAAAAAAAAAAApYchw98hoAxgRjUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClHP4OAAAAAAAAAAAAAEApYvg7AJQFzKgGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwlMPfAQAAAAAAAAAAAAAoPQx/B4AygRnVAAAAAAAAAAAAAABLkagGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAlnL4OwAAAAAAAAAAAAAApYdh+DsClAXMqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWYo9qAAAAAAAAAAAAACZDbFKNkseMagAAAAAAAAAAAACApUhUAwAAAAAAAAAAAAAsRaIaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEs5/B0AAAAAAAAAAAAAgNLDMPwdAcoCZlQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCkS1QAAAAAAAAAAAAAAS5GoBgAAAAAAAAAAAABYikQ1AAAAAAAAAAAAAMBSJKoBAAAAAAAAAAAAAJYiUQ0AAAAAAAAAAAAAsBSJagAAAAAAAAAAAACApUhUAwAAAAAAAAAAAAAs5fB3AAAAAAAAAAAAAABKD8PwdwQoC5hRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCmHvwMAAAAAAAAAAAAAUHoYMvwdAsoAZlQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCkS1QAAAAAAAAAAAAAAS7FHNQAAAAAAAAAAAACTwRbVsAAzqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACzl8HcAAAAAAAAAAAAAAEoPw98BoExgRjUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClHP4OAAAAAAAAAAAAAEApYvg7AJQFzKgGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwlMPfAQAAAAAAAAAAAAAoPQwZ/g4BZQAzqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACzl8HcAAAAAAAAAAAAAAEoPw/B3BCgLmFENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKVIVAMAAAAAAAAAAAAALEWiGgAAAAAAAAAAAABgKYe/AwAAAAAAAAAAAABQehj+DgBlAjOqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKXYoxoAAAAAAAAAAADAX9ikGhZgRjUAAAAAAAAAAAAAwFLMqAYAAAAAAAAAAACAUsLtdmv9+vXau3evjh49qvDwcEVHR6tp06YKCwvzd3jFhkQ1AAAAAAAAAAAAAPiZy+XShx9+qJkzZ+rw4cMFzoeFhemmm27SkCFDFBER4YcIi5fh8Xg8/g4CgJTl9HcEAADgfJ2kAQcAIOCs2v2nv0MAAADnqVvDKH+HUOZk5pa99GFYkH835k5LS9PAgQO1fv36c9atUaOGJk2apLi4OAsiKzkkqoFSgu+5AQAIPCSqAQAIPCSqAQAIPCSqrXcq198RWK9ckP+e7XQ6dd9992nFihXmsZo1a+rmm29WTEyMjh07pkWLFmnLli3m+aioKH366aeKigrc3w8S1UApwffcAAAEHhLVAAAEHhLVAAAEHhLV1iNRba0PPvhA48ePN8tdu3bV6NGjFRwc7FNvxowZeuWVV+RN77Zt21bvv/++pbEWJ5u/AwAAAAAAAAAAAACAsig9PV1Tpkwxy3FxcRo7dmyBJLUk9e3bV7179zbLS5cu1bp16yyJsySQqAYAAAAAAAAAAAAAP/jiiy904sQJszxkyBA5HI5C6z/22GMqV66cWZ4xY0ZJhleiSFQDAAAAAAAAAAAAgB8sXrzY/BwTE6PmzZuftX7FihXVqVMns7xs2TLl5OSUWHwliUQ1AAAAAAAAAAAAAJNhlL1//CErK0tr1qwxyy1atJBRhGBatGhhfs7IyAjY5b9JVAMAAAAAAAAAAACAxXbt2qXc3FyzfNVVVxXpusaNG/uUt23bVqxxWYVENQAAAAAAAAAAAABYbOfOnT7l2rVrF+m6mJgY2e12s7xr165ijcsqhe/EDQAAAAAAAAAAAABlQHJyspKTk//RPWrWrKmaNWsWuf7+/ft9ytHR0UW6zm63KzIyUikpKZKkffv2FT3IUoRENQAAAAAAAAAAAIAy7fPPP9fEiRP/0T0eeughPfzww0Wun56e7lOOiIgo8rXh4eFmojojI6PI15UmJKqBUiKU30YAAAJOaAUacAAAAk23hlH+DgEAAKDUI2dhjczMTJ9ySEhIka8NDQ0t9D6Bgj2qAQAAAAAAAAAAAMBi2dnZPuWgoKAiXxscHGx+zsrKKraYrMR4CAAAAAAAAAAAAABl2m233abmzZv/o3ucz/7UUsEZ1Lm5uUWeVZ2Tk2N+zj+7OpCQqAYAAAAAAAAAAABQptWsWfO8E83/VFhYmE85Ozu7yInq/LOoT79PoGDpbwAAAAAAAAAAAACwWIUKFXzKqampRb725MmT5ufy5csXW0xWIlENAAAAAAAAAAAAABarVauWT/ngwYNFus7lcunw4cNmOTY2tljjsgqJagAAAAAAAAAAAACw2MUXX+xT3rt3b5GuO3DggFwuV6H3CRQkqgEAAAAAAAAAAADAYhdffLGCgoLM8saNG4t03YYNG3zK9erVK86wLEOiGgAAAAAAAAAAAAAsVq5cOTVt2tQsr1y5Uh6P55zXrVixwvwcFhamJk2alEh8JY1ENQAAAAAAAAAAAAD4QceOHc3P+/fv18qVK89a/+TJk1q4cKFZbt26tYKDg0ssvpJEohoAAAAAAAAAAAAA/ODmm29WRESEWR4/frycTmeh9d98802dOnXKLPft27dE4ytJJKoBAAAAAAAAAAAAwA8qVqyoe++91yz//PPPGjZsmHJzcwvUnTlzphITE81y69atA3bZb0kyPEVZ6BwAAAAAAAAAAAAAUOxyc3P173//W6tXrzaPxcTEqFu3bqpVq5aOHTumRYsWafPmzeb5yMhIffbZZ6pRo4Y/Qi4WJKoBAAAAAAAAAAAAwI9SU1M1cOBAbdiw4Zx1q1evrkmTJunKK6+0ILKSQ6IaAAAAAAAAAAAAAPzM5XLpgw8+0KxZs3TkyJEC58PCwpSQkKAhQ4aoUqVK1gdYzEhUAwAAAAAAAAAAAEAp4XK5tH79ev3xxx/6888/FR4erujoaF177bUKCwvzd3jFhkQ1AAAAAAAAAAAAAMBSNn8HAAAAAAAAAAAAAAAoW0hUAwAAAAAAAAAAAAAsRaIaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKVIVAMAAAAAAAAAAAAALEWiGgAAAAAAAAAAAABgKRLVAAAAAAAAAAAAAABLkagGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAcHj8fj8GwAAlH4ej6dAG57/GAAAKLtIVAMAyhSPxyOn0+nvMAAAQBHl/xLbMAyff59+HgAAlA6nt9+GYSgzM1OGYSgnJ8c8BgAAyjbDQ68eAFBGOJ1OORwOSVJWVpZsNpuCg4P9HBUAADgTj8djfoHtdruVnp6u9PR0LVmyxPyy+4orrlBsbKxiY2MLXAMAAKx3evt94MABpaSkaMGCBdq9e7c8Ho/cbreaNGmiq6++Wi1btvRzxAAAwJ9IVAMALnhut1s221+LiCQmJmrEiBF65JFH9OCDD/oxMgAAcC67du3S+vXrtXLlSn333XfKyckxzzkcDlWqVEm33Xab+vTpo2rVqvkxUgAA4LVz506tXLlSy5cv14oVK5SdnS2bzSa3223WMQxDjz32mLp166aaNWsW6LsDAIALH4lqAECZsXr1ar300kvatWuXJKl69er6+OOPFRMT4+fIAACAl3cmVmZmplatWqWvvvpKq1at0vHjx33q2e12SZLL5ZIkXXfddRoxYoQuuugiy2MGAAB5vO33vHnztGLFCp04cUJSXlI6/9fQDodDTqdTERERuvHGGzVixAg/RQwAAPyJRDUA4IKXmZmpOXPm6J133tGxY8fkcDhkt9uVnZ2tf/3rX3ruuef8HSIAAJDvKihffPGFpkyZoh07dkiSKlWqpDp16sjhcCgiIkLbtm3T/v37zfput1u9evXSvffeS7IaAAALuVwucwDZp59+qpkzZ2r79u2SpMqVK6tx48aKjIzU1VdfrYMHD2rTpk36/vvvzetDQkI0atQode3alW08AAAoY0hUAwAuSN6OstPp1Jw5czR16lRzJvXpI7lnz56tRo0a+SlSAACQn9vt1ttvv63JkydLyptx1apVKyUkJOjyyy/XZZddZtZ977339PXXX2vbtm2SpIiICA0aNEi9e/c2vzAHAAAlLzc3V2PHjtWsWbMk5bXfbdq0UUJCgho2bKjatWv71B87dqymT59uLgXeokULTZ48WcHBwZbHDgAA/IdNPwAAFyTvl9MzZ87UmDFjzCR1TEyM2rRpo4iICLPupEmT5HQ6/RInAAD4S3p6ut58801NmTJFkhQWFqZbb71VDz74oLp27WomqXNzcyVJ99xzj5588kkFBQVJklJTU7Vq1Sr9+eef/nkBAADKoO3bt2vgwIFmkrpGjRrq3bu3Hn74YSUkJJhJaqfTaSamH374YTVt2tS8x59//qnk5GTrgwcAAH5FohoAcEHKysrSc889p7FjxyojI0OSVK5cOfXt21eDBg1Sq1atJOXNrl66dKm+/fZbf4YLAAAkLVq0SHPnzjUHkLVt21YPPfSQ4uPjzSW+JZmJ6ZCQELVu3Vp33XWXeW7ZsmVm2w8AAEqW2+3Wzz//rBUrVpjHbr75Zt1///26/PLLfdpvh8Mhm80mt9utsLAwde/e3Ty3Y8cOlStXztLYAQCA/5GoBgBckEJDQ332tapWrZrGjRunfv36KT4+Xu3atVNsbKy5BPikSZOUmprqr3ABACjznE6nXnvtNR0+fFihoaHq1auX3njjDUVFRZ3z2pYtW6pixYqy2WzKzc31+bIcAACUHJvNpjp16ig6OloOh0Njx47V448/rqpVqxZ6jbevftVVV5nJ6ejoaEviBQAApQuJagDABcflckmS7rvvPlWtWlXNmjXTO++8oxtuuMFMTLds2VJt2rSRYRgyDEM7duzQ7Nmz/Rk2AABlltvtlsPh0NChQyVJFStW1C233CLpr3b9bCpUqCCPx2N+8V2+fHlJMtt9AABQcurXr6+HHnpIgwcPNmdJn6399rbX27dvN7fzuOaaa4o0OA0AAFxYHP4OAACA4ma32+V2u3XRRRfp2WefVfny5dWwYUNJf3WIq1Spog4dOmjTpk3aunWrJGnKlCnq1KmT6tSp46/QAQAok7zLgnbr1k3fffedWrdurauvvlpSXrt+Lg0bNlRoaKjS09MlScePH5ckn9VVAABAyQgLC1PHjh19lu4urP32Diw7dOiQPvroI3O7j169epl13G63z5LhAADgwkWLDwC4IHm/mE5ISFDbtm19Orne2VXXXHON2rVrZ3amT548qSlTplgfLAAAMNvnZ599Vh06dJDH4ynyjOi9e/cqNzfX/FL8kksu8bknAAAoWREREQoODi607fV4PHK5XGZf/ZtvvtGvv/6qoKAgde/eXaGhofr444+1atUqHThwwLzO7XZbEj8AAPAPZlQDAC5Ip8+gyr8cqGEY8ng8CgkJUfv27bVx40b9+OOPkqTPPvtM3bp103XXXWd5zAAAlGXedvrvLPvpdDqVm5tr3iMsLMznngAAwBpnantdLpfsdrvsdruOHz+u0aNH68svvzTPL1++XF988YVZrlmzptq3b69BgwapcuXKlsQNAAD8gxnVAIAy4fTOsrccFxen9u3bq1q1aua5d999Vzk5OZbGBwAA/r5du3YpMzNTbrdbYWFhqlu3rr9DAgAA/8e74smHH36otm3b+iSpJeno0aM+9ZKTkzVr1iw99dRT+v33360NFgAAWIoZ1QCAMss7y7pNmzbasGGDvvrqKxmGodWrV2vevHnq0aOHv0MEAABFsH//fkl5y4NeffXVqlKlip8jAgAAXocOHdLQoUO1evVqn+Nt27ZVly5dlJubK0lau3atvvvuO506dUqGYeiHH35QdHS07r//fsXExPgjdAAAUMJIVAMAyizvrOpatWqpY8eO2rp1q3bv3i1JmjRpktq2bauqVav6M0QAAFAEW7duNT9feeWVLPkNAEApYrfbVatWLa1du1Y2m02tWrXS/fffr6uvvtqnXs+ePfX111/rww8/1M8//yxJWrx4sa666ioGkgMAcIFi6W8AQJnm8XgkSc2aNVObNm3Mpcb27dunWbNm+TM0AABQBBkZGVqzZo0cjrxx2HFxcZL+auMBAIB/VatWTTfddJO6dOmiUaNGafLkyWaS2u12S5K5/daNN96oRx55xLz26NGjWrt2rU6ePGl94AAAoMSRqAYAlGneGVcRERHq0KGDGjZsaJ6bOnWqtm/f7q/QAABAEfz+++86ceKE3G63KlSooAYNGkgSs6oBACgFvAPHrrvuOo0dO1bdu3eXJLlcLkmSzZb39XRwcLAkyeFwqFWrVrrlllvMeyxZskTZ2dkWRg0AAKxCohoAgP/TuHFjtW/fXhUqVJAkZWVl6f333y9Qz+PxmJ1qAADgH94vvnfs2CEpb0ZW/fr1FRkZWWh976wtAABgDe/AMbvdLofDYbbF3tXMzsRms+m6665TcHCwHA6HUlNTtW7dOkviBQAA1iJRDQCA8r68DgoKUrt27dS0aVPz+Lx587R06VKzjtPplGEYstvtOnTokNLS0sxzAADAOt4vvpcvX24eq1+/vsqVK1egrsvlkmEYstlsOn78uE6dOmVZnAAA4C/eGdSF8Xg8MgxD5cuXV05OjtnXrly5shXhAQAAi5GoBgBAf33ZXa9ePXXo0EE1atQwz02aNEknT56UYRhyOBxyuVyaMWOGOnfurOHDh/srZAAAyrxTp07pp59+MmdlxcfHS/prv0vvCih2u11ut1vTpk1Tnz59NGPGDP8EDAAAzsrbNw8PDzfLDofjnAluAAAQmGjhAQD4P96R2q1atVKLFi0k5XWKN27cqEWLFkmSFi1apLvuukvjxo1Tdna2Fi5cqFWrVrEPJgAAFvN4PNqzZ49Onjwpt9ut8PBw1a9f3zzn8XjMBPbixYt111136dVXX9XOnTuVmJio3377zZ/hAwCA03i36fB4PPr0008lSU6nU1dccYWuvPJKP0cHAABKgsPfAQAA4OV2u884Stq79FdJ8z6jRo0aat++vbZs2WLuezl+/HgtWLBAq1evVnZ2tpnUrlevXqF7YQIAUBb4o/323nvbtm3KysqSJEVHR+uiiy7ySVD/9ttvmjRpkpYuXerTftepU0cRERElEhsAAIHA3/3vMzEMQ4ZhaM2aNVq7dq15vGXLlgoNDS00ZgAAELhIVAMA/CZ/B9jb4Tx69Kh+//13Va5cWcHBwapbt66lnWRvHK1bt9a2bdu0e/duOZ1O/fnnn1q+fLmcTqckqXr16ho2bJgSEhIsiw0AgNKgNLTf3nv/8MMP5rF69eqpfPnykqTjx4/rgw8+UFJSklJTU80ENe03AKCsKg3t97niysnJ0ZIlSzRmzBgdPnxYdrtd7dq103333Sfp3PtbAwCAwEOiGgDgN97O6M6dO7Vx40atWrVKCxcuVFBQkDIyMhQZGak2bdooISFBLVu2LPF4XC6XOQMrJCREGRkZcjgcMgxDTqfTTFIPGjRIDz/8cInHAwBAaVQa2m+Px6OsrCz98ssv5rFOnTpJkhITEzVjxgzt3bvXrCvRfgMAyrbS0H7n502We+M6cOCAfvzxR82ZM0eHDh2SJIWFhem2225TuXLl/DrTGwAAlBzD4+21AwBgsWPHjumHH37Qt99+q7Vr1+rkyZPmOZvNJrfbLUlyOBx66qmndPPNNysiIqJElvvK3+ldtmyZ3n//fW3YsEEej0cul0uS1KVLFw0bNkxRUVHF+mwAAAJJaWm/d+7cqbvvvlupqamqXLmyevXqpU2bNumnn36S2+0240hISNBTTz1F+w0AKNNKQ/t9pmTzvn37tGXLFv34449atGiR0tLSJElNmzbV8OHDVa9evWJ5NgAAKJ1IVAMALOWdtZyamqrExER9/vnnOnDggCSpUqVKCgoKUlhYmNLS0nTy5ElzFnNkZKRuvvlmDRkypMRi27lzpyZPnqzFixfr1KlT5gysuLg4PfPMM2rSpEmJPRsAgNKsNLbf8+bN05NPPinDMOTxeFSpUiWlpaWZX7THxcXp2Wef1TXXXFPszwYAIBCUxvZ79+7dkvIS5wsWLNDu3bv1+++/KyUlRZJUrVo1derUSXfddZcuvfTSYn8+AAAoXUhUAwAsl5GRoRdffFFfffWVJKlcuXK6/vrr1axZMzVo0EDx8fFKSUnR1q1b9d5772nLli3mtZMnT1a7du2KfVbWoUOHNHz4cJ+9LiMiIjRkyBDdfvvtxfYcAAACVWlrv4cPH65PP/1UQUFB8ng85pfrtN8AAPylNLXfx44d0x133KFTp07p6NGjPudCQ0PVpEkTderUSQkJCSpfvvw/fh4AACj9SFQDACy1a9cujRo1SsuXL5ck1a9fX927d1f79u1Vu3btAsuAbdmyRRMnTtTSpUslSbVq1dLcuXNVoUKFYo0rKytL//3vf/XKK69Ikv7973/r0UcfVXBwcLE+BwCAQFSa2m/vl+VvvfWWJk2aJIfDYSapBwwYoMcee4z2GwAAla7222vGjBl65ZVXzBVRJKlDhw5q27at2rZty1YdAACUMSSqAQCWmjhxot5991253W5VrlxZgwcPVteuXRUWFibprz2rnE6n7Ha7DMPQvn37dNNNN8nlcsnlcmngwIEaPHhwsce2fft2LV68WAkJCapdu3ax3x8AgEBVGtvvHTt2aODAgUpOTlaHDh301FNP6aKLLiq2+wMAEOhKY/udnp6uZ555RhkZGapbt6569uyp2rVrKyQkpEDiHAAAXPgc/g4AAHBh8Xg8crvdstvtBc6dOnVKJ0+elNvtVnR0tEaMGKFWrVr51PF2kh2OvCZq165dGjNmjHJycsxjU6dOVZcuXdSgQYNijb1evXqqV69esd4TAIBAEIjtd+3atfX4448rPDxcbdq0KZZ7AgAQSAKx/a5QoYJGjhyp3NxcVa1atVjuCQAAAlfxbe4JACjznE6nDMOQ3W43l+DMr1y5curevbvi4uKUkJBgdpK9i3u4XC5JksPhUHZ2tkaPHq2EhAT98MMPMgxDLpdLdrtdOTk5mjx5slgUBACAfy5Q2+/g4GB17dqVJDUAoEwK1PZbksLDw0lSAwAASSSqAQDFyDviOjExUQkJCTp48GCBOnXq1NGwYcP0yCOPFDjnHQX+2WefqVWrVpo+fbqkvFHekZGR6tChg9mZXrBggf73v/+V0JsAAFB20H4DABB4aL8BAMCFgD2qAQDFZtu2bRo6dKi2bdumBg0aaPbs2QoNDS20vtvtls3215ip7du367XXXtPSpUvNY2FhYerUqZMeeOAB1a5dW3369NHatWslSVdeeaWmT5+u8uXLl9xLAQBwgaP9BgAg8NB+AwCACwEzqgEAxWblypXatm2bpLxlxs7WSZYkm81mjtDesGGDRo0apRUrVpjn4+PjNXHiRI0ePVq1a9eWy+XSzTffLClvlPfWrVuVlJRUQm8DAEDZQPsNAEDgof0GAAAXAhLVAFDGFcfCGt57pKenm8diY2Ml6Yx7ZeVnt9uVlZWladOmafXq1crNzZXNZtPjjz+u//73v2rRooUkmftj1a1bVxdddJE5Evy9995TcnLyP34HAAACCe03AACBh/YbAADAF4lqACij1qxZU2z3MgxDknTixAnzWFBQkKS/9s06m3feeUcLFy6UJF1yySV69913df/990uSOeLbu3/WZZddptTUVLlcLgUFBeno0aOaNm1acb0KAAClGu03AACBh/YbAADgzEhUA0AZs2nTJt15553q27evfvzxRxmGcdZR1x6PR263u0j33rNnj9lpvvjiiyXpnNceO3ZMX3/9tXndjTfeqBYtWsjj8cjj8ZgdZEnKzc1VWFiYatasacYmSTNnztTmzZuLFCMAAIGI9hsAgMBD+w0AAHB2JKoBoAw5ceKERo8erY0bN0qS3njjDUmFj7p2Op0yDEM2m005OTlmp/f0jrV31LXb7ZbH45HNZlNISIgkmUuEFSYlJUVHjhyR3W5XTEyM+vXrp+DgYBmGYXaevYKCgpSSkqKUlBSVK1dOFSpUkJTXYZ4wYcI5lzkDACAQ0X4DABB4aL8BAADOjUQ1AJQh4eHh+ve//212MH/++WclJiYWWt/bgZ44caISEhI0evRoHTx40Kdj7R11nZ6erv3790vK6zDXqFGjSDGdOnVKOTk5cjqdSk9PV1pamnnf/M/wWr58uY4fP64rrrhCQ4YMMY8vW7ZMu3btKtIzAQAIJLTfAAAEHtpvAACAcyNRDQBliM1mU9OmTdWqVStJUocOHdSxY8dC6//000+6/vrrNXHiRO3fv18zZ85Uz5499cQTT5h7bHlHXWdlZZmjsIODg83lwc6lYsWKqlOnjqS8Edv57+sdQe59xm+//Wbuh1W9enV169ZNTZo0UZs2bbRkyRLVq1fv/H4gAAAEANpvAAACD+03AADAuZ15rRkAwAWrUqVKeuCBB9SvXz81btxYUt4I7DMtEZaTk6PWrVtr9erV+uOPPyTl7Wk1f/58LVy4UJ06dVKHDh2UkJCg4OBg7du3TzabTbm5uUWOJyIiQjExMdqzZ4+OHj2qZcuWKT4+XvXq1TNjysrK0pYtW5SYmKh9+/YpJCREN910k4KDgzVp0iRVrFixGH4yAACUXrTfAAAEHtpvAACAszM8+ddzAQCUKW63W7m5ueZ+VtJfy3zl358qPT1dM2bM0NKlS7Vp0yZJeaPDPR6PPB6Prr32WtWrV0/z5s3TiRMnVLNmTX322WeqUqVKkeKYNm2aJk+erBMnTig4OFgNGjTQAw88oLi4OP3222/atWuXFi1apPXr10uSmjdvrjfeeEOVKlUqpp8EAACBg/YbAIDAQ/sNAABQEIlqAIAkadGiRWdchszlcslut0vK6zB/8803SkxM1K5du5STk1Ogvs1mU3R0tKZPn65atWr5XH8670jyEydO6Nlnn9WyZcvMe4aFhckwDNlsNp06dUpOp1OSdOONN+qFF15Q1apVi+vVAQAIWLTfAAAEHtpvAACAPCSqAaCM++GHHzR69Gjt3r1bEydOVMeOHeV0OuVw+O4Okb/Dm5qaqi1btmjq1Klau3at2bl1OBxyOp2KjIzUHXfcoV69eql69ermPTwej89IcemvzvKGDRs0a9YszZ8/37yPzWYz98mKjY3VjTfeqD59+qhGjRol+SMBAKDUo/0GACDw0H4DAAD4IlENAGXYiRMnNGjQIK1bt06SVKdOHS1YsEDSmTu1Xt5zHo9HK1as0JIlS5SYmGiOwHa5XJKk6tWrq2XLlurVq5e5H5d09j253njjDf3444/at2+fcnJyVK1aNV1//fVq166dWrZsqeDg4OL+MQAAEFBovwEACDy03wAAAAWRqAaAMszj8eiHH37Q448/royMDEnS0KFDNWDAgLMuGXYm/fv318qVK80OtCTZ7Xa5XC6VK1dOXbt2VceOHdW2bdszXp+/85yRkaH09HTt27dPcXFxCgoKUlBQ0D98WwAALgy03wAABB7abwAAgIJIVANAGZeWlqbXXntNn3zyiSQpODhYy5YtU0RERKEjr0+XkZGhHj16aO/evfJ4PGrZsqUyMzO1YcOGAnVbtmypu+66S1dffbWqVKlidqoLGz0OAAAKov0GACDw0H4DAAD4Ovf//QAALmjh4eG67bbbFB0dLSlv+a9XX321yNd7PB7Z7XbZ7XZ5PB5VqlRJ99xzj95++20NGzZMtWvXNkeGG4ah5cuX6/HHH9c999yjb775RhkZGWYnmbFTAAAUDe03AACBh/YbAADAFzOqAeACc75LhklSVlaWpk+frjfeeMM8lpSUpLi4ODmdTjkcjrNev3v3bvXo0UPZ2dlyu92aN2+eLr30UknSsWPHtH79ek2dOlWbN29Wbm6uuSSZJEVEROjJJ59Uz549z/NNAQC4cNB+AwAQeGi/AQAA/hlmVANAKVXUcUSn1/OOrN6+fbv+/PNPpaWlnfO+oaGh6ty5s+Lj481jo0aNkqRzdpI9Ho/cbrfsdrsMw1D16tVVpUoVsyNcqVIldezYUVOmTNGrr76qzp07m+cMw1CfPn3oJAMALhi03wAABB7abwAAAP84+//9AAAs53a7Jclnb6qz7VXlXbYrJSVFv/zyi9avX6958+bJ4/EoLS1NtWvXVuvWrZWQkKDLL7+80L2oYmJidPfdd2vz5s2SpHXr1unrr79WQkLCWUd1G4ah1NRUpaenm/fOP6rcG3e5cuXUuXNnde7cWStXrtTPP/+s7t27KzIy8nx/RAAAlDq03wAABB7abwAAAP9i6W8AKCXyj4yWpA0bNmjDhg0aMGDAWTvKGRkZWr16tRYtWqRVq1YpOTn5jPUqVqyoESNG6Prrr1dISIg8Hk+BTvPRo0f18ssv69tvv5UkRUVFaenSpWZ8hXWy58yZo+HDh8vpdKpx48b6+OOPzxjz2d4DAIBARPsNAEDgof0GAAAoHfi/FQAoBZxOpwzDkN1u1/Hjx/XMM8/orrvu0rhx47R9+3bZbDZzpLckc+mu7Oxsffnll5owYYKSkpKUnJyskJAQlS9fXhEREQoLCzOvOXnypEaPHq3Zs2ebnd7TxypVrVpVd955pypUqCBJOnTokCZOnChJPs/38h5zOp1yOp1mJ9jlcp2xU00nGQBwIaH9BgAg8NB+AwAAlB78HwsA+JG3w+td1mvKlClq3bq1kpKSzGPvvfeeJN9OpnfU9zvvvKNRo0bp119/lSQ1a9ZMgwYN0vjx47Vw4UJNnz5dY8aMUbVq1WS323Xo0CF99NFH+vLLLyUV3C/LMAzFx8erR48e5rF33nlHhw8flt1uN+P18sb0xx9/SMrrOEdHR5v7ZQEAcCGi/QYAIPDQfgMAAJQ+7FENAH7gHQnt7fAuXrxYo0eP1v79+yXldVjLly+vbt266d577y1wfUpKil599VXNnz9fklSrVi117dpVN9xwgy677DIFBwdLkipVqqSGDRuqcuXKmjZtmlauXKn9+/frww8/VIsWLRQZGVlgObAKFSro1ltv1dKlS/XHH3/I4/Fo7Nixeu211wqMyPbuhZW/A12zZk1JZ1+qDACAQET7DQBA4KH9BgAAKL2YUQ0AFvJ4POYSXTabTb///rsGDBigQYMGaf/+/bLZbAoODlbbtm31wQcf6LnnnlONGjUKLPu1ePFi/e9//5OUt/dVr1691KdPH11xxRVmJ9nj8cjlcsnj8aht27Z64IEHVL16dblcLm3fvl2TJ0+WdOblwC655BLdddddkvI67fPnz9e6detkGIacTqdZz9vR37Fjh9kpDgoKMq8DAOBCQPsNAEDgof0GAAAo/UhUA4BFvPtgORwOZWZmauTIkeratatWrFghwzBks9lUv359jRkzRpMnT1Z8fLwkFRhxnZ6ers2bNysjI0MOh0NDhw7V/fffr6pVq/o8zzva2jAM5ebm6ssvv9Thw4dlGIYMw1BSUpI2bdpk1s0vODhYHTt2VJMmTczlyUaNGiXpr2XSpLzOuNvtltvtlsfjUYUKFdSkSZPi/+EBAOAntN8AAAQe2m8AAIDAQKIaACzi7WAmJiaqVatWmjVrlqS8kc/Vq1fXo48+qtmzZyshIUHSX53X00dcV6hQQZ07d1ZcXJx69+6tnj17SvprObPT991KTEzUddddp88//9y8h8fj0alTpzRx4kRJf43Mzi86Olp33323OTL7l19+Me/hHdVtGIZSU1O1Z88e9erVS8uWLVPLli3/0c8JAIDShPYbAIDAQ/sNAAAQGAyPd6geAKBEbdiwQU888YSSk5Ml5XWAw8LC1KVLF91///2KjY2V9NdI7DPx7jt16tQpzZs3T+3atVNkZKR5Pv/o75UrV+qVV17Rjh07JOV1asPCwnTZZZdpy5YtcrlcstlsGjdunLp27XrG5x47dkyjR4/WV199JUmKiIjQjz/+qKCgIPNZubm5OnnypKpUqVK8PzAAAEoB2m8AAAIP7TcAAEBgYEY1AFggKytLS5cuVXJysmw2m4KCglSjRg29/vrrGjFihGJjY80lvArrJEt5nV2Px6Ny5cqpZ8+eioyMVP7xRjabTUePHtXzzz+v/v37m3tXBQUFqXnz5vrggw/0+uuvq1WrVpLyOtbvvfeesrOzZbfbC+zFVaVKFfXq1UuVKlWSJKWmpurVV1+VJPO5QUFBdJIBABck2m8AAAIP7TcAAEDgIFENABYIDQ1Vp06d1LJlS7ndbuXm5iojI0PVqlWTx+ORx+ORzWYrsMyYl3epL0nmUmD5y94O7m+//aYXXnhBc+bMMc/XrFlTL7zwgv7f//t/uvrqq1WtWjU1atRI5cqVkyTt2LFDH374YaGxx8XF6Y477jDLs2bN0smTJ8/aoQcA4EJA+w0AQOCh/QYAAAgcJKoBwCKXXHKJOnfubHZQU1NT9cEHH+jYsWMFOr9eLpdLHo/H3O9qwYIF2r17t3nOy9vB/uSTT/Tjjz8qNzdXktSrVy/NnTtXt99+uyQpNzdXwcHBuuqqq2S3283ObmJiovbt2yebzeZzX0kqX768unTpopo1a6p79+5asWKFKlasWFw/FgAASjXabwAAAg/tNwAAQGAgUQ0AFgkODlazZs3UoUMH89g333yjVatWFeicejwec88qwzC0fv163XbbbXrsscf0zjvvSJLZyfUuAfb+++/r448/VnZ2tmrUqKFXXnlFL7/8sipWrGh2uIOCgiRJzZo1U6VKlcxn/Pnnn3r33Xd97pvfpZdeqs8++0xjx441lyEDAKAsoP0GACDw0H4DAAAEBhLVAGCh2NhYdenSRdHR0eaxxMREJScnm2Wn0ynDMGS323XkyBE98cQTuvvuu/Xzzz/LMAytXLlSmzdvNusbhqHMzEwtWbLEPNauXTvdcMMNkmTuu+UdNe5yuZSWlqby5cub5w3D0Ndff63Vq1ebdfJzOBzsgwUAKLNovwEACDy03wAAAKUfiWoAsIh35HXjxo3VuXNn8/j69ev17bffKiMjQ5LMZcbeeecdtWnTRvPnz5dhGLLZbIqNjdWgQYMUHx/vc+/ff/9dv/zyixwOhyIiIvToo4+ay4Odvu+W3W5XuXLlzCXPoqOj5fF45HQ6C4wWBwCgrKP9BgAg8NB+AwAABAYS1QBgEe+I6ipVqqhDhw6Ki4szz3388cc6duyYpLzlyNq2basJEybI4/HIMAxFRESoX79+mj17tu6+++4C9w4ODlZOTo6cTqeCgoJ0+PBhSX91zr285cWLF+vIkSOqWrWq+vbtq3LlysnlcmnNmjVatWpVibw/AACBiPYbAIDAQ/sNAAAQGBz+DgAAyqLLL79cN910k3799Vd5PB7t379fb775pg4cOKCNGzdKyutYh4SEqE2bNvrPf/6jyy+/XFLesmA2m83seEtSRkaGatasqeTkZLlcLh09elT16tWTYRhyu93mqG7DMJScnKxZs2ZJkpo3b67mzZvr+++/19GjRzVixAhdffXV1v4wAAAIELTfAAAEHtpvAACA0otENQD4Qfny5dW6dWutWrVKy5YtkyTNnz9fksxOcFxcnAYOHKiOHTtKyhuN7fF4zrgs2BVXXKGwsDBJ0vHjxzVv3jzVqVNHMTExZifZ5XJpx44dmjlzpjZt2iRJatOmjerXr69Ro0apVq1aJf7eAAAEMtpvAAACD+03AABA6UWiGgD85OKLL9ZNN92kjRs36uTJk7Lb7XK73YqMjFT//v31r3/9y9wvy+VyyW63+4zi9nK5XAoNDVXv3r310ksvSZK++uor5ebm6u6779bll1+u33//XTt27NDixYu1dOlSuVwuxcXFqWXLlpJEJxkAgCKi/QYAIPDQfgMAAJROhuf0DVQAAJZJTk7WxIkTlZSUJJvNJrfbrWHDhumee+6RJDmdTrOzXBjvPlqS1LNnT23ZssU8Fx4errCwMNlsNqWnpystLU2S1LhxY40cOVKXXHJJybwYAAAXMNpvAAACD+03AABA6WPzdwAAUJbVrFlTnTp1UmxsrNxutyTpm2++0c6dO+XxeM7ZSZby9r1yOp2SpOHDh+uqq64yj2dkZCglJUXJyclKS0tT5cqV1bNnT7344ot0kgEA+JtovwEACDy03wAAAKUPM6oBwE+8I7GPHz+uadOm6b333jPPPfroo+rfv79CQ0PP+75//PGHZsyYoe+++06HDx+WJIWGhqp169Zq1aqVEhISVLFixWJ7DwAAyhLabwAAAg/tNwAAQOlEohoASoGNGzdq9OjR2rRpkyQpKipKEyZMUHx8/N+6n8fj0cGDB3X06FElJyfriiuuUOXKlVWhQoXiDBsAgDKN9hsAgMBD+w0AAFB6nHtNGwBAiWvQoIG6du2qn3/+WU6nU4cOHdJnn32mOnXqKDw8/LzvZxiGatasqZo1a/7tzjYAADg72m8AAAIP7TcAAEDpwR7VAFAKhIaGqkWLFmrbtq15bO7cufrpp5/EwhcAAJROtN8AAAQe2m8AAIDSg0Q1AJQSdevW1U033aTKlStLknJycvTxxx+b+1wBAIDSh/YbAIDAQ/sNAABQOpCoBoBSwmaz6ZprrtGNN95oHlu2bJm+//575ebm+jEyAABQGNpvAAACD+03AABA6UCiGgBKkaioKHXq1El169Y1j3300Ufau3evH6MCAABnQ/sNAEDgof0GAADwPxLVAFBKePfCuvLKK3XTTTeZx7dv36558+bp1KlT/goNAAAUgvYbAIDAQ/sNAABQOpCoBoBSwjAMSVJ4eLjatWunpk2bmuc++eQTbdy40U+RAQCAwtB+AwAQeGi/AQAASgcS1QBQCtWrV0/dunVTWFiYJOnYsWPatWuXOeobAACUPrTfAAAEHtpvAAAA/3H4OwAAQEHBwcFq2rSpGjVqpIMHD+rll1/2GeENAABKH9pvAAACD+03AACA/xgehgcCQKl14MABxcTE+DsMAABwHmi/AQAIPLTfAAAA1iNRDQAAAAAAAAAAAACwFHtUAwAAAAAAAAAAAAAsRaIaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKVIVAMAAAAAAAAAAAAALEWiGgAAAAAAAAAAAABgKRLVAAAAAAAAAAAAAABLkagGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCkS1QAAAABwFklJSapfv775z+rVq/0dEoAi2L9/v8/v7oQJE4qlLgAAAACgeDj8HQAAAACAsmX//v3q0KHDP7rHrbfeqjFjxhRTRDgfq1evVt++fUv0GaNHj1aPHj3Mcvv27XXgwIGzXhMcHKzw8HBVrVpVcXFxatKkibp06aLy5cuf17NPf79rr71WM2fOPL8XAAAAAAAA58SMagAAAABAwMvJydHRo0e1bds2zZkzR88++6xat26t999/Xy6Xy9/h4QKTf/b1sGHD/B0OAAAAAAQkEtUAAAAAgAtSRkaGXnvtNQ0aNIhkNQAAAAAApQxLfwMAAADwq6ioKH300UfndU1YWFgJRYNzadSokRYvXlykunfffbcOHTpklhMTE1WjRo1zXle5cuWznj/TfXJycnTkyBGtW7dOn3zyiVJSUsxz33//vd544w09+eSTRYobAAAAAACUPBLVAAAAAPzK4XCoVq1a/g6jUD169PDZL7msCwkJKfKfl8Ph2+WsUaNGsfxZF3afiy++WNddd5369eunxx9/XP/73//MczNmzFCfPn0UFRX1j5+PC0+tWrW0bds2f4cBAAAAAGUKS38DAAAAAC4o5cuX1+uvv65q1aqZx7Kzs/Xtt9/6MSoAAAAAAJAfiWoAAAAAwAWnfPny6t69u8+xtWvX+ikaAAAAAABwOpb+BgAAAHDB8Hg82rVrl3bt2qWUlBRlZGQoODhYERERqlOnjho2bKjg4GB/h1lsDh06pB07dmjfvn06efKkJCkiIkLR0dFq3LixKlas6OcI/athw4Y+5YMHD/opkpJx6NAhbd68WSkpKcrOzlb16tV11VVXqXbt2sX6nM2bN2vv3r06fPiwnE6nLrvsMl1//fVnvSYnJ0cbN27UgQMH9Oeff8pms6lKlSpq0KCBGjRo8I9j2rNnjzZv3qzDhw8rJCRENWrUUHx8fEAu7Z6ZmakdO3Zo9+7dOn78uLKyslSxYkVVqVJFV155pS666CJ/hwgAAAAAJYJENQAAAICAlpWVpSVLlmjhwoVatWqVTpw4UWjd0NBQJSQkaODAgapTp06R7p+UlKSnn37aLM+YMUPXXXedTx2326177rlHq1evNo8NHjxYDzzwQJGe8cQTT2jevHlm+e6779YLL7xQoJ7b7dZPP/2k+fPna/ny5dq3b1+h97TZbGrWrJkGDhyoZs2aFSmOC01ERIRPOS0tzU+R/D0TJkzQxIkTzfLixYtVq1Ytbd26VW+//bZ+/PFHuVyuAtddddVVGjZsmK6++uoiPad+/frm51tvvVVjxoyR2+3W1KlT9dFHH2n//v0+9Rs0aFBoonrXrl165513tGTJEmVmZp6xTlRUlPr376/evXuf98CRdevWacyYMdq8eXOBc3a7Xa1atdIjjzyiK6+88rzuu3//fnXo0MEsP/TQQ3r44Yd96gwbNkxz5swpcO2cOXPOeNzrTHtfHzhwQPPnz9f333+vLVu2KDc3t9DrY2Ji1LdvX915550KDQ0tyusAAAAAQEBg6W8AAAAAAe3555/X4MGDtWDBgrMmqaW8pHZSUpK6d+/ukxj+p2w2m8aPH68qVaqYxyZMmKB169ad89pPP/3UJ5YGDRr4JMbzS0pKUp8+fTR79uyzJqmlvKT2ihUr1K9fP40ZM+aMCc0LXXp6uk/5QphN/+WXX+rOO+/U0qVLC/0z3bRpk3r37q333nvvbz0jNTVV/fr107hx4wokqQvj8Xj01ltvqVu3bpo3b16hSWopbyb4mDFj1KNHj/Oa5T558mT17t37jElqSXK5XFq6dKnuvPNOffnll0W+r9VcLpc6dOig1157TevXrz9rklrKS2qPHj1ad9xxhw4cOGBRlAAAAABQ8phRDQAAACCgud1un3KlSpV06aWXqnLlygoNDVVGRoZ2796tPXv2yOPxSMpLWD/55JOqWLGi2rZtWyxxVK9eXePGjdN9990nj8cjp9OpJ554QnPnzlWlSpXOeM2OHTs0cuRIsxwWFqY333yz0ISqN36v0NBQXXrppYqMjFSFChWUnZ2t5ORkbdu2zSf5NXXqVDkcDj355JP//EUDyK+//upTjomJ8VMkYTTdvwAAFe5JREFUxWPt2rV67rnn5HQ6JeXNTL788ssVFham5ORkbd682fx9cLvdev311xUSEqJ77rmnyM/weDwaMmSI1qxZI0lyOBxq2LChatSooezsbP3xxx9nvOapp57SF1984XM8NDRUcXFxql69uiRp7969+vXXX82/xzt27NCdd96pzz77TJGRkWeNa9q0aXrjjTd8jtntdsXHxys6OloZGRn65ZdfdOTIEeXm5urpp5/WqFGjivzeVvJ4PD6/y4ZhqFatWqpdu7bCw8NlGIaOHz+uX3/9VcePHzfr/fbbbxowYICSkpJUvnx5f4QOAAAAAMWKRDUAAACAgFevXj316NFD119/faFLeu/bt0/vvfeePv30U0l5yaJhw4Zp8eLFCgsLK5Y4WrdurXvvvVcffPCBpLw9kYcNG6bJkycXqJuVlaXBgwcrKyvLPPbCCy+obt26Z31GtWrV1KNHD7Vv317x8fGy2+0F6qSlpWn27Nl69913derUKUnSlClTdMMNN+iqq676J68YMHJzcwskTps2beqnaIrHK6+8IqfTqapVq+qFF17QDTfcIJvtr4XSDh06pJEjR+rbb781j40fP14tWrRQvXr1ivSMb7/9VpmZmTIMQ/369dN//vOfAgMtTp9l/cEHH/j8rCMiIjR48GD16NFDISEhPnX37dunV155RUuWLJEkpaSkaNiwYZoyZYoMwzhjTNu2bdP48eN9jnXt2lXDhg3zSXC73W4tWLBAI0aM0LFjx/TKK68U6Z2LaujQoXrooYckyWeZ8E6dOmno0KHndS+Hw6EOHTqoc+fOat269Rn3k3e73Vq+fLnGjRun7du3S8rbm3v8+PFn3BoAAAAAAAINiWoAAAAAfnXgwAGfPXLPZfTo0erRo4dZfvzxx1WzZs1zXhcbG6uRI0fqkksu0ZgxYyRJx44d09y5c3X33Xeff+CFeOyxx/TTTz9pw4YNkqTvv/9e06ZNKzCrdeTIkdqxY4dZvvXWW3XLLbec9d7t2rVT9+7dz7mEdXh4uO6//341bdpUffv2VU5Ojjwej6ZOnao333zz77xWQHG5XHrxxRd9lkkODQ1Vt27d/BjVP5eWlqZKlSpp5syZuuSSSwqcj4qK0oQJE/T0008rKSlJUl7CfsSIEZo5c2aRnuFdsvvFF1/UnXfeecY6tWrVMj/v2LFDb731llmuUaOGEhMTferkFxsbq3fffVfPPPOMGeOPP/6opUuXql27dme8ZuTIkT4rBPTu3VvPP/98gXo2m00JCQm67LLL1Lt3b6Wmpp79Zc9TlSpVfJb39woLCyv0fc/Ebrfru+++O+d/t2w2m1q3bq1rrrlG/fv318aNGyXlbQHw6KOPFrpSAwAAAAAECvaoBgAAABDQipKkzq9///664oorzPI333xTrPE4HA69/vrrioiIMI+NHz9eW7ZsMcvz5883Z3ZLUt26dc+YeDtdZGTkee2z3LhxY/Xu3dssL1q0SDk5OUW+PpDk5OTowIED+uKLL9SrVy999tlnPucffvhhcwnqQPbUU0+dMUmd3/PPP+/ze7FmzRr9/vvvRX7G9ddfX2iS+nRTpkwxlyI3DENvvfXWOZO2hmHoxRdfVI0aNcxjM2bMOGPdHTt2mMuQS1KdOnU0bNiws97/sssu05AhQ4oUvz8YhnFe/90KCwvTSy+9ZJazsrLMGekAAAAAEMhIVAMAAAAoc9q3b29+3rp1q1wuV7Hev2bNmj7LDufm5mrw4MFKT0/XH3/8oeHDh5vnQkJC9Oabbxbb8uOny79EcW5uboF9mwNRhw4dVL9+fZ9/GjZsqPbt22vo0KHaunWrT/377rtP9957r5+iLT41a9bUrbfees565cqVU//+/X2OffXVV0V+zoABA4pULy0tTfPnzzfL7dq1U6NGjYp0bUhIiHr16mWWV69ebS5Tn9/pcd97771FGqxx2223KSoqqkixBIIGDRr4DADYtGmTH6MBAAAAgOLB0t8AAAAA/CoqKkofffRRketXrly5SPVcLpfS09OVmZlZIBGdP9GVmZmplJQUxcTEFDmGoujYsaP69u1rzhTdt2+fnnnmGe3fv18ZGRlmvWHDhqlBgwb/6Fkej0cZGRnKyMjwWSLZey6/Xbt2lYl9qg3DUNu2bXXfffepSZMm/g6nWHTq1KnQfZxPl5CQoFGjRpll71L051KxYsUi7+W9fv16n79vnTp1KtJ1Xvn/XJxOpzZt2qRmzZr51Mkft81mK/IzbDabOnfurOnTp59XTP6WnZ2t9PR0ZWVlFfjdrVSpkrk/+K5du/wRHgAAAAAUKxLVAAAAAPzK4XCc1/6uhcnIyNB3332nxYsX67ffftO+ffsKJHoKk5aWVuyJakkaMmSI1q9fb87wXbhwoc/5Tp06/a39sV0ul1asWKEFCxZoy5Yt2rVrV4EEdWGKe9/e0srj8SgzM/OCmlXbsGHDItetVq2aoqOjdfDgQUnSzz//XKTrGjRoUORk+Pr1633K+ROpReF2u33K+fcU9/rll1/Mz7Vr11Z4eHiR738+Py9/2bNnj+bNm6fVq1dr+/btOnHiRJGuS0tLK9nAAAAAAMACJKoBAAAABLykpCSNGzdOx48f/1vXp6enF3NEeYKDg/Xmm2/qlltuKfCMmJgYjRw58rzvuWHDBj3//PPavn3734qppN7VSomJiT77GzudTh08eFA7duzQrFmz9Mcff0jK25v5rrvu0scff6zY2Fh/hVtszvcdLrroIjNRnZ6erpycnHMum12lSpUi3z8lJcWn/MADD5xXfKc7fRCFd3ax10UXXXRe96tdu/Y/iqckpaWlaezYsfr888+LPKAmvwvh9xgAAAAA2KMaAAAAQEB7++239fTTT//tJLVUcGZncYqNjT3jrOlRo0ad1+xQSfrhhx/Ut2/fv52klgouBR6IatSooVq1apn/1KlTR82bN1ffvn21YMECn/2Zjxw5okGDBiknJ8ePERePChUqnFf9ihUr+pSLMgv3fPZKL+7Z+ZmZmT7l0+M93/c/3/pWSU1NVb9+/fTZZ5/97d/HC+H3GAAAAACYUQ0AAAAgYK1Zs0bvvPOOz7FGjRqpS5cuuvLKK1WjRg1VrlxZwcHBCgoKMuskJSXp6aeftiTGPXv2aNasWQWOz507V82bNy/yfU6cOKEhQ4b4JFxjYmLUvXt3NW7cWLGxsapWrZpCQkJ8Zs3u379fHTp0+GcvEUBsNpueeuop7dmzR99//70kadu2bZo0aZIeffRRP0d3YXE6ncV6v7KSfB0zZozPkuYhISHq0qWLWrRooXr16ql69eoKCwtTSEiIbLa/5hf06dNHa9as8UfIAAAAAFAiSFQDAAAACFjvvvuuT/m5555Tnz59znldRkZGSYXkIycnR4MHDy4wU1T6K1F9yy23FOleH330kc/+tTfddJPGjBlzzqWcrXrX0sQwDL300ktavXq1+bP/8MMPdfvtt5fIXuRWOd/lnk+ePOlTPt8Z/OcSERHhU/766691ySWXFNv9T4/3fN+/NC6PffDgQc2ZM8csV69eXdOnT9fFF198zmvL4u8yAAAAgAsbS38DAAAACEgZGRn66aefzHKLFi2KlKSWpKNHj5ZUWD7GjRvnM3OyefPmCg0NNcsvvfSSdu/eXaR7LV261PxcsWJFjRw58pxJasm6dy1toqKi9K9//cssZ2dnFxjYEGj27dt3XvX37t1rfq5QoUKR/r6cj9P3s/4ny++fSUhIiM/y3fnfpyi8e5WXJkuXLvWZOT5kyJAiJamlvGXsAQAAAOBCQqIaAAAAQEBKTk5Wbm6uWW7VqlWRr924cWMJRORr0aJFmjlzplmOjY3VxIkT9eyzz5rHMjMzNXjw4CLtn5w/6XbNNdcUeS9hK961tBowYIDPz2nu3Lnav3+/HyP6Z7Zs2VLkukeOHNHBgwfN8hVXXFHs8TRq1MinvGnTpmJ/RlxcnPn5jz/+KNI+217n8/OyyunJ86L+d+vgwYM6fPhwSYQEAAAAAH5DohoAAABAQDp9WeP8My/PJiUlxWcmdklITk7WM888Y5aDgoL0+uuvq0KFCurVq5e6dOlinvv11181duzYc94z/zLGRX1Xj8ejefPmnUfkF5bKlSurZ8+eZtnpdOr999/3Y0T/zMKFC4u8j/M333zjU27cuHGxx9OsWTMZhlHoM4tD/rjdbrcWLlxYpOvcbrcWLFhQ7PF45Z+dnn/AzLmcvhx5UX+Xv/rqqyI/AwAAAAACBYlqAAAAAAHp9P1r9+zZU6Tr3nrrLTmdzhKIKI/T6dTjjz+u1NRU89gTTzyh+Ph4szxixAjVqlXLLM+aNUuLFi06630rVqxofi7qcuFffPGFdu3aVdTQL0j//ve/FRQUZJaTkpJ06NAhP0b09yUnJ/vsb1yYrKwsTZ061edYt27dij2eatWqqWPHjmZ5y5YtxZ6sPj3uKVOmFGkFgs8//7xE/5zz/z6ez5Lc+a+TivbfrWPHjmnatGlFfgYAAAAABAoS1QAAAAAC0kUXXaRy5cqZ5blz555zj9yPP/5YSUlJJRrX22+/rQ0bNpjldu3a6Z577vGpU7FiRb3xxhs+CdRnnnnGZ6nm09WrV8/8/PPPP2vNmjVnjWPz5s0aMWLEeUZ/4YmKitItt9xilnNzc/XBBx/4L6B/aOzYseccfPDSSy8pOTnZLF977bW69NJLSySeQYMGyWb766uFZ5555px/N093+PBhnz3Y87vssst07bXXmuU9e/ZozJgxZ73f77//rldfffW8YjhfdevWNT9v2bJFGRkZRbou/++xpAIDCk536tQpDR48WH/++ef5BwkAAAAApRyJagAAAAABKTg4WO3atTPLx44d04ABA7R9+/YCdY8ePaoXXnhBL774oqS8JaFLwvLly32Wlo6KitLo0aN9lkf2io+P1+DBg81yamqqnnjiCblcrjPeu1OnTj7lhx9+WIsXLy5QLysrS9OmTVO/fv2Unp5eYu8aSO69916fZOqnn36qo0ePFuna7Oxs7d+//7z/SUlJKfb3CA8P14kTJ9SnTx8tXLhQbrfb5/yhQ4f0yCOP+AzGCAoK0vDhw4s9Fq/LL79cjz32mFnOzMzUPffco5EjR2rv3r2FXpeWlqavv/5ajz32mNq3b6+5c+cWWve5557zGdSRmJioJ554osBMZrfbrW+++UZ9+vRRampqgVUXilOTJk3Mz5mZmRo4cKC+++477dy5s8DfhfzatGnjM8AmKSlJo0ePLrAkuCT99NNPuuuuu7Rq1SoZhqFKlSqV2PsAAAAAgD84/B0AAAAAAPxdDz30kJYsWaLs7GxJ0i+//KJu3brp8ssvV926deV2u5WcnKytW7eaSb3atWurd+/eeuWVV4o1lqNHj2ro0KHmHsJ2u12vvfaaqlSpUug1AwYM0KpVq/TDDz9IktatW6e3337bJ4Htdfvtt2v69OnmUsEnTpzQgw8+qJiYGMXFxSkkJERHjhzR5s2bderUKUlSaGioXnzxRT366KPF+q6Bpk6dOurcubO+/vprSXnJ/A8//FBPPfXUOa/dtGmTOnTocN7PjImJ0ZIlS877urMZNmyYhg8frqNHj+qRRx5RVFSU4uLiFBYWpuTkZG3atKlA8vrJJ58sMIu3uA0cOFAHDhzQJ598IklyuVyaOXOmZs6cqVq1auniiy9WeHi4nE6nTp48qT179ujAgQNFvn/9+vX15JNPavTo0eaxefPm6ZtvvtFVV12l6OhoZWZmauvWrWby2uFw6Omnn9bTTz9dvC/7f3r27KmpU6ea/+1Zu3at1q5de8a627ZtMz9XqVJF/fv317vvvmsemzZtmv773/+qUaNGqlq1qtLT07Vt2zafWfH9+/fX1q1bz3u2OgAAAACUZiSqAQAAAASsSy+9VGPHjtWQIUOUm5trHv/111/166+/Fqhfp04dTZkypdCE0t/ldrs1ZMgQn1m6Dz74oJo2bXrW6wzD0NixY3XzzTebCbb3339fzZo1U/PmzX3qBgcH691331W/fv18ZpIeOHDgjEm/sLAwvfXWW7r44ov/yatdMAYOHGgmqiVp9uzZuu+++846kKC0ue666zRq1Cg9++yzcrlcOnToUKH7MBuGocGDBxdYdr6kvPzyy6pfv77GjRunrKws8/iZZhWfyblmP99zzz06deqU3nrrLXMwiMvl0vr16wvUdTgcGjVqlM+s5+JWq1YtjRkzRk8//bTP+xbFQw89pJ07d2rhwoXmsczMTK1YseKM9e+44w4NGTJE/fr1+0cxAwAAAEBpw9LfAAAAAAJaly5d9NFHH501KVW9enU98MADSkpKUmxsbLHH8P777/skma699lo9+OCDRbq2SpUqGj9+vLk0tTfpfaY9aS+55BLNmTNHN998sxyOM487DgsL0y233KIvv/xSbdq0+Rtvc2Fq0KCB2rZta5YzMzM1ffp0P0b099x6662aPXu2WrVq5bOceX7x8fFKTEzUwIEDLY2td+/eWrx4sQYMGKCoqKhz1q9Tp47+9a9/afbs2XrppZfOWf8///mPZs2apfj4+DOet9lsatWqlT7++GOffclLSkJCgr7++ms99NBDuvbaaxUZGanQ0NBzXme32/XWW2/p2WefVWRkZKH1GjdurAkTJujll18u9M8aAAAAAAKZ4fEORQYAAACAALdv3z6tW7fOnNkcGRmp2NhYNWrU6IJL9Bw/flw//fSTDhw4oOzsbFWtWlVRUVFq0qSJzx64CFwTJkzQxIkTzfLixYtVq1Yts5ySkqJNmzYpJSVFOTk5ioyMVKNGjVSnTh0/RFvQzp07tW3bNh0/flxpaWkKDg5WeHi4YmNjdemll6patWp/+9579uzRxo0bdeTIEYWEhCgqKkrx8fGKjo4uxjcoebm5udq8ebO2bdumtLQ0VahQQZGRkYqLiyuRQTUAAAAAUJqQqAYAAAAAoBQ6V6IaAAAAAIBAdmFNKQAAAAAAAAAAAAAAlHokqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACwFIlqAAAAAAAAAAAAAIClSFQDAAAAAAAAAAAAACxFohoAAAAAAAAAAAAAYCkS1QAAAAAAAAAAAAAASxkej8fj7yAAAAAAAAAAAAAAAGUHM6oBAAAAAAAAAAAAAJYiUQ0AAAAAAAAAAAAAsBSJagAAAAAAAAAAAACApUhUAwAAAAAAAAAAAAAsRaIaAAAAAAAAAAAAAGApEtUAAAAAAAAAAAAAAEuRqAYAAAAAAAAAAAAAWIpENQAAAAAAAAAAAADAUiSqAQAAAAAAAAAAAACWIlENAAAAAAAAAAAAALAUiWoAAAAAAAAAAAAAgKVIVAMAAAAAAAAAAAAALEWiGgAAAAAAAAAAAABgKRLVAAAAAAAAAAAAAABLkagGAAAAAAAAAAAAAFiKRDUAAAAAAAAAAAAAwFIkqgEAAAAAAAAAAAAAliJRDQAAAAAAAAAAAACw1P8HesEhARkDdaQAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 730
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b940dc4e431e48119f320de36b758fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2fc87ea31764ba2880dace55c47e8ed",
              "IPY_MODEL_caa2380db9014dddb37ec96f780a5f1f",
              "IPY_MODEL_1121d3534067446f8d044dd727a1f5c3"
            ],
            "layout": "IPY_MODEL_deb9589c3a4543f2b30bb8f7924ff7ad"
          }
        },
        "d2fc87ea31764ba2880dace55c47e8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e052766693c4b58a3f1d300712afe72",
            "placeholder": "​",
            "style": "IPY_MODEL_df2d4e0ea8df40a394c3a6b144ff6984",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "caa2380db9014dddb37ec96f780a5f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83cce591e4f14258abc3cc19eedd65c5",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6eed425fe98142d4b3612af18cbe322a",
            "value": 29
          }
        },
        "1121d3534067446f8d044dd727a1f5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_364e14124794417c861142131df5e0ad",
            "placeholder": "​",
            "style": "IPY_MODEL_34249fa658cc4f729d41172d2aba282c",
            "value": " 29.0/29.0 [00:00&lt;00:00, 623B/s]"
          }
        },
        "deb9589c3a4543f2b30bb8f7924ff7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e052766693c4b58a3f1d300712afe72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2d4e0ea8df40a394c3a6b144ff6984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83cce591e4f14258abc3cc19eedd65c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eed425fe98142d4b3612af18cbe322a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "364e14124794417c861142131df5e0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34249fa658cc4f729d41172d2aba282c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a79be80d076b4f9ba4378da4df7aa45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5be0179a2a924fba9ec9b475ad463208",
              "IPY_MODEL_b0768ad058a7410eb49e13ec280b1a28",
              "IPY_MODEL_03b2c99635a0435498b1da35f3d0d7b0"
            ],
            "layout": "IPY_MODEL_856b47eb7f1443729c0e2c909e477791"
          }
        },
        "5be0179a2a924fba9ec9b475ad463208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33382c9de19f47eca0feb6567e8f5a0d",
            "placeholder": "​",
            "style": "IPY_MODEL_d46a48a0963c440394b2429e44e8b7b0",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "b0768ad058a7410eb49e13ec280b1a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51d8d5c43a7049ae90d777450a2499bb",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d2fb7c9c6eb4e72b6b4880beb490998",
            "value": 995526
          }
        },
        "03b2c99635a0435498b1da35f3d0d7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6529d6df57044bb0815cb5029138b2db",
            "placeholder": "​",
            "style": "IPY_MODEL_47f8cc0aed09443195dfcd041cb2236b",
            "value": " 996k/996k [00:00&lt;00:00, 5.01MB/s]"
          }
        },
        "856b47eb7f1443729c0e2c909e477791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33382c9de19f47eca0feb6567e8f5a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46a48a0963c440394b2429e44e8b7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51d8d5c43a7049ae90d777450a2499bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d2fb7c9c6eb4e72b6b4880beb490998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6529d6df57044bb0815cb5029138b2db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f8cc0aed09443195dfcd041cb2236b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e57d95e0624341859582dd8974da749d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34896824bd66456faddff9013fde0ed9",
              "IPY_MODEL_4d2ebf7025804e64963410f32f1b1a75",
              "IPY_MODEL_626fe494664346478825306331a5dc8e"
            ],
            "layout": "IPY_MODEL_3d173ac5213f47dd8748c2e2191871e6"
          }
        },
        "34896824bd66456faddff9013fde0ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbab8d085db0485ea1ff3a9b303d4b20",
            "placeholder": "​",
            "style": "IPY_MODEL_7611df624d264f0ba5cf784abad7391c",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "4d2ebf7025804e64963410f32f1b1a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_080671c2e89f4d82bbe21958b403e29d",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_088f50bd522642bb8d9c4e31011a04d8",
            "value": 1961828
          }
        },
        "626fe494664346478825306331a5dc8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a35714abf634fe7a0350e023dcc2ed9",
            "placeholder": "​",
            "style": "IPY_MODEL_8a6ab8f7f6b44c2993ac61148e50ad27",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 19.7MB/s]"
          }
        },
        "3d173ac5213f47dd8748c2e2191871e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbab8d085db0485ea1ff3a9b303d4b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7611df624d264f0ba5cf784abad7391c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "080671c2e89f4d82bbe21958b403e29d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088f50bd522642bb8d9c4e31011a04d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a35714abf634fe7a0350e023dcc2ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6ab8f7f6b44c2993ac61148e50ad27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "464ba841815346c0b2bf96e24524fced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6115dce306b4d11babc18049091618a",
              "IPY_MODEL_4fd4c9fd70584034b56486e1fa373e1b",
              "IPY_MODEL_e340078e9bd44f45be2ebc0242f6bf42"
            ],
            "layout": "IPY_MODEL_400d9fdc112a4de280e35bcd9d5457fb"
          }
        },
        "f6115dce306b4d11babc18049091618a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34352a0e5c974116a6002ef3defde228",
            "placeholder": "​",
            "style": "IPY_MODEL_ce5056f782354ec0970b45dc6a3ae35a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "4fd4c9fd70584034b56486e1fa373e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6706cf212d4481eba9b7d05eced3c2c",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3486a5bfc8854b738d7e1f3dd98fd4bc",
            "value": 625
          }
        },
        "e340078e9bd44f45be2ebc0242f6bf42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f107f95c2384dffa006062deca7edae",
            "placeholder": "​",
            "style": "IPY_MODEL_194de5357ce04d1baf5b69699f08fdf4",
            "value": " 625/625 [00:00&lt;00:00, 42.9kB/s]"
          }
        },
        "400d9fdc112a4de280e35bcd9d5457fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34352a0e5c974116a6002ef3defde228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5056f782354ec0970b45dc6a3ae35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6706cf212d4481eba9b7d05eced3c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3486a5bfc8854b738d7e1f3dd98fd4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f107f95c2384dffa006062deca7edae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194de5357ce04d1baf5b69699f08fdf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422df16e8b46441587150ab0bf4f7dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc52dffe6a5d47f8849e398545dfabad",
              "IPY_MODEL_6df5aa9d6428435997fdd296aefd7cb5",
              "IPY_MODEL_c6a5a53a6b6a40049c02701dbfe9d956"
            ],
            "layout": "IPY_MODEL_b50a46e7d47d430cba6fe4415e7be8c2"
          }
        },
        "bc52dffe6a5d47f8849e398545dfabad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f06f06e52142d49b377ac5713a046f",
            "placeholder": "​",
            "style": "IPY_MODEL_530325af5c6f4bba9ba1ea5ab21c8bb8",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "6df5aa9d6428435997fdd296aefd7cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ea875bdf82a40e8b6f94d30dee1b366",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbc44b71dcf548a9a12d2eb60a6d0b64",
            "value": 714290682
          }
        },
        "c6a5a53a6b6a40049c02701dbfe9d956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21c3e77cd63a46f89c97fa3ae7f97e34",
            "placeholder": "​",
            "style": "IPY_MODEL_160df92cc3144054a371b648f5f7f3bc",
            "value": " 714M/714M [00:07&lt;00:00, 53.8MB/s]"
          }
        },
        "b50a46e7d47d430cba6fe4415e7be8c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27f06f06e52142d49b377ac5713a046f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "530325af5c6f4bba9ba1ea5ab21c8bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ea875bdf82a40e8b6f94d30dee1b366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbc44b71dcf548a9a12d2eb60a6d0b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21c3e77cd63a46f89c97fa3ae7f97e34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160df92cc3144054a371b648f5f7f3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}