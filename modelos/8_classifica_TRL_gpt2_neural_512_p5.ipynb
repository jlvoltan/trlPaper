{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - GPT-2 + 512 tokens +Rede Neural [kfold][P5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- **`pierreguillou/gpt2-small-portuguese`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 24 SET 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 5**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 512 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "NOeYJqHdTeHU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjJNdaXvTeze",
        "outputId": "2938f2bf-7d4d-4ddf-ffa7-5210b3780f78"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=5  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_gpt2_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "d1b4a1b9-4b41-4231-ae9a-a2ced203b876"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_gpt2_neural_5.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512   #O GPT-2 o máximo é 1024"
      ],
      "metadata": {
        "id": "v7gLFBuBT6WO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "9cZxPMZOfICS"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "h5RDBcpVf0TS"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "27eb5377-93c8-467e-bb8d-59c18ca687d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 15:48:49 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    32W /  70W |   5671MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "cdb06950-e347-403b-c624-5eca7e16643a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "import torch\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from transformers import GPT2Model, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "OXAUnWshi1w7"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "1f14f09d-d638-4b5f-8824-391ecfe851fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "c5a22fb8-81d3-4e9d-f6f0-33a6d4b59040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "36a8598d-be1f-41cf-931a-9ef09a61405e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4358a87-d134-4307-adb6-bb8e92218fda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4358a87-d134-4307-adb6-bb8e92218fda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4358a87-d134-4307-adb6-bb8e92218fda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4358a87-d134-4307-adb6-bb8e92218fda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df46e3c8-2c36-4e07-bd29-5fc408e8961d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df46e3c8-2c36-4e07-bd29-5fc408e8961d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df46e3c8-2c36-4e07-bd29-5fc408e8961d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/pierreguillou/gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@inproceedings{pierre2020gpt2smallportuguese,\n",
        "  title={GPorTuguese-2 (Portuguese GPT-2 small): a Language Model for Portuguese text generation (and more NLP tasks...)},\n",
        "  author={Pierre Guillou},\n",
        "  year={2020}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Tokenizer**: No GPT-2, ao contrário do BERT, o preenchimento é feito à esquerda, uma vez que o último token é utilizado para a previsão."
      ],
      "metadata": {
        "id": "yLIJaQxyg7JM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "WPj7c-IBgWRx"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = \"pierreguillou/gpt2-small-portuguese\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "# tokenizer.model_max_length=MAX_LEN\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "qSErznNMh4P5"
      },
      "outputs": [],
      "source": [
        "# bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "# model = AutoModelWithLMHead.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "model = GPT2Model.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exemplo da tokenização no GPT2"
      ],
      "metadata": {
        "id": "VK2XSMUYiABq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "78tJbGMogWaZ"
      },
      "outputs": [],
      "source": [
        "gpt2_input = tokenizer(frase, padding=\"max_length\", max_length=16, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt2_input['input_ids'])\n",
        "print(gpt2_input[\"attention_mask\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES67iwbAh2Jz",
        "outputId": "6d8d3859-8146-4cb1-8c9b-3e3d38af9257"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     0,     0,     0,     0,    33,  7912,   261,   374, 38198,\n",
            "         20142,   300,  9643,   261,  3325,  2303]])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tokenizer.decode(gpt2_input.input_ids[0])\n",
        "print(example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ6-184nh9hr",
        "outputId": "d45508e6-5a22-43e3-d2f5-3b84a30b4f60"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>A avaliação de prontidão tecnológica em tecnologias de interesse militar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Variáveis do modelo:"
      ],
      "metadata": {
        "id": "urxVLrRBZQhg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "PSjRYlnghJRw"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Devemos construir uma class Dataset para ler os textos, tokenizar e armazenar em _containers_ para o treinamento em lote."
      ],
      "metadata": {
        "id": "RlAPjXSWkL56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      truncation=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Estamos adicionando uma camada linear sobre as 12 camadas de decodificadores do GPT-2 com sua dimensão de saída igual ao nosso número de classes"
      ],
      "metadata": {
        "id": "sHe6lDI4lyhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2SequenceClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size: int,n_classes:int, max_seq_len:int):\n",
        "        super(GPT2SequenceClassifier,self).__init__()\n",
        "        self.gpt2model = GPT2Model.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.fc1 = nn.Linear(hidden_size*max_seq_len, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        gpt_out, _ = self.gpt2model(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "        batch_size = gpt_out.shape[0]\n",
        "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
        "        return linear_output"
      ],
      "metadata": {
        "id": "ik0pY8jfl9G6"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = GPT2SequenceClassifier(hidden_size=768, n_classes=len(class_names), max_seq_len=MAX_LEN)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "755b50b9-b197-4095-92b8-920729a23b05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((108, 2), (27, 2), (33, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "3478df74-b34a-44c0-9938-28b6dc1e86e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "87209324-4ee9-4311-dcb0-df6b74058638"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "f8086dea-43f2-4660-d2bb-4b603198469f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "4517c09a-ae67-4a73-9ee6-79efc3034c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "84e4c4c0-7cc1-4e74-8f6d-5bf56bc8f210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "de2093cd-4afb-4750-fba9-0dd7a2fcc584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "6086cfb3-9257-4308-af31-01afe0624b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 3.4887759004320418 accuracy 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6210055351257324 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9842703023127147 accuracy 0.6759259259259259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6200789669528604 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.0435201774484344 accuracy 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6298311799764633 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5195311198809317 accuracy 0.8518518518518519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1876787934452295 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4273971746609147 accuracy 0.8240740740740741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2168059572577477 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05933591877315588 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3317467272281647 accuracy 0.37037037037037035\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3059815035095588 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.720162087425706 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04107432775272254 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8055272921919823 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02662203910876672 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.195259812520817 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.12775820967575718 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9399942308664322 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.015134180544870495 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.017355689778924 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.056017930681308926 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.9146103901875904 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08082313347890617 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.480142591171898 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.027898547179274504 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.03037508198031 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0870485539583419 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3251584717072546 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.019389213181325107 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.702784602646716 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.06827318240474207 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2545568209607154 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03162223736189113 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.4785693371959496 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04469737938968267 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1275616814382374 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.030836751383718917 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.4873534184589516 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03901445221251519 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.120059052715078 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.034327103589297234 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3794366116053425 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.038040445291077925 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.118019486311823 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.029155341622403137 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.365626242302824 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02654453357566971 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.120169566012919 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.030592010455807537 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.334868166013621 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.027085086022667935 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1615588003769517 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.018898754139822165 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3942112987861037 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.032045758144314665 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.201267837313935 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013914941635947895 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3207386231515557 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.028774197015199628 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.142615399323404 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01622406707193948 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.337840421590954 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01575911355273466 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2310642836382613 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.019027868475169334 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1601833226159215 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02501165222769178 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3286134358495474 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.010678706387003396 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.208702569711022 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01346368337703195 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.296711689850781 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01639550049344101 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1724576906999573 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.020854363423584994 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.25501811504364 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.012168111517029599 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1987639410654083 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.011101090450032254 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2648702886071987 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.017443952727148826 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.271162973542232 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.024914069850914138 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2853917788597755 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.008814540223275864 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2755574894254096 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01009672974968063 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2630876261973754 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.008993737362954692 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1804750758456066 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.017092202300870798 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1394881797023118 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.007750485532743109 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1570027995621786 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01534372986731114 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.167945702909492 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.017385799658512596 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.164321121177636 accuracy 0.6666666666666666\n",
            "\n",
            "CPU times: user 10min 27s, sys: 28.1 s, total: 10min 55s\n",
            "Wall time: 12min 1s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "e109a6d8-fdc4-48a4-cbbb-9e5c904e097c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "4d70af71-87bf-4df9-a048-2fd050bc7c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "ef962d65-9a4e-4a69-da33-cd17f071684a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrcGxmh_yKxU",
        "outputId": "4111ed5e-6c37-4b4e-fa66-698e2e2021d8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.65      0.94      0.77        18\n",
            "     Faixa 2       0.00      0.00      0.00         9\n",
            "     Faixa 3       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.67        33\n",
            "   macro avg       0.50      0.59      0.54        33\n",
            "weighted avg       0.51      0.67      0.57        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HQ54xluu8RL3",
        "outputId": "2457a014-6a96-4a1b-ce7d-0e09b9cdd95f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 723
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "oENoyHsUPjWv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}