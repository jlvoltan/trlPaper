{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - GPT-2 + Rede Neural [kfold][P5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- **`pierreguillou/gpt2-small-portuguese`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 24 SET 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 5**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 242 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "NOeYJqHdTeHU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjJNdaXvTeze",
        "outputId": "2ba35a7f-b08d-49d6-ffcb-f3ab4e2fcad1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=5  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_gpt2_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "1d3d36e3-2dbe-494e-a11f-3a771319098c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_gpt2_neural_5.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 242   #O GPT-2 o máximo é 1024"
      ],
      "metadata": {
        "id": "v7gLFBuBT6WO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9cZxPMZOfICS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54db5532-240f-41c1-dfec-fb5614948418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h5RDBcpVf0TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7ade07-2077-4e00-f2c6-076fa0f79a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m957.3 kB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "2830c9f4-bb15-499a-b0e2-d467707c483d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 15:36:12 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "bf72d5a6-fb23-4c95-a32b-fb716194e04b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "import torch\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from transformers import GPT2Model, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "OXAUnWshi1w7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "69cd7920-f261-4f00-ccd1-ece2813d6e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "2e1d9ada-6e97-41d9-f1a6-6e36f8f9dd0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "3beb1080-f566-4981-8591-950a4d00a1ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-735b60fb-12dd-4522-b03e-4637dc67fe50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-735b60fb-12dd-4522-b03e-4637dc67fe50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-735b60fb-12dd-4522-b03e-4637dc67fe50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-735b60fb-12dd-4522-b03e-4637dc67fe50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb2a940d-8fd3-4171-bc32-655c62d3d947\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb2a940d-8fd3-4171-bc32-655c62d3d947')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb2a940d-8fd3-4171-bc32-655c62d3d947 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/pierreguillou/gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@inproceedings{pierre2020gpt2smallportuguese,\n",
        "  title={GPorTuguese-2 (Portuguese GPT-2 small): a Language Model for Portuguese text generation (and more NLP tasks...)},\n",
        "  author={Pierre Guillou},\n",
        "  year={2020}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Tokenizer**: No GPT-2, ao contrário do BERT, o preenchimento é feito à esquerda, uma vez que o último token é utilizado para a previsão."
      ],
      "metadata": {
        "id": "yLIJaQxyg7JM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WPj7c-IBgWRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "89b8d475f2164aab8edc0a3980ef3427",
            "477e78e01a194e6fb7356b8b24a5c76c",
            "a5681985a6e643cc9a7fb6ec834c27d8",
            "27c6eabdca09418ea9ba312a2bb139ff",
            "4c7b1548f69a4f25822d2cb67105a988",
            "dcde7d8ab64548329b804fe3dbcb2f2f",
            "2b7c45a1c28743ea9d9f01d9b715bb74",
            "932fb6c48a194bbca79855aecc1a63be",
            "b204f63b92864537b51a55b595eab920",
            "55b3dc839c604872ba3b9ba027390354",
            "f397ce4ae97b4998bbb191731f627c0b",
            "7998eb73c2004451be6e53670dbb8080",
            "5eb3f51e7ff4450c8212389da0ec8421",
            "67bc406f290e4848b41ddda436e1cf48",
            "acda5d5dc3184bec8c1a634cc7a5ab80",
            "ab83fa01fd004983aac3cfc2be447c37",
            "530421e29e094866917be2e699dfedbe",
            "950141511af04328a1005ddb58e2b9bc",
            "c5deeac8ead14dd4b6d8192462212528",
            "758cf6027fe54994a98403df01c975cb",
            "fbd23574cbe448ceb6afbd545a24f48a",
            "a0c17b98dc7741829501c43b9f6e9650",
            "f4991dc5bf664ce698d05b50a66ce023",
            "283361307a70436fbe50e760cf338856",
            "5d118edc10ac418eb188fe7af1bfeaf7",
            "46e3b3334be142b58ff503df2b29ee07",
            "195612466fd6480296d312cede9f72d8",
            "81597d5242f844b38a616679e89461c0",
            "1c913354d0154c67b04b64aa96b5c926",
            "68bbab33b5bf44668a603adc5b359112",
            "275b6fa4e36140ce9f47cf2ff2ea09dd",
            "5c674ec85e054f1f99a9c4c4304cea72",
            "7ad9c58858e14cbebd84ee678e8c9658",
            "ca9d3c9d1f04440a98d0b144d0fd6f22",
            "0d9e5641a8c6494ebbfa6a3d92791ed5",
            "8dc4f00b632b4bbf8fef1380d2817c93",
            "8fe29e8e58224fe692e1812df211d769",
            "5f80b2a79870495097d5a87be40bd362",
            "2a710971d8cd454aa6c27b8e54b4bd09",
            "2d09f2d4048744eb8209e3a7baa2ce61",
            "5e4ddc8831cc46b483f29b45f81648e1",
            "fc5226dc902d468983851cca5da9e22f",
            "9007c84bacae423b9ea7ddb2b6642ef5",
            "f222d5c2b6fe47a1bc7c8107bec7dce8",
            "18c247a9ff0245a0825fe7be7bfaab54",
            "21e34f6c222046fdbc1d0af02c4f1941",
            "52ad4043034544d1b51bc9d70dae2ec5",
            "13af89faa49c4659958d7e430fb7d524",
            "247e64472b0f44fe86cced3a36f67e33",
            "13f68233f4fa4e51ab8605355d6f1436",
            "bde77f4835e649ce88c140a580aa54e3",
            "15b5645a95114309be50850ebf93daad",
            "bd6489fcb642421eace0583514ad040a",
            "f7abb56e5012496ea276b2f9af755f08",
            "ae7bd81721d44491b31966123d5c5662"
          ]
        },
        "outputId": "008e9cb2-4dda-4a06-c761-fe18600a4136"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/92.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89b8d475f2164aab8edc0a3980ef3427"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/850k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7998eb73c2004451be6e53670dbb8080"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/508k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4991dc5bf664ce698d05b50a66ce023"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca9d3c9d1f04440a98d0b144d0fd6f22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18c247a9ff0245a0825fe7be7bfaab54"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = \"pierreguillou/gpt2-small-portuguese\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "# tokenizer.model_max_length=MAX_LEN\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qSErznNMh4P5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2628d5066b014910b4c816104916638e",
            "a7169fd98fc3412798bb19d969fd8312",
            "f9eb84dd0aab499f9300920ef68b5f71",
            "053986296d554085be061f538da0cb44",
            "d087a10aef10455a9f83c08b15e21d3d",
            "ad046c475485443bb90d40d64e5eab77",
            "4b65683266214d7bae7fd32316fe6891",
            "40b83adca8c244d4bf529985ce15f69f",
            "b1c9a88a261244f5becb29d8dd103884",
            "d94c39b91dc846178c3e5e0e7194eb73",
            "da481478a94f4810987cc46507cd5765"
          ]
        },
        "outputId": "d061f85e-d17f-4196-b51e-7fcf157570f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2628d5066b014910b4c816104916638e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "# model = AutoModelWithLMHead.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "model = GPT2Model.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exemplo da tokenização no GPT2"
      ],
      "metadata": {
        "id": "VK2XSMUYiABq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "78tJbGMogWaZ"
      },
      "outputs": [],
      "source": [
        "gpt2_input = tokenizer(frase, padding=\"max_length\", max_length=16, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt2_input['input_ids'])\n",
        "print(gpt2_input[\"attention_mask\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES67iwbAh2Jz",
        "outputId": "91293e4d-9210-4e21-cdd2-acdf310867e5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     0,     0,     0,     0,    33,  7912,   261,   374, 38198,\n",
            "         20142,   300,  9643,   261,  3325,  2303]])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tokenizer.decode(gpt2_input.input_ids[0])\n",
        "print(example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ6-184nh9hr",
        "outputId": "9a28dacf-097f-44f1-d64a-5320390306f8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>A avaliação de prontidão tecnológica em tecnologias de interesse militar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Variáveis do modelo:"
      ],
      "metadata": {
        "id": "urxVLrRBZQhg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PSjRYlnghJRw"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Devemos construir uma class Dataset para ler os textos, tokenizar e armazenar em _containers_ para o treinamento em lote."
      ],
      "metadata": {
        "id": "RlAPjXSWkL56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      truncation=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Estamos adicionando uma camada linear sobre as 12 camadas de decodificadores do GPT-2 com sua dimensão de saída igual ao nosso número de classes"
      ],
      "metadata": {
        "id": "sHe6lDI4lyhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2SequenceClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size: int,n_classes:int, max_seq_len:int):\n",
        "        super(GPT2SequenceClassifier,self).__init__()\n",
        "        self.gpt2model = GPT2Model.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.fc1 = nn.Linear(hidden_size*max_seq_len, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        gpt_out, _ = self.gpt2model(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "        batch_size = gpt_out.shape[0]\n",
        "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
        "        return linear_output"
      ],
      "metadata": {
        "id": "ik0pY8jfl9G6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = GPT2SequenceClassifier(hidden_size=768, n_classes=len(class_names), max_seq_len=MAX_LEN)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "e7ca5925-fb04-4fd3-eb36-6dd1e957df56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((108, 2), (27, 2), (33, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "5064d8b3-1016-4b0b-cb3e-e70a4e541001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "99948d57-9d79-489a-a0a1-116de8250027"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "33061b87-9ace-4a40-fcf5-5d79db059cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "0aabb6ca-5bf7-472f-cc46-e907991fd48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "2a8e9b2e-8091-4221-9d05-f7740de9b874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "031eb4bc-1b24-4bf7-d6f6-d20ad1e95c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "43e10c0c-f236-4ae0-9353-16174dfe190b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.8528554567268916 accuracy 0.6203703703703703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.186261111870408 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8819932864446726 accuracy 0.7222222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.414588804866071 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5737059366209516 accuracy 0.8425925925925926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.82103181630373 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.31230133145163563 accuracy 0.9166666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8861008882522583 accuracy 0.48148148148148145\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2857192065639517 accuracy 0.9166666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9147204905748367 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.24045070167180224 accuracy 0.9351851851851851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5128232338779526 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.16852008846181413 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.565114818746224 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04947978644745733 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7310198843479156 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.019791148506068827 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5558841256424785 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04549736583672776 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6018043868243694 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04344255732297496 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3621699399664067 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.047968925937141194 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0037030247040093 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.025769842320820708 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3794157273950987 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03780322040489433 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8542360602878034 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03327800776984954 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2345401171478443 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.032618884101330944 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8475406104698777 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.029949065597325637 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1679119954351336 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03321891813787455 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8265449539758265 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01565701799904673 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1214679193217307 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02060718083584488 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8448896971531212 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.015403817659897559 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.120802478864789 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02246350683918966 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8863366437144578 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.014379771343750443 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.88476315070875 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02138184844286276 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7024767575785518 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.022302291799793546 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.894583514193073 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0072145584181971655 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.129564228176605 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.049995915047604936 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.941280592000112 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02106860272195275 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8570141112431884 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.015826369973901855 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9855694839498028 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03043319378134652 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8029760904610157 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02171996763532188 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.931471504853107 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02717802987122488 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.798511117696762 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02447545307206094 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8908794741146266 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.020582865358968454 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7970121880061924 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.018965570988411402 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8953517396003008 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01768375282908354 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8453485134523362 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01665719164122034 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8488483782857656 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01757518197783625 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9721914876718074 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03422570969645885 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8762018645647913 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.016527611126337178 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8050958276726305 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.010064473952277402 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.888974237255752 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01598360275450769 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.868095551384613 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0034840364335896163 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9374153090175241 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01015745418985503 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8936059072148055 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.008215401561276916 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8612331696785986 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.014695942360332432 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8224971438758075 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.015577110796608094 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.847559624351561 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.026262274773370415 accuracy 0.9814814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8686904923524708 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.012573435832732929 accuracy 0.9907407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8589853970333934 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.008965198431626702 accuracy 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8577887606807053 accuracy 0.6296296296296295\n",
            "\n",
            "CPU times: user 3min 26s, sys: 1min 38s, total: 5min 4s\n",
            "Wall time: 6min 1s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "ae408168-1b83-499b-c0eb-03102cf72c43"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "69765d7a-63cf-45ec-895a-09f1e5c1b500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "332971da-ce79-4404-872b-ebdf2f0788ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrcGxmh_yKxU",
        "outputId": "768ccbfe-6e4e-4c83-a7fe-987a6fcbd996"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.65      0.94      0.77        18\n",
            "     Faixa 2       0.00      0.00      0.00         9\n",
            "     Faixa 3       0.71      0.83      0.77         6\n",
            "\n",
            "    accuracy                           0.67        33\n",
            "   macro avg       0.46      0.59      0.51        33\n",
            "weighted avg       0.49      0.67      0.56        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HQ54xluu8RL3",
        "outputId": "5c69a52e-9b28-408a-acc0-784621c29c8d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 723
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "oENoyHsUPjWv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89b8d475f2164aab8edc0a3980ef3427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_477e78e01a194e6fb7356b8b24a5c76c",
              "IPY_MODEL_a5681985a6e643cc9a7fb6ec834c27d8",
              "IPY_MODEL_27c6eabdca09418ea9ba312a2bb139ff"
            ],
            "layout": "IPY_MODEL_4c7b1548f69a4f25822d2cb67105a988"
          }
        },
        "477e78e01a194e6fb7356b8b24a5c76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcde7d8ab64548329b804fe3dbcb2f2f",
            "placeholder": "​",
            "style": "IPY_MODEL_2b7c45a1c28743ea9d9f01d9b715bb74",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "a5681985a6e643cc9a7fb6ec834c27d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_932fb6c48a194bbca79855aecc1a63be",
            "max": 92,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b204f63b92864537b51a55b595eab920",
            "value": 92
          }
        },
        "27c6eabdca09418ea9ba312a2bb139ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b3dc839c604872ba3b9ba027390354",
            "placeholder": "​",
            "style": "IPY_MODEL_f397ce4ae97b4998bbb191731f627c0b",
            "value": " 92.0/92.0 [00:00&lt;00:00, 3.97kB/s]"
          }
        },
        "4c7b1548f69a4f25822d2cb67105a988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcde7d8ab64548329b804fe3dbcb2f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7c45a1c28743ea9d9f01d9b715bb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "932fb6c48a194bbca79855aecc1a63be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b204f63b92864537b51a55b595eab920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55b3dc839c604872ba3b9ba027390354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f397ce4ae97b4998bbb191731f627c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7998eb73c2004451be6e53670dbb8080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eb3f51e7ff4450c8212389da0ec8421",
              "IPY_MODEL_67bc406f290e4848b41ddda436e1cf48",
              "IPY_MODEL_acda5d5dc3184bec8c1a634cc7a5ab80"
            ],
            "layout": "IPY_MODEL_ab83fa01fd004983aac3cfc2be447c37"
          }
        },
        "5eb3f51e7ff4450c8212389da0ec8421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_530421e29e094866917be2e699dfedbe",
            "placeholder": "​",
            "style": "IPY_MODEL_950141511af04328a1005ddb58e2b9bc",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "67bc406f290e4848b41ddda436e1cf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5deeac8ead14dd4b6d8192462212528",
            "max": 849961,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_758cf6027fe54994a98403df01c975cb",
            "value": 849961
          }
        },
        "acda5d5dc3184bec8c1a634cc7a5ab80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd23574cbe448ceb6afbd545a24f48a",
            "placeholder": "​",
            "style": "IPY_MODEL_a0c17b98dc7741829501c43b9f6e9650",
            "value": " 850k/850k [00:00&lt;00:00, 932kB/s]"
          }
        },
        "ab83fa01fd004983aac3cfc2be447c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "530421e29e094866917be2e699dfedbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "950141511af04328a1005ddb58e2b9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5deeac8ead14dd4b6d8192462212528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758cf6027fe54994a98403df01c975cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbd23574cbe448ceb6afbd545a24f48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c17b98dc7741829501c43b9f6e9650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4991dc5bf664ce698d05b50a66ce023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_283361307a70436fbe50e760cf338856",
              "IPY_MODEL_5d118edc10ac418eb188fe7af1bfeaf7",
              "IPY_MODEL_46e3b3334be142b58ff503df2b29ee07"
            ],
            "layout": "IPY_MODEL_195612466fd6480296d312cede9f72d8"
          }
        },
        "283361307a70436fbe50e760cf338856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81597d5242f844b38a616679e89461c0",
            "placeholder": "​",
            "style": "IPY_MODEL_1c913354d0154c67b04b64aa96b5c926",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "5d118edc10ac418eb188fe7af1bfeaf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68bbab33b5bf44668a603adc5b359112",
            "max": 508261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_275b6fa4e36140ce9f47cf2ff2ea09dd",
            "value": 508261
          }
        },
        "46e3b3334be142b58ff503df2b29ee07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c674ec85e054f1f99a9c4c4304cea72",
            "placeholder": "​",
            "style": "IPY_MODEL_7ad9c58858e14cbebd84ee678e8c9658",
            "value": " 508k/508k [00:00&lt;00:00, 24.6MB/s]"
          }
        },
        "195612466fd6480296d312cede9f72d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81597d5242f844b38a616679e89461c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c913354d0154c67b04b64aa96b5c926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68bbab33b5bf44668a603adc5b359112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "275b6fa4e36140ce9f47cf2ff2ea09dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c674ec85e054f1f99a9c4c4304cea72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad9c58858e14cbebd84ee678e8c9658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca9d3c9d1f04440a98d0b144d0fd6f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d9e5641a8c6494ebbfa6a3d92791ed5",
              "IPY_MODEL_8dc4f00b632b4bbf8fef1380d2817c93",
              "IPY_MODEL_8fe29e8e58224fe692e1812df211d769"
            ],
            "layout": "IPY_MODEL_5f80b2a79870495097d5a87be40bd362"
          }
        },
        "0d9e5641a8c6494ebbfa6a3d92791ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a710971d8cd454aa6c27b8e54b4bd09",
            "placeholder": "​",
            "style": "IPY_MODEL_2d09f2d4048744eb8209e3a7baa2ce61",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "8dc4f00b632b4bbf8fef1380d2817c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e4ddc8831cc46b483f29b45f81648e1",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc5226dc902d468983851cca5da9e22f",
            "value": 120
          }
        },
        "8fe29e8e58224fe692e1812df211d769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9007c84bacae423b9ea7ddb2b6642ef5",
            "placeholder": "​",
            "style": "IPY_MODEL_f222d5c2b6fe47a1bc7c8107bec7dce8",
            "value": " 120/120 [00:00&lt;00:00, 5.66kB/s]"
          }
        },
        "5f80b2a79870495097d5a87be40bd362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a710971d8cd454aa6c27b8e54b4bd09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d09f2d4048744eb8209e3a7baa2ce61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e4ddc8831cc46b483f29b45f81648e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc5226dc902d468983851cca5da9e22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9007c84bacae423b9ea7ddb2b6642ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f222d5c2b6fe47a1bc7c8107bec7dce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18c247a9ff0245a0825fe7be7bfaab54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21e34f6c222046fdbc1d0af02c4f1941",
              "IPY_MODEL_52ad4043034544d1b51bc9d70dae2ec5",
              "IPY_MODEL_13af89faa49c4659958d7e430fb7d524"
            ],
            "layout": "IPY_MODEL_247e64472b0f44fe86cced3a36f67e33"
          }
        },
        "21e34f6c222046fdbc1d0af02c4f1941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13f68233f4fa4e51ab8605355d6f1436",
            "placeholder": "​",
            "style": "IPY_MODEL_bde77f4835e649ce88c140a580aa54e3",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "52ad4043034544d1b51bc9d70dae2ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15b5645a95114309be50850ebf93daad",
            "max": 666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd6489fcb642421eace0583514ad040a",
            "value": 666
          }
        },
        "13af89faa49c4659958d7e430fb7d524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7abb56e5012496ea276b2f9af755f08",
            "placeholder": "​",
            "style": "IPY_MODEL_ae7bd81721d44491b31966123d5c5662",
            "value": " 666/666 [00:00&lt;00:00, 40.5kB/s]"
          }
        },
        "247e64472b0f44fe86cced3a36f67e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f68233f4fa4e51ab8605355d6f1436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bde77f4835e649ce88c140a580aa54e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15b5645a95114309be50850ebf93daad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd6489fcb642421eace0583514ad040a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7abb56e5012496ea276b2f9af755f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7bd81721d44491b31966123d5c5662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2628d5066b014910b4c816104916638e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7169fd98fc3412798bb19d969fd8312",
              "IPY_MODEL_f9eb84dd0aab499f9300920ef68b5f71",
              "IPY_MODEL_053986296d554085be061f538da0cb44"
            ],
            "layout": "IPY_MODEL_d087a10aef10455a9f83c08b15e21d3d"
          }
        },
        "a7169fd98fc3412798bb19d969fd8312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad046c475485443bb90d40d64e5eab77",
            "placeholder": "​",
            "style": "IPY_MODEL_4b65683266214d7bae7fd32316fe6891",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "f9eb84dd0aab499f9300920ef68b5f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40b83adca8c244d4bf529985ce15f69f",
            "max": 510378682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1c9a88a261244f5becb29d8dd103884",
            "value": 510378682
          }
        },
        "053986296d554085be061f538da0cb44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d94c39b91dc846178c3e5e0e7194eb73",
            "placeholder": "​",
            "style": "IPY_MODEL_da481478a94f4810987cc46507cd5765",
            "value": " 510M/510M [00:01&lt;00:00, 283MB/s]"
          }
        },
        "d087a10aef10455a9f83c08b15e21d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad046c475485443bb90d40d64e5eab77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b65683266214d7bae7fd32316fe6891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40b83adca8c244d4bf529985ce15f69f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1c9a88a261244f5becb29d8dd103884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d94c39b91dc846178c3e5e0e7194eb73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da481478a94f4810987cc46507cd5765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}