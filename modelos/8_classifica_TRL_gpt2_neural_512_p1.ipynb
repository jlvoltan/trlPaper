{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - GPT-2 + Rede Neural + 512 tokens [kfold][P1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- https://huggingface.co/pierreguillou/gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 24 SET 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 1**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 512 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "NOeYJqHdTeHU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjJNdaXvTeze",
        "outputId": "f4b9d8d4-b6f4-4172-c837-568b79c280e0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=1  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_gpt2_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "70f7f153-8923-4af2-ae78-8e6efe0e4138"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_gpt2_neural_1.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512   #O GPT-2 o máximo é 1024"
      ],
      "metadata": {
        "id": "v7gLFBuBT6WO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "9cZxPMZOfICS"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "h5RDBcpVf0TS"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "ce83fe78-23ed-445a-fcb1-d352e99094e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 13:44:43 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    27W /  70W |   5521MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "5edcc27c-5fee-4fee-aacc-523b53c78a33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "import torch\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from transformers import GPT2Model, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "OXAUnWshi1w7"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "d1c18a0c-6287-476e-8357-d916410e20a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "a7bda8ef-b80d-47e2-b816-35b0667370e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "adbaa369-adcd-4b49-8dad-a82825ad599d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f15e252-9d2c-4d14-af9f-cce94a4bcf24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f15e252-9d2c-4d14-af9f-cce94a4bcf24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f15e252-9d2c-4d14-af9f-cce94a4bcf24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f15e252-9d2c-4d14-af9f-cce94a4bcf24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c43554a1-7359-478e-b814-a99161821ed5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c43554a1-7359-478e-b814-a99161821ed5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c43554a1-7359-478e-b814-a99161821ed5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/pierreguillou/gpt2-small-portuguese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "@inproceedings{pierre2020gpt2smallportuguese,\n",
        "  title={GPorTuguese-2 (Portuguese GPT-2 small): a Language Model for Portuguese text generation (and more NLP tasks...)},\n",
        "  author={Pierre Guillou},\n",
        "  year={2020}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Tokenizer**: No GPT-2, ao contrário do BERT, o preenchimento é feito à esquerda, uma vez que o último token é utilizado para a previsão."
      ],
      "metadata": {
        "id": "yLIJaQxyg7JM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "WPj7c-IBgWRx"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = \"pierreguillou/gpt2-small-portuguese\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "# tokenizer.model_max_length=MAX_LEN\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "qSErznNMh4P5"
      },
      "outputs": [],
      "source": [
        "# bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "# model = AutoModelWithLMHead.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "model = GPT2Model.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exemplo da tokenização no GPT2"
      ],
      "metadata": {
        "id": "VK2XSMUYiABq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "78tJbGMogWaZ"
      },
      "outputs": [],
      "source": [
        "gpt2_input = tokenizer(frase, padding=\"max_length\", max_length=16, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt2_input['input_ids'])\n",
        "print(gpt2_input[\"attention_mask\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES67iwbAh2Jz",
        "outputId": "af01e131-9d06-48ca-e678-70f65506f5ca"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     0,     0,     0,     0,    33,  7912,   261,   374, 38198,\n",
            "         20142,   300,  9643,   261,  3325,  2303]])\n",
            "tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tokenizer.decode(gpt2_input.input_ids[0])\n",
        "print(example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ6-184nh9hr",
        "outputId": "0282f896-c93f-4d78-ecb0-99fc39ab7625"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>A avaliação de prontidão tecnológica em tecnologias de interesse militar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Variáveis do modelo:"
      ],
      "metadata": {
        "id": "urxVLrRBZQhg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "PSjRYlnghJRw"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Devemos construir uma class Dataset para ler os textos, tokenizar e armazenar em _containers_ para o treinamento em lote."
      ],
      "metadata": {
        "id": "RlAPjXSWkL56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      truncation = True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Estamos adicionando uma camada linear sobre as 12 camadas de decodificadores do GPT-2 com sua dimensão de saída igual ao nosso número de classes"
      ],
      "metadata": {
        "id": "sHe6lDI4lyhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2SequenceClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size: int,n_classes:int, max_seq_len:int):\n",
        "        super(GPT2SequenceClassifier,self).__init__()\n",
        "        self.gpt2model = GPT2Model.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.fc1 = nn.Linear(hidden_size*max_seq_len, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        gpt_out, _ = self.gpt2model(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "        batch_size = gpt_out.shape[0]\n",
        "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
        "        return linear_output"
      ],
      "metadata": {
        "id": "ik0pY8jfl9G6"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = GPT2SequenceClassifier(hidden_size=768, n_classes=len(class_names), max_seq_len=MAX_LEN)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "b5ae5cbd-594a-4806-a245-61806595da70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107, 2), (27, 2), (34, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "599c9ace-884f-4e10-b1aa-25e94b665b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "299b5792-0fc4-4394-c6be-03c330707a18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "c906596b-6499-4c83-8a2c-68694b93e3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "b304c7a4-e58d-45fe-c922-5664f2027ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "db054675-fec5-41eb-c883-d1339fcb4c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "bd5cf4a9-6849-462f-a7d8-7f873ff8da65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "0f524c12-6eda-40df-cf07-1c406dfd3838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 3.4011139188494 accuracy 0.4579439252336448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.1211608052253723 accuracy 0.37037037037037035\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 3.741879985268627 accuracy 0.5981308411214953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 5.6532557010650635 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.4737470928313476 accuracy 0.6261682242990654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 4.12867343340622 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.102116955243608 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.749019462025899 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5967258659797413 accuracy 0.794392523364486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.8622345603071153 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.41182014227732516 accuracy 0.8411214953271028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.610226382618748 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.4185540943776036 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5227849655784667 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.1829071280600536 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 4.040310740470886 accuracy 0.4074074074074074\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.1451948513565964 accuracy 0.8037383177570093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9784636497497559 accuracy 0.4444444444444444\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.18759070974868206 accuracy 0.9532710280373831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6746644340455532 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.07815103438794527 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6998345870524645 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.036372745822534726 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8772218558005989 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08912958371411049 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9303677980788052 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.017131829137018224 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6743143908679485 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.027602625426514545 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7217882871627808 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.07478586754513117 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7107271030545235 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1019257136942997 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7785007506608963 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08285103566092696 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8107794225215912 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02535617215940939 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6959132254123688 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.004348632512056432 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.9084843427408487 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05026156149671631 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.575913171749562 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.014002941479915876 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2886820193380117 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10345000994072352 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2054561469703913 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.009560609012315322 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1672814898192883 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.020800126767162346 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1903009973466396 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.026028007633771364 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.139713814482093 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01604525346323271 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1837590485811234 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.022011123236648444 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.205069236457348 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03638353691308893 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2035595644265413 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.032831204391323 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2062361910939217 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02141916052267082 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2571206567808986 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03413458945626248 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2273053266108036 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01888023385888817 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.195158108137548 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013332584499619113 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.21071953792125 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0008749932148833953 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.264768618158996 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.07618396564718058 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.258754812180996 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.023962612477333778 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2143732830882072 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0018580623785844352 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2550088576972485 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.040483663368706554 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3113174475729465 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03352883813530738 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3000139161013067 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.025441110595302012 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.29187394073233 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.024700302643036003 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2905971757136285 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.012584231521857805 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3071575150825083 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.021569183102481508 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.326507226098329 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.06553678830984667 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3249061130918562 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013038333049352044 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.316859931219369 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.006728226943169753 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3241802635602653 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03833330592052166 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3310414608567953 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05882948495808701 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3340047099627554 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.012959643159924943 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.336332377512008 accuracy 0.6666666666666666\n",
            "\n",
            "CPU times: user 10min 4s, sys: 26.7 s, total: 10min 31s\n",
            "Wall time: 11min 48s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "7cbc389d-5996-4b5f-f9d7-876b79fad4a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "09f3c81d-231d-4428-aa8e-52b2bf872b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7647058823529411"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "d9d9d7d5-8049-41a2-b05d-f805b7987522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrcGxmh_yKxU",
        "outputId": "a59241ab-d10a-438c-9970-137ad01fb695"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.79      1.00      0.88        19\n",
            "     Faixa 2       0.00      0.00      0.00         8\n",
            "     Faixa 3       0.70      1.00      0.82         7\n",
            "\n",
            "    accuracy                           0.76        34\n",
            "   macro avg       0.50      0.67      0.57        34\n",
            "weighted avg       0.59      0.76      0.66        34\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HQ54xluu8RL3",
        "outputId": "71bd2daf-ad91-4211-a272-4138f0b531b7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 998,
              "height": 723
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "oENoyHsUPjWv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}