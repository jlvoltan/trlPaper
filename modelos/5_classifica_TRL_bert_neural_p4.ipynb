{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural [kfold][P4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 4**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 242 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "f0cfc680-e717-425c-c51c-126db9c1660e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=4  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "7cefdf21-4f41-4d33-ee18-e7d7cca3b0d6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_4.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 242"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9cZxPMZOfICS"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "h5RDBcpVf0TS"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "b0c9989e-eb03-4d80-d4e7-f2bd8080ea47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 24 01:49:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P0    27W /  70W |   5601MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "23a4e9f1-a875-4a18-d64a-73d6faff72d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "3840ffcd-d001-4256-b58a-49a6b680508d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "WPj7c-IBgWRx"
      },
      "outputs": [],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "qSErznNMh4P5"
      },
      "outputs": [],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "8119ff4b-9ab9-4ce1-ba7c-52c68e00f051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "5057eee8-564a-49a9-81e3-0c21cc3caab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "ecebd285-2417-44b5-dab4-2079caa42101"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a5d7b32-48b0-4f0e-8dfd-9089f1b0e248\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a5d7b32-48b0-4f0e-8dfd-9089f1b0e248')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a5d7b32-48b0-4f0e-8dfd-9089f1b0e248 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a5d7b32-48b0-4f0e-8dfd-9089f1b0e248');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7e1be3f-30fa-40f3-ad5e-dc507e43be37\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7e1be3f-30fa-40f3-ad5e-dc507e43be37')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7e1be3f-30fa-40f3-ad5e-dc507e43be37 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "1e85a45d-f701-4d18-cc7f-3d53d2df9a53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "cefd03fe-e68a-4c8c-e8d2-b17845d995fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((108, 2), (27, 2), (33, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "ad5f0fd0-c652-4030-da1b-e14b55a09368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "9b1cbb97-8c2c-41ac-eea5-71621d0a8bda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "67398e0d-80c7-473e-ab4e-6866e800c09a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "90052fdc-3621-4706-a7eb-cef69556a21e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "48ebe03f-97d8-469f-8d35-c7da809a2078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "a89ff3f0-ef7d-4570-eda3-e16a0813d1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "0592d0e9-fe94-480c-bc8f-8e9e6b5337ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9633484525339944 accuracy 0.5462962962962963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6511682793498039 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.753334064568792 accuracy 0.6481481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6289946660399437 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9753860660961696 accuracy 0.6481481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6707825064659119 accuracy 0.18518518518518517\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.2995992515768324 accuracy 0.28703703703703703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9249127507209778 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8502893788473946 accuracy 0.611111111111111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.761325366795063 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7373726623398917 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8181809633970261 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.728744917682239 accuracy 0.7222222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7459421679377556 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6816775458199638 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6540020257234573 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6877677014895848 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7340991199016571 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6734287376914706 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7423667535185814 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.682239721928324 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7381728067994118 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6679409593343735 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7404691278934479 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6674007070916039 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7402109578251839 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6701076967375619 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7425236776471138 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6657132016760963 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7321439012885094 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6825931583132062 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7366193160414696 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6648269423416683 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7383937537670135 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6452677547931671 accuracy 0.7314814814814814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7598490417003632 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5647871302706855 accuracy 0.7777777777777777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6739371567964554 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.621840272630964 accuracy 0.7407407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.3649758100509644 accuracy 0.4444444444444444\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7572213815791267 accuracy 0.6944444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7835727073252201 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5246953261750085 accuracy 0.8148148148148148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6934627369046211 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4859686813184193 accuracy 0.8240740740740741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.795579269528389 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4140969163605145 accuracy 0.8518518518518519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5511927008628845 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.35909150461001055 accuracy 0.8796296296296295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.0979467928409576 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.26804130444569246 accuracy 0.8981481481481481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.67553049325943 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.26135985406913925 accuracy 0.9074074074074073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.226314425468445 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.24902604879545315 accuracy 0.9259259259259258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.320737898349762 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1671053252315947 accuracy 0.9444444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.673649847507477 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.13069995612438237 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.368602216243744 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.17391021137258836 accuracy 0.9444444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6019543409347534 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11129140631029648 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.654038816690445 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11089163130548384 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.67124342918396 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.12328246170987509 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.844258189201355 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.12541024453405822 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.1108628511428833 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11711849819403142 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.172291576862335 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11798170282106314 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.1514984369277954 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.12665201620464878 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.0313215255737305 accuracy 0.5185185185185185\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11762418152232255 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.966735601425171 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11126168657626424 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.973093032836914 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11997810456835266 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.9789004921913147 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.12252525968610176 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.9856905341148376 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.12023085623513907 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.9952878952026367 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11948557741873499 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.006674826145172 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11624974547885358 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.0140089988708496 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11274936193201159 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.0207901000976562 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11910161701962352 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.0261300802230835 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.12013431423942425 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.0297995805740356 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11410800380898374 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.031967580318451 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11462002972673092 accuracy 0.9629629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 3.0329182147979736 accuracy 0.5925925925925926\n",
            "\n",
            "CPU times: user 2min 57s, sys: 1min 27s, total: 4min 25s\n",
            "Wall time: 5min 28s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "8d48035d-1f2b-46a8-a3ed-5149db58e2ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "fa91c0b8-fab0-4a01-c5b9-2cf1b4df6ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8181818181818182"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "4012a313-ca87-4803-a65c-cc0a057e86f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "456bcd11-9453-4f52-c3a6-2021c0ef47cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.86      0.95      0.90        19\n",
            "     Faixa 2       0.67      0.50      0.57         8\n",
            "     Faixa 3       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.82        33\n",
            "   macro avg       0.79      0.76      0.77        33\n",
            "weighted avg       0.81      0.82      0.81        33\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "HQ54xluu8RL3",
        "outputId": "4923b083-ec34-42e5-b67f-7ac6e94d658e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 730
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}