{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - Bertimbau + Rede Neural + 512 tokens [kfold][P1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- BERTimbau Base (aka \"bert-base-portuguese-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 21 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 1**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 512 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "vXMRttjhRQ2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYJkf84RR64K",
        "outputId": "b836c1b4-fbe0-437e-b915-cd92eb9c3305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=1  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bertimbau_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "709e633e-3300-46e3-a1ec-2961032986bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bertimbau_base_neural_1.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "_6clpQcISMQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8\n",
        "- Quantidade de tokens máxima = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZxPMZOfICS",
        "outputId": "5440169d-4e74-4993-f4dc-571806257d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RDBcpVf0TS",
        "outputId": "05f94cfc-8aee-485a-f7a7-c97a0d3aebd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "75a965f1-cb16-4d2f-d36f-e1e3e66b2b29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 25 23:25:02 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "4032cee0-3032-49a2-c9c6-7398788d40c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "0f13bff9-6c48-4bb3-ec1b-6a5bfe18326c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### Bertimbau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/neuralmind/bert-base-portuguese-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@inproceedings{souza2020bertimbau,\n",
        "  author    = {F{\\'a}bio Souza and\n",
        "               Rodrigo Nogueira and\n",
        "               Roberto Lotufo},\n",
        "  title     = {{BERT}imbau: pretrained {BERT} models for {B}razilian {P}ortuguese},\n",
        "  booktitle = {9th Brazilian Conference on Intelligent Systems, {BRACIS}, Rio Grande do Sul, Brazil, October 20-23 (to appear)},\n",
        "  year      = {2020}\n",
        "}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "69f8d54564ea4d1cb59f61c1d3555bb1",
            "8f5518b7852c4b25a79907511eeb90a2",
            "30e350ffbb3846ca889acc82eb0f0505",
            "1baa20c982fd4da380975e2466f6a239",
            "0c571a125de549f0bb02adc2d81a4e6e",
            "b5c4ac1c27c842a29f468ad625f9cb6e",
            "0ba86b546e3e47afa63694307a8b317d",
            "7aa292cce2d64806a569ca5616691f9a",
            "23ab6bfeac9f42f1961b4a3a2d024b61",
            "ca76c6c00eec4e13b6c3ec2261a5213c",
            "7ba7288c35e4420791b66adcfcdc9fae",
            "ec68dbe2c68647c483733b3ddac94af0",
            "ff997f387daf4662ba4a0fd84a6f3583",
            "00a2c0f7a1d146d6a1208cd882b48fd8",
            "b78b56b5b5ad45cf87ccb1281ebfcb2e",
            "c05c5201dca8416696c13c680c30f689",
            "8bf56cf6e5ad438aaa46090573092946",
            "654de489fa934209a34f9459a8658ada",
            "a9740ac3bb3f40fd8c053a261f387e0b",
            "b2d15b0658de4359bef0baddb45ee625",
            "e0f396e8ee6f42bab3238492d90d191d",
            "aa86cd02887b49b98190726edf8fc6de",
            "ad58c5983fc34f8a9bfa56e4c7f54810",
            "7713f25b6ad4463eb900a3a328cb30b1",
            "24064157582c484c8b519f1aacdb119d",
            "9f7888c9f63e47c680d42b68c2004f4c",
            "c77522e65cc44d9e8ebe76f4c179fc8f",
            "a60e3c028dcd41c89c3af699c5121799",
            "6e42f345a9524bb2abf31f0214045325",
            "d367122172c24793a4932e7b4c646436",
            "2017c93469eb44fc8dc58865a2857a20",
            "2f02900e577246b5905fd35d67aee351",
            "33b0203f951243cb9f69db9aac868fc6",
            "020ff3fd6dc14f80b5a91685e58dfd4a",
            "c71c25dc8f5a4f5891059fded18d5d57",
            "dc7dc76a2d7a4da3ae5044ec28efb117",
            "4ca5335f5b36478591d51b21562058ba",
            "3f9c86026a7f4be8a2abc807b3dfea33",
            "88e1f4cf5a204ddabd6de07d9fd35dbb",
            "264316fc87ac4d129bd57b5e703b1f13",
            "922c075e1e50411dbf8fedbd52719178",
            "1a6e7e09d93b4ffb820ab9f9d30249c4",
            "658e9c3c352c4a53a8a54141e9c8d1f9",
            "5fc4755315e34157ae99aa886d016864",
            "52a1fda23cdd4a3286f4c49dc7ed67a1",
            "3757ddfd9e2e4cabbb5e44b01a78e0f3",
            "0854c3fa2f7f48adb0a06d8ef5dfd8c3",
            "994a2e613b624c93950cc6f3ce107030",
            "22e46202b3814602a7f2b8ebdf95be4d",
            "4576c5e76d6c4329b039efa7b7868e5f",
            "1fd8895cdae441158843d8eca4dc196d",
            "01dbd99c5f9c43d985a257e30577a3fd",
            "8e25cc316e02476699932cc3d6e57eab",
            "75301f889b144b65b073bc65b6d12c0c",
            "a4cd8641578c448da6f2ff9b83eb8240"
          ]
        },
        "id": "WPj7c-IBgWRx",
        "outputId": "62e7df2e-0c46-4cce-be2f-c9b493e8a43c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69f8d54564ea4d1cb59f61c1d3555bb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec68dbe2c68647c483733b3ddac94af0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad58c5983fc34f8a9bfa56e4c7f54810"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "020ff3fd6dc14f80b5a91685e58dfd4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52a1fda23cdd4a3286f4c49dc7ed67a1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "aebbeeb48dfd42febe0bb02b201ae439",
            "79d8246414bc44ea8e04d9fe147ca739",
            "0dc247b98abd433088f7555e9d8e8fad",
            "8f67861e4e6a4d3d9a9c797466d3231f",
            "f9866c5e74734445a84cac0f620f7d3f",
            "9bcd5d19ac3d4ceb8457cfefd8185291",
            "ab15aaee9da54877994c9e75d459c56b",
            "62b25242680a4b32b097a57ff6984e25",
            "c923146b9126487e83883307df492ef8",
            "42e45d5022204d2ca3a1099e26920fb7",
            "936345695c024877909f09797eafc51c"
          ]
        },
        "id": "qSErznNMh4P5",
        "outputId": "5e0d016c-fcc8-4a60-e8dd-2cdd11480c0d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aebbeeb48dfd42febe0bb02b201ae439"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "afc57866-7104-486e-b755-e032747c0f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "7cd26806-66db-440b-b5d4-4077574e3df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "c8e2c1ad-9aae-4ed9-a867-90926b00881f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d209f19a-b7e4-4bb4-baa7-85517d01da15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d209f19a-b7e4-4bb4-baa7-85517d01da15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d209f19a-b7e4-4bb4-baa7-85517d01da15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d209f19a-b7e4-4bb4-baa7-85517d01da15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8e642b0-c416-4d61-8ba5-138304898336\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8e642b0-c416-4d61-8ba5-138304898336')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8e642b0-c416-4d61-8ba5-138304898336 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "f79642f1-2f2e-413b-d247-7e4cd95d5726"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "bfa554ae-aa8b-4c0f-8532-2736000243ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107, 2), (27, 2), (34, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "b21acd6f-d475-406c-a90e-00258ed420a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "fc1fa353-5709-42db-bd41-e9d8c020aae4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "65862782-50b0-42da-bb06-2ca87f6ef73f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "19011b1f-6b94-4dc1-b01a-5915397ebbc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "084f28b3-1191-43c4-fd4f-853ff5ec0fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "4eed0ad2-da32-4962-cc5b-e4372f423c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "9b85c83b-d6ee-4370-bb61-53bf39cb6aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8608095326593944 accuracy 0.514018691588785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7425057962536812 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7698385438748768 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8900111019611359 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6755941978522709 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8204634785652161 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5508170127868652 accuracy 0.7850467289719626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9815402626991272 accuracy 0.2962962962962963\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5008734831852573 accuracy 0.7663551401869159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8551831990480423 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.36975846559341463 accuracy 0.8971962616822429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.3887605369091034 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.21791345991992525 accuracy 0.9439252336448597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4803083837032318 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.12928836919101222 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6727940142154694 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.11915957743102419 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9506006836891174 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0634101948235184 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.1319349706172943 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.04453356131645186 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.2998575270175934 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03948754687527461 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.283991754055023 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0268312862525428 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.309664696455002 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.03556974953971803 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.255118429660797 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.031160753860604018 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.3996104300022125 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.020955139006088887 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5127504765987396 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.022521539029964645 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5399700701236725 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.017405471498412744 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5170941054821014 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.018372124214822958 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5036656856536865 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.014791764352204544 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.5227381587028503 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.015475101411409144 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.527686446905136 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01529487389988 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.513232558965683 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.016681307889354815 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.529356747865677 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.014102345640172384 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.530442178249359 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02171159121540508 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.516139328479767 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.015007079050909462 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.4994992315769196 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01801387855084613 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.523163676261902 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.018051595346020934 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.568472772836685 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.019376963593198786 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6018762588500977 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.00902814167368758 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6623823940753937 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013367915447036336 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6612850427627563 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01337107464080743 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.666968822479248 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.017328840160709142 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6828829050064087 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.023873175698099658 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6920023560523987 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01711902151873801 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.680483102798462 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.014904642747881423 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.671038717031479 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013744770210385988 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.677590787410736 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01476706392921707 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6767388582229614 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.012861161405453458 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.684186428785324 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.011383834263792128 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.687465190887451 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.011571573609087085 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.680994004011154 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.017366283226043118 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6752392649650574 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01209633334656246 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.675276458263397 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.011449757668222966 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.662879168987274 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.012849389706389047 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.656835049390793 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.01296287720573933 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6583513021469116 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.012649579973575393 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6667876839637756 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.011453123883776633 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.669037491083145 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013436048067108328 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.669715404510498 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.013493707680027 accuracy 0.9906542056074765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 2.6690120697021484 accuracy 0.6296296296296295\n",
            "\n",
            "CPU times: user 8min 39s, sys: 20.1 s, total: 8min 59s\n",
            "Wall time: 9min 42s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "a6d0f8a6-2eb5-4b61-d6bc-a1ece0a7044d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "96ed50b6-9329-4bce-b12a-f7d69aa5cdba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7058823529411764"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "24c1f35d-9c41-4fd3-d8d6-45f1819176af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "839356c5-fb9e-42cd-b851-dfcb7d1052c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.83      0.79      0.81        19\n",
            "     Faixa 2       0.40      0.25      0.31         8\n",
            "     Faixa 3       0.64      1.00      0.78         7\n",
            "\n",
            "    accuracy                           0.71        34\n",
            "   macro avg       0.62      0.68      0.63        34\n",
            "weighted avg       0.69      0.71      0.69        34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HQ54xluu8RL3",
        "outputId": "f4d3450b-2838-465b-a865-60cfe5103a4c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 723
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69f8d54564ea4d1cb59f61c1d3555bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f5518b7852c4b25a79907511eeb90a2",
              "IPY_MODEL_30e350ffbb3846ca889acc82eb0f0505",
              "IPY_MODEL_1baa20c982fd4da380975e2466f6a239"
            ],
            "layout": "IPY_MODEL_0c571a125de549f0bb02adc2d81a4e6e"
          }
        },
        "8f5518b7852c4b25a79907511eeb90a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5c4ac1c27c842a29f468ad625f9cb6e",
            "placeholder": "​",
            "style": "IPY_MODEL_0ba86b546e3e47afa63694307a8b317d",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "30e350ffbb3846ca889acc82eb0f0505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa292cce2d64806a569ca5616691f9a",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23ab6bfeac9f42f1961b4a3a2d024b61",
            "value": 43
          }
        },
        "1baa20c982fd4da380975e2466f6a239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca76c6c00eec4e13b6c3ec2261a5213c",
            "placeholder": "​",
            "style": "IPY_MODEL_7ba7288c35e4420791b66adcfcdc9fae",
            "value": " 43.0/43.0 [00:00&lt;00:00, 2.47kB/s]"
          }
        },
        "0c571a125de549f0bb02adc2d81a4e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5c4ac1c27c842a29f468ad625f9cb6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ba86b546e3e47afa63694307a8b317d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aa292cce2d64806a569ca5616691f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ab6bfeac9f42f1961b4a3a2d024b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca76c6c00eec4e13b6c3ec2261a5213c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba7288c35e4420791b66adcfcdc9fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec68dbe2c68647c483733b3ddac94af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff997f387daf4662ba4a0fd84a6f3583",
              "IPY_MODEL_00a2c0f7a1d146d6a1208cd882b48fd8",
              "IPY_MODEL_b78b56b5b5ad45cf87ccb1281ebfcb2e"
            ],
            "layout": "IPY_MODEL_c05c5201dca8416696c13c680c30f689"
          }
        },
        "ff997f387daf4662ba4a0fd84a6f3583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf56cf6e5ad438aaa46090573092946",
            "placeholder": "​",
            "style": "IPY_MODEL_654de489fa934209a34f9459a8658ada",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "00a2c0f7a1d146d6a1208cd882b48fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9740ac3bb3f40fd8c053a261f387e0b",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2d15b0658de4359bef0baddb45ee625",
            "value": 209528
          }
        },
        "b78b56b5b5ad45cf87ccb1281ebfcb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f396e8ee6f42bab3238492d90d191d",
            "placeholder": "​",
            "style": "IPY_MODEL_aa86cd02887b49b98190726edf8fc6de",
            "value": " 210k/210k [00:00&lt;00:00, 8.69MB/s]"
          }
        },
        "c05c5201dca8416696c13c680c30f689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bf56cf6e5ad438aaa46090573092946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654de489fa934209a34f9459a8658ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9740ac3bb3f40fd8c053a261f387e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d15b0658de4359bef0baddb45ee625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0f396e8ee6f42bab3238492d90d191d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa86cd02887b49b98190726edf8fc6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad58c5983fc34f8a9bfa56e4c7f54810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7713f25b6ad4463eb900a3a328cb30b1",
              "IPY_MODEL_24064157582c484c8b519f1aacdb119d",
              "IPY_MODEL_9f7888c9f63e47c680d42b68c2004f4c"
            ],
            "layout": "IPY_MODEL_c77522e65cc44d9e8ebe76f4c179fc8f"
          }
        },
        "7713f25b6ad4463eb900a3a328cb30b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a60e3c028dcd41c89c3af699c5121799",
            "placeholder": "​",
            "style": "IPY_MODEL_6e42f345a9524bb2abf31f0214045325",
            "value": "Downloading (…)in/added_tokens.json: 100%"
          }
        },
        "24064157582c484c8b519f1aacdb119d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d367122172c24793a4932e7b4c646436",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2017c93469eb44fc8dc58865a2857a20",
            "value": 2
          }
        },
        "9f7888c9f63e47c680d42b68c2004f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f02900e577246b5905fd35d67aee351",
            "placeholder": "​",
            "style": "IPY_MODEL_33b0203f951243cb9f69db9aac868fc6",
            "value": " 2.00/2.00 [00:00&lt;00:00, 105B/s]"
          }
        },
        "c77522e65cc44d9e8ebe76f4c179fc8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a60e3c028dcd41c89c3af699c5121799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e42f345a9524bb2abf31f0214045325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d367122172c24793a4932e7b4c646436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2017c93469eb44fc8dc58865a2857a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f02900e577246b5905fd35d67aee351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b0203f951243cb9f69db9aac868fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "020ff3fd6dc14f80b5a91685e58dfd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c71c25dc8f5a4f5891059fded18d5d57",
              "IPY_MODEL_dc7dc76a2d7a4da3ae5044ec28efb117",
              "IPY_MODEL_4ca5335f5b36478591d51b21562058ba"
            ],
            "layout": "IPY_MODEL_3f9c86026a7f4be8a2abc807b3dfea33"
          }
        },
        "c71c25dc8f5a4f5891059fded18d5d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88e1f4cf5a204ddabd6de07d9fd35dbb",
            "placeholder": "​",
            "style": "IPY_MODEL_264316fc87ac4d129bd57b5e703b1f13",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "dc7dc76a2d7a4da3ae5044ec28efb117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_922c075e1e50411dbf8fedbd52719178",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a6e7e09d93b4ffb820ab9f9d30249c4",
            "value": 112
          }
        },
        "4ca5335f5b36478591d51b21562058ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_658e9c3c352c4a53a8a54141e9c8d1f9",
            "placeholder": "​",
            "style": "IPY_MODEL_5fc4755315e34157ae99aa886d016864",
            "value": " 112/112 [00:00&lt;00:00, 6.32kB/s]"
          }
        },
        "3f9c86026a7f4be8a2abc807b3dfea33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e1f4cf5a204ddabd6de07d9fd35dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "264316fc87ac4d129bd57b5e703b1f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "922c075e1e50411dbf8fedbd52719178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6e7e09d93b4ffb820ab9f9d30249c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "658e9c3c352c4a53a8a54141e9c8d1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fc4755315e34157ae99aa886d016864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a1fda23cdd4a3286f4c49dc7ed67a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3757ddfd9e2e4cabbb5e44b01a78e0f3",
              "IPY_MODEL_0854c3fa2f7f48adb0a06d8ef5dfd8c3",
              "IPY_MODEL_994a2e613b624c93950cc6f3ce107030"
            ],
            "layout": "IPY_MODEL_22e46202b3814602a7f2b8ebdf95be4d"
          }
        },
        "3757ddfd9e2e4cabbb5e44b01a78e0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4576c5e76d6c4329b039efa7b7868e5f",
            "placeholder": "​",
            "style": "IPY_MODEL_1fd8895cdae441158843d8eca4dc196d",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "0854c3fa2f7f48adb0a06d8ef5dfd8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01dbd99c5f9c43d985a257e30577a3fd",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e25cc316e02476699932cc3d6e57eab",
            "value": 647
          }
        },
        "994a2e613b624c93950cc6f3ce107030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75301f889b144b65b073bc65b6d12c0c",
            "placeholder": "​",
            "style": "IPY_MODEL_a4cd8641578c448da6f2ff9b83eb8240",
            "value": " 647/647 [00:00&lt;00:00, 27.5kB/s]"
          }
        },
        "22e46202b3814602a7f2b8ebdf95be4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4576c5e76d6c4329b039efa7b7868e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd8895cdae441158843d8eca4dc196d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01dbd99c5f9c43d985a257e30577a3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e25cc316e02476699932cc3d6e57eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75301f889b144b65b073bc65b6d12c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4cd8641578c448da6f2ff9b83eb8240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aebbeeb48dfd42febe0bb02b201ae439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79d8246414bc44ea8e04d9fe147ca739",
              "IPY_MODEL_0dc247b98abd433088f7555e9d8e8fad",
              "IPY_MODEL_8f67861e4e6a4d3d9a9c797466d3231f"
            ],
            "layout": "IPY_MODEL_f9866c5e74734445a84cac0f620f7d3f"
          }
        },
        "79d8246414bc44ea8e04d9fe147ca739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bcd5d19ac3d4ceb8457cfefd8185291",
            "placeholder": "​",
            "style": "IPY_MODEL_ab15aaee9da54877994c9e75d459c56b",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "0dc247b98abd433088f7555e9d8e8fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62b25242680a4b32b097a57ff6984e25",
            "max": 438235074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c923146b9126487e83883307df492ef8",
            "value": 438235074
          }
        },
        "8f67861e4e6a4d3d9a9c797466d3231f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e45d5022204d2ca3a1099e26920fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_936345695c024877909f09797eafc51c",
            "value": " 438M/438M [00:01&lt;00:00, 230MB/s]"
          }
        },
        "f9866c5e74734445a84cac0f620f7d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bcd5d19ac3d4ceb8457cfefd8185291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab15aaee9da54877994c9e75d459c56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62b25242680a4b32b097a57ff6984e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c923146b9126487e83883307df492ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42e45d5022204d2ca3a1099e26920fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936345695c024877909f09797eafc51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}