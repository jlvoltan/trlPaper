{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6jKuooZfNFU"
      },
      "source": [
        "# Classificação faixa TRL - BERT multilingual + Rede Neural [kfold][P3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9-gf3IMD5C"
      },
      "source": [
        "- bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i41YvsyfSUR"
      },
      "source": [
        "## Código Versão 1.0 - 23 OUT 23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLfR22FfgbJ"
      },
      "source": [
        "- Uso dos classificadores: *Rede Neural*\n",
        "- **k-Fold cross-validation: Esse código executou a rodada 3**.\n",
        "- Matriz de confusão;\n",
        "- Semente 42\n",
        "- 50 épocas\n",
        "- BATCH_SIZE = 8\n",
        "- Limite 242 tokens\n",
        "- optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.csv   ou  dataset_pre_processado_1.csv  ou  dataset_pre_processado_stem_2.csv\n",
        "#     CSV1                  CSV2                                   CSV3\n",
        "dataset = \"dataset.csv\""
      ],
      "metadata": {
        "id": "eFArWAgDLymg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lembre-se estamos usando o dataset: \" + dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UByGMOxBLzMp",
        "outputId": "c66719fb-01ef-4a98-9c58-8358cf101d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lembre-se estamos usando o dataset: dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particao=3  # O KFold apresenta 5 partições (rodadas)\n",
        "particao-=1  #Funcionará com o índice de kfold_train e kfold_test"
      ],
      "metadata": {
        "id": "k2TIOYIqQNps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_modelo = 'best_model_TRL_bert_base_neural_' + str(particao+1) + '.bin'\n",
        "melhor_modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFCPPlujqL5L",
        "outputId": "7d633a53-549f-466a-e763-06d3946d7e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_model_TRL_bert_base_neural_3.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 242"
      ],
      "metadata": {
        "id": "mzoxzAczL5ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jlIjUzOgRY"
      },
      "source": [
        "- 63,7% treinamento - 16% validação...............20% teste\n",
        "- EPOCHS = 50\n",
        "- lr=2e-5\n",
        "- BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Msvyn0MfsOS"
      },
      "source": [
        "## Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjC81VL_gQ-5"
      },
      "source": [
        "### Bibliotecas e ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZxPMZOfICS",
        "outputId": "e9571661-3be8-4a40-dce6-b3b473c6ee84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RDBcpVf0TS",
        "outputId": "d0ca0423-3181-406a-ff73-fb70878cd5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmcqgWcf0WZ",
        "outputId": "bd069197-a1f4-4d65-f68e-3d6681b17a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 24 01:42:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoneZ3CngEDZ",
        "outputId": "483b07c2-b6a8-4c7c-c548-8593502544b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWHFe7ef0Zp",
        "outputId": "1ae317eb-1f89-4ea4-8c12-f88132722237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy       : 1.23.5\n",
            "pandas      : 1.5.3\n",
            "torch       : 2.1.0+cu118\n",
            "transformers: 4.34.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Particoes KFOLD"
      ],
      "metadata": {
        "id": "oENoyHsUPjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para mais detalhes, consulte o código *1-kfold.ipynb* em que as partições foram sorteadas. As células a seguir recriam o resultado obtido."
      ],
      "metadata": {
        "id": "qL3FKCGlPtBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array([  0,   1,   2,   3,   5,   7,   9,  10,  11,  12,  13,  14,  15,\n",
        "         16,  17,  19,  20,  21,  22,  23,  25,  26,  27,  28,  30,  32,\n",
        "         33,  34,  35,  36,  37,  39,  40,  44,  45,  46,  47,  48,  49,\n",
        "         50,  52,  53,  54,  55,  56,  57,  59,  60,  61,  63,  64,  66,\n",
        "         68,  69,  70,  71,  72,  75,  76,  77,  78,  79,  80,  81,  82,\n",
        "         83,  84,  85,  87,  91,  92,  93,  94,  96,  97,  98,  99, 100,\n",
        "        102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116,\n",
        "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130,\n",
        "        131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
        "        146, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163,\n",
        "        164, 165, 166, 167])\n",
        "\n",
        "array2 = np.array([  0,   1,   3,   4,   5,   6,   7,   8,  10,  13,  14,  15,  16,\n",
        "         17,  18,  19,  20,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
        "         34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  47,  49,  51,\n",
        "         52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  80,  83,\n",
        "         84,  86,  88,  89,  90,  92,  93,  94,  95,  96,  97,  98,  99,\n",
        "        100, 101, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115,\n",
        "        116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
        "        129, 130, 132, 133, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
        "        147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162,\n",
        "        163, 165, 166, 167])\n",
        "array3 = np.array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
        "         17,  18,  20,  21,  22,  23,  24,  25,  28,  29,  30,  31,  32,\n",
        "         33,  35,  36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  47,\n",
        "         48,  50,  51,  52,  54,  55,  56,  57,  58,  59,  62,  63,  65,\n",
        "         67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
        "         82,  84,  85,  86,  87,  88,  89,  90,  91,  93,  95,  96,  97,\n",
        "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111,\n",
        "        112, 113, 114, 118, 120, 121, 122, 123, 124, 126, 128, 129, 131,\n",
        "        132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 146, 147,\n",
        "        148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 161, 162,\n",
        "        163, 164, 165, 166])\n",
        "array4 = np.array([  0,   2,   3,   4,   6,   8,   9,  10,  11,  12,  15,  16,  18,\n",
        "         19,  20,  21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,\n",
        "         34,  35,  37,  38,  39,  40,  41,  42,  43,  45,  46,  47,  48,\n",
        "         49,  50,  51,  53,  56,  57,  58,  60,  61,  62,  63,  64,  65,\n",
        "         66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
        "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
        "         94,  95,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
        "        112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129,\n",
        "        130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145,\n",
        "        146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159,\n",
        "        162, 163, 164, 166, 167])\n",
        "array5 = np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
        "         14,  15,  16,  17,  18,  19,  21,  23,  24,  26,  27,  28,  29,\n",
        "         30,  31,  32,  33,  34,  35,  36,  38,  39,  40,  41,  42,  43,\n",
        "         44,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,\n",
        "         60,  61,  62,  64,  65,  66,  67,  68,  69,  70,  72,  73,  74,\n",
        "         77,  78,  79,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
        "         92,  94,  95,  96,  97,  99, 101, 102, 103, 105, 106, 107, 108,\n",
        "        110, 111, 113, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127,\n",
        "        128, 130, 131, 132, 133, 134, 136, 137, 138, 140, 141, 143, 144,\n",
        "        145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160,\n",
        "        161, 162, 164, 165, 167])\n",
        "# Criar a lista composta\n",
        "kfold_train = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "Cn4vhJ9LPncE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar as cinco arrays numpy\n",
        "array1 = np.array([  4,   6,   8,  18,  24,  29,  31,  38,  41,  42,  43,  51,  58, 62,  65,  67,  73,  74,  86,  88,  89,  90,  95, 101, 107, 111, 128, 133, 144, 147, 149, 152, 156, 162])\n",
        "array2 = np.array([  2,   9,  11,  12,  21,  28,  32,  33,  35,  39,  46,  48,  50, 56,  72,  78,  79,  81,  82,  85,  87,  91, 103, 106, 108, 131, 134, 140, 141, 146, 148, 158, 159, 164])\n",
        "array3 = np.array([  0,   3,  15,  16,  19,  26,  27,  34,  40,  49,  53,  60,  61, 64,  66,  68,  69,  83,  92,  94, 110, 115, 116, 117, 119, 125, 127, 130, 137, 143, 145, 154, 157, 167])\n",
        "array4 = np.array([  1,   5,   7,  13,  14,  17,  23,  30,  36,  44,  52,  54,  55, 59,  70,  77,  96,  97,  99, 102, 105, 113, 118, 120, 122, 126, 132, 136, 138, 151, 160, 161, 165])\n",
        "array5 = np.array([ 10,  20,  22,  25,  37,  45,  47,  57,  63,  71,  75,  76,  80,  84,  93,  98, 100, 104, 109, 112, 114, 121, 123, 124, 129, 135, 139, 142, 150, 153, 155, 163, 166])\n",
        "\n",
        "\n",
        "# Criar a lista composta\n",
        "kfold_test = [array1, array2, array3, array4, array5]"
      ],
      "metadata": {
        "id": "c3Ia2J4DPpO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4aPPergNnL"
      },
      "source": [
        "### BERT multilingual base model (cased)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXl6AUm0K3yE"
      },
      "source": [
        "- https://huggingface.co/bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RQrbYpK5vC"
      },
      "source": [
        "```\n",
        "@article{DBLP:journals/corr/abs-1810-04805,\n",
        "  author    = {Jacob Devlin and\n",
        "               Ming{-}Wei Chang and\n",
        "               Kenton Lee and\n",
        "               Kristina Toutanova},\n",
        "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
        "               Understanding},\n",
        "  journal   = {CoRR},\n",
        "  volume    = {abs/1810.04805},\n",
        "  year      = {2018},\n",
        "  url       = {http://arxiv.org/abs/1810.04805},\n",
        "  archivePrefix = {arXiv},\n",
        "  eprint    = {1810.04805},\n",
        "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
        "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
        "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "f83753f5d82a42248742c55309403332",
            "5bf0a53d7dd34bebaf5cdcceab6de50d",
            "c3041f5a03a048a2b512ff6dceda29e0",
            "7f4561dd0b624c4989b16611ea8bd9c6",
            "abb7d6ac769f456ca7899126d03f027a",
            "8e3c6e540a2040709e688579f2def995",
            "aedf1e09ec154720b428e815fc2587b8",
            "495f2fa28e38400eb7e230f79dcf7f83",
            "9dadc82a9c56456b81d9db2ba617c39c",
            "f7bab96efb9b4ca9af5a36b4f288e427",
            "f4f150cbb40342f3b1a5cf21523bd736",
            "c8930365dc3e4a6d9cc5359950e9891a",
            "ca50c392bd60442d86301c3cb5f4cfde",
            "375888f349fd4e70a33a80a56e1e8274",
            "c7ae66e8475d47c1a910fc76194c64ed",
            "67ff8aa20acd48e48271dde0bed0db35",
            "482c72853132498e985a3301b695b832",
            "0a179a4236ae44b2805d973c492e3b76",
            "c8b4a0a04565434f9d7b22c84e3da2b8",
            "78f7bd99b4ec43dc995b026c84c61ec0",
            "f8a1ae23280f430593b906d72030e499",
            "ebd4889c5a384ea29daf28b75282486a",
            "1c9bbd2b9aa14d44b5314f0247103336",
            "0f678cb0dcb1410398e23f1497569c7f",
            "cf57b20ee3514de9b8045cd430740584",
            "90cbd1985bc94d6a89bfdd8ef6dc270a",
            "227bb8755b974ec88b2320d05a7acbeb",
            "13ea776300a34bff969d1fa0082f2cbb",
            "1b0dd8f1ce324a238c964e2c2245e7b7",
            "447352fbbbca4791999b9f40f9cc942c",
            "9edbfe5692844a54a3510093162fd4d2",
            "6814b2338754466abfe77a2a33a79108",
            "f3e1185465b8477791193c384c24fdfe",
            "2d69d58d184d4c71adfef827739a6f57",
            "49b0e9a4266a405da68baf91b6880082",
            "70b9d871a1434ef0a7663dddf3816e0a",
            "8b072b3260114c75b1301e8c3c160ac9",
            "f4e3fa3b727841759bf3affb4126288b",
            "52b3abaf3a8242ccb0b9ceb4c4f2b36e",
            "3d61f4f4843c4b1d854ffb53206e6dda",
            "ae61b584431449eb98c4a3ca50e659e9",
            "de1095b98c384ada9c03a16df492f883",
            "e5639c33fbba4ab581d24476b8fd1705",
            "70ec2fce9a094d08bff539d61ebdfd37"
          ]
        },
        "id": "WPj7c-IBgWRx",
        "outputId": "db5f489c-27b9-48e0-ff43-d9f6e0f0a095"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f83753f5d82a42248742c55309403332"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8930365dc3e4a6d9cc5359950e9891a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c9bbd2b9aa14d44b5314f0247103336"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d69d58d184d4c71adfef827739a6f57"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d981774df17742238d487b6f776051c7",
            "881dc4b0f2bc4e4ca92695fe31cac89d",
            "54cbccde31354dedaee337c8b0d5749c",
            "39f23a3be52f4f838e4b264dec425aa3",
            "f01f7411bc854443a5ef9b1a79fb826c",
            "219f0c07be944e2fb4eccea0fc45a897",
            "93dbc0e2ad804e849a9542aa7b3403ac",
            "73ec5c3f7d254b63a2f07505aa365a81",
            "41eab1cefebe4d05879e09846a0d5090",
            "18a65a29da114be2a68a05b9efc5578c",
            "6a0215a6d51e43aeaa2e1c3eb3fe4954"
          ]
        },
        "id": "qSErznNMh4P5",
        "outputId": "2e7cc623-5d59-4bf4-f3e5-10fdf970feda"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d981774df17742238d487b6f776051c7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6s_rPsFgWUr"
      },
      "outputs": [],
      "source": [
        "frase = 'A avaliação de prontidão tecnológica em tecnologias de interesse militar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78tJbGMogWaZ",
        "outputId": "3a4f1a59-5389-480c-eeff-861582391246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  frase,\n",
        "  max_length=20,   #Perceba que irei cortar um token da minha frase anterior\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fSHD8KgqDb"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bYjQrfrglJS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvfsVlnFglPp"
      },
      "outputs": [],
      "source": [
        "novo_df = df[[\"resumo\", \"rotulo\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nth2Ui-qg6Ix"
      },
      "outputs": [],
      "source": [
        "def adapto_faixa(faixa):\n",
        "    faixa -=1\n",
        "    return faixa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKj3lo8Qg9Vj",
        "outputId": "91f7e23e-2254-482e-920b-919b0fca7391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3dc243303e67>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)\n"
          ]
        }
      ],
      "source": [
        "novo_df ['rotulo'] = novo_df.rotulo.apply(adapto_faixa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_cANKWhOhCix",
        "outputId": "0494c782-23c7-4aa3-fcf4-e01ff0a5258d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                resumo  rotulo\n",
              "163  Rio de Janeiro (RJ) – O Centro de Avaliações d...       2\n",
              "164  Este trabalho apresenta um sistema para contro...       2\n",
              "165  No contexto das comunicações táticas baseadas ...       2\n",
              "166  O valor da velocidade de alvos móveis em image...       0\n",
              "167  Neste artigo é apresentada a análise da seção ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b9f254c-524f-4c0d-9a45-7767f7cebb7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resumo</th>\n",
              "      <th>rotulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>Rio de Janeiro (RJ) – O Centro de Avaliações d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Este trabalho apresenta um sistema para contro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>No contexto das comunicações táticas baseadas ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>O valor da velocidade de alvos móveis em image...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>Neste artigo é apresentada a análise da seção ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b9f254c-524f-4c0d-9a45-7767f7cebb7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8b9f254c-524f-4c0d-9a45-7767f7cebb7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8b9f254c-524f-4c0d-9a45-7767f7cebb7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-429df12b-b518-4331-a6ff-2da7c16deb9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-429df12b-b518-4331-a6ff-2da7c16deb9e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-429df12b-b518-4331-a6ff-2da7c16deb9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "novo_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZK6EQ4xhFHI"
      },
      "outputs": [],
      "source": [
        "class_names = ['Faixa 1', 'Faixa 2', 'Faixa 3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmol6gshNCR"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFoXmzH5hFOo"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      #padding='longest',\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K-OuLWzhYhB"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.resumo.to_numpy(),\n",
        "    targets=df.rotulo.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBrznGAWiJWg"
      },
      "outputs": [],
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ-yCbjniOLI",
        "outputId": "a9e13855-0127-4917-c3b4-55e0c8c9d2df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "bert_model.config.hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxhW_89kRiv"
      },
      "source": [
        "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiZnSuuTiTOZ"
      },
      "outputs": [],
      "source": [
        "class TRLClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(TRLClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    #The last_hidden_state is a sequence of hidden states of the last layer of the model\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kX7ClUGiiCQ"
      },
      "outputs": [],
      "source": [
        "model = TRLClassifier(len(class_names)) #Pois tenho 3 classes\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXw5SIa0hkah"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTSemYwhnlI"
      },
      "source": [
        "### Separação e preparação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lembrar que estamos utilizando o Kfold"
      ],
      "metadata": {
        "id": "z09fs6pHk5FG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTLzT3ttq-0t"
      },
      "source": [
        "    - 63,7% treinamento - 16% validação                20% teste\n",
        "\n",
        "      ------------ 80%----------------------------------20%--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando o índice dos conjuntos\n",
        "index_df_train = kfold_train[particao]\n",
        "index_df_test = kfold_test[particao]"
      ],
      "metadata": {
        "id": "FeqFToMFnaMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = novo_df.iloc[index_df_train], novo_df.iloc[index_df_test]"
      ],
      "metadata": {
        "id": "EpR4mtHLoDzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Bhg2qAhSlg"
      },
      "outputs": [],
      "source": [
        "#Separando o treinamento em treino e validação\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify= df_train['rotulo'], random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FAkW0qhW2J",
        "outputId": "74309ed1-9710-42dc-a28f-b43729f54008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((107, 2), (27, 2), (34, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfxinAAqhW5A",
        "outputId": "6c639110-1c26-46b1-dc93-2e45068bd19d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fsBv27hW8L",
        "outputId": "f1d70920-578a-4432-9220-f798b99d5371"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjbQEYoXhvVA",
        "outputId": "3d0defa8-b208-4777-a7af-4bd32a53dccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7qyCztOhvX4",
        "outputId": "a771b244-542b-4d6c-e6f6-76adb0be2b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP6kiy4whvaa",
        "outputId": "47386305-6423-4566-caa6-43ec1d7caed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 242])\n",
            "torch.Size([8, 242])\n"
          ]
        }
      ],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzMSQeLlRHn"
      },
      "source": [
        "### Treinamento mesmo..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oRhXpG_iBWB",
        "outputId": "cb32080b-f205-4207-a439-e89fa8ea0d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp8dJvCviFTI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tKAqpPliFWJ"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZisESWlkqH",
        "outputId": "43cd75ff-6003-4ee2-d7a1-52116d468bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.009652099439076 accuracy 0.49532710280373826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8848435059189796 accuracy 0.5555555555555556\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9273998630898339 accuracy 0.5887850467289719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.770401231944561 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7979738925184522 accuracy 0.6728971962616822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7078311890363693 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7818178683519363 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6770956963300705 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7627720694456782 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6635023728013039 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7279863570417676 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7275178208947182 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7444220940981593 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7687229365110397 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7405729187386376 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6659996584057808 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7137805585350309 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7655573561787605 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7601095725383077 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7954263985157013 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6750160157680511 accuracy 0.7383177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7494383826851845 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6999363877943584 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7690515741705894 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6604456944125039 accuracy 0.719626168224299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8218632563948631 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6664105100291116 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.8763177245855331 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7171642003314835 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6525295823812485 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6927067083971841 accuracy 0.7102803738317757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7482359632849693 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6087364256381989 accuracy 0.7476635514018691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6579112000763416 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5911310953753335 accuracy 0.7289719626168224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.80576241761446 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4517392803515707 accuracy 0.8037383177570093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7596554830670357 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3067230773823602 accuracy 0.8785046728971962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7621845323592424 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.24189210310578346 accuracy 0.8878504672897196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.9513270880561322 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1709144386196775 accuracy 0.9532710280373831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1801258069463074 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.10444964209039297 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.625992864370346 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.1878818854623075 accuracy 0.9345794392523363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.3157613304210827 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.124966872573298 accuracy 0.9626168224299064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.2012983716558665 accuracy 0.7407407407407407\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.06041976264012711 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6588614719221368 accuracy 0.5925925925925926\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.20003965816327504 accuracy 0.9532710280373831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.3991384899418335 accuracy 0.7037037037037037\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.08568438225691873 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5995043294969946 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0940027802966402 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.446630758291576 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0835318570524188 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4502439931238769 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.05030392161903104 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.860054584176396 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.059126653093179424 accuracy 0.9719626168224298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.4605887006473495 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.030380153878858045 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.5810518204962136 accuracy 0.6666666666666666\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.02332359761931002 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8233773999672849 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.031292606386289536 accuracy 0.9813084112149532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.6024547954439186 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.009949587085949523 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9298322473332519 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.006876311198409114 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.9089192358078435 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0029805685792650494 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7968364193220623 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.004246560549030879 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.7765541924745776 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0021510513075294773 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.820853160970728 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0020216164994053543 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8342148848023498 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0019745949705663535 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.830297569380491 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0016909989644773304 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.830365052628622 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0017120092733031405 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8222872034893953 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0016692009355340684 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8238714758990682 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.001905746225799833 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8225679924871656 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.001690836253276627 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8218500549628516 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.001462781781031351 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8210298059275374 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0014018460517815714 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8205293555511162 accuracy 0.6296296296296295\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.0014859165572228708 accuracy 0.9999999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.8203863541348255 accuracy 0.6296296296296295\n",
            "\n",
            "CPU times: user 2min 58s, sys: 1min 25s, total: 4min 23s\n",
            "Wall time: 5min 13s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "#   if val_acc > best_accuracy:\n",
        "#     torch.save(model.state_dict(), melhor_modelo)\n",
        "#     best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVjGnJKDmZVJ"
      },
      "source": [
        "- Gráfico de desempenho no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQOy_NBBlks7"
      },
      "outputs": [],
      "source": [
        "A= history['train_acc']\n",
        "A2 = [tensor.item() for tensor in A]\n",
        "B= history['val_acc']\n",
        "B2 = [tensor.item() for tensor in B]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "hHRH2aNQlkvy",
        "outputId": "ef591511-3b90-4a82-977b-e79b12f751e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 1017,
              "height": 717
            }
          }
        }
      ],
      "source": [
        "plt.plot(A2, label='train accuracy')\n",
        "plt.plot(B2, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syd9c9eGmecP"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jFRntT6mgoW",
        "outputId": "ee0fffe6-2f5c-415c-f949-e6c1b78e2b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6470588235294118"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBG2MIlgmkHv"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXTHRhD5mqnn",
        "outputId": "50a13ded-6833-4b05-de96-0426ecb5c730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTdojX6Jmqqm",
        "outputId": "5691fcea-069f-4f01-f4b2-b670eda0ae07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Faixa 1       0.65      0.79      0.71        19\n",
            "     Faixa 2       0.20      0.12      0.15         8\n",
            "     Faixa 3       1.00      0.86      0.92         7\n",
            "\n",
            "    accuracy                           0.65        34\n",
            "   macro avg       0.62      0.59      0.60        34\n",
            "weighted avg       0.62      0.65      0.63        34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "HQ54xluu8RL3",
        "outputId": "f88136b0-6504-4b96-ac01-e9c9f0af887c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 981,
              "height": 723
            }
          }
        }
      ],
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('Faixa TRL verdadeira')\n",
        "  plt.xlabel('Faixa TRL predita');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZTajeJuiP_z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f83753f5d82a42248742c55309403332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bf0a53d7dd34bebaf5cdcceab6de50d",
              "IPY_MODEL_c3041f5a03a048a2b512ff6dceda29e0",
              "IPY_MODEL_7f4561dd0b624c4989b16611ea8bd9c6"
            ],
            "layout": "IPY_MODEL_abb7d6ac769f456ca7899126d03f027a"
          }
        },
        "5bf0a53d7dd34bebaf5cdcceab6de50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e3c6e540a2040709e688579f2def995",
            "placeholder": "​",
            "style": "IPY_MODEL_aedf1e09ec154720b428e815fc2587b8",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "c3041f5a03a048a2b512ff6dceda29e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_495f2fa28e38400eb7e230f79dcf7f83",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dadc82a9c56456b81d9db2ba617c39c",
            "value": 29
          }
        },
        "7f4561dd0b624c4989b16611ea8bd9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7bab96efb9b4ca9af5a36b4f288e427",
            "placeholder": "​",
            "style": "IPY_MODEL_f4f150cbb40342f3b1a5cf21523bd736",
            "value": " 29.0/29.0 [00:00&lt;00:00, 566B/s]"
          }
        },
        "abb7d6ac769f456ca7899126d03f027a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e3c6e540a2040709e688579f2def995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aedf1e09ec154720b428e815fc2587b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "495f2fa28e38400eb7e230f79dcf7f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dadc82a9c56456b81d9db2ba617c39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7bab96efb9b4ca9af5a36b4f288e427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f150cbb40342f3b1a5cf21523bd736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8930365dc3e4a6d9cc5359950e9891a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca50c392bd60442d86301c3cb5f4cfde",
              "IPY_MODEL_375888f349fd4e70a33a80a56e1e8274",
              "IPY_MODEL_c7ae66e8475d47c1a910fc76194c64ed"
            ],
            "layout": "IPY_MODEL_67ff8aa20acd48e48271dde0bed0db35"
          }
        },
        "ca50c392bd60442d86301c3cb5f4cfde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_482c72853132498e985a3301b695b832",
            "placeholder": "​",
            "style": "IPY_MODEL_0a179a4236ae44b2805d973c492e3b76",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "375888f349fd4e70a33a80a56e1e8274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8b4a0a04565434f9d7b22c84e3da2b8",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78f7bd99b4ec43dc995b026c84c61ec0",
            "value": 995526
          }
        },
        "c7ae66e8475d47c1a910fc76194c64ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a1ae23280f430593b906d72030e499",
            "placeholder": "​",
            "style": "IPY_MODEL_ebd4889c5a384ea29daf28b75282486a",
            "value": " 996k/996k [00:00&lt;00:00, 7.27MB/s]"
          }
        },
        "67ff8aa20acd48e48271dde0bed0db35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482c72853132498e985a3301b695b832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a179a4236ae44b2805d973c492e3b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8b4a0a04565434f9d7b22c84e3da2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f7bd99b4ec43dc995b026c84c61ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8a1ae23280f430593b906d72030e499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd4889c5a384ea29daf28b75282486a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c9bbd2b9aa14d44b5314f0247103336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f678cb0dcb1410398e23f1497569c7f",
              "IPY_MODEL_cf57b20ee3514de9b8045cd430740584",
              "IPY_MODEL_90cbd1985bc94d6a89bfdd8ef6dc270a"
            ],
            "layout": "IPY_MODEL_227bb8755b974ec88b2320d05a7acbeb"
          }
        },
        "0f678cb0dcb1410398e23f1497569c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13ea776300a34bff969d1fa0082f2cbb",
            "placeholder": "​",
            "style": "IPY_MODEL_1b0dd8f1ce324a238c964e2c2245e7b7",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "cf57b20ee3514de9b8045cd430740584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_447352fbbbca4791999b9f40f9cc942c",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9edbfe5692844a54a3510093162fd4d2",
            "value": 1961828
          }
        },
        "90cbd1985bc94d6a89bfdd8ef6dc270a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6814b2338754466abfe77a2a33a79108",
            "placeholder": "​",
            "style": "IPY_MODEL_f3e1185465b8477791193c384c24fdfe",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 24.4MB/s]"
          }
        },
        "227bb8755b974ec88b2320d05a7acbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ea776300a34bff969d1fa0082f2cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b0dd8f1ce324a238c964e2c2245e7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "447352fbbbca4791999b9f40f9cc942c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9edbfe5692844a54a3510093162fd4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6814b2338754466abfe77a2a33a79108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3e1185465b8477791193c384c24fdfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d69d58d184d4c71adfef827739a6f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49b0e9a4266a405da68baf91b6880082",
              "IPY_MODEL_70b9d871a1434ef0a7663dddf3816e0a",
              "IPY_MODEL_8b072b3260114c75b1301e8c3c160ac9"
            ],
            "layout": "IPY_MODEL_f4e3fa3b727841759bf3affb4126288b"
          }
        },
        "49b0e9a4266a405da68baf91b6880082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b3abaf3a8242ccb0b9ceb4c4f2b36e",
            "placeholder": "​",
            "style": "IPY_MODEL_3d61f4f4843c4b1d854ffb53206e6dda",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "70b9d871a1434ef0a7663dddf3816e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae61b584431449eb98c4a3ca50e659e9",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de1095b98c384ada9c03a16df492f883",
            "value": 625
          }
        },
        "8b072b3260114c75b1301e8c3c160ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5639c33fbba4ab581d24476b8fd1705",
            "placeholder": "​",
            "style": "IPY_MODEL_70ec2fce9a094d08bff539d61ebdfd37",
            "value": " 625/625 [00:00&lt;00:00, 46.0kB/s]"
          }
        },
        "f4e3fa3b727841759bf3affb4126288b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b3abaf3a8242ccb0b9ceb4c4f2b36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d61f4f4843c4b1d854ffb53206e6dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae61b584431449eb98c4a3ca50e659e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1095b98c384ada9c03a16df492f883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5639c33fbba4ab581d24476b8fd1705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70ec2fce9a094d08bff539d61ebdfd37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d981774df17742238d487b6f776051c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_881dc4b0f2bc4e4ca92695fe31cac89d",
              "IPY_MODEL_54cbccde31354dedaee337c8b0d5749c",
              "IPY_MODEL_39f23a3be52f4f838e4b264dec425aa3"
            ],
            "layout": "IPY_MODEL_f01f7411bc854443a5ef9b1a79fb826c"
          }
        },
        "881dc4b0f2bc4e4ca92695fe31cac89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219f0c07be944e2fb4eccea0fc45a897",
            "placeholder": "​",
            "style": "IPY_MODEL_93dbc0e2ad804e849a9542aa7b3403ac",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "54cbccde31354dedaee337c8b0d5749c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73ec5c3f7d254b63a2f07505aa365a81",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41eab1cefebe4d05879e09846a0d5090",
            "value": 714290682
          }
        },
        "39f23a3be52f4f838e4b264dec425aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18a65a29da114be2a68a05b9efc5578c",
            "placeholder": "​",
            "style": "IPY_MODEL_6a0215a6d51e43aeaa2e1c3eb3fe4954",
            "value": " 714M/714M [00:07&lt;00:00, 86.8MB/s]"
          }
        },
        "f01f7411bc854443a5ef9b1a79fb826c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219f0c07be944e2fb4eccea0fc45a897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93dbc0e2ad804e849a9542aa7b3403ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73ec5c3f7d254b63a2f07505aa365a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41eab1cefebe4d05879e09846a0d5090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18a65a29da114be2a68a05b9efc5578c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a0215a6d51e43aeaa2e1c3eb3fe4954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}