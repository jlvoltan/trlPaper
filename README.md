# Technology Readiness Level - TRL 

üìå  Trata-se de reposit√≥rio para a disserta√ß√£o de mestrado voltada para o problema de classifica√ß√£o de documentos utilizando a escala TRL.

üìå  Aqui encontramos o [_corpus/dataset_](https://github.com/jlvoltan/trl/tree/main/dataset)  constru√≠do e [modelos treinados](https://github.com/jlvoltan/trl/tree/main/modelos) para essa tarefa.

‚úèÔ∏è  Maiores explica√ß√µes sobre a metodologia utilizada pode ser encontrada nos artigos e disserta√ß√£o.


### üìù Resumo do trabalho üìù

A escala TRL surgiu na d√©cada de 70, com o prop√≥sito de mensurar a maturidade tecnol√≥gica de um produto ou tecnologia. A partir dos anos 2000, ganhou destaque em diversos √≥rg√£os e empresas ao redor do mundo, tendo emprego n√£o s√≥ no acompanhamento de projetos, como tamb√©m na gest√£o e prospec√ß√£o tecnol√≥gica. Apesar desse aumento de import√¢ncia, a abordagem predominante para avaliar o n√≠vel TRL de uma tecnologia ou produto, _i.e._, a Avalia√ß√£o de Prontid√£o Tecnol√≥gica (_Technology Readiness Assessment_ - TRA), √© baseada na avalia√ß√£o de especialistas. Tal abordagem tem como desvantagens o elevado custo, demora, al√©m de um poss√≠vel vi√©s. Diante desse cen√°rio, tem-se o problema, de como seria poss√≠vel realizar uma TRA escal√°vel, com um menor custo e maior padroniza√ß√£o de crit√©rios. As propostas de TRA automatizadas s√£o poucas e apresentam espa√ßo para aprimoramento. O estado da arte ainda √© baseado na combina√ß√£o de t√©cnicas de representa√ß√£o vetorial esparsa e algoritmos de classifica√ß√£o. Essas t√©cnicas de representa√ß√£o, derivadas do _Bag-of-Words_, n√£o utilizam o contexto em que as palavras ocorrem (_e.g._ a palavra manga, parte da vestimenta, possui a mesma representa√ß√£o vetorial que a fruta manga), al√©m de gerarem vetores de alta dimensionalidade com muitos valores nulos. Essas limita√ß√µes podem impactar negativamente no desempenho dos algoritmos de classifica√ß√£o. Diante desta perspectiva, inspirado por resultados bem sucedidos em diversas aplica√ß√µes de classifica√ß√£o textual em outras √°reas, o presente trabalho levantou como hip√≥tese que o emprego de t√©cnicas de representa√ß√£o vetorial densa contextualizada (_i.e._ que considerem o contexto onde as palavras ocorrem) pode trazer melhora no desempenho de algoritmos de classifica√ß√£o tamb√©m no escopo da TRA. Para verificar essa hip√≥tese, foi constru√≠do um corpus voltado para o dom√≠nio da Defesa, reunindo artigos cient√≠ficos e not√≠cias escritos em l√≠ngua portuguesa (PT-BR). Tamb√©m foi proposta uma metodologia para aplica√ß√£o da minera√ß√£o de texto na TRA. Atrav√©s dela, foram avaliadas as combi na√ß√µes de cinco t√©cnicas de representa√ß√£o vetorial (Count Vectorizer, TF-IDF, BERT, BERTimbau e GPorTuguese-2 - varia√ß√£o do GPT-2) e sete algoritmos de aprendizado de m√°quina voltados para a tarefa de classifica√ß√£o. Ao final, os melhores resultados foram obtidos pelo modelo de linguagem BERTimbau combinado com Redes Neurais Artificias, chegando-se a uma acur√°cia de 72%, superando o estado da arte. Os resultados mostraram que as representa√ß√µes densas contextualizadas contribu√≠ram para uma pequena melhora de desempenho na maioria dos algoritmos avaliados.

### üí¨ Breve explica√ß√£o üí¨

- Neste trabalho, constru√≠mos um [_corpus_](https://github.com/jlvoltan/trl/tree/main/dataset) utilizando not√≠cias e artigos cient√≠ficos. Eles se encontram na pasta [_dataset_]((https://github.com/jlvoltan/trl/tree/main/dataset));

- Na pasta [question√°rio](https://github.com/jlvoltan/trl/tree/main/questionario) h√° um arquivo que sintetiza esse _corpus_, na forma de planilha.

- Na pasta [_manipula-dataset_](https://github.com/jlvoltan/trl/tree/main/manipula-dataset), existem alguns cadernos relacionados com a an√°lise do _corpus_, pr√©-processamento e divis√£o dos _folders_.

- Por fim, na pasta [_modelos_](https://github.com/jlvoltan/trl/tree/main/modelos), s√£o apresentados os cadernos dos experimentos, em que se obteve a representa√ß√£o vetorial, atrav√©s de t√©cnicas baseadas no BoW ou atrav√©s de Modelos de Linguagem, e posteriormente se treinou e testou modelos de classifica√ß√£o. 
